{"entry_id": "http://arxiv.org/abs/2303.07071v1", "published": "20230313124652", "title": "Correlates of Programmer Efficacy and Their Link to Experience: A Combined EEG and Eye-Tracking Study", "authors": ["Norman Peitek", "Annabelle Bergum", "Maurice Rekrut", "Jonas Mucke", "Matthias Nadig", "Chris Parnin", "Janet Siegmund", "Sven Apel"], "primary_category": "cs.SE", "categories": ["cs.SE"], "text": "\n\nCorrelates of Programmer Efficacy and Their Link to Experience]Correlates of Programmer Efficacy and Their Link to Experience: A Combined EEG and Eye-Tracking Study\n\n\n\n\n\n  Saarland University,\nSaarland Informatics Campus\n  Saarbr\u00fccken\n  Germany \n\n\n\n\n  Saarland University,\nSaarland Informatics Campus,\nGraduate School of Computer Science\n  Saarbr\u00fccken\n  Germany\n\n\n\n\n  German Research Center for Artificial Intelligence, Saarland Informatics Campus, Saarbr\u00fccken, Germany\n  \n  \n\n\n\n\n  Chemnitz University of Technology\n  Chemnitz \n  Germany\n\n\n\n\n  German Research Center for Artificial Intelligence, Saarland Informatics Campus, Saarbr\u00fccken, Germany\n  \n  \n\n\n\n\n  NC State University\n  Raleigh \n  North Carolina \n  USA\n\n\n\n\n  Chemnitz University of Technology\n  Chemnitz \n  Germany\n\n\n\n\n  Saarland University,\nSaarland Informatics Campus\n  Saarbr\u00fccken\n  Germany\n\n\n\nBackground: Despite similar education and background, programmers can exhibit vast differences in efficacy. While research has identified some potential factors, such as programming experience and domain knowledge, the effect of these factors on programmers' efficacy is not well understood.\n\nAims: We aim at unraveling the relationship between efficacy (speed and correctness) and measures of programming experience. We further investigate the correlates of programmer efficacy in terms of reading behavior and cognitive load. \n\nMethod: For this purpose, we conducted a controlled experiment with 37\u00a0participants using electroencephalography (EEG) and eye tracking. We asked participants to comprehend up to 32\u00a0Java source-code snippets and observed their eye gaze and neural correlates of cognitive load. We analyzed the correlation of participants' efficacy with popular programming experience measures.\n\nResults: We found that programmers with high efficacy read source code more targeted and with lower cognitive load. Commonly used experience levels do not predict programmer efficacy well, but self-estimation and indicators of learning eagerness are fairly accurate.\n\nImplications: The identified correlates of programmer efficacy can be used for future research and practice (e.g., hiring). Future research should also consider efficacy as a group sampling method, rather than using simple experience measures.\n\n\n\n<ccs2012>\n   <concept>\n       <concept_id>10003120.10003121.10011748</concept_id>\n       <concept_desc>Human-centered computing\u00a0Empirical studies in HCI</concept_desc>\n       <concept_significance>300</concept_significance>\n       </concept>\n   <concept>\n       <concept_id>10003120.10003121.10003122</concept_id>\n       <concept_desc>Human-centered computing\u00a0HCI design and evaluation methods</concept_desc>\n       <concept_significance>300</concept_significance>\n       </concept>\n </ccs2012>\n\n\n[300]Human-centered computing\u00a0Empirical studies in HCI\n[300]Human-centered computing\u00a0HCI design and evaluation methods\n\n\n\n[\n    Sven Apel\n    March 30, 2023\n==================\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nProficient programmers are essential for providing the critical infrastructure and functioning applications for our modern society\u00a0<cit.>. Although the learning strategies, education, and pathways to becoming a programmer may differ, the general expectation is that, with more time and experience, a programmer should generally become more proficient. For example, many research studies of programmers use years of experience\u00a0<cit.>, education level\u00a0<cit.>, or employment status\u00a0<cit.> as foundational measures for proficiency. While all these choices are sensible, they all implicitly encode the expectation that higher proficiency should correlate with more experience.\n\nHowever, in practice, reported observations violate this expectation. Hiring managers and technical founders\u00a0<cit.> report that they routinely encounter \u201cengineers with years of experience who couldn't competently program\u201d\u00a0<cit.>, who \u201cstruggle with tiny problems\u201d\u00a0<cit.>, and \u201cSenior Engineers who can't write basic code\u201d\u00a0<cit.>. The original creator of the infamous FizzBuzz interview question\u00a0<cit.> only did so after seeing that the \u201cmajority of comp sci graduates... and self-proclaimed senior programmers\u201d had difficulty solving simple problems in a timely manner. Research has also found that, in companies, the seniority level showed little correlation to actual programming skill\u00a0<cit.>, and programmers with similar education and background can exhibit vast differences in productivity, up to factors of ten\u00a0<cit.>.\nResearch is still at a loss when it comes to explaining the cause of these differences, accounting for different\ntrajectories of learning that underlie programming education and training\u00a0<cit.>, or identifying proficient programmers during a hiring process\u00a0<cit.>. \n\nIn this paper, we explore the idea of unraveling programmer efficacy[Efficacy specifically refers to the ability to quickly produce the intended result. Notably, this differs from expertise, which involves additional facets, such as deep knowledge, effort, and mastery of skills.]\u2014based on speed and correctness\u2014with the help of programmer experience\u2014amount of learning or practice. To improve our understanding of the relationship between efficacy and experience, we conducted a combined electroencephalography (EEG) and eye-tracking study, allowing us to take a close look at how differences in efficacy and experience are related to cognitive differences among programmers. In our study, 37\u00a0participants with varying levels of experience performed program-comprehension tasks. We found that programmers with higher efficacy read code more targeted, with shorter fixations, fewer (re)fixations, and skipping more code elements. They also complete their tasks with lower cognitive load, in less time, and make fewer errors than programmers with lower efficacy. Interestingly, we found that commonly used experience measures do not correlate with the observed efficacy, but instead self-estimation and learning indicators have considerable predictive power. To this end, we have identified correlates of high programmer efficacy as well as experience measures that provide a strong link to efficacy.\n\nIn summary, we make the following contributions:\n\n\n  * A combined EEG and eye-tracking experiment to investigate programmer efficacy with a diverse participant pool.\n\n  * Confirmation of prior results that programmers with high efficacy read source code more efficiently and with lower cognitive load.\n\n  * Empirical evidence that conventional experience measures have only poor predictive power for programmer efficacy. Self-estimation and indicators of learning eagerness are better suited.\n\n  * An online replication package[<https://github.com/brains-on-code/NoviceVsExpert>], including experiment design, raw data, and executable analysis scripts.\n\n\n\n\n\u00a7 RESEARCH QUESTIONS AND VARIABLES\n\n\n\n\n\nOur study on programmer efficacy builds on the methodology of previous experiments investigating program comprehension and programming experience. Our aim is to incorporate measures of program comprehension from these experiments into a single coherent study as shown in\u00a0<Ref>. We specifically designed our study to better understand programmer efficacy across a wide range of experience levels in the context of program-comprehension tasks. Programmer efficacy is therefore the independent variable for our experiment. We operationalize programmer efficacy as follows:\n\n\n\n\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc54\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc5f\u00a0\ud835\udc52\ud835\udc53\ud835\udc53\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc50\ud835\udc66 = \ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f\u00a0\ud835\udc5c\ud835\udc53\u00a0\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc61\u00a0\ud835\udc50\ud835\udc5c\ud835\udc51\ud835\udc52\u00a0\ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc5f\ud835\udc52\u210e\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b\u00a0\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58\ud835\udc60/\ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\u00a0\ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52\u00a0\ud835\udc56\ud835\udc5b\u00a0\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc62\ud835\udc61\ud835\udc52\ud835\udc60\n\n\nNote that programmer efficacy captures both the speed and correctness of a participant's behavior. Due to the strict one-hour time limit of the experiment\u00a0(see\u00a0<Ref>), only fast participants were able to see all snippets before the experiment ended. Our definition of programmer efficacy eliminates effects arising from a difference in the number of attempted tasks and is in line with prior work\u00a0<cit.>.\n\nTo guide our experiment design regarding dependent variables, we defined several research questions, which we introduce next.\n\n\n\n \u00a7.\u00a7 Reading Behavior (RQ1)\n\n\n\nSeveral studies have shown that experienced programmers show a different reading behavior than novices based on eye-gaze measures. The reading behavior describes a programmer's eye movements while they are comprehending a source-code snippet. Therefore, we state the following research question:\n\nRQ1Do different levels of programmer efficacy exhibit differences in reading behavior (in terms of navigation strategy and code element coverage)?\n\n\n\n  \nOperationalization\n\nFor RQ1, we adopt 7 measures that have been identified in the literature: In a longitudinal study, Al Madi et al. observed differences in the navigation strategy at the token level\u00a0<cit.>. Specifically, they analyzed fixation duration and how likely it was that a participant (re)fixated on a token. Experts showed significantly shorter fixation durations, a lower chance of refixating on a token, and a higher chance to skip tokens. Likewise, Aljehane et al. found differences between novices and experts in terms of code element coverage\u00a0<cit.>. It refers to the number of elements on which a participant fixates during a task in contrast to the total number of code elements. They found that novices read, in particular, more method signatures, variable declarations, identifiers, and keywords. Finally, Busjahn et al. have also identified a difference in code element coverage, in that novices fixate more code elements than experts\u00a0<cit.>. They also identified a difference in the reading order. However, our replication study revealed that this effect is principally driven by the execution order of the snippets\u00a0<cit.>. As our snippets are not balanced for this aspect, we will not consider reading order as a measure; these studies used different measures to pinpoint the participants' reading behavior. In our study, we aim at answering how programmer efficacy affects reading behavior across all described measures to increase comparability.\n\n\n\n \u00a7.\u00a7 Cognitive Load (RQ2)\n\n\n\nSimilar to reading behavior, previous studies found that different levels of programming experience can be distinguished by the observed neural correlates of cognitive load, which leads us to our next research question:\n\nRQ2Do different levels of programmer efficacy exhibit differences in neural correlates of cognitive load?\n\n\n\n\n  \nOperationalization\n\nRelated to RQ2, Crk et al. used event-related desynchronization along alpha and theta powerbands measured by an EEG device to classify participants into two programming experience levels\u00a0<cit.>. Similarly, Lee et al. found a similar effect also using EEG, but using a more comprehensive analysis across more EEG bands\u00a0<cit.>. Ishida and Uwano found an increase in the alpha frequency band for programmers who successfully finished tasks\u00a0<cit.>. However, Madeiros et al. compared several EEG measures to distinguish different experience levels and suggested the ratio between theta and alpha power as a measure of cognitive load\u00a0<cit.>. Notably, this ratio is commonly used as a cognitive load measure in other fields\u00a0<cit.>. We analyze both powerbands and the ratio measure in our study to better understand the link between programmer efficacy and cognitive load.\n\n\n\n\n \u00a7.\u00a7 Experience Measures (RQ3)\n\n\nFinally, we focus on programmer efficacy as a distinguishing factor between our participants. Prior research most commonly uses rather simple experience measures to separate participants (e.g., years of programming). In this vein, we pose our last research question:\n\nRQ3Do different levels of programmer efficacy correlate with common measures of programming experience?\n\n\n\n\n  \nOperationalization\n\nMany commonly used experience measures can be inconsistent in their predictive power, which led us to use programmer efficacy as the distinguishing factor. In RQ3, we analyze widely used experience measures[We share the full list of experience measures on the project's Web site.] and distill the relevant measures that correlate best with the observed programmer efficacy.\n\n\n\n\n\u00a7 STUDY DESIGN AND CONDUCT\n\n\nTo answer our research questions, we designed and conducted a study, which we describe in this section. All materials including snippets, tasks, and the experiment script, are available on the project's Web site.^2\n\n\n\n \u00a7.\u00a7 Experiment Plan\n\n\n\n\n\n\nWe opted for a within-subject experiment design\u00a0<cit.>, which we illustrate in\u00a0<Ref>. We presented up to 32 source-code snippets with a program-comprehension task (cf.\u00a0<Ref>), which were pseudo-randomized to avoid learning and fatigue effects. The experiment ended after the 32 program-comprehension tasks were completed or after 60\u00a0minutes, whichever happened first. The tasks were presented in three runs of 20\u00a0minutes and a voluntary break of 5 minutes between runs. In addition to the program-comprehension tasks, we included a search task, in which participants had to count brackets. This serves as a baseline for neural activation and is common in neuroscience studies of program comprehension\u00a0<cit.>. We chose a 4:1 design, so a participant completes four program-comprehension tasks and one search task. Between tasks, we included a 30\u00a0second rest condition, in which participants were instructed to focus their eyes on a fixation cross and relax.\n\nFor the comprehension tasks, the participants could choose among four answer options (cf.\u00a0<Ref>) as well as the option \u201cnext\u201d to skip a task. Participants used the left hand to press space as \u201csubmit\u201d and \u201ccontinue\u201d buttons, and the right hand to navigate with the arrow keys between answer options. After a short training session on the experiment flow (i.e., presentation of an example snippet, example input/output task, answering possible clarification questions), participants could use the keyboard without constantly looking at their hands, which minimizes motion artifacts.\n\nOur study was approved by the ethical review board of the faculty of Mathematics and Computer Science at Saarland University.\n\n\n\n \u00a7.\u00a7 Snippet Selection\n\n\n\n\n\n\nExample source-code snippet with intermediate complexity that checks a string for the existence of a substring. An example input provided to the participant would be  with answer options \u201c\u201d, \u201c\u201d (correct), \u201c\u201d, and \u201c\u201d.\n\n[\n    fontsize=7pt7pt,\n    linenos,\n    xleftmargin=10pt,\n    numbersep=5pt,\n    frame=lines]Java\npublic boolean containsSubstring(String word, String substring) \n    boolean containsSubstring = false;\n\n    for (int i = 0; i < word.length(); i++) \n        for (int j = 0; j < substring.length(); j++) \n            if (i + j > word.length()) \n                break;\n            \n            if (word.charAt(i + j) != substring.charAt(j)) \n                break;\n             else \n                if (j == substring.length() - 1) \n                    containsSubstring = true;\n                    break;\n                \n            \n        \n    \n\n    return containsSubstring;\n\n\n\n\nA crucial element of our experiment are the source-code snippets. We aimed at selecting snippets covering a variety of complexities. This ranges from simple snippets, with only a few lines that can be understood within seconds, to complex source-code snippets that require substantial mental effort to comprehend. Thus, our snippets require different levels of cognitive effort to comprehend them. This helps us to comprehensively capture program comprehension in relation to programmer efficacy.\n\nWe started our search by selecting Java snippets from a variety of previous studies of program comprehension\u00a0<cit.>. We then searched for further snippets implementing algorithms of comparable complexity (in terms of size, nesting depth, and execution length), which lead to a pool of 38\u00a0snippets. Three of the authors independently assessed each snippet's complexity and suitability for the study (e.g., whether prior knowledge is necessary to comprehend it). While the snippets are in Java, we aimed at selecting snippets that did not require deep knowledge of the language. This resulted in 32\u00a0snippets. We show a sample snippet that checks for the existence of a substring in\u00a0<Ref>. We list all included snippets in\u00a0<Ref> and provide them in the replication package.\n\n\n\n \u00a7.\u00a7 Program-Comprehension Task\n\n\n\nWe subdivided the program-comprehension task into two distinct steps to isolate the underlying cognitive processes of program comprehension and mental calculation of the result. To this end, we first presented the source-code snippet and instructed participants to comprehend it. Once a participant confirmed they comprehended its functionality (by pressing a button), we presented a sample input. Then, the participant had to mentally calculate the resulting output. The sample input was not shown until after the participant fully comprehended the code snippet, to prevent premature mental calculation without fully understanding the snippet. We informed participants of this multiple-step process beforehand and ensured their understanding with two training snippets.\n\n\n\n \u00a7.\u00a7 Experiment Execution and Data Collection\n\n\n\nAll participants provided their informed consent and completed our experience questionnaire (see\u00a0<Ref>).\nWe put the EEG cap on the participant's head, calibrated the eye-tracker, and started the experiment.\nAfter the experiment, we conducted a semi-structured interview, including questions on their subjective views about the experiment as well as each snippet.\n\nThe EEG laboratory is in a dim-light room with minimized distractions, such as external sounds or mobile devices. Participants sat in a comfortable chair to prevent unnecessary muscle movements to reduce noise and artifacts in the EEG signal.\nEEG signals were recorded using LiveAmp 64[Brain Products GmbH, <https://brainvision.com/products/liveamp-64/>], which is a 64-channel EEG device.\nThe sampling rate was set to 500\u00a0Hz, and the international 10\u201320 system of electrode placement\u00a0<cit.> was used to cover the entire scalp and obtain spatial information from the brain recordings.\nFor simultaneous eye tracking, we used the Tobii Pro Fusion eye-tracker[Tobii AB, <https://www.tobiipro.com/product-listing/fusion/>] attached to the screen. The eye gaze was recorded with a sampling rate of 250\u00a0Hz. The experiment was run with a PsychoPy\u00a0<cit.> script (available in the replication package).\n\n\n\n\n \u00a7.\u00a7 Participants\n\n\n\n\n\n\nWe recruited participants at Saarland University via e-mail lists and online bulletin boards. Participants received 10\u00a0Euro compensation each.\nThe prerequisite for participation was, at least, one year of experience with Java or, at least, three years of experience with a related programming language, such as . It was important to recruit a diverse set of programmers with a wide range of experience levels to explore the differences and commonalities across different efficacy levels. In\u00a0<Ref>, we provide an overview of our participants' demographics. Based on the conventionally used experience measures, our participant sample exhibits a wide range of programming experience, from programmers in their first year of programming at the university to 30\u00a0years of experience in industry.\n\nWe invited 39\u00a0participants to start the experiment. 38 out of the 39\u00a0measured participants completed the experiment.[One participant aborted the experiment early due to personal time constraints.] For one participant, the eye-tracker could not be calibrated, but all other modalities are available and the data are included in the analysis. We later excluded one complete participant data set due to their behavioral data consisting of a majority of outliers\u00a0(cf.\u00a0<Ref>), leaving us with 37\u00a0participants included in the data set. We based our programming experience questions on a validated questionnaire\u00a0<cit.>, but extended it to cover more topics for further investigation\u00a0(e.g., programming-content consumption and production and daily work; the questionnaire is available in the replication package).\n\n\n\n\u00a7 DATA ANALYSIS\n\n\n\nIn this section, we describe our data-analysis procedure for eye-tracking data, EEG data, and experience measures.\n\n\n\n \u00a7.\u00a7 Outlier Removal\n\n\n\nWe started with removing outliers in response time for comprehending a source-code snippet. Specifically, we discarded the slowest 5% (i.e., a response time of over 2\u00a0min\u00a032\u00a0s) as well as the fastest 5% (under 11\u00a0s), but only if a participant chose the option \u201cNext\u201d, since some tasks can be rapidly answered by proficient programmers (e.g., the  snippet). This way, data points were only removed when participants did not thoroughly attempt to understand the snippet and program comprehension may not have occurred. \nWith these rules, we removed 9\u00a0data points[One data point here is the response time for one participant to one snippet] in the lower 5% and 55 in the upper 5%, leaving 1072 data points for further analysis.\nThis led to the removal of more than half of the data points for one (slow) participant, so we excluded the participant's entire data set from the study.\n\n\n\n \u00a7.\u00a7 Eye-Tracking Data\n\n\nWe defined areas-of-interests (AOIs) for each source-code snippet to relate eye-gaze behavior with particular regions and elements of code. For this purpose, we first obtained the abstract syntax tree of each source-code snippet to identify each token and code element. Then, we manually identified higher-order syntactical structures such as the head and body of loops or if-else-statements for each snippet and thereupon defined AOIs based on categories defined in previous work\u00a0<cit.>.\n\nWe preprocessed the eye-tracking data to separate fixations and saccades from the raw stream of  coordinates. For this purpose, we used , which is a noise-robust algorithm\u00a0<cit.>. Then, we computed the token-level and element-coverage measures described in\u00a0<Ref>.\n\n\n\n \u00a7.\u00a7 EEG Data\n\n\n\nOur cognitive load measures are based on a spectral analysis of EEG data. To improve the robustness of our analysis, we calculate cognitive load using two different approaches: theta/alpha power ratio and relative power analysis.\n\n\n\n  \u00a7.\u00a7.\u00a7 Data Cleaning\n\n\nFirst, we removed noise from the EEG data, especially movement artifacts, using established preprocessing methods: We filtered the data using Hamming-windowed finite impulse response (FIR) filters.\nPower line noise was removed by a notch filter with a lower cutoff frequency of 49 and an upper cutoff frequency of 51.\nSecond, to obtain a more robust performance in the subsequent analysis, we also removed baseline drifts and high-frequent noise with a bandpass filter ranging from 4 to 200\u00a0<cit.>.\n\nDue to the nature of the experiment, where participants have to look at different points of the screen, eye movements and other muscle activity cannot be fully avoided.\nTherefore, we performed blind source separation as a second step to remove corresponding artifacts.\nThe used  toolbox\u00a0<cit.>[Version 2021.1, <https://sccn.ucsd.edu/eeglab/>] provides an automated implementation of the independent component analysis (ICA).\nFor each component, it yields a classification with a confidence level, which we can use to automatically reject noisy components.\nRejection thresholds for eye and muscle artifacts were set to the default values of 0.9, while components without a clear assignment to a group were rejected at 0.95.\n\n\n\n  \u00a7.\u00a7.\u00a7 Theta/Alpha Power Ratio\n\n\nAs a first technique, we computed the cognitive load based on the work of Holm et al.\u00a0<cit.> and Kartali et al.\u00a0<cit.> as the ratio of the relative power of the theta and alpha band of the EEG. We calculated the power spectral density on a sliding window obtaining the mean power within each frequency band of interest.\nThe sliding window had a size of 3 and was shifted by 0.1 over each task. The cognitive load measure is obtained by dividing the mean power within a window. By using the sliding window, we can observe the time course of the cognitive load during the tasks.\n\n\n\n  \u00a7.\u00a7.\u00a7 Relative Power Analysis\n\n\nAs a second technique, we also computed a per-band and per-channel relative power analysis along alpha, beta, gamma, and theta band based on the technique established by Lee et al.\u00a0<cit.>, which is sensitive to the spatial location of brain activation by considering the channel of the electrode.[To facilitate comparison with Lee et al.'s work\u00a0<cit.>, which used two groups, we formed two groups post-hoc based on experimental scores of efficacy. We separated our participants by performance into thirds. For increased potential, we contrasted the high-performing group (i.e., efficacy >= 0.35, n=12) and the low-performing group (i.e., efficacy <= 0.29, n=13), leaving out the middle group.]\n\n\n\n \u00a7.\u00a7 Efficacy and Experience\n\n\nFor RQ3, we correlated the observed efficacy with all collected numerical and categorical experience measures. To this end, we used Spearman's\u00a0\u03c1 correlation due to the mix of continuous and ordinal nature of our data.\n\n\n\n\u00a7 RESULTS AND DISCUSSION\n\nIn this section, we present the results of our EEG and eye-tracking data analysis, along with their subsequent interpretation.\n\n\n\nApplying our programmer efficacy definition to the data, we find that, on average, 1\u00a0task was correctly solved around every 3 minutes (i.e., mean programmer efficacy of 0.33 \u00b1 0.10). We visualize the distribution of participant efficacy in\u00a0<Ref>, which is a non-normal distribution according to a Shapiro-Wilk test (W = 0.94, p = 0.046). It could be normalized by removing the upper tail (2 participants)\u2014neither which were the most experienced programmers\u2014but since we already removed outliers, this appears to be the real distribution in our sample.\n\n\n\n \u00a7.\u00a7 Reading Behavior (RQ1)\n\n\n\n\n\n\n\n\nOur eye-tracking data show a change in reading behavior with increasing efficacy levels. Based on the token-level measures from Al Madi et al., we found that increased efficacy leads to:\n\n\n\n  * shorter (first) fixations (\u03c1=-0.14),\n\n  * shorter gaze duration (\u03c1=-0.19),\n\n  * a much lower chance that a token is revisited (\u03c1=-0.37), and\n\n  * a slightly higher probability that a token is skipped (\u03c1=0.08).\n\nWe visualize these relationships in\u00a0<Ref>.\n\nRegarding code element coverage, based on Aljehane et al. and Busjahn et al., we find a similar result, such that higher efficacy leads to a lower code element coverage (\u03c1=-0.35). Notably, this difference increases throughout the task, as we illustrate in\u00a0<Ref>. To underline the difference between programmer with low and high efficacy, we show an example scanpath in\u00a0<Ref> (Page\u00a0fig:EyetrackingScanpathSample). Clearly, the programmer with high efficacy requires fewer fixations and refixations to comprehend the source-code snippet.\n\nOverall, this leads to the following answer to our research question:\n\nRQ1We can confirm prior results that programmers with higher efficacy read code more efficiently in terms of shorter fixations on fewer code elements. However, some measures show only weak correlations.\n\n\n\n  \nDiscussion\n\nOur results for RQ1 confirm prior results and corroborate the theory that proficient programmers read source code more efficiently\u00a0<cit.> and are actively looking for an efficient way to solve a task\u00a0<cit.>. This supports the view that their knowledge guides their eyes\u00a0<cit.>. However, the established measures that we use capture this effect to different degrees. Fixation duration measures show only weak correlations (\u03c1=-0.14), while fixation probabilities show, at best, medium correlations with programmer efficacy (\u03c1=-0.37). These results support that proficient programmers read individual elements faster, and, in particular, focus on the important elements\u2014skipping several parts that they deem unimportant. This narrow focus on important elements is further highlighted in the code element coverage measure. Programmers with high efficacy read fewer code elements throughout the task, increasing over time as shown in\u00a0<Ref>. Even at the end of a task, they still only fixated on\u00a069 % of the tokens, on average\u2014skipping tokens they rate as irrelevant.\n\nWhile a narrow focus enables high performers to quickly solve a task, they might overlook relevant elements. For example, research in psychology has shown that experts' internal filtering heuristics can lead them to miss relevant information and make mistakes\u00a0<cit.>. In programming, this effect was observed with experts missing obvious syntax errors that novices consistently notice\u00a0<cit.>.\n\n\n\n \u00a7.\u00a7 Cognitive Load (RQ2)\n\n\n\n\n\n\nThe observed ratio of alpha and theta band as an indicator of cognitive load can be analyzed regarding different features, which we summarize in\u00a0<Ref>. While generally the cognitive load appears to be lower for programmers with higher efficacy (\u03c1 = -0.09), the correlations are weak. Still, it has to be taken into account that programmers with higher efficacy tend to complete their tasks faster. In\u00a0<Ref>, we visualize the cognitive load over time depending on efficacy, which shows that the level of cognitive load generally stays lower, and with fewer spikes, for programmers with higher efficacy.\n\n\n\nResults from our powerband analysis confirm results from Lee et al.\u00a0<cit.>. Like Lee et al., we separated our participants into a high-performing and low-performing group\u00a0(cf.\u00a0<Ref>). We found a lower beta power for programmers with higher efficacy, and higher alpha and gamma power, which is illustrated in\u00a0<Ref>.\n\n\nRQ2The cognitive load is slightly lower for programmers with higher efficacy, despite faster completion times. Programmers with higher efficacy further experience fewer high spikes of cognitive load. This is in line with previous findings of lower beta and higher alpha and gamma power for programmers with higher efficacy.\n\n\n\n  \nDiscussion\nThe results of RQ2 indicate that programmers with higher efficacy can not only comprehend source code faster, but also with less mental effort. This could be explained by an increased neural efficiency, which has been shown in other fields\u00a0<cit.> or as an effect of source code structures serving as beacons for program comprehension\u00a0<cit.>, but not as a factor of proficiency in programming. One explanation would be a difference in underlying cognitive processing: Experts may see the presented snippets as a task, that is, they have a strategy to solve the problem, and simply need to implement the solution. This is unlike novice programmers, who also need to find a strategy first, then implement the solution, which leads to higher cognitive load and longer response times\u00a0<cit.>. Due to the lower cognitive-load levels, programmers with high efficacy likely can sustain longer periods of work. By contrast, programmers with lower efficacy are more likely to be overwhelmed by constant spikes of cognitive load (<Ref>).\n\n\n\n\n  \nSynthesis of RQs1\u20132\nOur study was inspired by several prior experiments investigating program comprehension with various operationalizations and different definitions of experience. We aimed at finding a common ground across their measures, specifically when focusing on programmer efficacy. Overall, our study confirmed the accuracy of some of these measures, but to different degrees. Programmers with higher efficacy can be particularly identified due to their efficient reading strategy and lower spikes in cognitive load. This is not only important for future research, but also has practical implications. For example, a lot of hiring processes use technical interviews in front of a whiteboard, which artificially introduce stress and high cognitive load\u00a0<cit.>. An alternative solution to evaluate potential talent with measures that allow for accurate and quick responses, without inducing unnecessary stress and cognitive load, would be private interviews, comprehension tasks, or other alternative interview methods, for example, as proposed by Behroozi et al.\u00a0<cit.>.\n\nRegarding programming language design, the combination of eye tracking and EEG may have potential. Future work shall explore whether we can use eye-tracking data to pinpoint spikes in cognitive load to specific code elements, similar to Fakhoury et al.'s work with functional near-infrared spectroscopy (fNIRS)\u00a0<cit.> or our prior work on combining eye tracking and fMRI\u00a0<cit.>. Such combination may reveal code structures that are particularly difficult for programmers to comprehend.\n\n\n\n\n \u00a7.\u00a7 Experience Measures (RQ3)\n\n\n\n\n\nIn\u00a0<Ref>, we show the strength of correlations between programmer efficacy and a subset of popular measures of programming experience. Notably, some commonly used experience measures (e.g., years of (professional) programming\u00a0<cit.>) show little predictive power to our participants' efficacy. But, several other dimensions of experience show, at least, medium-strength correlations. Specifically, self-estimation in comparison to peers (\u03c1=0.59) and a 10-year professional programmer (\u03c1=0.38) show that our participants seem to be keenly aware of their proficiency level. The number of known programming languages also shows a medium-strength correlation (\u03c1=0.42). For the subset of professional programmers\u00a0(n=26), several questions that capture learning eagerness (e.g., learning, mentoring, code review) show medium correlations. However, strikingly, the time professionals spend on pure programming does not correlate to their performance in our experiment (\u03c1=0.06).\n\nOverall, these results allow us to answer this research question:\n\nRQ3Programmer efficacy does not correlate with commonly used experience measures, such as years of programming. Self-estimation and indicators of learning eagerness show, at least, medium correlations with observed programmer efficacy.\n\n\n\n  \nDiscussion\n\n\nOur experiment highlights two fundamental problems for studying programmers. One issue is that programming is such a diverse field with different technologies that require different skill sets, so it is incredibly difficult to accurately measure a programmer's experience. Therefore, many researchers rely on simple measures, such as years of programming. However, this can become problematic if the difference between the selected measure and the actual proficiency level becomes a significant confounding factor\u00a0<cit.>. Our experiment, in line with prior research\u00a0<cit.>, underlines how limited common experience measures are in predicting programmers' efficacy. Thus, future research must carefully consider collecting more comprehensive experience data, in particular, when using it to separate the participants into groups. While this may not be completely new insights, our experiment further corroborates this critical point. The use of too simplistic measures can potentially weaken empirical studies of programmers and their conclusions.\n\n\n\n\u00a7 THREATS TO VALIDITY\n\n\n\nIn this section, we discuss threats to construct, internal, and external validity of our study.\n\n\n\n \u00a7.\u00a7 Construct Validity\n\n\nOur programmer efficacy measure may deviate from a participant's true efficacy due to the nature of our selected snippets and programming language. We mitigated this threat by selecting a variety of source-code snippets such that prior knowledge plays a minuscule role, and we ensured sufficient Java knowledge for each participant.\n\n\n\n \u00a7.\u00a7 Internal Validity\n\n\n\nWe have operationalized program comprehension in a multiple-step design, in which participants first had to comprehend a source-code snippet, then compute an input/output task, and finally select the output from four answers. Clearly, program comprehension is a multi-faceted phenomenon for which a variety of operationalizations are possible\u00a0<cit.>, but our approach ensures that participants genuinely comprehended each snippet. \n\nRegarding data collection, we limited the experiment to a maximum of 1\u00a0hour (with two breaks) to avoid fatigue effects. Depending on each participant's speed, this led to an unequal number of collected data points (17 of 37\u00a0participants completed all 32\u00a0snippets). While we could have ended the experiment after, for example, 25 instead of 32\u00a0snippets for everyone, we would have lost around 10% of data. Therefore, we chose a small potential bias as a trade-off for a notably larger data set (to gain more statistical power and external validity). We mitigated the threat of an unequal number of snippets by randomizing the presentation order of snippets.\n\nOur results indicate a strong influence regarding measures of several programming activities, including the amount of code review and testing, on observed efficacy. This relationship between observed efficacy and time spent with these identified programming activities may be overly emphasized by our experiment design since they are close in nature to our program-comprehension task.\n\n\n\n \u00a7.\u00a7 External Validity\n\nDue to our focus on internal validity, our presented study is limited regarding its generalizability. While our participant sample covers a wide range of experience and proficiency levels, the presented tasks were limited to algorithms in an object-oriented programming language. Thus, our study on program comprehension may not generalize to all software-engineering activities, including comprehension of large code bases and other programming paradigms. Still, our study pinned down an effect with high internal validity; future work shall replicate, vary, and extend the setup toward external validity.\n\n\n\n\u00a7 RELATED WORK\n\n\nOur study is at the intersection between the fields of program comprehension, eye tracking, neuroimaging, and programming expertise, which we each discuss below.\n\n\n\n  \nProgram Comprehension\nThere is a multitude of program-com-\nprehension studies\u00a0<cit.>, on which we build by re-using source-code snippets as a foundation for our experiment. In the early years, behavioral or reflective studies were popular\u00a0<cit.>. Our study shares a similar design with them in terms of snippets and tasks, but our observed measures are more in line with the recent movement toward more objective measurement methods, such as eye tracking or EEG\u00a0<cit.>, which we discuss next.\n\n\n\n  \nEye Tracking\nEye tracking enables researchers to objectively observe attention during complex tasks and has increased in popularity, including program comprehension\u00a0<cit.>. Again, there is a multitude of studies that use various eye-gaze measures\u00a0<cit.>. We have used recently established eye-gaze measures for differentiation of programmer expertise\u00a0<cit.>, but we applied these measures to a larger pool of diverse programmers than before and included insights from neural correlates via EEG data. With efficacy, we also arguably used a better way to separate participants\u00a0(cf.\u00a0<Ref>).\n\n\n\n\n  \nNeural Correlates of Program Comprehension\nIn addition to eye tracking, some studies have employed methods to observe neural correlates of program comprehension. Some have used fMRI\u00a0<cit.> or fNIRS\u00a0<cit.>, others have used EEG\u00a0<cit.>. Our study adopted the measures of cognitive load of Lee et al. (i.e., alpha and beta power)\u00a0<cit.> and Medeiros et al. (i.e., ratio of theta and alpha)\u00a0<cit.>, but it differs in terms of the goal and the participant pool. Lee et al. focused on classification between two distinct groups, while Medeiros et al. focused on software metrics\u00a0<cit.>. By contrast, we focused on the programmer and investigated their efficacy on a continuous distribution, without the need to create two groups.\n\n\n\n  \nProgramming Experience and Expertise\nThere have been multiple waves of program-comprehension research regarding expertise. In the early years, several studies have devised theories of expertise, in particular related to plans\u00a0<cit.>, mental models\u00a0<cit.>, strategy\u00a0<cit.> and knowledge\u00a0<cit.>. More recently, researchers have focused on visual attention\u00a0<cit.> and implementation style\u00a0<cit.>. Our study differs in that we operationalize on a more narrow scope of expertise based on programmer efficacy, rather than measures of knowledge, mental representations, or other intangible factors. We argue our operationalization offers a higher relevance to practical and educational problems as well as a clearer definition over an obfuscated experience measure, because of its better link to task performance.\n\n\n\nIn summary, our experiment is a fusion of established research designs from different fields and is novel by integrating several measures in one experiment. Furthermore, we focused on inviting a diverse participant pool as well as on efficacy as a separating factor (while still collecting a wide array of experience measures).\n\n\n\n\u00a7 PERSPECTIVES AND CONCLUSION\n\n\n\n\n\n  \nMeasuring Programming Experience\n\n\nFor future studies, one major obstacle is to select the correct measure of programming experience. Cognitive psychology has investigated the relationship between experience and expertise in many fields beyond programming\u00a0<cit.>. One consistent finding is that the length of experience can be part of expertise, as people continue to acquire skill\u00a0<cit.>, but is not everything\u00a0<cit.>. In programming, studies from the 1990s identified a similar effect, in that there are two elements at play: the time and learning\u00a0<cit.>. In our questionnaire, we aimed to capture many aspects of programming experience, including measures of learning, but also regarding content creation and work-time distribution. One theme that consistently showed a strong connection with observed efficacy is the eagerness of learning and inquisitiveness. The number of known programming languages, how much time is spent on mentoring, and on code review are all highly relevant factors. Psychology describes this conscious effort to keep learning as deliberate practice. It also highlights that not necessarily the length of practice, but the intensity and goal-orientation is critical to achieve expertise in a topic\u00a0<cit.>. The effect of deliberate practice has been observed in programming education and practice, as well. For example, students show higher ability when participating in programming competitions\u00a0<cit.>. In an industry survey, software engineers shared the notion that a great software engineer is shown by their open-mindedness and eagerness to learn. They considered the ability to learn as more important than technical skill\u00a0<cit.>. This was later confirmed in an experimental setting, in which company seniority level showed little correlation to actual programming skill\u00a0<cit.>. \nOverall, the results of our experiment underlined that the learning component is a highly relevant measure to capture efficacy, which leads us to suggest it as important measure(s) for future experiments.\n\n\n\n  \nImplications for Research\nBeyond learning measures, our results indicate that future research could maximize its potential when collecting self-estimation measures. This result is in line with a similar finding by Siegmund et al., which also highlighted self-estimated comparison as a differentiating factor among students\u00a0<cit.>. In the same vein, Kleinschmager and Hanenberg found self-estimated comparison, at least, as effective as pretests or university grades in its predictive power of efficacy\u00a0<cit.>. Our shared experience questionnaire provides a proven basis for others to use to capture several dimensions of programming experience.\n\n\n\n  \nImplications for Industry\nFrom a practical perspective, our empirical results provide scientific evidence that technical interviews may be necessary for establishing efficacy, since common measures selected for decisions (e.g., years of experience), have limited to no predictive power. Our questionnaire provides a few promising directions for operationalizing a more effective method for assessing efficacy in industry, such as peer review and mentoring experience, peer comparison, and learning behaviors. However, in high-stake decisions, such as promotion or hiring, the degree to which self-estimation can be reliable remains an open question.\n\n\n\n\n  \nConclusion\nExperience, expertise, and efficacy are three dimensions of characteristics of programmers that are not well understood. In particular, the relationship between them is unclear. In this paper, we have presented correlates of efficacy in terms of reading order and cognitive load across a wide range of programmers. \n\nCommonly used experience measures do not correlate well to observed efficacy. Instead, we underline to use self-estimation and learning eagerness as more accurate measures for programming experience.\n\nDespite encouraging results, future work shall explore programmer efficacy in more detail. For example, the link between reading behavior and cognitive load could be explored to understand causalities. Is the more efficient reading strategy of programmers with high efficacy the cause for lower cognitive load, or vice versa?\n\n\nWe thank all participants of our study. Furthermore, we thank Julia Hess, Tobias Jungbluth, and Johannes Ihl for their support during data acquisition.\n\nRekrut's work is supported by the German Federal Ministry of Education and Research (01IS12050). Parnin's work is supported by the National Science Foundation under grant number\u00a02045272. Siegmund's work is supported by DFG grant SI\u00a02045/2/\u03042. Apel's work is supported by ERC Advanced Grant 101052182 as well as DFG Grant 389792660 as part of TRR 248 \u2013 CPEC.\n\n\nACM-Reference-Format \n\n\n"}