{"entry_id": "http://arxiv.org/abs/2303.12736v2", "published": "20230313134039", "title": "DPPMask: Masked Image Modeling with Determinantal Point Processes", "authors": ["Junde Xu", "Zikai Lin", "Donghao Zhou", "Yaodong Yang", "Xiangyun Liao", "Bian Wu", "Guangyong Chen", "Pheng-Ann Heng"], "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nDPPMask: Masked Image Modeling with Determinantal Point Processes\n    \n\n\n\n\nJunde Xu 1, 2\nEqual Contribution. Zikai Lin 1, 2 *  Donghao Zhou 1, 2 Yaodong Yang 4 Xiangyun Liao 1 Bian Wu 3 Guangyong Chen 3Corresponding Author (mailto:gychen@zhejianglab.comgychen@zhejianglab.com). Pheng-Ann Heng 1, 4 1 Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences 2 University of Chinese Academy of Sciences \n3 Zhejiang Lab 4 The Chinese University of Hong Kong\n       \n    March 30, 2023\n==========================================================================================================================================================================================================================================================================================================================================================================================================================\n\n\nempty\n\n\n\n\n\n\n    Masked Image Modeling (MIM) has achieved impressive representative performance with the aim of reconstructing randomly masked images.\n    Despite the empirical success, most previous works have neglected the important fact that it is unreasonable to force the model to reconstruct something beyond recovery, such as those masked objects.\n    In this work, we show that uniformly random masking widely used in previous works unavoidably loses some key objects and changes original semantic information, resulting in a misalignment problem and hurting the representative learning eventually.\n    To address this issue, we augment MIM with a new masking strategy namely the DPPMask by substituting the random process with Determinantal Point Process (DPPs) to reduce the semantic change of the image after masking.\n    Our method is simple yet effective and requires no extra learnable parameters when implemented within various frameworks.\n    In particular, we evaluate our method on two representative MIM frameworks, MAE and iBOT.\n    We show that DPPMask surpassed random sampling under both lower and higher masking ratios, indicating that DPPMask makes the reconstruction task more reasonable.\n    We further test our method on the background challenge and multi-class classification tasks, showing that our method is more robust at various tasks.\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\nSelf-supervised learning aims to extract semantic features by solving auxiliary prediction tasks (or pretext tasks) with pseudo labels generated solely based on input features.\nWhile various tasks have been proposed for self-supervised learning, one intuitive idea is learning representations by recovering the original data from the corrupted structure.\nThe philosophy behind such methods is simple: what the model generates can examine whether the model understands.\nThis principle was first introduced by the denoising autoencoder  <cit.> which has supported significant advances in NLP <cit.>.\nMethods that follow this idea such as BERT <cit.> now have become a dominant routine.\nIn the field of image processing tasks, although reconstruction-based pre-training was first put forth by  <cit.>, it wasn't until recently that methods based on this concept were brought back to state-of-the-art performance.\nBenefiting from the new network architectures like ViT <cit.>, Masked Image Modeling (MIM) has become highly popular, and there is a series of more aggressive masking strategies like MAE <cit.>, simMIM <cit.>.\n  \n\nHowever, simply random masking can be problematic in practice. \nAn important fact is that it is unreasonable to force the model to reconstruct something beyond recovery.\nConsider a simple case as Fig.\u00a0<ref>.\nThe top row of Fig.\u00a0<ref> shows the underlying logic of MIM: successful reconstruction implies the network captures the correct semantic features.\nWhile the bottom row of Fig.\u00a0<ref> shows a failure case: if the masking process happens to drop an important semantic of the original image, the book in Fig.\u00a0<ref>, then will change the semantics of the original image and make the network hardly recover it from the rest.\nIn this case, if the model continues to be forced to reconstruct the original image, the model might fill in the obscured image with whatever is feasible, which will interfere with the process of learning the original features.\nFurthermore, as the masking rate increases, the original semantic information is distorted with a higher probability.\nWe refer to such a situation as a misalignment problem, i.e. the semantics of masked image and the original image are miss-aligned.\nConsequently, the misalignment problem will cause the alignment of improper sample pairs, which will eventually harm the performance of the downstream task.\n\nSome studies also proposed constructing better sample pairs for MIM.\nIn MaskFeat <cit.>, they change the pixel reconstruction task to HOG reconstruction, to reduce the impact of some ambiguous situations for the network to prediction, such as colors, and textures.\nHowever, MaskFeat can only reduce the impact of hardly recoverable high-frequency signals. \nIf the masked part contains the whole object instance, there is still not enough information for the network to rebuild.\nIn ADIOS <cit.> and SemMAE <cit.>, they train an extra segmentation network to partition the image into different semantics. \nHowever, the number of semantics varies significantly in different images, thus, it is hard to find an optimal semantic partition network. \nIn AttMask <cit.>, they mask the most attended patches according to their attention score to construct more challenging MIM tasks.\nHowever, AttMask needs an attention map to perform sampling, which can not fit into\nreconstruction-based MIM methods (e.g., MAE) seamlessly.\nRecently, AMT <cit.> adding attention map guided masking to MAE.\nUnfortunately, these algorithms do not take into account the misalignment problem, which leads to inferior performance.\n\nIn contrastive learning, an InfoMin principle suggests that two augmented views of an image should retain task-relevant information while minimizing irrelevant nuisances <cit.>.\nAnalog to MIM, we can summarize the following two conditions:\nFirst, the selected patches should be representative enough to cover the whole semantic information of the original image.\nSecond, the masking ratio should be set to a high level to minimize the irrelevant information shares between different masks of the same image.\nWhile the second constraint is easy to satisfy, the problem is how to retain the task-relevant original semantics under the limited input ratio. \nTo address this, we propose a novel masking strategy based on Determinantal Point Process (DPPs).\nDPPs are elegant probabilistic models on sets that can capture both quality and diversity when a subset is sampled from a ground set <cit.>, making them ideal for modeling the set that contains more information of original images as possible.\nDuring the sampling process, DPPs will compute the distance of each patch, and select patches that are dis-similar from the selected subset.\nThis process makes the network focus on the patches with more representative information.\nFor example, the unique color, texture, etc. \nWe show that our new sampling strategy can obtain more representative patches to keep the semantics unchanged and alleviate the impact of the misalignment problem.\nMore importantly, We show that DPPMask surpassed random sampling under both lower and higher masking ratios, indicating that DPPMask makes the reconstruction task more reasonable.   \nFurthermore, our method needs no extra training process and achieves minimal computational resource consumption. \n\nOur contribution can be summarized as follows:\n\n    \n  * We analyze the training behavior of reconstruction-based MIM and discuss the impact of the misalignment problem.\n    \n  * To alleviate the impact of misalignment in MIM, we proposed a novel plug-and-play sampling strategy called DPPMask based on DPPs. Our method can generate more reasonable training pairs, is simple yet effective, and requires no extra learning parameters.\n    \n  * We verify our method on two representative MIM frameworks, our experiments evidence that features learned by fewer misalignment problems achieve better performance in downstream tasks.\n\n\n\n\n\n\n\u00a7 RELATED WORK\n\n\nSelf-supervised learning. Classic deep learning trains the parameters of the model by utilizing labeled data. \nInstead, self-supervised learning(SSL) expects to acquire representations with unlabeled data by a pre-text task.\nAmong them, Masked language modeling (MLM) has taken the lead to be a highly influential self-supervised learning model before.\ne.g.,, BERT  <cit.> and GPT  <cit.> are such successful methods that the academia has focused on these two models for pre-training in NLP.\nThese models leverage visible tokens in a sequence and predict invisible tokens to gain appropriate representations, which have been proved to successfully repaint the field  <cit.>.\nIn other fields of SSL, there have been numerous methods that focus on different pretext tasks like reconstructing original tokens from image/patch operations  <cit.>and Spatio-temporal operation  <cit.>.\nA well-known method is contrastive learning that capitalizes on augmentation invariance in the feature space and could be evaluated by linear probing <cit.>, which was the previous mainstream based on SSL.\n\n\n\nMasked Image Modeling(MIM) Masked Image Modeling recently has shown capability to reconstruct pixels  <cit.> from corrupted images. \nMIM can be seen as a generalized Denoising AutoEncoders (DAE) <cit.>, \nwhich aims to reconstruct the original tokens from corrupt input.\ne.g., inputing missing color channels <cit.> or missing pixels  <cit.>.\nContext Encoder  <cit.> reconstructs a rectangle area of the original images using convolutional networks.\nThen ViT  <cit.> and iGPT  <cit.>\nrecall the learning approach of predicting patches with a contrastive predictive coding loss on the modern vision Transformers, and show strong potential in representation learning.\nBEiT  <cit.> proposes to use a pre-trained discrete VAE  <cit.>as the tokenizer, and improves MIM's performance further.\nHowever, the tokenizer needs to be offline pre-trained with matched model and dataset which limits its adaptivity.\nTo end this, iBOT  <cit.> presents a new framework that performs masked prediction with an online tokenizer and gains prominence achievement.\nRecently, equipped with a more aggressive masking strategy, SimMIM  <cit.> and MAE  <cit.> further demonstrate that simple pixel reconstruction can achieve competitive results from previous pre-training methods.\n\n\n \nDeterminantal Point Process.\nDeterminantal point processes (DPPs) are probabilistic models of configurations that favor diversity  <cit.>.\nIts repulsion brings new potential to enhance diversity in multiple machine\nlearning problems, such as feature extract from high dimensional data  <cit.>,\ntexture synthesis in image processing  <cit.>,\nbuilding informative summaries by selecting diverse sentences  <cit.>.\n\nIn addition to DPPs, there are some previous methods like Markov random fields(MRFs).\nHowever, MRF assumes that repulsion does not depend on context too much, so it cannot express that, say, there can be only a certain number of selected items overall  <cit.>.\nThe DPPs can naturally implement this kind of restriction through the rank of the kernel.\n\n\n\n\n\u00a7 METHODS\n\nIn this section, we first discuss the impact of the misalignment problem on the downstream tasks, then, we give a brief introduction to DPPs.\nFinally, we propose our method of applying DPPs in the patch masking process.\n\n\n \u00a7.\u00a7 Misalignment in MIM\n\n\nLet x_1, x_2, z be the masked image, reconstruction target, and hidden vector.\nIn the ideal situation, the input x_1 and reconstruction target x_2 all followed an identical distribution x_1, x_2 \u223c P(z).\nHowever, consider the input only captures the partial information of the original image, in this case, x_1 \u223c P(z') where z' defines a different distribution to z.\nFor pixel reconstruction tasks, we denote the encoder and the decoder parameterized by \u03d5 and \u03b8 respectively.\nFollowing  <cit.>, MIM training can be viewed as variational autoencoder training  <cit.>, which can be described as a Maximum A Posteriori (MAP) Estimation: \n\n    max_\u03d5, \u03b8\ud835\udd3c_z'\u223c q_\u03d5(z'|x_1)log p_\u03b8 (x_2|z')\n\nSuppose the encoder is capable of capturing the semantic information of x_1 and the decoder is capable of recovering the image described by z and z', by unfolding the decoder part, we get:\n\n    p_\u03b8(x_2|z') = \u222b p_\u03b8(x_2|z)P(z|z')dz\n\n\nThe Eq.<ref> indicates that the pixel reconstruction task is minimizing the distance between representations of masked image z' and original image z.\nNow, let's zoom the lens to multiple steps, MIM can receive multiple different masked images of the original image.\nBy training the network to reconstruct original images from different masked ones, MIM minimizes the distance between those different masks.\nFig.\u00a0<ref> shows a diagram of such training behavior, where different masking result lies at a different location of a hyperplane and construct the semantic space.\nDuring the reconstruction training process, data points in the semantic space are pushed to align with the location of the original image.\nConsequently, as they are aligned with the same data point, the distance between each data point in semantic space is also minimized.\nWhile misalignment is a false aggregation of data points that have skewed semantics (orange dot in Fig.\u00a0<ref>).\nFor other MIM reconstruction targets, such as visual tokens in BEiT  <cit.> and iBOT  <cit.>, it is easy to verify that they also share similar training behavior.\nA similar conclusion has also been reported in  <cit.>, however, they focus on the dimensional collapse issue in MAE and neglect the misalignment problem of MIM.\nIn practice, semantics are not evenly distributed in images.\nThese semantics are likely to be ignored by random masking strategies.\nAs the MIM pulls masked samples together, two images with different semantics are miss-aligned.\nIf the changed semantics is an important clue for image understanding, such a problem can seriously affect downstream performance.\nTo this end, we propose a new sampling strategy to select as representative patches as possible.\n\n\n\n \u00a7.\u00a7 Determinantal Point Process\n\nOur core technical innovation is modeling the patch masking process with DPPs.\nTo this end, we start with a high-level overview of DPPs. \n\n\n\n\nBrief intro.\nA determinantal point process (DPPs) is a distribution over configurations of points. \nThe defining characteristic of the DPP is that it is repulsive, which makes it useful for modeling diversity <cit.>.\nFormally, a point process \ud835\udcab on a discrete set S = {1, 2, ..., N} is a probability measure on 2^S, the set of all subsets of S.\n\ud835\udcab is called a determinantal point process if, when A is a random subset drawn according to \ud835\udcab, we have,\n\n    \ud835\udcab(Y=A) \u221ddet(L_A),\n\nwhere L \u2208 R^N\u00d7 N is a real, symmetric, positive semi-definite kernel, and L_A \u2208 R^|A| \u00d7 |A| is a submatrix of L indexed by elements of A.\nNote this is an unnormalized probability of sampling a set of A.\nThe normalization constant is defined as the sum of the unnormalized probabilities over all subsets of the S, i.e.\n\u2211_A \u2286 Sdet( L_A ).\nWe can compute the normalized constant by the following theorem  <cit.>:\n\nFor any A \u2286 S:\n\n    \u2211_A \u2286 Y \u2286 Sdet(L_Y)=det(L+I_A\u0305),\n\nwhere I_A\u0305 is a diagonal matrix such that I_ii = 0 for indices i \u2208 A and I_ii = 1 for i \u2208A\u0305.\n\nSetting A = \u2205, we obtain the following corollary:\n\n\n    \u2211_A \u2286 Sdet(L_A)=det(L+I_S).\n\n\nTherefore, for any A \u2286 S, we can compute its probability by:\n\n    \ud835\udcab(Y=A)=det(L_A)/det(L+I ),\n\nwhere I is the identity matrix.\n\n\n\n\nWe give a simple example to illustrate how DPPs model diversity. \nSuppose we have two patches i, j to select, i.e. A = {i, j}, we denote the vector of each patch as S_i, S_j \u2208 R^1\u00d7 n, where n is the dimension of elements in S.\nWe can compute the L-ensemble L_ij = S_i^T S_j and their co-occurrence probability by Eq.<ref>. \nThe numerator of Eq.<ref> can be written as:\n det(L_A) = L_ii\u00d7 L_jj - L_ij\u00d7 L_ji.\nNote that L_ij and L_ji measure the similarity between elements i and j, being more similar lowers the probability of co-occurrence. \nOn the other hand, when the subset is very diverse, i.e. L_ij\u00d7 L_ji becomes small, the determinant is bigger and correspondingly its co-occurrence is more likely. \nThe DPP thus naturally diversifies the selection of subsets.\n\nUnfortunately, to our best knowledge, the implementation of exact DPP sampling needs matrix decomposition  <cit.>, which is an unacceptable computation cost during the training iteration.\nThus, to apply DPPs in MIM, an approximation is needed.\n\n\n\n\nGreedy approximation.\nConsidering we only select the subset Y with the highest probability under a cardinality constraint n, then such problem can be defined as:\n\n    Y_MAP = max_Y \u2286 Sdet(L_Y).\n\nThis problem is known as maximum a posteriori (MAP) inference and has been proved as an NP-hard problem in DPPs  <cit.>.\n\nInstead, the greedy algorithm is widely used for approximation <cit.> for MAP inference, justified by the fact that the log-probability of set in DPPs f(Y) =  log det(L_Y) is sub-modular <cit.>.\nThus, the selection process of our method can be described as follows:\n\n    j = max_i\u2208 S\u2216 Y_g f(Y_g \u222a{i}) - f(Y_g),\n\nwhere Y_g is the subset of Y. \nIn each iteration, we add an item that maximizes the marginal gain to Y_g, until the maximal marginal gain emerges negative or goes against the cardinality constraint.\nWe adopt a fast implementation of the greedy MAP inference algorithm for DPPs following  <cit.>.\nFormally, since L is a PSD matrix,\n\nthe Cholesky decomposition of L_Y_g is available as\n\n    L_Y_g = V V^T,\n\nwhere V is an invertible lower triangular matrix. \nFor any i \u2208 Z \u2216 Y_g, the Cholesky decomposition of L_Y_g \u222a{i}can be derived as:\n\n    L_Y_g\u222a{i}=[[    L_Y_g L_Y_g, i; L_i, Y_g    L_i i ]]=[[   V   0; c_i d_i ]][[   V   0; c_i d_i ]]^\u22a4,\n\nwhere row vector c_i and scalar d_i \u2265 0 satisfies:\n\n    V c_i^\u22a4 =L_Y_g, i,     \n    d_i^2 =L_i i-c_i_2^2.\n\nThen the determinate of  L_Y_g\u222a{i} can be written as \n\n    det(L_Y_g\u222a{i})=det(V V^\u22a4) \u00b7 d_i^2=det(L_Y_g) \u00b7 d_i^2.\n\nTherefore, Eq.<ref> is equivalent to select the element i with maximum d_i^2.\n\nAfter solving the equation, the Cholesky factor of L_Y_gcan therefore be efficiently updated after a new item is added to Y_g.\nWith these approximations, the selecting process can be fit in the GPU training loops.\nIn our experiments, the acceleration ratio is up to 10 times faster with respect to exact DPPs sampling and brings the time cost of DPPs to the same level of random, more details can be found in the supplementary.\n\n\n\n\n\n\n \u00a7.\u00a7 Purge misalignment with DPPs\n\nIn this section, we introduce two key factors of DPPMask: kernel and purge ratio.\n\nKernels.\nA common-used type of kernel is the class of Gaussian kernels <cit.>.\nDefined by\n\n    \u2200 S_i, S_j \u2208 S,      L_ij = exp(- ||S_i - S_j||^2/\u03f5).\n\nWhere \u03f5 is called the bandwidth or scale parameter.\nThis kernel depends on the squared Euclidean distance between the intensity values of pairs of patches. \nIt is often used as a similarity measure on patches. \nThe value of the parameter \u03f5 has an impact on how repulsive the DPPs are. \nHowever, note we only choose patches that maximize Eq.<ref>, and the value of \u03f5 influences a little to model performance.\nThis is because \u03f5 will not change the order of distances between patches.\nThus, for better numerical stability, we normalize each patch before computing the distances and set \u03f5 to 1 empirically.\n\n\n\nPurge ratio.\nAs shown in Fig.\u00a0<ref>, DPPMask aims to purge those cases in that semantic information has been changed by masking.\nHowever, DPPMask can get over-purged in some cases.\nAs Fig.\u00a0<ref> shows, due to patches of the sky being too similar to each other, then the greedy selection will only focus on the foreground, as it is more diverse than the background.\nThis situation makes the MIM task too easy and purges most of useful augmented inputs, which is not helpful in feature learning.\nA simple modification can tackle this problem.\nInstead of letting the selection process hit the cardinality constraint, we set a parameter called purge ratio \u03c4\u2208 (0, 1)  as the threshold of maximal marginal gain.\nConcretely, in each iteration, we monitor the distance of the next patch to the selected subsets, if the distance is below the purge ratio \u03c4, abort the greedy selection process and fill the subset will random patches.\nThe purge ratio plays a role of adjust how \"severe\" the DPPMask is.\nIn particular, \u03c4 = 0 indicates the selection process becomes fully greedy and \u03c4 = 1 indicates fully random sampling.\nFig.\u00a0<ref> shows greedy selection under three different purge ratios, a higher purge ratio can prevent DPPMask get over-purged and maintain the input diversity for training the network.\n\nIn this section, we first analyze the training behavior of MIM, then we give our method namely DPPMask which uses DPPs to model the repulsion of image patches, in order to sample the most representative patches and preserve the original semantic information of images.\nWe summarize our algorithm in Alg.\u00a0<ref>.\n\n\n\n\u00a7 EXPERIMENT\n\n\n\n \u00a7.\u00a7 Implementation details\n\nTo examine the effectiveness of our method, we perform DPPMask on two representative MIM methods: MAE <cit.>, iBOT <cit.>, which represent two different MIM frameworks: pixel reconstruction and feature contrast.\nFor MAE, images are patched by convolutional kernels and added with a position embedding, after that, we compute the distances of patches.\nFor iBOT, images are fed into a teacher model to get semantic tokens, which we compute distances based on.\nCompare to direct computing with pixel intensities, semantic tokens may contain more useful information for partitioning images.\nFor example, to identify instances that share similar appearances.\n\nWe adopt two different scales of backbones, ViT-Base and ViT-Small for MAE and iBOT respectively. \nWe mainly evaluate our algorithms on the ImageNet-100 dataset, which is derived from ImageNet-1K <cit.>.\nWe train MAE and iBOT for 400 and 100 epochs respectively.\nUnfortunately, our computational resources can not support us to make out larger-scale experiments, such as more training epochs and heavier backbones. We leave this for future work.\nWe set the masking ratio is set to 0.75 for MAE and 0.7 with 0.05 variance for iBOT by default.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 A detailed study of misalignment\n\nWe give our main result in Tab.\u00a0<ref> and Tab.\u00a0<ref>.\nThe final feature vector for classification is obtained by global pooling.\nFor fine-tuning tasks, we run each setting with three random seeds and report their average performance.\nWe train the iBOT model under the fine-tuning and linear probing parameter setting of MAE for reducing the experiment's complexity.\n\n\n\nThe performance gain brings by DPPMask.\nWe first observed a steady performance gain on fine-tuning tasks in both MAE and iBOT frameworks.\nIn MAE, we make 0.2% accuracy gains.\nIn iBOT, we make 0.4% accuracy gains. \nThis shows our method can improve the representation power by purging the misalignment samples.\nAs the threshold \u03c4 increases, the pre-train loss becomes smaller in response.\n\n\n\n\nHowever, when \u03c4 is too low, greedy sampling goes over-purged and makes the task too simple for the network to learn useful features.\nBesides, iBOT and MAE show different preferences of \u03c4, this is because we apply DPPs on the output of the teacher model, which is a different distribution from MAE.\nFor linear probing, we notice a significant performance drop of MAE.\nThis does not surprise us as we analyze in Sec.\u00a0<ref>.\nDPPs make the sample space shrunk in order to purge the misalignment samples. \nAggregating fewer samples together makes the feature space more continuous and less linear separable.\nNotably, the features also become more precise to describe an image, which can reflect the fine-tuned performance.\nThis behavior is not observed on iBOT, which uses extensive augmentation to further expand the scale of positive samples.\nInstead, iBOT got 0.3% performance gain on linear probing as well as cluster performance (NMI and ACC), which proves our method indeed purged improper samples that hurt feature learning.\nTab.\u00a0<ref> shows our method alongside other advanced sampling methods\non ImageNet-1K, our methods surpassed other sampling methods.\n\nDPPMask makes the MIM task more reasonable.\nAnother key factor of successfully applying MIM is the masking ratio of input images <cit.>.\nIt should be high enough to construct a meaningful reconstruction target while preventing the task from degenerating to simply copying-pasting from neighboring patches.\nHowever, the root cause of the misalignment problem is also the aggressive masking strategy.\nTo better understand the relationship between the masking ratio and the misalignment problem, we study the fine-tuned performance of MAE under different masking ratios.\n\n\nWe perform each experiment three times and report their mean accuracy of ImageNet-100.\nFor DPPs sampling, we run two values of \u03c4, 0.90 and 0.85, we report the higher performance.\nAs Fig.\u00a0<ref> shows, we find that the original 0.75 masking ratio is not the optimal setting for fine-tuned performance.\nInstead, lowering the masking ratio significantly improves the accuracy, this is further evidence of the impact of the misalignment problem on feature learning, as a higher masking ratio raises the probability of misalignment.\nWith DPPs sampling equipped, our method has achieved higher performance in all masking ratio settings.\nIn the masking ratio 0.7, the maximal performance boost reached 0.4%.\nWhen the masking ratio gets lower, the pretext task actually becomes more simple, which leads to a performance drop.\nNotably, we make a better result than the best in MAE (masking ratio at 0.6) with both higher and lower masking ratios (0.5, 0.7).\nThis is meaningful, as the reconstruction problem becomes more simple while our method still performs better than MAE, which shows our sampling method makes the pre-train task more reasonable rather more simple. \n\n\n \u00a7.\u00a7 Robustness\n\nThe misalignment problem makes the network align images with different semantics.\nIn some severe cases, the network may are required to align the original image with the background. \nThus, the misalignment problem can interfere with the network decision by letting the network more focusing the background of images.\nTo verify this, we evaluate the quality of the learned feature on the background challenge <cit.>.\nWe run fine-tuned models of each method on 4 different variations from the original image.\nEach variation replaces the original background with empty (O.F.), with another image in the same class (M.S.), with a random image in any class (M.R.), or with an image from the next class (M.N.), examples are shown in Fig.\u00a0<ref>. Tab.\u00a0<ref> shows the performance of our method on the background challenge.\n\n\n\n\nBoth iBOT and MAE witnessed a steady performance gain in four different variations of original images.\nNotably, our method on MAE achieves 1.08% and 1.13% improvements on O.F. and M.N images respectively, which is higher than the original images (0.86%). \nSuch results were also observed in the iBOT framework.\nOur method achieves 0.42% improvements on original images, while other variations both improved by a large margin.\nIn particular, we achieve 1.58% improvements on M.S. which largely surpasses the original improvements.\nThis shows our methods are more robust to background changes, as we do not impose the network to align the background to the original image as the random strategy does.\n\n\n\n \u00a7.\u00a7 Multi-label classification\n\nTo further examine the influence of the misalignment problem, we also test our method on a multi-label classification task.\nAn intuitive understanding is that: the network can not reflect the semantic changes, which are trained to reconstruct objects whether are been masked or not.\nWhere in multi-label classification, every semantics is important, which makes them suitable to test whether the network is capable to extract whole information of images.\nWe test our method on CLEVR <cit.> and MS-COCO <cit.> datasets, which are widely used in multi-label classification.\nThe CLEVR dataset contains 24 binary labels, each indicating the presence of a particular color and shape (8 \u00d7 3) combination in the image <cit.>.\nFor the MS-COCO dataset, we report the following fine-tuned performance on the validation set: mean average precision (mAP), average per-class F1 score (F1_class), and the average overall F1 score (F1_all)  <cit.>.\nFor the CLEVR dataset, we train MAE with and without DPPs for 200 epochs, we report the linear probing and fine-tuned performance of F1_micro, F1_macro and F1_weighted, where \u2018micro\u2019 evaluate F1 across the entire dataset, \u2018macro\u2019 evaluates an unweighted average of per-label F1 score, and \u2018weighted\u2019 scale the per-label F1 score by a number of examples when taking the average.\nWe show our result in Tab.\u00a0<ref> and Tab.\u00a0<ref>.\nOur method shows better performance on both COCO and CLEVR datasets.\nThis shows our sampling method can select more informative patches for the network to reconstruct or align, which reduces the impact of the misalignment problem.\n\n\n\n \u00a7.\u00a7 Qualitative analysis of DPPs sampling\n\nTo better understand the sampling behavior of DPPs, we compare the DPPs sampling result with random sampling.\nFig.\u00a0<ref> shows the MAE reconstruction result from the ImageNet validation set, each triplet from left to right indicates the original image, reconstruction result with random sampling and DPPs sampling.\nFor each image, we fix the random seed in order to find the difference between DPPs and random.\nWe show coincide patches with white boxes, patches in random sampling while not in DPPs are shown in red boxes, and patches in DPPs while not in random are shown in blue boxes.\nOur experiment shows the reconstruction result of DPP sampling is better than random sampling, which proves that DPPs can represent more complete semantics than random.\nIn particular, the sampling result shows two important properties of DPPs.\nFirst, DPPs can catch the appearance of each object more precisely, which is an important clue for image understanding.\nFor example, the slot of the mailbox is crucial evidence to classify with cabin.\nAnother important property is DPPs can retain more small foreground information, which is highly likely omitted in random sampling.\nSuch properties show our method successfully alleviates the impact of misalignment problem, and achieve better performance in feature learning.\n\nIn our experiments, the MAE does not reconstruct the unobserved semantics, indicating that false positive samples are not perfectly aligned.\nA proper guess of such a phenomenon can be the diversity of ImageNet or the representative capabilities of networks.\nHowever, despite the network does not fall into over-fit, the incorrect gradient of misalignment will still interfere with the learning process.\nOur experiment also shows the potential of MIM with fewer misalignment problems.\n\n\n\n\u00a7 CONCLUSION\n\nIn this paper, we show that uniformly random masking widely used in previous works unavoidably loses some key objects and changes original semantic information, resulting in a misalignment problem and hurting the representative learning\neventually.\nTo this end, we propose a new masking strategy namely the DPPMask to reduce the semantic change of the image after\nmasking.\nWe show that DPPMask can make the MIM task more reasonable by purging the misalignment of training pairs.\nWe hope our work can provide insights to help design a better MIM algorithm.\n\nieee_fullname\n\n\n\n\n\u00a7 IMPLEMENTATION DETAILS OF DPPMASK\n\nSuppose we add i into the subset Y_g \u222a{j}. \nFrom Eq.\u00a0<ref>, we have\n\n    [\n        [   V   0; c_j d_j ]] \n        c_i^'\u22a4 = L_Y_g\u222a{j}, i=\n        [\n        [ L_Y_g, i;    L_j i ]],\n\nwhere\n\n    c_i^'=[\n        [                       c_i (L_j i-\u27e8 c_j, c_i\u27e9) / d_j ]] \u2250[[ c_i e_i ]].\n\nFor updating d_i, we have\n\n    d_i^' 2   =L_i i-c_i^'_2^2 \n       =L_i i-c_i_2^2-e_i^2 \n       =d_i^2-e_i^2.\n\nWith Eq.\u00a0<ref> and Eq.\u00a0<ref>, we can update d incrementally.\n\n\n\n\n\n\u00a7 IMAGENET-100 SETTING\n\nWe follow the original MAE <cit.> experiment setting, except for the learning rate of fine-tuning task.\nWe list our fine-tuning parameters in Tab.\u00a0<ref>.\nFor iBOT <cit.>, we train a ViT-small backbone with 100 epochs. \nWe change the block mask strategy with random, and set masking ratio to 70% with 5% variation.\nWe list our fine-tuning parameters in Tab.\u00a0<ref>\n\n\n\n\n\n\n\n\u00a7 GREEDY APPROXIMATION PERFORMANCE\n\nWe examine the approximation performance with respect to original DPPs.\nWe run each setting with one entire epoch and report the mean time cost of each iteration.\nAs Tab.\u00a0<ref> shows, the greedy approximation achieved 10x faster than original DPPs, which makes it possible to fit into a GPU training loop.\n\n\n\n\u00a7 MORE DISCUSSION ABOUT RELATIVE WORKS\n\nOur method is different from recent masking strategies.\nRecent strategies can roughly divide into two lines of work, learning-based and attention-based.\n\nLearning-based strategies include ADIOS<cit.> and SemMAE<cit.>.\nThey both need extra learning parameters.\nADIOS trains a network to propose masks adversarially, in order to find out more meaningful masks for MIM tasks.\nHowever, the semantic meaningful masks proposed by the network are hard to predict, which is less explainable.\nSemMAE separates the mask learning process from pre-training and makes the training process into two stages.\nThe type of masks they learned are more like semantic parts, such as heads, arms, etc.\nHowever, as the semantics varies in images, the number of classes is hard to define, therefore weakening the application of such methods.\n\nAttention-based strategies include AttMask<cit.> and AMT<cit.>. \nThis line of work selects patches according to the attention map.\nDespite different policies to manipulate the attention map, both intend to retain some patches with high attention scores to give a \"hint\" to the model as such patches are more likely to have more semantics.\nNote this policy aligns with our ideas.\nHowever, they do not associate it with misalignment problems in MIM, thus leading to an inferior policy.\nFurthermore, attention maps require an extra forward pass to compute, which brings more computation. \n\n\n\n\u00a7 ALIGNMENT VERSUS DIVERSITY\n\nAs we discussed in <ref>, DPPMask aims to purge the training pairs that are polluted by misalignment problems.\nHowever, the network also needs irrelevant information between different masks to perform feature learning which can be measured as the variance of sampled masks.\nHere, we show that DPPMask achieves the adjustment between alignment and diversity. \nWe first obtain the original semantic representation by feeding the network with unmasked images and saving the cls token.\nThen, we obtain the masked semantic representation by saving the cls tokens of masked images under different masking strategies.\nWe compute the L2 distance between masked semantics and original semantics to illustrate the alignment of different masking strategies.\nFor masked semantic representation, we run 5 independent trails and compute the L2 distance between each trail to illustrate the diversity of different masking strategies.\nAs shown in <ref>, random masking has the most diversity, but it also suffers from the misalignment problem, i.e. the farthest distance between masked semantics and original semantics\u00a0<ref>.\nAs the \u03c4 decrease, the distance between masked semantics and original semantics has been reduced, indicating more alignment to the original semantics.\nHowever, a lower \u03c4 cause less diversity of different masks, which can purge some useful training pairs and is not helpful for feature learning\u00a0<ref>.\n\n\n\n\n\u00a7 BROADER IMPACT\n\nDespite the eye-catching performance of MIM algorithms, what makes a good mask for MIM tasks still remains unclear.\nDPPMask provides a possible answer to this question.\nBy analog to the InfoMin principle of contrastive learning.\nWe conclude two properties of MIM.\nMasked images should retain the original semantics while minimizing shared information from different masks. \nMinimizing shared information can be achieved by setting a high mask ratio, while how to retain the original semantics is a non-trivial problem.\nFurthermore, DPPMask also models the probability-of-co-occurrence of each patch and thus can serve as a potential tool to study the relationship between such two properties.\n\n"}