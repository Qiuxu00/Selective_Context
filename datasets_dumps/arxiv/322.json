{"entry_id": "http://arxiv.org/abs/2303.06889v1", "published": "20230313062758", "title": "Finding the minimum distance and decoding linear codes with Gaussian Elimination Method", "authors": ["Tianshuo Yang"], "primary_category": "cs.IT", "categories": ["cs.IT", "cs.CR", "math.IT"], "text": "\n\n\n\n\n\n\n\n[Tianshuo Yang: Department of Robotics Engineering, Widener University, Chester, PA 19013, USA, Email: tyang3@widener.edu.]\n\n\nWe propose an algorithm using the Gaussian elimination method to find the minimal Hamming distance and decode received messages of linear codes. This algorithm is easy to implement as it requires no Gr\u00f6bner bases to compute solutions for systems of polynomial equations. \n\n\nFinding the minimum distance and decoding linear codes with the Gaussian elimination method\n    Tianshuo Yang\n    March 30, 2023\n===========================================================================================\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nLet \ud835\udd42 be a field and \ud835\udd42^n the n-dimensional \ud835\udd42-vector space. A linear code C of length n over \ud835\udd42 is a subspace of \ud835\udd42^n. Let v=[[ v_1   \u2026 v_n ]] and w=[[ w_1   \u2026 w_n ]] be two vectors in \ud835\udd42^n. Recall the (Hamming) distance from v to w, denoted by d(v, w), is defined to be the number of positions at which v and w differ. The (Hamming) weight of v, denoted by wt(v), is defined as d(v, 0), i.e., the number of entries in v that are different from zero. Let C be a code containing at least two codewords. The minimum (Hamming) distance of C is defined as d(C)= min{d(v, w) | v, w\u2208 C, v\u2260w} and the minimum (Hamming) weight of C is defined as wt(C)= min{ wt (v) | v\u2208 C, v\u22600}. In the case that C is a linear code, one has d(C)= wt(C). By an [n, k, d] linear code C we mean a k-dimensional subspace of \ud835\udd42^n such that the minimum distance d(C)=d. Under the standard coding theory, the code C can detect up to d-1 errors and correct up to \u230ad-1/2\u230b errors. Thus, determining the value of d is critical for understanding the error detection/correction capability of C. However, Vardy <cit.> showed that for general linear codes, computing the minimum distance is an NP-hard problem and the corresponding decision problem is NP-complete. Hence any general algorithm for computing the minimum distance will run in super polynomial time unless P=NP.\n\nHistorical techniques of decoding and computing the minimal distance reduce the problems to systems of polynomial equations in several variables over finite fields and then use Gr\u00f6bner bases to solve them (see for example <cit.>, <cit.>, and <cit.>).\n\nGr\u00f6bner bases can be computed via computer algebra packages such as Axiom, CoCoA, Gap, Macaulay, Singular, etc. The complexity of computing them is exponential in the case of a finite set of solutions. Motivated by the work of M. De Boer and R. Pellikaan <cit.>, B. Anzis and S. Toh\u0103neanu <cit.>, and R. Burity, S. Toh\u0103neanu and Y. Xie <cit.>, we reduce the problem of decoding and computing the minimal distance to systems of linear equations in several variables and use Gaussian elimination in linear algebra to compute their solutions.\n\nThis paper is structured as follows: In next section, we propose an algorithm using Gaussian elimination for computing the minimal distance and codewords with minimal distance for a linear code. Then we provide a similar algorithm to decode received messages of a linear code in Section 3. After that, we show examples to illustrate our algorithms. In the last section, we close the paper with concluding remarks.\n\n\n\n\u00a7 THE MINIMAL HAMMING DISTANCE\n\n\nLet C be an [n, k, d] linear code over the field \ud835\udd42. Since C is a k-dimensional subspace of the vector space \ud835\udd42^n, one can use a basis of C to form a generating matrix of rank k\n\n    G=[[ a_11 a_12    \u22ef a_1n; a_21 a_22    \u22ef a_2n;    \u22ee    \u22ee    \u22ee; a_k1 a_k2    \u22ef a_kn ]],\n\nwhere a_ij\u2208\ud835\udd42. Observe C is the image of the injective linear map \u03d5: \ud835\udd42^k \ud835\udd42^n via \u03d5(x)=xG for x\u2208\ud835\udd42^k. Assume G is nondegenerate, i.e., none of the columns of G is the zero column vector in \ud835\udd42^k.\n\nLet R=\ud835\udd42[x_1, \u2026, x_k] be a polynomial ring of k variables over the field \ud835\udd42. Observe the n columns in the generating matrix G define n nonzero homogeneous linear forms \u2113_j=\u2211_i=1^ka_ijx_i 1\u2264 j\u2264 n, in R.  These linear forms \u2113_1, \u2026, \u2113_n are called the defining linear forms for the linear code C. For 1\u2264 a\u2264 n, the ideal generated by a-fold products of linear forms of C is defined as\n\n    I_a(C)=\u27e8{\u2113_i_1\u22ef\u2113_i_a |  1\u2264 i_1<\u22ef<i_a\u2264 n}\u27e9.\n\n\nLet \u2119_\ud835\udd42^k-1 be the projective (k-1)-space. Recall the projective variety defined by a homogeneous ideal J\u2282 R is V(J)={P\u2208\u2119_\ud835\udd42^k-1 |  f(P)=0      f\u2208 J}.\n\nLet v be a nonzero codeword in C. Then v=xG, where 0\u2260x\u2208\ud835\udd42^k. Observe wt(v)\u2264 e if and only if all products of e+1 distinct entries of v are zero. This means x is a nonzero solution for all of the equations \u2113_i_1\u22ef\u2113_i_e+1=0, where 1\u2264 i_1<\u22ef<i_e+1\u2264 n, i.e., x\u2208 V(I_e+1(C)). One has that (see <cit.>)\n\n    V(I_a(C))={x\u2208\u2119_\ud835\udd42^k-1 |  wt(v)<a    with  v=xG},\n\nand\n\n    d= min{a  |  V(I_a+1(C))\u2260\u2205}.\n\n\nLet \u0393(C) be the set of all linear prime ideals generated by linear forms in {\u2113_1, \u2026, \u2113_n}. Let \ud835\udd2d\u2208\u0393(C) and \u03bd_C(\ud835\udd2d) be the number of linear forms in {\u2113_1, \u2026, \u2113_n} that belong to \ud835\udd2d. The irrelevant maximal ideal \ud835\udd2a=\u27e8 x_1, \u2026, x_k\u27e9=\u27e8\u2113_1, \u2026, \u2113_n\u27e9 and \u03bd_C(\ud835\udd2a)=n. By <cit.>, for 1\u2264 a\u2264 n, the ideal I_a(C) has the primary decomposition\n\n    I_a(C)=\u2229_\ud835\udd2d\u2208\u0393(C)\ud835\udd2d^a-n+\u03bd_C(\ud835\udd2d),\n\nwhere if a-n+\u03bd_C(p)\u2264 0, then the corresponding component is replaced with the ring R.\n\nConsider the case a=1 and I_1(C)=\u27e8\u2113_1, \u2026, \u2113_n\u27e9=\u27e8 x_1, \u2026, x_k\u27e9. One has V(I_1(C))=\u2205 as \u2113_1, \u2026, \u2113_n span a k-dimensional vector space so that the homogeneous equations \u2113_1=0, \u2026, \u2113_n=0 have only the trivial solution 0 in \ud835\udd42^k. By the above results, to compute the minimal distance d, one needs to find the maximum number of linear forms in {\u2113_1, \u2026, \u2113_n} that span a k-1-dimensional vector space.\nIn other words, d is the minimal number of linear forms we have to delete from {\u2113_1, \u2026, \u2113_n} so that the remaining linear forms span a k-1-dimensional vector space. The question of whether a set of linear forms span a (k-1)-dimensional vector space can be answered by reducing the matrix formed by the coefficients of these linear forms to a row echelon matrix and looking at the rank.\nSince we need at least k-1 linear forms to span a k-1-dimensional vector space, one has that 1\u2264 d\u2264 n-k+1. We state the algorithm using Gaussian elimination for computing the minimal distance and codewords with minimal distance in the following:\n\n\nAlgorithm 2.1\n\n\n\n\n  * Input a generating matrix G of size k\u00d7 n\n\n  * For 1\u2264 j\u2264 n-k+1\n\n  *   Compute S_j={{i_1, \u2026, i_j} |  1\u2264 i_1<i_2<\u22ef<i_j\u2264 n}\n\n  *   For each {i_1, \u2026, i_j}\u2208 S_j\n\n  *     Let G_i_1\u22ef i_j be the matrix obtained from G by deleting j columns i_1, \u2026, i_j\n\n  *     Reduce G_i_1\u22ef i_j^T to a row echelon matrix H. Compute rank(H).\n\n  *     If rank(H)<k\n\n         Solve the system of linear equations Hx=0 in the projective space \u2119_\ud835\udd42^k-1\n\n         Store the solutions in the set X\n\n  *   If X\u2260\u2205, let d=j and Y=X^TG. Return d, X, and Y.\n\n\n\nIn the above algorithm, observe |S_j|=nj for each 1\u2264 j\u2264 n-k+1. Thus the complexity of this algorithm is large as the number of all possible subsets of {1, \u2026, n} grows exponentially. However, the algorithm is easy to implement and requires no symbolic computations in computer algebra systems.\n\n\n\n\u00a7 DECODING LINEAR CODES\n\n\nLet C be an [n, k, d] linear code with a generating matrix G as in Section 2. Suppose that a codeword w=[[ w_1   \u2026 w_n ]]\u2208\ud835\udd42^n is received. The most commonly used rule for decoding w is to find the codeword v\u2208 C which minimizes wt(w-v) (i.e., v is the nearest neighbor of w in C), and decode w to v. Of course, a codeword w\u2209C might have more than one nearest neighbors. In this case the nearest neighbor decoding rule fails. As we have mentioned above, the minimal distance d determines the error detection/correction capability of C as it can detect up to d-1 errors and correct up to \u230ad-1/2\u230b errors.\n\nTraditionally one translates the syndrome decoding algorithm into the language of varieties (called syndrome varieties) and use computational algebraic techniques (such as Gr\u00f6bner bases) to find the error and the nearest neighbor of a received word (see for example <cit.>, <cit.>, and <cit.>). In 2015, it was shown in <cit.> that any error with weight up to \u230ad-1/2\u230b in data transmission can be computed as the codeword of minimum weight of a new linear code C(w) with a generating matrix\n\n    G(w)=[[ a_11 a_12    \u22ef a_1n;    \u22ee    \u22ee    \u22ee; a_k1 a_k2    \u22ef a_kn;  w_1  w_2    \u22ef  w_n ]],\n\nwhich is created from the generator matrix G of C by augmenting the received word w as a new row (a code with such a generating matrix is called an augmented code). Let d(w)= min{ wt(e) | e\u2208\ud835\udd42^n    with  w-e\u2208 C}= min{ wt(e) | e\u2208 C(w)}. Then one can compute the codeword of minimum weight by solving the ideal I_d(w)+1(C(w)) using Gr\u00f6bner bases or by finding a primary decomposition of this ideal. Both methods require symbolic computations.\n\nApplying similar idea to the new linear code C(w) as in Section 2, we can use Gaussian elimination to compute the codeword of minimal weight in C(w). Hence we obtain the following algorithm for decoding a linear code C with minimal distance d:\n\n\nAlgorithm 3.1\n\n\n\n\n  * Input a generating matrix G of size k\u00d7 n and a received message w\n\n  * Let G(w) be the matrix obtained by appending w to G in the last row\n\n  * For 1\u2264 j\u2264\u230ad-1/2\u230b\n\n  *   Compute S_j={{i_1, \u2026, i_j} |  1\u2264 i_1<i_2<\u22ef<i_j\u2264 n}\n\n  *   For each {i_1, \u2026, i_j}\u2208 S_j\n\n  *     Let G(w)_i_1\u22ef i_j be the matrix obtained from G(w) by deleting j columns i_1, \u2026, i_j\n\n  *     Reduce G(w)_i_1\u22ef i_j^T to a row echelon matrix H. Compute rank(H).\n\n  *     If rank(H)<k+1\n\n         Solve the system of equations Hx=0 in the projective space \u2119_\ud835\udd42^k\n\n         Let x be the nonzero solution (with the last entry =1)\n\n         Let e=x^TG(w) and v=w-e\n\n         Return e and v\n\n  * Return w is non-decodable\n\n\n\n\n\u00a7 EXAMPLES\n\n\nIn this section, we provide examples to illustrate the above algorithms for computing the minimal distance and decoding linear codes.\n\n\nExample 4.1   Let \ud835\udd42=\ud835\udd3d_2. Consider the linear code C with a generating matrix\n\n    G=[[ 1 0 0 1 1 0; 0 1 0 1 0 1; 0 0 1 0 1 1 ]].\n\nThis code has 6 homogeneous linear forms x_1, x_2, x_3, x_1+x_2, x_1+x_3, x_2+x_3 generated by the columns of G. Applying Algorithm 2.1, we found that d=d(C)=3 and there are 4 linear prime ideals of height 2; each is generated by n-d=6-3=3 linear forms: \ud835\udd2d_1=\u27e8 x_1+x_2, x_1+x_3, x_2+x_3\u27e9, \ud835\udd2d_2=\u27e8 x_2, x_3, x_2+x_3\u27e9, \ud835\udd2d_3=\u27e8 x_1, x_3, x_1+x_3\u27e9, and \ud835\udd2d_4=\u27e8 x_1, x_2, x_1+x_2\u27e9. To find \u222a_i=1^4V(\ud835\udd2d_i), we solve the 4 homogeneous linear systems with augmented matrices (formed by the coefficients of linear forms in \ud835\udd2d_i, 1\u2264 i\u2264 4)\n\n    [[ 1 1 0 0; 1 0 1 0; 0 1 1 0 ]],\n    [[ 0 1 0 0; 0 0 1 0; 0 1 1 0 ]],\n    [[ 1 0 0 0; 0 0 1 0; 1 0 1 0 ]],\n    [[ 1 0 0 0; 0 1 0 0; 1 1 0 0 ]],\n\nand obtain 4 nonzero solutions x_1=[[ 1 1 1 ]]^T, x_2=[[ 1 0 0 ]]^T,\nx_3=[[ 0 1 0 ]]^T, and x_4=[[ 0 0 1 ]]^T. This yields 4 codewords in C of minimal weight 3:\n\n    y_1   =   x_1^TG=[[ 1 1 1 0 0 0 ]],\n    y_2   =   x_2^TG=[[ 1 0 0 1 1 0 ]],\n    y_3   =   x_3^TG=[[ 0 1 0 1 0 1 ]],\n    y_4   =   x_4^TG=[[ 0 0 1 0 1 1 ]].\n\nHence the outputs of Algorithm 2.1 are\n\n    d=3,\n\n\n    X={[[ 1 1 1 ]]^T, [[ 1 0 0 ]]^T, [[ 0 1 0 ]]^T, [[ 0 0 1 ]]^T},\n\nand\n\n    Y={[ [[ 1 1 1 0 0 0 ]] [[ 1 0 0 1 1 0 ]];                  ; [[ 0 1 0 1 0 1 ]] [[ 0 0 1 0 1 1 ]] ]}.\n\n\nIndeed, there are 8 codewords in C, i.e.,\n\n    C={[ [[ 0 0 0 0 0 0 ]] [[ 1 0 0 1 1 0 ]] [[ 0 1 0 1 0 1 ]] [[ 0 0 1 0 1 1 ]];                  ; [[ 1 1 0 0 1 1 ]] [[ 1 0 1 1 0 1 ]] [[ 0 1 1 1 1 0 ]] [[ 1 1 1 0 0 0 ]] ]}.\n\nOne can see that d(C)=3 and there are 4 codewords in C of minimal weight 3.\n\nSince d(C)=3, the linear code C can fix one error. Suppose the codeword w=[[ 0 1 1 1 0 0 ]] is received. Then we have the augumented code C(w) with the augumented matrix\n\n    G(w)=[[ 1 0 0 1 1 0; 0 1 0 1 0 1; 0 0 1 0 1 1; 0 1 1 1 0 0 ]].\n\nThe augumented code C(w) has 6 homogeneous linear forms x_1, x_2+x_4, x_3+x_4, x_1+x_2+x_4, x_1+x_3, x_2+x_3 generated by the columns of G(w). Applying Algorithm 3.1, we have d(C(w))=1 and there is a unique linear prime ideal of height 3 generated by n-d=6-1=5 linear forms: \ud835\udd2d=\u27e8 x_1, x_2+x_4, x_3+x_4, x_1+x_2+x_4, x_2+x_3\u27e9. \nAgain to find V(\ud835\udd2d), we solve the homogeneous linear system with augmented matrix (formed by the coefficients of linear forms in \ud835\udd2d)\n\n    [[ 1 0 0 0 0; 0 1 0 1 0; 0 0 1 1 0; 1 1 0 1 0; 0 1 1 0 0 ]]\n\nand obtain the unique nonzero solution x=[[ 0 1 1 1 ]]^T. The error codeword e=x^TG(w)=[[ 0 0 0 0 1 0 ]]. Hence the codeword in C with minimal distance to w is\n\n    v=w-e=[[ 0 1 1 1 1 0 ]].\n\nThe outputs of Algoritm 3,1 are e=[[ 0 0 0 0 1 0 ]] and v=[[ 0 1 1 1 1 0 ]], and we decode w to v.\n\n\nExample 4.2   Let \ud835\udd42=\ud835\udd3d_2. Consider the [7, 4] cyclic code C generated by the polynomial g(x)=1+x^2+x^3. Then this code has a generating matrix (note that we identify a vector with a polynomial)\n\n    G=[[    g(x);   xg(x); x^2g(x); x^3g(x) ]]=\n    [[ 1 0 1 1 0 0 0; 0 1 0 1 1 0 0; 0 0 1 0 1 1 0; 0 0 0 1 0 1 1 ]].\n\nThis code has 7 homogeneous linear forms x_1, x_2, x_1+x_3, x_1+x_2+x_4, x_2+x_3, x_3+x_4, x_4 generated by the columns of G. Applying Algorithm 2.1, we found that d=d(C)=3 and there are 7 linear prime ideals of height 3 generated by n-d=7-3=4 linear forms: \ud835\udd2d_1=\u27e8 x_1, x_2, x_1+x_3, x_2+x_3\u27e9, \ud835\udd2d_2=\u27e8 x_1, x_2, x_1+x_2+x_4, x_4\u27e9, \ud835\udd2d_3=\u27e8 x_1, x_1+x_3, x_3+x_4, x_4\u27e9,\n\ud835\udd2d_4=\u27e8 x_1, x_1+x_2+x_4, x_2+x_3, x_3+x_4\u27e9, \ud835\udd2d_5=\u27e8 x_2, x_1+x_3, x_1+x_2+x_4, x_3+x_4\u27e9, \ud835\udd2d_6=\u27e8 x_2, x_2+x_3, x_3+x_4, x_4\u27e9, and \ud835\udd2d_7=\u27e8 x_1+x_3, x_1+x_2+x_4, x_2+x_3, x_4\u27e9.\n\nTo find \u222a_i=1^7V(\ud835\udd2d_i), we solve the 7 homogeneous linear systems with augmented matrices (formed by the coefficients of linear forms in \ud835\udd2d_i, 1\u2264 i\u2264 7)\n\n    [[ 1 0 0 0 0; 0 1 0 0 0; 1 0 1 0 0; 0 1 1 0 0 ]],\n    [[ 1 0 0 0 0; 0 1 0 0 0; 1 1 0 1 0; 0 0 0 1 0 ]],\n    [[ 1 0 0 0 0; 1 0 1 0 0; 0 0 1 1 0; 0 0 0 1 0 ]],\n    [[ 1 0 0 0 0; 1 1 0 1 0; 0 1 1 0 0; 0 0 1 1 0 ]],\n\n\n    [[ 0 1 0 0 0; 1 0 1 0 0; 1 1 0 1 0; 0 0 1 1 0 ]],\n    [[ 0 1 0 0 0; 0 1 1 0 0; 0 0 1 1 0; 0 0 0 1 0 ]],\n    [[ 1 0 1 0 0; 1 1 0 1 0; 0 1 1 0 0; 0 0 0 1 0 ]],\n\nand obtain 7 nonzero solutions, i.e., X={x_i  |  1\u2264 i\u2264 7}, where \nx_1=[[ 0 0 0 1 ]]^T, \nx_2=[[ 0 0 1 0 ]]^T,\nx_3=[[ 0 1 0 0 ]]^T,\nx_4=[[ 0 1 1 1 ]]^T,\nx_5=[[ 1 0 1 1 ]]^T,\nx_6=[[ 1 0 0 0 ]]^T,\nand x_7=[[ 1 1 1 0 ]]^T. \nThis yields 7 codewords in C of minimal weight 3, i.e.,\nY={y_i  |  1\u2264 i\u2264 7}, where\n\n    y_1   =   x_1^TG=[[ 0 0 0 1 0 1 1 ]],\n    y_2   =   x_2^TG=[[ 0 0 1 0 1 1 0 ]],\n    y_3   =   x_3^TG=[[ 0 1 0 1 1 0 0 ]],\n    y_4   =   x_4^TG=[[ 0 1 1 0 0 0 1 ]],\n    y_5   =   x_4^TG=[[ 1 0 0 0 1 0 1 ]],\n    y_6   =   x_4^TG=[[ 1 0 1 1 0 0 0 ]],\n    y_7   =   x_4^TG=[[ 1 1 0 0 0 1 0 ]].\n\nBy computing the 16 codewords in C, one can verify that d(C)=3 and there are 7 codewords of minimal weight 3.\n\nAgain since d(C)=3, the cyclic code C can only fix one error. Suppose w=[[ 1 1 0 1 0 1 1 ]] is the received codeword. Then we have the augumented code C(w) with the augumented matrix\n\n    G(w)=[[ 1 0 1 1 0 0 0; 0 1 0 1 1 0 0; 0 0 1 0 1 1 0; 0 0 0 1 0 1 1; 1 1 0 1 0 1 1 ]].\n\nThis augumented code C(w) has 7 homogeneous linear forms x_1+x_5, x_2+x_5, x_1+x_3, x_1+x_2+x_4+x_5, x_2+x_3, x_3+x_4+x_5, x_4+x_5 generated by the columns of G(w). Applying Algorithm 3.1, we have d(C(w))=1 and there is a unique linear prime ideal of height 4 generated by n-d=7-1=6 linear forms: \ud835\udd2d=\u27e8 x_1+x_5, x_2+x_5, x_1+x_3, x_1+x_2+x_4+x_5, x_2+x_3, x_4+x_5\u27e9. \nTo find V(\ud835\udd2d), we solve the homogeneous linear system with augmented matrix (formed by the coefficients of linear forms in \ud835\udd2d)\n\n    [[ 1 0 0 0 1 0; 0 1 0 0 1 0; 1 0 1 0 0 0; 1 1 0 1 1 0; 0 1 1 0 0 0; 0 0 0 1 1 0 ]]\n\nand obtain the unique nonzero solution x=[[ 1 1 1 1 1 ]]^T. The error codeword e=x^TG(w)=[[ 0 0 0 0 0 1 0 ]]. Hence the codeword in C with minimal distance to w is\n\n    v=w-e=[[ 1 1 0 1 0 0 1 ]].\n\nThe outputs of Algoritm 3,1 are e=[[ 0 0 0 0 0 1 0 ]] and v=[[ 1 1 0 1 0 0 1 ]], and we decode w to v.\n\n\n\n\n\u00a7 CONCLUDING REMARKS\n\n\nThe purpose of this paper is to propose a practical algorithm for computing the minimal distance and decoding general linear codes without using symbolic computations in computer algebra systems. The computational complexity of this algorithm is large as one cannot hope for a polynomial algorithm to decode and compute the minimal distance for general linear codes. However since the implementation is not hard, one can use it to compute certain examples to verify your intuition. This can help design new linear codes.\n\nOne can modify the above algorithm to compute other things for an [n, k] linear code C such as the primary decomposition of I_a(C) for 1\u2264 i\u2264 n, the weight distribution {(i, \u03b1_i) | i=0, 1, \u2026, n}, where \u03b1_i denotes the number of codewords in C of weight i, the polynomial W_C(X, Y)=\u2211_i=0^n\u03b1_iX^n-iY^i, and the MacWilliams identity W_C^\u22a5(X, Y)=q^-kW_C(X+(q-1)Y, X-Y), where \ud835\udd42=\ud835\udd3d_q is a finite field of q elements and C^\u22a5 is the dual code of C.\n\nThis algorithm may be improved to reduce the computational complexity in special classes of linear codes. For example, if the generator matrix G is of the form [[ G_1   \u22ef G_s ]], where G_1, \u2026, G_s are matrices such that the first k columns of G_j form the k\u00d7 k identity matrix for all j=1, \u2026, s, we know that any linear combination of r rows with non-zero coefficients gives a codeword of weight at least rs. Hence s\u2264 d\u2264 n-k+1 and we can start our loop from j=s. In the future, one may implement this algorithm to study special classes of linear codes such as cyclic codes, maximum distance separable (MDS) codes, BCH codes, Golay codes, etc.\n\n0.5in\namsalpha\n10\n\nAT\nB. Anzis and S. Toh\u0103neanu, Error-correction of linear codes via colon ideals, J. Algebra 443 (2015), 479-493.\n\nBP\nS. Bulygin and R. Pellikaan, Decoding and finding the minimum distance with  Gr\u00f6bner bases: history and new insights, pp.\n585-622 in: I. Woungang, S. Misra, S. C. Misra (editors). Series on Coding Theory and Cryptology vol. 7, Selected Topics in\nInformation and Coding Theory, World Scientific 2010.\n\nBTX\nR. Burity, S. Toh\u0103neanu and Y. Xie, Ideals generated by a-fold products of linear forms have linear graded free resolution, to\nappear in Michigan Math J., arXiv: 2004.07430.\n\nDP1\nM. De Boer and R. Pellikaan, Gr\u00f6bner bases for codes, In: Some Tapas of Computer Algebra, 237-259, Springer, Berlin 1999.\n\nDP2\nM. De Boer and R. Pellikaan, Gr\u00f6bner bases for decoding, In: Some Tapas of Computer Algebra, 260-275, Springer, Berlin 1999.\n\n\n\n\nV\nA. Vardy, The intractability of computing the minimum distance of a code, IEEE Trans. Inf. Theory, 43 (1997), 1757-1766.\n\n\n"}