{"entry_id": "http://arxiv.org/abs/2303.06776v1", "published": "20230312233142", "title": "Robot Health Indicator: A Visual Cue to Improve Level of Autonomy Switching Systems", "authors": ["Aniketh Ramesh", "Madeleine Englund", "Andreas Theodorou", "Rustam Stolkin", "Manolis Chiou"], "primary_category": "cs.RO", "categories": ["cs.RO", "cs.HC", "I.2.9"], "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAxr1050@student.bham.ac.uk\n\n  Extreme Robotics Laboratory, University of Birmingham\n  Edgbaston\n  Birmingham\n  England\n  B15 2TT\n\n\n\nMaen0191@student.umu.se\n\n\n\n\n\n\n\n\nAndreas.Theodorou@umu.se\n\n  Ume\u00e5 university\n  MIT-huset\n  Ume\u00e5\n  Sweden\n  901 87\n\n\n\nR.Stolkin@bham.ac.uk\n\nM.Chiou@bham.ac.uk\n\n  Extreme Robotics Laboratory,\n University of Birmingham\n  Edgbaston\n  Birmingham\n  England\n  B15 2TT\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing different Levels of Autonomy (LoA), a human operator can vary the extent of control they have over a robot's actions. LoAs enable operators to mitigate a robot's performance degradation or limitations in the its autonomous capabilities. However, LoA regulation and other tasks may often overload an operator's cognitive abilities. Inspired by video game user interfaces, we study if adding a Robot Health Bar  to the robot control UI can reduce the cognitive demand and perceptual effort required for LoA regulation while promoting trust and transparency. This Health Bar uses the robot vitals and robot health framework to quantify and present runtime performance degradation in robots. Results from our pilot study indicate that when using a health bar, operators used to manual control more to minimise the risk of robot failure during high performance degradation. It also gave us insights and lessons to inform subsequent experiments on human-robot teaming.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobot Health Indicator: A Visual Cue to Improve Level of Autonomy Switching Systems\n    Manolis Chiou\n    \n===================================================================================\n\n\n\n\n\n\u00a7 INTRODUCTION AND RELATED WORK\n\n\nDuring mobile robot navigation tasks, factors like uneven terrain, obstacles, sensor noise etc. can degrade a robot's performance. If left unattended, performance degradation can cause robots to fail or perform sub-optimally <cit.>. Timely operator intervention or triggering of recovery behaviours can mitigate this. Using Levels of Autonomy (LoA) <cit.>, the extent of control that a human operator has over the robot's actions can be varied. For example during high performance degradation, an autonomous robot can be switched to manual control by an experienced human operator. The LoA can be switched back once the robot is capable of functioning autonomously again.\n\nIn Human Initiative (HI) LoA switching systems, the robot operator is in charge of LoA regulation during the task. Compared to fully autonomous robots, manually controlled robots, and other implementations of variable autonomy systems, HI-LoA shows better task performance during remote navigation tasks in unknown environments <cit.>. However, the additional perceptual and mental effort required to monitor robot operation data and determine if LoA switching is needed, imposes comparatively higher levels of cognitive workload on the operator. While overloading an operator's cognitive abilities for prolonged periods can reduce task performance <cit.> due to stress, fatigue and varying levels of trust in the system <cit.>, low workload can cause out-of-loop performance problems like complacency and over-trusting the system <cit.>.\n\nEffective HI-LoA system design remains an open problem in existing literature <cit.>. A well-designed system should keep operator cognitive workload within a sweet spot  <cit.> (i.e., acceptable levels). LoA switches by operators should be due to a clear understanding of the robot's capabilities and limitations, not due to trust issues. Transparent design, i.e., where the operator can accurately interpret the robot's capabilities, goals, and its progress, have reported effective calibration of trust <cit.>, even with increasing levels of automation <cit.>. Systems where information about the robot is presented over the graphic/visual modalities are trusted more than the audio and textual modalities <cit.>. Independent of systems design considerations, significant differences still exist in people's perceived reliability of variable autonomy systems. However, they can be minimised through standardised training <cit.>. \n\nVideo games serve as inspiration to understand how real-time information can be presented in a transparent manner, while keeping the operator cognitive workload in the sweet spot. Video game players report that they are receptive to information presented through visual cues as long as they are clear and consistent <cit.>. Game visual cues are usually colour coded UI elements overlayed on the interface during gameplay, e.g. the Health Bar. In popular online games[See https://overwatch.blizzard.com/en-us/], remotely situated players use these cues to get their teammates attention. Similarly, robot operators can use colour coded visual cues to acquire quick situational awareness <cit.> while operating a robot with minimum perceptual effort. For robot interfaces, Murphy et al. <cit.> recommend that visual cues may be added to the robot control UI, without blocking useful information.\n\n\n\nThe existing literature shows that effective trust calibration, system transparency and standardised training are crucial for a well designed HI-LoA switching system. Information to assist the operator with making decisions about LoA regulation can be presented through properly designed visual cues. Therefore, in this study, we present our pilot experiments to explore how visual cues about a robot's performance degradation can help LoA regulation decisions during high cognitive workload situations. Based on the Robot Vitals and Robot Health framework <cit.> to quantify performance degradation, we design a colour coded Robot Health Bar  UI element. We hypothesise that using the Health Bar will reduce the perceptual effort required by operators to make LoA switching decisions, improve task performance, and result in a lower overall cognitive workload. We also took feedback from the participants about their overall trust in the system, its transparency and recommendation for improving the Health Bar design.\n\n\n\n\u00a7 SYSTEM DESIGN\n\n\nThe experiment consisted of two tasks, similar to the experiments setup by Chiou et al. <cit.>. The primary task was a mobile robot navigation task using the Clearpath Husky Robot, simulated on Gazebo. As shown in Figure <ref>, these arenas were designed to mimic urban search and rescue scenarios, and were populated with performance degrading factors commonly found in them like - obstacles, uneven terrain and laser noise. A 2D laser scan of an empty map (Figure <ref> - Right) was generated before the performance degrading factors were added. The difference between the map used for robot navigation and the actual arena affects robot navigation planning, thereby adding another performance degrading factor. Two different arenas were created to compare operator performance with (condition A) and without the Health Bar (condition B). \n\n\n\n\nRViz was used to visualise the robot map, sensor data, and give commands to the robot. The standard RViz interface in Figure <ref> was used for Condition B, and the interface with a Robot Health Bar  shown in Figure <ref> was used for Condition A. The Husky robot used two LoAs - 1) Waypoint-based navigation and 2) Manual Control by an operator using a Joystick. The Robot Health at each instant was calculated using the Robot Vitals and Robot Health framework <cit.>, and the Health Bar was created and displayed using the JSK Visualisations[http://wiki.ros.org/jsk_visualization/] ROS Package. Here, Robot Health is defined as an overall scalar estimate of a robot\u2019s ability to carry out its tasks without its capabilities being impaired by any performance degrading factors . Therefore, an operator can monitor the health to detect situations where a robot is likely to fail, and trigger LoA switches to assist the robot. To improve readability, the Robot Health was standardised to the range [0,1]. The Red-Amber-Green colour coding convention was used for the Health Bar as shown in Figure <ref>. Based on preliminary experiments, health above 0.7 was decided as Healthy , and the colour of the Health Bar was green. Values between 0.5-0.7 were coloured in amber, and values below 0.5 were coloured red. Instead of sharp colour changes, the Health Bar gradually went from green to amber to red. This was done to minimise rapid colour changes due to small fluctuations in health near the threshold values.\n\nThe secondary task was a 3D object rotation task <cit.>, used to induce additional cognitive workload for the operator. Here participants were successively presented with two 3D objects. They had to determine whether the objects were the same or different. Instead of having a fixed time limit like in Chiou et al.<cit.>, here the participants did this task throughout the runtime.  Both the primary and secondary tasks were displayed on adjacent screens. Participants were explicitly instructed to prioritise the robot navigation task and minimise the likelihood of robot failure . They were also told to simultaneously do the secondary task to the best of their ability, and that they were not being evaluated on their performance in it.\n\n\n\n\n\n\n\u00a7 EXPERIMENT METHODOLOGY\n\nEight test subjects participated in the experiment and performed both conditions (i.e. within subjects design). The order of the conditions was counterbalanced to minimise learning and fatigue effects. First, participants had to fill out background information (see appendix <ref>). Then they were introduced to basic robot navigation in a training arena similar to the one used in Chiou et al.<cit.>. All participants trained on this arena till they were able to demonstrate a minimum proficiency in robot navigation. This ensured that confounding factors due to a variation in skill levels were minimised. Next, they were shown the 2 different LoA, how to switch between them and were given some time to practice LoA switching on the training arena. \n\nParticipants were then introduced to the interface with the Health Bar and asked open-ended questions without prior explanation (see appendix <ref>). After answering the questions, they were given the following instructions regarding the Health Bar: \u201cThe Robot Health Bar indicates how much a robot\u2019s performance is degraded by environmental factors. These environmental factors can be anything ranging from bad terrain to laser noise. During low health, the Health Bar will become redder. During high health, the Health Bar will become greener. The lower the robot's health, the more likely it will fail. You may use the Health Bar to help you determine when the robot requires a LoA switching\u201d. The effect of performance degrading factors on the Health Bar was demonstrated by introducing obstacles and laser noise in the training arena. Participants were also given time to familiarise themselves with the interface before starting the navigation task. Next participants were familiarised only with the secondary task, and allowed multiple practice runs till they felt comfortable with it. Their baseline on the secondary task alone was measured before the experiment.\n\n\n\nBefore each condition, participants were shown the start and finish points in the navigation task and told that the next waypoint would be assigned automatically on reaching the current one. Then the participants carried out each experimental condition followed by a NASA-TLX form to evaluate the perceived cognitive workload during the task. Lastly, participants completed open-ended questions and a transparency/trust questionnaire after the experimental trials and the NASA-TLX forms (see <ref> and <ref>).\n \n\n\n\n\n\n\n\n\n\n\n\n\u00a7 RESULTS\n\n\nRobot health values under 0.7 were classified as unhealthy . This criterion was heuristically determined based on previous studies on the robot vitals and robot health framework <cit.>. Results from the experiments conducted on 8 participants were computed and tested for statistical differences using two-tailed pairwise T-Tests. These results are summarised in table <ref>.\n\nThe total percentage of runtime that the robot was autonomous, manually controlled and unhealthy  was calculated for each experimental condition. The percentage of run time that the robot health was unhealthy  showed no statistical differences between the two conditions. Similarly, no significant differences were observed in the percentage of run time the robot was manually controlled. However, the percentage of run time that the robot was manually controlled when it was unhealthy, showed a significant (p <0.05, t = -2.36) difference between both conditions. That is, operators manually controlled unhealthy robots for longer when the health of the robot was displayed (i.e., Condition A). As a result, the robot was unhealthy  for an average of 61.91% of the runtime in condition A, but 78.03% of the runtime in condition B.\n\nThe change in perceptual effort required to carry out LoA switching tasks was measured using the operator's accuracy on the secondary task. When the health bar was not displayed (Condition B), operators showed significantly higher levels of accuracy (p <0.05, t = 2.36) on the secondary task. This indicates the perceptual effort required to use the interface with the robot health bar, is higher. However, the NASA-TLX scores showed no significant differences in the overall cognitive workload imposed by both conditions.\n\n\n\n\n\nOpen-ended questions asked before the experiment showed that some participants were slightly confused about what the Robot Health Bar was. One participant said - \"The health bar looks like a timer, because it has a number. I thought it meant seconds\". Others successfully grasped the idea behind the UI element. Another participant thought \"When the number goes down the robot dies\", indicating a game-like perception of the Health Bar's function. However, all participants understood it was there to assist or alert an operator performance degradation.\n\n\n\nMost participants preferred the interface of condition A (with the Robot Health bar ), finding it intuitive for regulating LoA - \"When the health was low, it was better to manually control the robot\". One participant said - \"Without the health bar I had to actively use my brain to detect when the robot needed help\". Three participants, however, felt that the colours were sometimes inaccurate and did not match the robot's state. One of them pointed out that while red and green clearly helped indicate which LoA was better, amber was confusing because they did not know what to do. Although not significant, operators that had experience with operating robots (according to the background information) seemed to prefer more transparency in the UI, while the rest preferred less transparency. Novice operators (as reported by the background information), instead, stated that they responded to the colours of the UI to a greater extent than the participants with more experience in operating robots.\n\n\n\nPearson's correlation showed a significant negative trend between how often the participants operated remote-controlled vehicles and how easy it was to know when to change LoA for alternative 1 (Figure <ref>) in the questionnaire (p <0.01). Significant positive trends were also observed for how often they used AI for work and how easy it was to know when to change LoA for alternative 3 in the questionnaire (Figure <ref>) (p <0.05), and how easy it was to understand why to change LoA for alternative 2 (Figure <ref>) (p <0.01) and alternative 3 in the questionnaire(Figure <ref>) (p <0.01) (see Table <ref>). \n\nIn terms of determining when to change LoA for the alternatives in the questionnaire, four participants rated either the highest or both the lowest and highest levels of transparency equally highly on the Likert scale (Figure <ref>). Conversely, the remaining four participants rated the lowest level of transparency highest in comparison to the other two levels. Overall, the medium level of transparency was rated the lowest. As for why to change LoA, six participants either increased or maintained their rating for each increase in the level of transparency, resulting in the highest level of transparency being rated the highest (Figure <ref>). However, two participants decreased their rating on the Likert scale for each increase in the level of transparency.\n\n\n\n\u00a7 DISCUSSION AND INSIGHTS\n\n\nOur experimental results illustrate how informing an operator about a robot's performance degradation through visual cues can affect the operator's driving and LoA regulation style. When shown the health bar, operators triggered LoA switches to mitigate situations where the robot was unhealthy . This style of HI-LoA regulation reduces the aggregate risk of robot failure. The interface with the health bar did not impose a significant additional cognitive workload on the operator during the experiment, and did not significantly change the task completion time. Contrary to our hypothesis, LoA regulation using the Health Bar required significantly (p<0.05) higher perceptual effort. In condition A, Participants carried out fewer rotations and gave less accurate answers. One likely explanation for this is that adding a Health Bar increased the number of points on the UI the operator had to focus on, which increased the perceptual effort for the primary task.\n\nTable <ref> shows that novice robot prefer significantly less transparency than experienced robot operators. Participant feedback revealed that while novice operators responded more to the colours of the health bar, experienced operators preferred having more information displayed to inform their LoA switching decisions. This indicates that participants value transparency only when they understand the necessity of transparency. People with different levels of experience have varied mental models about the Robot, leading them to perceive the system and the Health Bar differently. This makes it difficult to standardise explanations. Depending on their experience, each participant may want to clarify different aspects of the Human-Robot System, leading to differences in the way they are primed for the experiment. Therefore, rigorous training coupled with detailed explanations about the different components of the system are required to minimise the differences in perception. Finally, the major limitation of this study is the small sample size. Therefore all the results and insights presented in this study can require validation with a larger set of participants.\n\n\n\n  \u00a7.\u00a7.\u00a7 Participant Recommendations to improve the Robot Health Bar and User Interface Design:\n\n\n\n  * Make the Health Bar more Salient, so that it attract attention when necessary\n\n  * Do not include a drop down-menu in the Health Bar as shown in the Questionnaire\n\n  * Use a percentage to the health value instead of a value between [0,1]\n\n  * To attract attention to 'low health' use multi-modal awareness cues like sound alerts or UI elements e.g. By Shaking or Blinking the health bar after a threshold value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION AND FUTURE WORK\n\n\nIn this study, we explored if visual cues about a robot's performance degradation can reduce the perceptual effort required to make LoA switching decisions for remote mobile robot navigation tasks. Inspired by video games, we designed a 'Robot Health Bar'. This health bar displayed the total runtime performance degradation the robot is facing. A total of 8 participants carried out a mobile robot navigation task with and without the health bar UI element under high cognitive workload, and their performance was measured. Adding a Robot Health Bar to the robot control UI significantly changed how the operator makes Level of Autonomy Switching Decisions. When the Health Bar was displayed, operators were more attentive and took control of the robot more to minimise the risk of the robots failing. Visual cues that indicate a robot's health can serve as an effective way of ensuring safer control of robots, especially in extreme environments where robot missions have high levels of risk and environmental adversities.  In the future, we aim to explore how the insights gained from this study can scale to multi-robot systems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunsrtnat\n\n\n\n\n\n\n\u00a7 OPEN-ENDED QUESTIONS AND QUESTIONNAIRES\n\n\n\n \u00a7.\u00a7 Background information questionnaire\n \nThe background questionnaire consisted of the following questions:\n\n\n  Q1: How often do you operate or use to operate remote controlled vehicles (e.g. Robots, Drones, Heavy machinery)\n\n  Q2: How often do you play or used to play video games involving driving, flight simulation and third person shooters, RPG and sports?\n\n  Q3: Do you use AI (e.g. Autonomous Robots, Machine Learning Algorithms, AI Tools ) for work?\n\n  Q4: Do you use AI (e.g. Personal Assistant) in your personal life?\n\nThe possible answers ranged between 1-5; i.e., least to most often.\n\n\n\n \u00a7.\u00a7 Open-ended questions\n \nQuestions asked before participants had performed the experiment under both conditions are listed below:\n\n\n  Q1: What are you thinking as you look at this?\n\n  Q2: What is your first impression of this UI element?\n\n  Q3: What do you think this UI element does or will do?\n \n\nAll questions asked after participants had performed the experiment under both conditions are listed below:\n\n\n  Q1: Was anything surprising or did not perform as expected in either of the interfaces?\n\n  Q2: Was the interface without the Robot Health Bar  easy to understand?\n\n  Q3: Was the interface with the health bar easy to understand?\n\n  Q4: What did you think about the colours used in the health bar when the health changed?\n\n  Q5: Was the LoA switching behaviour of the interface without the Robot Health Bar  transparent?\n\n  Q6: Was the LoA switching behaviour of the interface with the Robot Health Bar  transparent? \n\n\n  Q7: Is there anything else that you can think of, specific to the UI and UX to improve the use of LoA switching Robots?\n\n\n\n\n \u00a7.\u00a7 Transparency/trust questionnaire\n \n\nThe transparency/trust questionnaire consisted of images of three different alternatives of a health bar ranging from low to high transparency and a 7-point Likert scale for each image (Figure <ref>). The questions were the following pair, for each alternative:\n\n\n  Q1: It is easy to understand WHEN to change Level of Autonomy (LoA) based ONLY on alternative 1?\n\n  Q2: It is easy to understand WHY to change or not change Level of Autonomy (LoA) based ONLY on alternative 1? \n\n\n\n\n\u00a7 RESULTS\n\n\n\ntablesection\nfiguresection\n\n\n\n\n\n\n\n\n"}