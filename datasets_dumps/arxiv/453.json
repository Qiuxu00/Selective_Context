{"entry_id": "http://arxiv.org/abs/2303.06682v2", "published": "20230312145704", "title": "DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration", "authors": ["Yuchun Miao", "Lefei Zhang", "Liangpei Zhang", "Dacheng Tao"], "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "text": "\n\t\n\t\n\t\n\t\n\t\n\nDDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration\n    Yuchun Miao^1 Lefei Zhang^1Corresponding Author Liangpei Zhang^2 Dacheng Tao^3,4 \n\n\t\t^1School of Computer Science, Wuhan University\n\n\t\t^2 State Key Lab. of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University\n\n\t\t^3JD Explore Academy\n\n    \t^4School of Computer Science, University of Sydney\n\n\n\t\t{miaoyuchun, zhanglefei, zlp62}@whu.edu.cn, dacheng.tao@gmail.com\n\t\t\n\t\t\n\t\n\t\n\t\n\t\n    March 30, 2023\n=======================================================================================================================================================================================================================================================================================================================================================================================================================\n\n\nempty\n\n\n\n\n\tDiffusion models have recently received a surge of interest due to their impressive performance for image restoration, especially in terms of noise robustness. However, existing diffusion-based methods are trained on a large amount of training data and perform very well in-distribution, but can be quite susceptible to distribution shift. This is especially inappropriate for data-starved hyperspectral image (HSI) restoration. To tackle this problem, this work puts forth a self-supervised diffusion model for HSI restoration, namely Denoising Diffusion Spatio-Spectral Model (), which works by inferring the parameters of the proposed Variational Spatio-Spectral Module (VS2M) during the reverse diffusion process, solely using the degraded HSI without any extra training data. In VS2M, a variational inference-based loss function is customized to enable the untrained spatial and spectral networks to learn the posterior distribution, which serves as the transitions of the sampling chain to help reverse the diffusion process. Benefiting from its self-supervised nature and the diffusion process,  enjoys stronger generalization ability to various HSIs compared to existing diffusion-based methods and superior robustness to noise compared to existing HSI restoration methods. Extensive experiments on HSI denoising, noisy HSI completion and super-resolution on a variety of HSIs demonstrate 's superiority over the existing task-specific state-of-the-arts.\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\n\n\n\nAs a new trendy generative model, diffusion models\u00a0<cit.> have attracted significant attention in the community owing to their state-of-the-art performance in image synthesis\u00a0<cit.>. In essence, diffusion model is a parameterized sampling chain trained using a variational bound objective, which is equivalent to that of score-based models\u00a0<cit.>. After training, samples are generated by the sampling chain, starting from white noise and gradually denoising to a clean image.\n\nRemarkably, diffusion models can go beyond image synthesis\u00a0<cit.>, and have been widely utilized in image restoration tasks, such as super-resolution\u00a0<cit.>, inpainting\u00a0<cit.>, denoising\u00a0<cit.>, and so on. Among these methods, \u00a0<cit.>, a diffusion-based image restoration framework, has achieved powerful robustness to noise, which is also noteworthy for hyperspectral images (HSIs). HSIs often suffer from noise corruption due to the limited light, photon effects, and atmospheric interference\u00a0<cit.>. This motivates us to inherit the powerful noise robustness of \u00a0<cit.> to HSI restoration by capitalizing on the power of diffusion model for HSI restoration.\n\n\n\n\nHowever, harnessing the power of the diffusion model for HSI restoration is challenging. The bottleneck lies in the poor generalization ability to HSIs in various scenarios. Existing diffusion-based methods are excessively dependent on the adversity and quantity of the training data, and often focus on a specific domain, such as the face. As a result, these methods may perform very well in-distribution, but can be quite susceptible to distribution shifts, resulting in degraded performance. This is particularly inappropriate for data-poor applications such as HSI restoration, where very limited HSIs are available for training\u00a0<cit.>. This is because HSIs are much more expensive to acquire in real-world scenarios, compared to natural RGB images. In addition, different sensors often admit large different specifications, such as the frequency band used, the spatial and spectral resolution. Therefore, a diffusion model trained on HSIs captured by one sensor may not be useful for HSIs captured by other sensors. In addition to the generalization ability issues mentioned above, how to leverage the intrinsic structure of HSIs is also critical for harnessing the power of the diffusion model for HSI restoration. Bearing the above concerns in mind, an effective diffusion model tailored for HSI restoration, which is able to generalize to HSIs in various practical scenarios and leverage the intrinsic structure of HSIs, is highly desired.  \n\n\n\n\n\nTo address the generalization ability problem mentioned above, one remedy is to use the emerging untrained neural networks, such as those in <cit.>. These methods learn a generative neural network directly from a single degraded image, rather than from a large volume of external training data. The rationale is that an appropriate neural network architecture, without training data, could already encode much critical low-level image statistical prior information. Owing to their training data-independent nature, untrained networks can usually generalize well to the wild data. Meanwhile, due to our need to flexibly cope with various HSIs in real scenarios, untrained networks are rendered as a natural choice. In addition, their powerful expressiveness allows the deployment of such untrained networks in the diffusion models for HSI restoration.\n\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\n\n\n\n\nIn this work, we put force a self-supervised Denoising Diffusion Spatio-Spectral Model (), which can cleverly alleviate the generalization ability problem, while exploiting the intrinsic structure information of the underlying HSIs.  is a denoising diffusion generative model that progressively and stochastically denoises samples into restored results conditioned on the degraded HSI and the degradation model after a finite time. Unlike existing diffusion models\u00a0<cit.>, which use a neural network pre-trained a large number of training data,  reverses the diffusion process by virtue of the proposed Variational Spatio-Spectral Module (VS2M), solely using the degraded HSI without any extra training data; see Figure <ref> for visual comparison with \u00a0<cit.>. \n\n\n\n\n\nSpecifically, the proposed VS2M consists of two types of untrained networks (i.e., untrained spatial and spectral networks) and a customized variational inference-based loss function. The untrained spatial and spectral networks leverage the intrinsic structure of HSIs by modeling the abundance maps and endmembers derived from the linear mixture model\u00a0<cit.>, respectively. The variational inference-based loss function is customized to enable these untrained networks to learn the posterior distribution of the task at hand. The specific contributions of this work are summarized as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u2219\nWe propose a self-supervised Deep Diffusion Spatio-Spectral Model (). Benefiting from its diffusion process and self-supervised nature,  enjoys stronger robustness to noise relative to existing HSI restoration methods and superior generalization ability to various HSIs relative to existing diffusion-based methods. To the best of our knowledge,  is the first self-supervised diffusion model that can restore HSI only using the degraded HSI without any additional training data. \n\n\u2219 \nWe design a variational spatio-spectral module (VS2M) to help reverse the diffusion process, which serves as the transitions of the sampling chain. VS2M is capable of approximating the posterior distribution of the task at hand by leveraging the intrinsic structure of the underlying HSI.\n\n\n\n\u2219 \nExtensive experiments on HSI denoising, noisy HSI completion and super-resolution illustrate the superiority of  over the existing task-specific state-of-the-arts, especially in terms of the robustness to noise, and the generalization ability to HSIs in diverse scenarios.\n\n\n\n\n\n\n\n\n\n\u00a7 RELATED WORKS\n\n\n\n \u00a7.\u00a7 HSI Restoration Methods\n\nHSI restoration is a long-standing problem with a wide range of applications, with model-based approaches dominating the early years\u00a0<cit.>. Recently, triggered by the expressive power of deep neural networks, a plethora of supervised\u00a0<cit.> and self-supervised methods\u00a0<cit.> were developed.\n\n\n\n\n\nThe supervised methods mainly concentrate on exploring different neural network architectures to learn a mapping from a degraded HSI to the ground truth, such as convolution neural network\u00a0<cit.>, recurrent neural network\u00a0<cit.>, and transformer\u00a0<cit.>. The main bottleneck of these supervised methods is that their performance is limited by the adversity and amount of training data, and is often susceptible to distribution outliers. In contrast, our  is not affected by such distribution outliers, since no extra training data is required in .\n\n\n\n\n\n\nAmong the self-supervised methods, a representative family is the untrained neural network-based methods\u00a0<cit.>. As a promising tool for image restoration, untrained neural networks enjoy the expressive power of neural networks yet do not require additional training data\u00a0<cit.>. Ulyanov et al.\u00a0<cit.> first extended untrained neural network from RGB images to HSIs, putting forth a self-supervised HSI restoration framework. Then, Luo et al.\u00a0<cit.> further proposed a spatio-spectral constrained untrained neural network. Inspired by these methods, Meng et al.\u00a0<cit.> integrated untrained neural network into the plug-and-play regime\u00a0<cit.>. In general, these methods learn a generator network directly from the degraded HSI in an iterative scheme. The critical drawback of these methods is that they easily accumulate errors inevitable in the iterative process, being quite fragile to degraded HSI with significant noise. Although our proposed  is also a multi-step generation process, it does not suffer from such accumulated errors. This is because diffusion-based methods have systematic mathematical formulation, and the errors in the intermediate step can be regarded as noise, which could be refined during the diffusion process\u00a0<cit.>. Therefore, as compared with the above untrained network-based methods, our  is able to decently restore high-quality HSIs from the degraded HSI corrupted by noise.\n\n\n\n\n\n \u00a7.\u00a7 Diffusion Models for Image Restoration\n\nRecent emerged diffusion models have been widely utilized in image restoration. One branch of these works mainly focuses on tailoring a diffusion model suitable for a specific task, often leading to remarkable performance at the expense of flexibility across different tasks; see\u00a0<cit.>. Another branch is concerned with tailoring a diffusion model that can be flexibly applied to different tasks; see\u00a0<cit.>. To achieve this, these methods leave the training procedure intact, and only modify the inference procedure so that one can sample the restored image from a conditional distribution related to the task at hand. Among them, a representative method is \u00a0<cit.>, which achieves promising performance in multiple useful scenarios, including denoising, noisy super-resolution, and noisy completion, especially in terms of the robustness to noise. \n\nHowever, the main shortcoming of these diffusion-based methods is their generalization ability to the wild data. These methods excessively depend on the adversity and amount of training data, and may perform very well in-distribution, but can be quite susceptible to distribution shifts, sometimes resulting in severely degraded performance. This becomes more problematic for data-poor applications such as HSI restoration. In this work, we aim to inherit the advantage of diffusion model (i.e., noise robustness) to HSI restoration, and boost its generalization ability to HSIs in practical scenarios.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 NOTATIONS AND PRELIMINARIES\n\n\n\n \u00a7.\u00a7 Notations\n\nA scalar, a vector, a matrix, and a tensor are denoted as x, x, X, and \ud835\udcb3, respectively. x^(i), X^(i,j), and \ud835\udcb3^(i,j,k) denote the i-th, (i,j)-th, and (i,j,k)-th element of \ud835\udc31\u2208\u211d^I, \ud835\udc17\u2208\u211d^I\u00d7 J, and \ud835\udcb3\u2208\u211d^I\u00d7 J\u00d7 K, respectively. The Frobenius norms of x are denoted as x_F=\u221a(\u2211_ix^(i)x^(i)). Given \ud835\udc32\u2208\u211d^N and a matrix \ud835\udc17\u2208\u211d^I\u00d7 J, the outer product is defined as \ud835\udc17\u2218\ud835\udc32. In particular, \ud835\udc17\u2218\ud835\udc32\u2208\u211d^I\u00d7 J\u00d7 N and (\ud835\udc17\u2218\ud835\udc32)^(i,j,n) = \ud835\udc17^(i,j)\ud835\udc32^(n). The vec(\ud835\udc17) operator represents vec(\ud835\udc17)=[\ud835\udc17^(:,1);\u2026;\ud835\udc17^(:,J)] \u2208\u211d^IJ, and vec(\ud835\udcb3) is further defined as vec(\ud835\udcb3) = [ vec(\ud835\udcb3^(:,:,1));\u2026; vec(\ud835\udcb3^(:,:,K))] \u2208\u211d^IJK. \n\n\n\n \u00a7.\u00a7 Degradation Model\n\nThe goal of HSI restoration is to recover a HSI from potentially noisy degraded HSI given through a known linear degradation model. In general, HSI restoration can be formulated as\n\n    \ud835\udc32 = \ud835\udc07\ud835\udc31 + \ud835\udc33,\n\nwhere \ud835\udc31\u2208\u211d^n is the vector version of the original HSI \ud835\udcb3 defined as \ud835\udc31 =  vec(\ud835\udcb3), \ud835\udc32\u2208\u211d^m is corresponding to the degraded HSI \ud835\udcb4 defined as \ud835\udc32 =  vec(\ud835\udcb4), \ud835\udc07  is the degradation matrix that depends on the restoration task at hand, and \ud835\udc33\u223c\ud835\udca9(0, \u03c3_\ud835\udc32^2 I) represents an i.i.d. additive Gaussian noise with standard deviation \u03c3_\ud835\udc32. It is worth noting that in this work, following previous diffusion-based methods\u00a0<cit.>, \ud835\udc31 and \ud835\udc32 in Eqn. (<ref>) are all scaled linearly to the range of [-1, 1], which ensures the neural network to operate on consistently scaled inputs during the reverse diffusion process. Therefore, when they are linearly scaled back to the range of [0, 1], the standard deviation of the Gaussian noise becomes \u03c3=0.5\u03c3_y.\n\n\n\n\n\n\u00a7 DENOISING DIFFUSION SPATIO-SPECTRAL MODELS\n\n\nIn this section, we introduce the proposed . The key idea behind  is to reverse the diffusion process solely using the degraded HSI without extra training data, with the help of the proposed VS2M. We first give an introduction to the diffusion process for image restoration, then describe our design in VS2M, and finally elaborate on the VS2M-aided reverse diffusion process.\n\n\n\n\n\n \u00a7.\u00a7 Diffusion Process for Image Restoration\n\nDiffusion models for image restoration are generative models with Markov chain \ud835\udc31_T \u2192\ud835\udc31_T-1\u2192\u2026\u2192\ud835\udc31_1 \u2192\ud835\udc31_0 conditioned on \ud835\udc32\u00a0<cit.>, which has the following marginal distribution equivalent to that in\u00a0<cit.>: \n\n    q(\ud835\udc31_t | \ud835\udc31_0)=\ud835\udca9(\ud835\udc31_t ; \u221a(\u03b1\u0305_t)\ud835\udc31_0,(1-\u03b1\u0305_t) \ud835\udc08)\n\nwith\n\n    \u03b1_t=1-\u03b2_t,   \u03b1\u0305_t=\u220f_i=0^t \u03b1_i,\n\nwhere \ud835\udc31_0 and \ud835\udc32 are the vector version of high-quality HSI \ud835\udcb3 and degraded  HSI \ud835\udcb4, and \u03b2_t is a hyperparameter. The forward process (i.e., diffusion process ) progressively injects Gaussian noise to the original data \ud835\udc31_0 and obtains \ud835\udc31_T that looks indistinguishable from pure Gaussian noise, while the reverse diffusion process samples a slightly less noisy image \ud835\udc31_t from \ud835\udc31_t+1 by leveraging the forward process posterior distribution q(\ud835\udc31_t | \ud835\udc31_t+1, \ud835\udc31_0, \ud835\udc32). More details can be found in the supplementary materials. \n\nIn , denoising is performed using a network pre-trained on a large number of additional training data like other diffusion models\u00a0<cit.>, which perform well in-distribution, and can be susceptible to distribution shift. This is especially inappropriate with data-starved HSI restoration. In this work we break this routine and propose to reverse the diffusion process utilizing the VS2M that can perform denoising solely using the degraded image without any extra training data.\n\n\n\n \u00a7.\u00a7 Variational Spatio-Spectral Module (VS2M)\n\nThe VS2M utilized in  consists of untrained spatial and spectral networks, and a variational inference-based loss function. The untrained spatial and spectral networks are capable of leveraging the intrinsic structure of HSIs using designated network structures. The variational inference-based loss function is customized to enable these untrained networks to learn the posterior distribution. In this way, the untrained networks and the diffusion model can be incorporated to achieve promising performance.\n\n\n\nUnder VS2M, HSI \ud835\udcb3\u2208\u211d^I\u00d7 J\u00d7 K is represented as:\n\n    \ud835\udcb3 = \u2211_r=1^R \ud835\udc12_r \u2218\ud835\udc1c_r,\n\nwhere \ud835\udc1c_r\u2208\u211d^K and \ud835\udc12_r\u2208\u211d^I\u00d7 J  represent the r-th endmember and the r-th endmember's abundance map, respectively, and R is the number of endmembers contained in the HSI. More details about the decomposition in Eqn. (<ref>) can be found in the supplementary materials. Here we introduce the untrained network architecture and the variational inference-based loss function individually.\n\nUntrained Network Architecture.\nThe physical interpretation of  \ud835\udc12_r and \ud835\udc1c_r makes it possible to utilize certain untrained networks to model these factors. Specifically, untrained U-Net-like \u201chourglass\u201c architecture in\u00a0<cit.> and untrained full-connected networks (FCNs) are employed for abundance map modeling and endmember modeling, since abundance maps reveal similar qualities of the nature images\u00a0<cit.> and the endmembers can be regarded as relatively simple 1D signals, as was done in\u00a0<cit.>. Following this perspective, we model the HSI \ud835\udc31\u2208\u211d^IJK  as follows:[Actually, The parameters of the r U-Nets are independent of each other, as are the parameters of the r FCNs. In order to simplify notations, here we use \u03b8 and \u03b6 to represent {\u03b8_r}_r=1^R and {\u03b6_r}_r=1^R, respectively. ] \n\n    \ud835\udc31 =  vec(\ud835\udcb3) =   vec(\u2211_r=1^R  S_\u03b8(\ud835\udc33_r) \u2218 C_\u03b6(\ud835\udc30_r )),\n\n\n\n\nwhere S_\u03b8(\u00b7):\u211d^N_a\u2192\u211d^I\u00d7 J is the untrained U-Net-like network for abundance map generation, and \u03b8 collects all the corresponding network weights; similarly, C_\u03b6(\u00b7):\u211d^N_s\u2192\u211d^K and \u03b6 denote the untrained FCN for endmember generation and the corresponding network weights, respectively; the vectors \ud835\udc33_r\u2208\u211d^N_a and \ud835\udc30_r\u2208\u211d^N_s are low-dimensional random vectors that are responsible for generating the r-th abundance map and endmember respectively. \ud835\udc33_r and \ud835\udc30_r are randomly initialized but fixed during the optimization process. It is worth noting that, instead of directly using the vanilla U-Net structure for abundance map modeling, we propose to introduce the attention mechanism\u00a0<cit.> into the U-Net, which aims to enhance the self-supervised expression ability of the VS2M. The concrete structure of the untrained spatial and spectral networks is illustrated in the supplementary materials.\n\nVariational Inference-based Loss Function.\nWe aim to estimate high-quality HSI \ud835\udc31_0  using the aforementioned untrained spatial and spectral networks, and update their parameters at every reverse process step. Denoting {\u03b8_t, \u03b6_t } as the parameters at step t, we first define a learnable generative process p_\u03b8_t,\u03b6_t(\ud835\udc31_t | \ud835\udc31_t+1,\ud835\udc32) by replacing the \ud835\udc31_0 in q(\ud835\udc31_t | \ud835\udc31_t+1, \ud835\udc31_0, \ud835\udc31) with \ud835\udc31_\u03b8_t,\u03b6_t, i.e.,  \n\n    p_\u03b8_t,\u03b6_t(\ud835\udc31_t | \ud835\udc31_t+1,\ud835\udc32) \u225c q(\ud835\udc31_t | \ud835\udc31_t+1, \ud835\udc31_\u03b8_t,\u03b6_t, \ud835\udc32),\n\nwhere  \ud835\udc31_\u03b8_t,\u03b6_t denotes the vector version of the estimated HSI at reverse process step t, i.e.,\n\n    \ud835\udc31_\u03b8_t,\u03b6_t =  vec(\u2211_r=1^R  S_\u03b8_t(\ud835\udc33_r) \u2218 C_\u03b6_t(\ud835\udc30_r ))\n \nThe goal of  is to find a set of parameters {\u03b8_t, \u03b6_t} to make p_\u03b8_t,\u03b6_t(\ud835\udc31_t | \ud835\udc31_t+1,\ud835\udc32) as close to q(\ud835\udc31_t | \ud835\udc31_t+1, \ud835\udc31_0,\ud835\udc32) as possible, by maximizing the \nvariational lower bound of the log likelihood objective:\n\n    \ud835\udd3c_q(\ud835\udc31_0), q(\ud835\udc32|\ud835\udc31_0)[log p_\u03b8, \u03b6(\ud835\udc31_0 | \ud835\udc32)] \n    \u2265   \ud835\udd3c_q(\ud835\udc31_0:T), q(\ud835\udc32|\ud835\udc31_0)[log p_\u03b8, \u03b6(\ud835\udc31_0:T | \ud835\udc32) - log q (\ud835\udc31_1:T|\ud835\udc31_0,\ud835\udc32)].\n\n\n\n\n\n\n\n\nNotably, the objective in Eqn.\u00a0(<ref>) can be reduced into a denoising objective, i.e., estimating the underlying high-quality HSI \ud835\udc31_0 from the noisy \ud835\udc31_t (please refer to the supplementary materials for derivation). By reparameterizing Eqn. (<ref>) as \n\n\n    \ud835\udc31_t(\ud835\udc31_0, \u03f5)=\u221a(\u03b1\u0305_t)\ud835\udc31_0+\u221a(1-\u03b1\u0305_t)\u03f5     for \u03f5\u223c\ud835\udca9(0, \ud835\udc08),\n\nour variation inference-based loss function can be designed as follows:\n\n    min_{\u03b8, \u03b6}\u00a0\ud835\udc31_t  -  vec(\u221a(\u03b1\u0305_t)\u2211_r = 1^R  S_\u03b8 (\ud835\udc33_r) \u2218 C_\u03b6(\ud835\udc30_r))_F^2.\n\n\n\n\nIntuitively, given a noisy observation \ud835\udc31_t+1, after optimizing {\u03b8_t,\u03b6_t } from \ud835\udc31_t+1 via Eqn.\u00a0(<ref>) using the Adam\u00a0<cit.>, \ud835\udc31_\u03b8_t,\u03b6_t can be derived via Eqn. (<ref>), and then \ud835\udc31_t could be sampled from p_\u03b8_t,\u03b6_t(\ud835\udc31_t | \ud835\udc31_t+1,\ud835\udc32) defined in Eqn. (<ref>). In this way, the diffusion process could be reversed in a self-supervised manner with no need for extra training data.\n\n\n\n\n\n\n\n \u00a7.\u00a7 VS2M-Aided Reverse Diffusion Process\n\nGiven a degradation matric \ud835\udc07\u2208\u211d^m \u00d7 n, its singular value decomposition is posed as:\n\n    \ud835\udc07 = \ud835\udc14\u03a3\ud835\udc15^\ud835\uddb3,\n\nwhere \ud835\udc14\u2208\u211d^m \u00d7 m, \ud835\udc15\u2208\u211d^n \u00d7 n are orthogonal matrices, and \u03a3\u2208\u211d^m \u00d7 n is the rectangular diagonal matrix consisting of the singular values denoted as s_1 \u2265 s_2 \u2265\u2026\u2265 s_n. \nThe idea behind this is to tie the noise in the degraded signal \ud835\udc32 with the diffusion noise in \ud835\udc31_1:T, ensuring that the diffusion result \ud835\udc31_0 is faithful to the degraded signal \ud835\udc32\u00a0<cit.>.\n\nBefore illustrating the reverse diffusion process in detail, we first rethink the difference between our  and other diffusion-based methods\u00a0<cit.> to guide the design of the reverse diffusion process. The main difference is how \ud835\udc31_0 is predicted from \ud835\udc31_t at each reverse step. In\u00a0<cit.>, a denoising network is trained on a large amount of additional training data to predict \ud835\udc31_0. By exploiting the external prior knowledge, this network could produce satisfactory \ud835\udc31_0 even if \ud835\udc31_t looks like pure Gaussian noise. Because of this, such a denoising network could work during the whole reverse diffusion process. However, it is difficult for untrained networks to produce a satisfactory image by denoising an image that is almost pure Gaussian noise. Therefore, starting inference from pure Gaussian is unsuitable for our .\n\n\nFollowing the above argument, we propose to start inference from a single forward diffusion with better initialization, instead of starting from pure Gaussian noise\u00a0<cit.>. Specifically, we first perturb the degraded HSI \ud835\udc32 via the forward diffusion process up to t_0 < T, where t_0 denotes the step that the reverse diffusion process starts from. \nDenoting \ud835\udc31\u0305^(i) as the i-th index of vector \ud835\udc31\u0305_t=\ud835\udc15^\ud835\uddb3\ud835\udc31_t, \ud835\udc32\u0305^(i) as the i-th index of \ud835\udc32\u0305=\u03a3^\u2020\ud835\udc14^\ud835\uddb3\ud835\udc32,  and \ud835\udc31\u0305_\u03b8_t, \u03b6_t^(i) as the i-th index of \ud835\udc31\u0305_\u03b8_t, \u03b6_t = \ud835\udc15^\ud835\uddb3\ud835\udc31_\u03b8_t, \u03b6_t, for all t < t_0, the variational distribution is defined as:\n\n    p_\u03b8_t_0,\u03b6_t_0(\ud835\udc31\u0305_t_0^(i) | \ud835\udc32) = \ud835\udca9(\ud835\udc32\u0305^(i), \u03c3_t_0^2-\u03c3_y^2/s_i^2)     if  s_i>0 \n    \ud835\udca9(0, \u03c3_t_0^2)     if  s_i=0\n\n\n    p_\u03b8_t,\u03b6_t(\ud835\udc31\u0305_t^(i) | \ud835\udc31_t+1, \ud835\udc32)= \n       \ud835\udca9(\ud835\udc31\u0305_\u03b8_t,\u03b6_t^(i)+\u221a(1-\u03b7^2)\u03c3_t \ud835\udc31\u0305_t+1^(i)-\ud835\udc31\u0305_\u03b8_t,\u03b6_t^(i)/\u03c3_t+1, \u03b7^2 \u03c3_t^2)     if  s_i=0 \n    \ud835\udca9(\ud835\udc31\u0305_\u03b8_t,\u03b6_t^(i)+\u221a(1-\u03b7^2)\u03c3_t \ud835\udc32\u0305^(i)-\ud835\udc31\u0305_\u03b8_t,\u03b6_t^(i)/\u03c3_\ud835\udc32 / s_i, \u03b7^2 \u03c3_t^2)     if \u03c3_t<\u03c3_\ud835\udc32/s_i\n    \ud835\udca9((1-\u03b7_b) \ud835\udc31\u0305_\u03b8_t,\u03b6_t^(i)+\u03b7_b \ud835\udc32\u0305^(i), \u03c3_t^2-\u03c3_\ud835\udc32^2/s_i^2\u03b7_b^2)     if \u03c3_t \u2265\u03c3_\ud835\udc32/s_i\n\nwhere \u03c3_t depending on the hyperparameter \u03b2_1:T  denotes the variance of diffusion noise in \ud835\udc31_t, and \u03b7, \u03b7_b are the hyperparameters, which control the level of noise injected at each timestep. Once \ud835\udc31\u0305_\u03b8_t, \u03b6_t is sampled from Eqn. (<ref>), it is easy to obtain \ud835\udc31_\u03b8_t, \u03b6_t exactly by left multiplying \ud835\udc15. And the values of the parameters {\u03b8_t_0, \u03b6_t_0} are randomly initialized.\n\nIt is worth noting that the parameter updating (i.e, {\u03b8, \u03b6}) and the reverse diffusion process are iteratively performed. The parameter values of each reverse diffusion step are inherited from the previous step, thus the parameters can be updated continuously during the reverse diffusion process. This reverse diffusion process is summarized in Algorithm\u00a0<ref>.\n\n\n\n\n\u00a7 EXPERIMENTS\n\n\n\n \u00a7.\u00a7 Comparisons with State-of-the-Arts\n\nIn this paper, our interest lies in inheriting the 's powerful robustness to noise (which is unavoidable in the hyperspectral imaging process) to HSI restoration. Herein we mainly consider noisy HSI completion, HSI denoising, and noisy HSI super-resolution, and compare the proposed  with the existing task-specific state-of-the-arts. Two frequently used evaluation metrics, namely, peak signal-to-noise ratio (PSNR) and structure similarity (SSIM), are adopted to evaluate the results. In general, better performance is reflected by higher PSNR and SSIM values. In , T is set as {3000, 1000, 1000}  for noisy HSI completion, HSI denoising, and noisy HSI super-resolution, respectively, and the step t_0 to start reverse the diffusion process is set as T/2. We use \u03b7=0.95, \u03b7_b=1, and linearly increase \u03b2_1:T in which \u03b2_1=10^-4 and \u03b2_T = {2\u00d710^-3, 5\u00d710^-3}. The variance \u03c3_t is set as a constant \u03c3_t = 1-\u03b1\u0305_t-1/1-\u03b1\u0305_t\u03b2_t  for all experiments. The number of endmembers R is selected from {5, 10}. As for diffusion-based restoration methods \u00a0<cit.> and \u00a0<cit.>, the diffusion model in them is trained on a large-scale remote sensing imagery dataset AID\u00a0<cit.> containing ten thousands of scene images, and HSI restoration is performed in a channel-by-channel manner. All of the compared methods' parameters are set as suggested by the authors, with parameter fine-tuning efforts to uplift their performance. For implementation details, parameters sensitivity analysis, and inference time analysis, please refer to the supplementary materials. \n\n\n\n  \u00a7.\u00a7.\u00a7 Datasets and Compared Methods\n\nNoisy HSI Completion. The noisy HSI completion aims at recovering the underlying HSI from the noisy incompleted observation. We adopt a wide range of HSIs to conduct the experiments, including 32 natural HSIs[<https://www.cs.columbia.edu/CAVE/databases/multispectral/>] (i.e., CAVE dataset\u00a0<cit.>), and 3 remote sensing HSIs[<http://lesun.weebly.com/hyperspectral-data-set.html>] (i.e., WDC Mall, Pavia Centre, and Pavia University datasets). The sampling rates are set as {0.1, 0.2, 0.3}, and the standard deviation \u03c3 of Gaussian noise in the range of [0,1] is set as 0.1. The compared methods consist of seven model-based methods (i.e., \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, and \u00a0<cit.>), two unsupervised deep learning-based methods (i.e., \u00a0<cit.> and \u00a0<cit.>), and two diffusion-based methods (i.e., \u00a0<cit.> and \u00a0<cit.>).\n\n\nHSI Denoising. The HSI denoising aims at recovering the clean HSI from its noisy observation. The data adopted in this experiment is the same as that in HSI completion, including 32 natural HSIs and 3 remote sensing HSIs. Herein we mainly consider Gaussian noise, and the standard deviation of Gaussian noise \u03c3 in the range of [0,1] is set as {0.1, 0.2, 0.3}. The compared methods consist of six model-based methods (i.e., \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, \u00a0<cit.>, and \u00a0<cit.>), two unsupervised deep learning-based methods (i.e., \u00a0<cit.> and \u00a0<cit.>), and a supervised deep learning-based method (i.e., \u00a0<cit.>). Since the purpose of the comparison with supervised methods in this work is to highlight the generalization ability of our methods, we directly use the models of  trained on ICVL\u00a0<cit.> with Gaussian noise provided by the authors.\n\n\nNoisy HSI Super-Resolution. The noisy HSI super-resolution aims at recovering high-resolution HSI from its noisy low-resolution counterpart. We adopt CAVE dataset\u00a0<cit.> to conduct the experiments. The scale factor is set as \u00d72, \u00d74, and \u00d78, and the standard deviation of Gaussian noise \u03c3 in the range of [0,1] is set as 0.1. The compared methods include three supervised deep learning-based methods (i.e., \u00a0<cit.>, \u00a0<cit.>, and \u00a0<cit.>), a model-based method (i.e., \u00a0<cit.>), two unsupervised deep learning-based methods (i.e., \u00a0<cit.> and \u00a0<cit.>), and a diffusion-based method (i.e., \u00a0<cit.>). In order to comprehensively compare with supervised methods in terms of generalization ability to other datasets and other noise standard deviations, we train each supervised model under five different settings, i.e., CAVE without noise denoted as , CAVE with 0.1 Gaussian noise denoted as , CAVE  with 0.05 Gaussian noise denoted as , CAVE with 0.03 Gaussian noise denoted as , and Chikusei dataset\u00a0<cit.> with 0.1 Gaussian noise denoted as *. Here  denotes the method name, i.e., , , and .\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Experimental Results\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\n\n\n\n\n\n\n\n\n\n\n\nThe quantitative results of noisy HSI completion, HSI denoising, and noisy HSI super-resolution are reported in Tables <ref>, <ref>, and <ref>. We can observe that the proposed  outperforms existing model-based, unsupervised deep learning-based, and diffusion-based methods in all three tasks, while yielding competitive results with respect to the state-of-the-art supervised deep learning-based methods. Specifically, as compared with the diffusion-based method , our method offers average PSNR improvement of 5.878 dB, 5.909 dB, and 3.998 dB in completion, denoising, and super-resolution, respectively. This observation validates that  can more flexibly adapt to diverse HSIs in real scenarios. Additionally, in HSI super-resolution experiments, the supervised methods (i.e., , , and ) all perform best when trained with CAVE dataset with 0.1 Gaussian noise among the five different training settings, and their performance degrades significantly when trained with other noise levels or datasets. It is worth noting that, our  achieves comparable performance with the best version of these supervised methods, and outperforms the models trained with other settings. This demonstrates the superiority of our  against these supervised methods.   \n\n\n\n\n\n\n\n\n\n\nSome visual results for different tasks are shown in Figures <ref>, <ref>, and <ref>[In Figure <ref> (i.e., super-resolution), the best results of the supervised methods are shown.].  As observed, the proposed  is capable of preserving the most detailed information and demonstrating the best visual performance among the compared methods, which is consistent with its satisfactory performance in PSNR and SSIM. In addition, there is the least residual noise remaining in the results produced by , which demonstrates the superiority of  in terms of noise robustness. \n\nWe conjecture that such promising results can be attributed to the organic cooperation of untrained spatial and spectral networks and diffusion model, which is beneficial to the generalization ability to various HSIs and the robustness to noise.\n\n\n\n\n \u00a7.\u00a7 Ablation Study\n\nWe test the impact of untrained spatial and spectral networks, and diffusion process in . The compared methods are listed as follows:\n\n\u2219  without untrained spatial and spectral networks (dubbed DDS2M w/o untra.): To evaluate the impact of the untrained spatial and spectral networks,  we remove the untrained spatial and spectral networks, and use an untrained U-Net to directly generate the whole HSI.\n\n\u2219  without diffusion process (dubbed DDS2M w/o diffu.):  To clarify the influence of the diffusion process, we remove the diffusion process and make the untrained spatial and spectral networks directly fit the degraded HSI in an iterative scheme.\n\n\nWe consider HSI denoising (\u03c3=0.3), noisy HSI completion (sampling rate=0.1, \u03c3=0.1), and noisy HSI super-resolutin (scale factor=2, \u03c3=0.1). HSI Fruits from the CAVE dataset is selected as an example. The results are shown in Table <ref>. We can observe that the untrained spatial and spectral networks, and the diffusion process could indeed significantly boost the restoration performance. More implementation details can be found in the supplementary materials. \n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\nThis work reveals a new insight on how to synergistically integrate existing diffusion models with untrained neural networks, and puts forth a self-supervised diffusion model for HSI restoration, namely Denoising Diffusion Spatio-Spectral Model (). By virtue of our proposed Variational Spatio-Spectral Module (VS2M), the diffusion process can be reversed solely using the degraded HSI without any extra training data. Benefiting from its self-supervised nature and diffusion process,  admits stronger generalization ability to various HSIs relative to existing diffusion-based methods and superior robustness to noise relative to existing HSI restoration methods.\n\n\n \n\nieee_fullname\n\t\n\n"}