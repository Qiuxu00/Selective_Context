{"entry_id": "http://arxiv.org/abs/2303.06719v1", "published": "20230312175438", "title": "A quantum spectral method for simulating stochastic processes, with applications to Monte Carlo", "authors": ["Adam Bouland", "Aditi Dandapani", "Anupam Prakash"], "primary_category": "quant-ph", "categories": ["quant-ph"], "text": "\n\n\nQTrail-DB: A  Query Processing Engine for Imperfect Databases with Evolving Qualities\n    Maha Asiri,  Mohamed Y. Eltabakh\nComputer Science Department, Worcester Polytechnic Institute (WPI), MA, USA.\n{mmasiri,\u00a0meltabakh}@wpi.edu\n\n    March 30, 2023\n===============================================================================================================================================\n\nempty\n\n\n Stochastic processes play a fundamental role in physics, mathematics, engineering and finance. \nOne potential application of quantum computation is to better approximate properties of stochastic processes. For example, quantum algorithms for Monte Carlo estimation combine a quantum simulation of a stochastic process with amplitude estimation to improve mean estimation.\nIn this work we study quantum algorithms for simulating stochastic processes which are compatible with Monte Carlo methods. We introduce a new \u201canalog\u201d quantum representation of stochastic processes, in which the value of the process at time t is stored in the amplitude of the quantum state, enabling an exponentially efficient encoding of process trajectories. \n    We show that this representation allows for highly efficient quantum algorithms for simulating certain stochastic processes, using spectral properties of these processes combined with the quantum Fourier transform.\n    In particular, we show that we can simulate T timesteps of fractional Brownian motion using a quantum circuit with gate complexity  (T), which coherently prepares the superposition over Brownian paths.\n We then show this can be combined with quantum mean estimation to create end to end algorithms for estimating certain time averages over processes in time O((T)\u03f5^-c) where 3/2<c<2 for certain variants of fractional Brownian motion, whereas classical Monte Carlo runs in time O(T\u03f5^-2) and quantum mean estimation in time O(T\u03f5^-1).\n Along the way we give an efficient algorithm to coherently load a quantum state with Gaussian amplitudes of differing variances, which may be of independent interest.\n\n    \n    \n    \n    \n\n\n\n\n\narabic \n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\nStochastic processes play a fundamental role in mathematics, physics, engineering, and finance, modeling time varying quantities such as the motion of particles in a gas, the annual water levels of a reservoir, and the prices of stocks and other commodities. \nOne potential application of quantum computation is to better estimate properties of stochastic processes or random variables derived therefrom.\nA long line of works have shown that one can quadratically improve the precision of estimating expectation values of random variables, using quantum amplitude estimation and variants thereof <cit.>.\nFor example, if one wishes to estimate the expectation value of a random variable that one can efficiently classically sample, then classical Monte Carlo methods require \u0398(1/\u03f5^2) samples to \u03f5-approximate the mean, while\nquantum algorithms can do so using only \u0398(1/\u03f5) calls to the classical sampling algorithm in superposition.\nThese algorithms are optimal in a black-box setting <cit.>. \nSuch algorithmic approaches have received much attention as a potential application of quantum computation.\nFor example, there has been much excitement about the possibility of using this approach for the Monte Carlo pricing of financial derivatives and risk analysis, e.g. <cit.>.\n\n\n\n\nHowever, achieving a practical quantum speedup for estimation of expectations over stochastic processes is challenging, even with potential future improvements in quantum hardware. \nThis is for two reasons.\nFirst, in these algorithms one must simulate the underlying random variable/stochastic process in quantum superposition.\nThat is, one needs to coherently prepare a quantum state which encodes the randomness used to generate the trajectory as well as a trajectory of the stochastic process under consideration.\nWhile in principle this can always be done in the same amount of time to classically simulate the process \u2013 for example by compiling the classical simulation down to Toffoli gates with uniform random seeds as input \u2013 in practice this can result in prohibitively \nlarge gate counts in the simulation circuit.\nSecond, one must not only simulate the above simulation circuit once, but (O(1/\u03f5)) in series in order to achieve the quadratic quantum speedup[It is however possible to perform lower-depth variants of the algorithm at the cost of decreased speedups <cit.> that are proportional to the number of times the simulation circuit is performed in series.]. The depth for the simulation circuit is therefore another bottleneck in obtaining speedups\nfor quantum Monte Carlo methods. \nDue to these constraints, it has recently been noted that in certain future projections of quantum hardware development, the clockspeed overheads of quantum error correction might overwhelm the quadratic speedups for relevant parameter regimes <cit.>. For example, recent estimates of the effective error rate needed to implement financial derivative pricing in a practical setting using state of the art algorithms has revealed it might require many orders of magnitude improvements over existing hardware <cit.>.\n\n\nFortunately, these quantum Monte Carlo algorithms naturally compound with any speedup in the process simulation.\nTherefore, a critical goal is to find a quantum speedup for simulating stochastic processes, or at the very least a more gate-efficient method of simulating such processes, to render these techniques practical in the future. \nIndeed, <cit.> noted that quantum walk methods can achieve such a speedup in certain cases, and used this to show a quantum algorithm for estimating the partition function of the Ising model exhibiting a quadratic speedup in both the error parameter \u03f5^-1 and the mixing time of the corresponding random walk over classical methods.\nIn a similar spirit there has been interest in efficient loading of particular probability distributions, such as the Gaussian distribution <cit.>, into quantum registers for future use in finance algorithms.\n\n\n\n\n\n\n\n \u00a7.\u00a7 Our results\n\n\n\n\nIn this work we study the quantum simulation of stochastic processes for use in Monte Carlo algorithms. We focus on two questions: first, beyond quantum walks, are there scenarios can one create a coherent quantum simulation of a stochastic process using significantly fewer gates than trivially \u201cquantizing\u201d a classical simulation algorithm (i.e. compiling to Toffolis)? And second, could this create an end to end algorithm for an any potentially relevant applications which surpasses classical Monte Carlo?\n\n\nWe answer both questions in the affirmative.\nFirst, we introduce a new notion of stochastic process simulation which we call the analog simulation of a process, as opposed to the digital simulation obtained by \u201cquantizing\u201d a classical algorithm.\nWe then show that one can create a highly efficient analog simulation for Brownian motion (BM) and a generalization thereof known as fractional Brownian motion (fBM). In particular we show how to \u03f5-approximately simulate a T-step Brownian motion process in merely \u00d5((T)(\u03f5^-1)) qubits and even shorter circuit depth. \n\n\nThere is a quantum algorithm to produce an \u03f5-approximate analog simulation for fractional Brownian motion with Hurst parameter H\u2208 (0, 1], using a quantum circuit with \nO((T)+(\u03f5^- 1/2H)) gates,  O((T)+(\u03f5^-1/2H)) depth, and O((T)+O(\u03f5^-1/2H)) qubits.\n\n\n\n\n\n\n\nHere the input to the algorithm is a description of the parameters of the fractional Brownian motion \u2013 namely the drift, variance and the \u201cHurst parameter\u201d which describes the amount of correlation or anti-correlation between subsequent steps of the Brownian motion. We define this more formally in Section <ref>.\nOur algorithm makes critical use of the quantum Fourier transform and spectral properties of fractional Brownian motion, as well as a recursive application of data loading algorithms which uses special properties of this spectrum.\nAdditionally, we generalize these methods to a broader class of stochastic processes known as L\u00e9vy processes, albeit with weaker simulation guarantees. \n\n\n\n\n\n\nSecond, we show how to use this new representation to obtain an end to end quantum algorithm for estimating properties of stochastic processes, which is faster than classical Monte Carlo. This is not straightforward, as our analog simulation makes use of the exponential size of Hilbert space to efficiently encode the stochastic process trajectories. This does not allow one to directly measure quantities readily available in the digital simulation. For example, one cannot easily read out the value of the process at a particular time, similar to how the HHL algorithm does not allow one to extract individual entries of the solution vector of a linear system <cit.>.\nTherefore, some work must be done to identify properties of stochastic processes which are easily extractable from this analog representation. \n\nTo this end, we describe two quantities which are time averages of the stochastic processes which meet this criteria, which can be efficiently estimated by combining our analog simulation algorithm with quantum mean estimation algorithms <cit.>. \nFor example, we show that one an efficiently price a certain over-the counter financial option currently traded \u2013 in particular, an option on realized variance \u2013 under a particular assumption about the evolution of the asset.\nWe also show that one can create an efficient statistical test for anomalous diffusion in fluids.\nThe first algorithm runs in time O((T)\u03f5^-c) where 3/2<c<2 is a constant depending on certain parameters of the stochastic process. This is an improvement over classical Monte Carlo which runs in time O(T\u03f5^-2), and incomparable[Here the algorithms are incomparabale as coming from the fact that our analog simulation introduces additional error terms into the simulation at order (\u03f5^-1), which are exponentially suppressed in the digital simulation. ] to standard quantum mean estimation which runs in time O(T\u03f5^-1). \nOur algorithm therefore creates a black-box quantum speedup compared to the best black-box classical algorithm.\n\n\n\n\nWe leave open the question of whether our techniques can generate a genuine (white box) quantum speedup for estimating certain properties of stochastic processes.\nHere the central questions are a) to characterize what sorts of properties of fBM we can estimate with our methods and b) to determine if there exist faster classical methods for computing such properties than classical Monte Carlo sampling.\nFor the particular quantities we consider here, there exist closed-form analytical formulae for these quantities, and therefore our results do not represent white-box speedups over the best possible classical algorithm.\nHowever, our technique easily generalize to (mildly) postselected subsets of the process trajectories, which quickly allow one to depart from the regime of closed-form analytical formulae. \nTherefore we expect that our techniques can easily price certain options or evaluate properties of sub/super diffusive fluids which do not have closed-form analytical formulae, and therefore could possibly represent white-box quantum speedups.\nAs with all black-box speedups (including standard quantum mean estimation algorithms), the central question is whether or not faster classical algorithms exist beyond classical Monte Carlo despite the non-existence of closed form solutions.\nWe discuss this further, as well as additional open problems, in Section <ref>.\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Analog vs digital simulation\n\n\n\nA discrete-time stochastic process S(T) is a description of a probability distribution over values v_1, v_2,\u2026 v_T of a particular quantity at specified times 1,2,\u2026 T. \nThe differences between successive values v_i+1-v_i are referred to as the increments of the processes, which might be dependent on one another.\nFor example, the  stochastic process describing a particle subject to diffusion will have independent increments, while the process representing the annual water level in a reservoir will have positively correlated increments due to long-term drought cycles <cit.>. \n\nWe say one can perform a quantum simulation of a stochastic processes if one can coherently produce a quantum state \u03c8 representing the stochastic process. The complexity of this task might depend on the quantum representation of the stochastic process. For example, a commonly used representation (e.g. as mentioned in <cit.>) is to consider the quantum state\n\n    \u2211_v_1,v_2,\u2026 v_T\u221a(p_v_1,v_2,\u2026 v_T)|v_1,v_2,\u2026 v_T\u27e9|g\u27e9\n\nwhere p_v_1,v_2,\u2026 v_T is the probability the process takes values v_1,v_2,\u2026 v_T, |g\u27e9 is a garbage state entangled with the values, and the sum is taken over all possible values of the tuples v_1\u2026 v_T.\nIn other words, the ket of the state encodes the trajectory of the process (i.e. the tuple of values v_1,v_2,\u2026 v_T), and the amplitude stores the probability that trajectory occurs.\nIf one traces out the garbage qubits, the diagonal entries of the reduced density matrix are precisely the probability distribution of the stochastic process. \n\n\nWe call this the digital representation of the stochastic process, because  it meshes well with classical digital simulation algorithms.\nNamely, if one has a classical algorithm to sample from v_1,v_2,\u2026 v_T in time f(T), then it immediately implies a quantum algorithm to produce the digital representation in time O(f(T)) \u2013 simply by compiling the algorithm down to Toffoli gates, and replacing its coin flips with |+\u27e9 states[The coin flip registers then become the garbage register of the above state.].\nTherefore there is no quantum slowdown for the digital simulation task in general.\nTo the best of our knowledge, the best type of quantum speedup for digital simulation occurs via quantum walk algorithms as noted in <cit.>, where f(T) goes to \u221a(f(T)) in certain cases.\n\n\n\nIn this work we introduce a new representation of stochastic processes, which we call the analog representation. \nWe first describe the analog encoding of a single trajectory (v_1,v_2,\u2026 v_T) of the stochastic process S(T) is defined as, \n\n\n\n\n\n    |\u03c8_v_1,v_2,\u2026 v_T\u27e9=(1/v\u2211_i=1^T v_i|i\u27e9)\n\n\nHere the value of the process is encoded in the amplitude of the quantum state and the ket stores the time. This representation of the stochastic process manifestly takes advantage of the exponential nature of quantum states \u2013 as only O(log T) qubits are required to represent a T-timestep process. It is an analog representation as the values are stored in the amplitude of the state, rather than digitally in the value of the ket.\nAn \u03f5-approximate encoding of the trajectory of the stochastic process trajectory is a state such that |\u03c8'_v_1,v_2,\u2026 v_T\u27e9 - |\u03c8_v_1,v_2,\u2026 v_T\u27e9^2\u2264\u03f5. \nNote that here the representation discards the normalization information, but we will later consider modifications of this formalism which keeps normalization information as well, at the cost of introducing an additional flag register which is 0 on the desired (sub-normalized) state.\n\n\n\nPreparing the analog encoding of a single trajectory of S(T) is equivalent to the task of preparing copies of a density matrix \u03c1= \ud835\udd3c_v_1,v_2,\u2026 v_T[ |\u03c8_v_1,v_2,\u2026 v_T\u27e9\u27e8\u03c8_v_1,v_2,\u2026 v_T|]. Such a density matrix represents a single trajectory of the stochastic process sampled according to the correct probabilities.  \nHowever, for quantum Monte Carlo methods to estimate a function of a stochastic process, a stronger notion of coherent analog encodings for S(T) is required. \n\n\n\nThe coherent analog representation of the stochastic process S(T) is defined as follows\n\n\n\n    |S(T)\u27e9= \u2211_v_1,v_2,\u2026 v_T\u221a(p_v_1,v_2,\u2026 v_T)|\u03c8_v_1,v_2,\u2026 v_T\u27e9|g\u27e9\n\nwhere |g\u27e9 is an orthonormal garbage register entangled with the trajectory v_1\u2026 v_T.\nIn other words, we assume that tracing out the garbage register yields the state\n\n    \u03c1 = \ud835\udd3c_v_1,v_2,\u2026 v_T \u223c S|\u03c8_v_1,v_2,\u2026 v_T\u27e9\u27e8\u03c8_v_1,v_2,\u2026 v_T| .\n\nThe garbage register essentially encodes the randomness needed to sample from the process trajectories.\nThe coherent analog representation |S(T)\u27e9 of the stochastic process is compatible with quantum Monte Carlo methods and can be used as part of the simulation circuit/oracle for estimating a function of the stochastic process using the \nquantum amplitude estimation algorithm. An \u03f5 approximate analog encoding for |S_\u03f5(T)\u27e9 is defined similarly where the trajectories generated are \u03f5 approximately correct. We note that a method of preparing \u03c1 directly (e.g. by classically sampling random trajectories and then coherently preparing the trajectory states) is not compatible with amplitude estimation as it is not unitary. \n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Proof sketch\n\nOur first result is to show that the mathematical structure of fractional Brownian motion \u2013 a fundamental stochastic process that can be used to model diffusion processes like the motion of particles in a gas \u2013 is particularly amenable to efficient analog simulation.\n\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Step 1: View in Fourier basis using the QFT\n\nOur algorithm is derived from combining spectral techniques with the quantum Fourier transform. \nThe starting point is the classic spectral analysis of Brownian motion and its Wiener series representation as a Fourier series with stochastic coefficients.\nBrownian motion is a continuous time process, i.e. a probability distribution over continuous real-valued functions B(t):[0,1]\u2192\u211d, with Gaussian increments between distinct times. \nThere are several mathematical definitions of Brownian motion, but the most helpful is a description of its Fourier series due to Wiener (1924).\nWiener observed that Brownian motion[Technically, this is the description of a Brownian bridge which has fixed start and end points. But this spectral analysis can be generalized to other forms of Brownian motion.] with zero drift and variance \u03c3 on the interval [0,1] can be written as\n\n    B(t) =  \u2211_k=1^\u221ea_k/ksin(\u03c0 kt)\n\nwhere the variables a_k are independent identically distributed (i.i.d.) Gaussian variables with mean 0 and variance 1.\nIn other words, when viewed in frequency space, Brownian motion is extremely simple \u2013 its frequency components decouple from one another. \n\n\n\nThe Wiener series representation gives rise to a family of classical spectral algorithms for simulating Brownian motion, which are commonly used in computational finance <cit.>. The basic idea is to discretize time to T timesteps, draw a set of random Gaussian variables a_k of diminishing variances (typically imposing some cutoff on the maximum frequency considered), and take their Fourier transform to obtain a trajectory of B(t).\nClassically this takes time O(Tlog T) via the fast Fourier transform algorithm <cit.>.\n\n\nOur first key observation is that this classical spectral algorithm offers an opportunity for a highly efficient quantum analog simulation for Brownian motion trajectories via the quantum Fourier transform (QFT). \nThe QFT performs a Fourier transform over a vector of length T using only (T) qubits and quantum gates \u2013 essentially by exponentially parallelizing the FFT algorithm \u2013 and is at the is at the core of many quantum speedups, e.g. <cit.>.\nTherefore, if one could efficiently prepare a quantum state encoding the Fourier transform of a stochastic process, then by taking its QFT[For technical reasons we perform a Real version of quantum Fourier transform on such a vector known as the Discrete Sine Transform (DST), but this also admits an efficient quantum circuit implementation based on the QFT circuit.] one would obtain an analog simulation of the process.\nThe problem of analog simulation therefore reduces to the problem of loading the stochastic coefficients of the processes' Fourier transform.\nThis is the conceptual core of our quantum spectral algorithm.\n\n\nFor Brownian motion we therefore need to efficiently load a quantum state where the amplitudes are distributed as independent Gaussians of diminishing variances[We note that this task is different than the one considered in <cit.>, as we are probabilistically loading the Gaussian into a single amplitude, rather than deterministically preparing a single quantum state with many amplitudes in the shape of a Gaussian.].\nAs we discuss next, the symmetries of the Brownian motion and the decoupling of the stochastic coefficients allows us to obtain a very efficient quantum analog \nsimulation algorithm for the Brownian motion. A similar analysis holds for fractional Brownian motion as well. Here the Fourier coefficients of the process decouple as well to independent Gaussians, but the functional form of the diminishing variances is given by a power low function of the Hurst parameter which controls the amount of correlation between steps. For simplicity of presentation, we will sketch our algorithm for standard Brownian motion. The extension to fractional Brownian motion will later be shown in Section <ref> using similar ideas.\n\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Step 2: Efficient Gaussian loading\n\n\nVia the QFT, we have shown that to produce an analog simulation of a single trajectory of Brownian motion, we need to show how to efficiently prepare a quantum state encoding its Fourier transform.\nIn other words, we need to prepare the state, \n\n\n\n    |\u03d5_a\u20d7\u27e9\u221d\u2211_k=1^Ta_k/k|k\u27e9\n\nwhere the a_k \u223c N(0,1) and the series coefficients are independent Gaussian variables of decreasing variance according the function f(k)=1/k.\nWe call this the \u201cGaussian loading problem\u201d for the function f(k)=1/k \u2013 and in general one can consider this problem with different decay functions of the variance.\n\n\nThe first step of our algorithm is to truncate the Fourier series to a finite number of terms L. That is, we instead prepare the state\n\n    |\u03d5_a\u20d7\u27e9\u221d\u2211_k=1^La_k/k|k\u27e9\n\nThis introduces a small amount of error in our simulation algorithm. However, as the function 1/k is rapidly diminishing as a function of k, we show that this only introduces a small amount of error in our simulation. More generally in one wishes to find an \u03f5-approximate simulation algorithm, this only requires setting L=(\u03f5^-1).\n\n\n\n\n\nWe then give an efficient quantum for solving this truncated Gaussian loading problem, which we believe may be of independent interest.\nOur algorithm uses only O(L+log T + log(\u03f5^-1)) qubits and computation time. \nOur algorithm applies to a variety of decay functions for the variance \u2013 which will play a key role in our generalization to fractional Brownian motion.\n\nThis algorithm is the technical core of our results.\n\n\nThe starting point for our Gaussian loading algorithm is highly efficient data loader circuits <cit.> for particular quantum states. These are circuit realizations of previous recursive constructions that used specialized quantum memory devices such as those of Grover and Rudolph <cit.> and Kerenidis and Prakash <cit.>. For any fixed values of the a_i, one can define a log-depth circuit to load the vector |\u03d5_a\u20d7\u27e9, by now standard recursive doubling tricks \u2013 one simply computes how much \u2113_2 mass is on the first vs second half of the state, hard-codes this as a rotation angle between the first and second halves, and recurses in superposition.\nThis results in a log-depth circuit for loading the state, where k is represented in unary. \n\nThere are two issues which must be solved to apply this algorithm to our Gaussian loading problem.\nFor one, this loading occurs in unary, and we are using a binary representations of k and T in our analog encoding, but this turns out to be a minor issue which can be solved with low-depth binary to unary converters (see Appendix <ref>). The second and more fundamental issue is that this only describes how to efficiently load a single state, and we wish to load the analog representation of the Brownian motion |B(t)\u27e9 in order to be \ncompatible with quantum Monte Carlo methods. \n\nWe solve this by applying the data loading algorithm twice recursively \u2013 which we call \u201cdata loading the data loader.\" The basic idea is that for any data loading algorithm \ud835\udc9c, it takes as input some rotation angles \u03b8\u20d7, and outputs a state |\ud835\udc9c(\u03b8\u20d7)\u27e9.\nThe data loading algorithms we consider are onto, in other words for any state |\u03c8\u27e9, there exists a setting of the angles |\u03b8\u27e9 such that \ud835\udc9c(\u03b8\u20d7)=|\u03c8\u27e9.\nThus, given any distribution D over quantum states, this induces a classical probability distribution D' over vectors \u03b8\u20d7. Therefore, if we could only efficiently load the quantum state corresponding to D', i.e.\n\n    |D'\u27e9 = \u2211_\u03b8\u20d7\u221a(D'(\u03b8\u20d7))|\u03b8\u20d7\u27e9\n\nwhere D'(\u03b8\u20d7) is the probability of \u03b8\u20d7 in D', \nthen by feeding this state into \ud835\udc9c and tracing out the angle registers, this would efficiently allow us to prepare \u03c3.\n\nIf one considers applying this technique directly, however, it turns out to produce highly complex quantum circuits. \nWhile there exists a distribution D' over data loader angles to produce states of independent diminishing Gaussians, the joint distribution induced on angles is quite complicated.\nIn particular, the angles are highly correlated with one another.\nIn other words, the induced distribution on the angle \u03b8_i applied at a particular stage of the algorithm is dependent on the prior angles applied.\nTherefore, to load the probability distribution on angles D' would be prohibitively costly \u2013 as it would require solving a highly correlated data loading problem across many qubit registers. This increases the complexity of the data loading circuit which reduces or eliminates our potential advantage from using the QFT.\n\n\n\nWe circumvent this obstacle in two steps. First, we show one can highly efficiently load large vectors of i.i.d. Gaussians, i.e. where the Gaussian entries all have the same variance. \nThis is because the induced distribution on data loader angles is independent \u2013 we show the angles decouple due to symmetries of the high-dimensional Gaussian, which mesh particularly well with the binary tree data-loading circuits.\nIn fact the distribution on data loader angles \u03b8\u20d7 turn out to have a closed form given in terms of the \u03b2 and \u03b3 distributions due to the fact that the sum of squares of k i.i.d. Gaussians are distributed according to the \u03b3(k/2) distribution.\nTherefore, there is a highly efficient circuit to load these angles - one just loads each angle register separately, and feeds it into the <cit.> circuits.\nThis allows us to quickly prepare quantum states with i.i.d. Gaussian entries. \n\nSecond, we show that we can efficiently convert such states into states with decreasing variances with a simple trick.\nThe basic idea is to artificially inject diminishing variances with reversible addition \u2013 we first prepare prepare \u2211_1^L b_k|k\u27e9 where the b_k\u223c N(0,1) as described above, then prepare the state \u2211_1^L 1/k|k\u27e9, and reversibly add their register mod L to produce\n\n    \u2211_k,k'=1^Lb_k/k'|k\u27e9|k'\u27e9|k+k'  L\u27e9\n\nwe then measure the auxiliary register to get the value of l=(k+k'  L).\nPost measurement, the amplitudes are b_k+l/k' \u2013 which looks like exactly what we desire, except the entries of the Guassian vector b have been permuted (shifted by l). \nThe key observation, however, is that the iid Gaussian vector b\u20d7 is permutation invariant.\nTherefore\n\n b_k'+l/k' ranging over k' have the same distribution as i.i.d. Gaussian amplitudes with decaying variances, irrespective of the value of l. \n The same technique works for a wide variety of functional forms of diminishing variances, which we discuss in detail in the main text, as it is key to generalizing our algorithm to fractional Brownian motion.\n\n\n\n  \u00a7.\u00a7.\u00a7 Sketch of end to end applications\n\n\n\n\n\n\nWe also provide two end-to-end examples using our analog encoding which provide black-box speedups over classical Monte Carlo sampling.\n\nThe first example entails the pricing of a variance swap. A variance swap is a financial instrument which pays out proportional to the mean squared volatility observed in a stock price \u2013 so the more volatile the stock, the more it pays out. It can be used as a hedge against volatility, and is traded as an over the counter option in financial markets. We show that we can use our analog encoding to efficiently price a variance swap in certain conditions. At a high level, our algorithm is efficient because the price of a variance swap is naturally a time average of a square of values of the volatility, and it is particularly easy to extract time averages from our analog encoding (as they are certain amplitudes of our state which are relatively large). Our algorithm works under a particular assumption about the time evolution of the price of the underlying asset. In particular, the asset must evolve by Geometric Brownian motion with changing variance, and where the variance evolves by fractional Brownian motion. By combining our algorithm with quantum mean estimation, we can \u03f5-approximate the value of the option in time O((T)\u03f5^-c) where 3/2<c=1+1/2H<2 where H is the Hurst parameter of the fBM. Our algorithm works better with higher Hurst parameters of the volatility. See Section <ref> for details. \n\nWhile this particular option has a closed-form analytical solution, we note we can easily apply post-selection on the fBM, for example over paths whose norm lies in a given interval, which would circumvent the possibility of an analytic solution. \n\nOur second example involves a statistical test to distinguish between different diffusive regimes in single- particle motion. While in ideal fluids particle positions evolve by Brownian motion, in particular sub or super-diffusive fluids, they evolve by fBM with a nontrivial Hurst parameter.\nWe show that we can use our analog encoding for fBM to create a statistical test that distinguishes between a particle following an fBM with given Hurst parameter, or fBM with an alternative Hurst parameter, or even a simple case of a continuous-time-random walk. \nOur algorithm again runs in time \u00d5((T) \u03f5^-c'), where c'>2 depends on the Hurst parameter of the fBM, rather than \u00d5((T)*N) in the classical case, where N is determined by the discretization used to sample its characteristic function. \nUnlike our prior application, here we do not run quantum mean estimation, but rather use our simulation directly to produce estimates of the average mean-squared-displacement of the particle under certain Hurst parameters, which is compared to the observed data. Therefore this application has a worse scaling in \u03f5^-1 compared to classical, but a better scaling in T. As we will discuss shortly, this could still possibly generate a faster black-box algorithm than classical Monte Carlo in situations with large T.\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Generalizations and Open Problems\n\n\n\n\n\nThere are many open problems remaining.\nOf course, the most direct one is whether or not our method can produce an end to end asymptotic speedup for computing properties of certain stochastic processes, as previously discussed. \nHere the basic issue is to identify interesting properties of fractional Brownian motion which are complicated enough to require classical Monte Carlo approaches.\nIn this direction we believe considering functions of postselected subsets of trajectories is the most promising approach. \nPostselection typically takes one out of the regime of analytical formulae.\nFor example, in computational finance, barrier options (which only can pay out if the price of the underlying asset breaches a certain value at some point in time) typically do not have analytical formulae and therefore are priced by Monte Carlo methods. \nPostselection slows both our quantum algorithm and classical Monte Carlo in unison, preserving the relative speedup of our method relatively to classical MC.\nTherefore, if one could find a postelected property of fBM for which the best classical estimation algorithm is classical MC, then this could yield a white-box speedup for our algorithm.\n\nAnother possible direction to search for speedups is to consider other inner products one could compute with respect to Brownian Motion. We generalize our algorithm to the following: given a function f(t), one can efficiently evaluate its inner product with BM, i.e. |\u27e8f(T)|B(T)\u27e9|^2, assuming that one can prepare a quantum state encoding f(t) (for details see Section <ref>). \nOur given applications are the special case where f is the indicator function between times t_1 and t_2.\nOne can ask if other functions might give a quantum speedup.\n\n\nIn any case, quantifying such a speedup would require careful work.\nFor one, there are many parameters at play.\nTo quantify an end to end speedup, one would need to take into account that the parameter T is implicitly a function of \u03f5 (see e.g. <cit.>).\nFor example if one must set T=O(\u03f5^-1) vs T=O(\u03f5^-2) vs T=O(\u03f5^-1/2), then our method's black-box speedup becomes polynomial, but with differing degrees.\nWe note that even if T=O(\u03f5^-1), our method's savings in T pushes our algorithms' performance beyond that of standard quantum mean estimation \u2013 and the gap only grows if T is larger.  \nOther factors might also affect the apparent speedup \u2013 for example if the quantity being estimated is invariant to high-frequency components of the stochastic process (as with a time average), then our algorithms' omission of high-frequency content might result in a better error scaling than our naive bounds, and potentially result in a \u00d5((T) \u03f5^-c) algorithm where c<1.\nFor this reason we believe quantifying potential asymptotic speedups for potential problems of interest to be an interesting line of inquiry.\nMore broadly, we leave open the question of whether our techniques can be \u201cde-quantized\u201d in a similar spirit to <cit.>, i.e. if it is possible achieve a similar (T) dependence for sampling from values/times of fBM trajectories[However, we note that this would only \u201cde-quantize\u201d the applications which do not make use of quantum mean estimation/amplitude estimation, as the latter algorithms intrinsically require coherent state preparation and not probabilistic samples.\n].\n\n\nAnother interesting direction is to explore what other stochastic processes might be amenable to efficient analog simulation. For example, would it be possible to give an efficient analog simulation for Geometric Brownian motion? The case of Brownian motion is particularly nice because its Fourier spectrum decouples.\n For a general stochastic processes, there are non trivial dependencies between the stochastic coefficients and the resources \nrequired for loading the joint distribution of the Fourier coefficients may be prohibitive. \nHowever there are more general families of stochastic processes with well-behaved spectra,\nOne reason the Fourier spectrum of Brownian motion is well-behaved it that it is a stationary process, i.e. the joint probability distribution does not change when shifted in time. This cyclic shift symmetry is precisely the symmetry of the QFT, and therefore it might be possible to give simulations for other stationary processes. In another direction, our results use the fact that Brownian motion can be expressed as an integral over white noise \u2013 which is noise with i.i.d Gaussian Fourier components.\n\nIn this spirit, in Section <ref> we generalize our algorithm to produce analog encodings of trajectories of L\u00e9vy processes.\nL\u00e9vy processes are stationary stochastic processes generalizing Brownian motion, which can be expressed as integrals over a linear combination of Poisson and Brownian noise. The quantum simulation method for L\u00e9vy process trajectories is obtained by quantizing the classical method that embeds the Toeplitz discrete integration operator into a circulant matrix <cit.>. The method remains efficient in the quantum setting with gate complexity O((log T, 1/\u03f5)) as circulant matrices are diagonalized by the quantum Fourier transform and further the Fourier spectrum of L\u00e9vy noise is flat, similar to the spectrum of the white noise. However our simulation results for L\u00e9vy processes are weaker than those for fBM, as we can only provide an incoherent simulation of these processes due to the coupling of the Fourier coefficients, and therefore cannot combine this method with amplitude estimation. The stochastic integral method can be used to generate encodings of It\u00f4 processes that are defined as integrals over white noise and time.  We leave open the question of whether the quantum spectral method can be generalized further to (fractional) integrals over white noise and Poisson shot noise\u2013 this  family of stochastic processes includes L\u00e9vy and It\u00f4 processes as well as fractional Brownian motions. Indeed our extension to fractional Brownian motion \u2013 which can be expressed as a fractional integral of Brownian motion \u2013 is a step in this direction.\n\n\nThere is also the more direct question of whether analog simulation results in smaller quantum circuits than digital simulation for stochastic processes of interest beyond Brownian motion, in a non-asymptotic setting relevant to potential future applications of error-corrected quantum computers. This was part of our original motivation for this line of work, and we hope our work spurs further efforts in this area.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 PRELIMINARIES\n \nWe introduce some preliminaries on stochastic processes and quantum computing in this section. \nIn subsection <ref>, we begin with the defining the Brownian motion. More generally, our techniques are applicable to stochastic processes that can be written as stochastic integrals over time and over Brownian motion, these processes include the fractional Brownian motion and It\u00f4 processes. \nSubsection <ref> introduces the quantum Fourier transform and state preparation circuits that will be used for constructing the quantum encoding for the stochastic processes. \n\n\n \u00a7.\u00a7 Brownian motion and It\u00f4 processes\n  \nThe stochastic processes considered in this work are Brownian motion and its generalization to It\u00f4 processes. We first introduce the Brownian motion and then the more general processes that can be represented as \nintegrals over Brownian motion.  The Brownian motion is defined as follows, \n \nThe Brownian motion is a stochastic process B: ^+\u2192 such that: \n \n\n  * B(0)=0 and B(t+h) - B(t) \u223c N(0, h) for all t, h \u2208^+ where N(0,h) is the normal distribution with mean 0 and variance h. \n\n  * For any finite subdivision 0< t_1 <t_2\u22ef <t_n of time steps, the increments B(t_i+1) - B(t_i) are independent random variables. \n\n  * Almost surely, t \u2192 B(t) is a continuous function. \n \n \nThe existence of Brownian motion is not obvious from this definition, it was first demonstrated by Wiener <cit.> and \na different alternate construction was given by L\u00e9vy <cit.>.  Wiener obtained a stochastic Fourier series representation for the Brownian motion on [0,\u03c0], \n (Wiener <cit.>)  \nFor independent random variables a_i\u223c N(0,1), the following Fourier series represents Brownian motion on the interval [0, \u03c0], \n \nB(t) = \u221a( 1/ \u03c0 )  a_0 t + \u221a( 2/\u03c0)  \u2211_k\u22651 a_k  sin(kt) /k  \n \n \nThe Brownian motion on ^+ is obtained by concatenating independent Brownian motions on intervals [k\u03c0, (k+1)\u03c0]. Discarding the drift term in the Wiener series, one obtains the Brownian bridge, which represents a Brownian path with the values at the start and end point fixed to 0. The Fourier series representation of the Brownian motion will also be used for the quantum simulation algorithm. \n\nMore general stochastic processes can be defined as stochastic integrals over the Brownian motion. The stochastic integral \u222b^t_0 f(s) dB_s=  lim_N \u2192\u221e\u2211_i \u2208 [N] f(t_i) (B(t_i) - B(t_t-1) is defined as the limit over equal subdivisions t_i, i \u2208 [N] of the interval [0,t] of the sum \u2211_i \u2208 [N] f(t_i) (B(t_i) - B(t_t-1). An important class of processes defined as stochastic integrals over Brownian motion is the fractional Brownian motion (fBM), a one parameter extension of Brownian motion for a Hurst parameter H\u2208 [0,1]. The fBM with Hurst parameter H=1/2 corresponds to standard Brownian motion.  The fractional Brownian motion was first discussed by L\u00e9vy <cit.> as an integral over the standard Brownian motion.\n\n\n  \nThe fractional Brownian motion with Hurst exponent H \u2208 [0, 1] is defined to be the stochastic process, \n \nfBM_H (t) := \u222b^t_0 ( t- s)^H-0.5 dB_s \n eq2 \n \nMandelbrot and Van Ness <cit.> provided an origin independent fractional Brownian motion given by the \nWeyl integral, this definition as well can be written in integral form as  \u222b^t_0 K_H(s-t) dB_s for a Kernel function depending only on the difference (s-t). The definition of fBM used for spectral simulation is that as a fractional integral of the white noise, the BM in turn can be viewed as  \nintegral of the white noise. \n\nStochastic processes that can written as a linear combination of a stochastic integral over Brownian motion and a stochastic integral over time are called It\u00f4 processes. An It\u00f4 process has a representation of the form, \n\nX_t = X_0 + \u222b\u03c3_s dB_s + \u222b\u03bc_t dt \n \nIn addition to fractional Brownian motion, we also develop quantum simulation methods for generating trajectories of It\u00f4 and L\u00e9vy processes \nthat can be represented as stochastic integrals in section <ref>. \n\n\n\n \u00a7.\u00a7 Quantum computing preliminaries\n  \nWe introduce in this section the quantum Fourier transform and logarithmic depth state preparation circuits that are components of the quantum stochastic process simulation \nalgorithm. The quantum Fourier transform is defined as follows, \n \nThe quantum Fourier transform () is an N dimensional unitary matrix U with entries given by (U)_jk = e^2\u03c0 i jk/N = \u03c9^jk for 0\u2264 j, k \u2264 n, where \u03c9 = e^2 \u03c0 i/N is an N-th root of unity. \n \nThe real and the imaginary part of the the quantum Fourier transform are known as the discrete cosine transform (DCT) and the discrete sine transforms (DST) respectively. It is well known that the quantum Fourier transform (QFT) can be implemented as a logarithmic depth circuit, an explicit implementation using Hadamard and phase gates is provided in Appendix <ref>. It also follows that the logarithmic depth circuit for the QFT can be used to implement the discrete sine and cosine transforms. \n\nThe second quantum computing primitive that we use are the logarithmic depth state preparation circuits in quantum machine learning termed as data loaders <cit.>. The data loader circuit is a parametrized circuit that prepares the amplitude encoding |x\u27e9 for a vector x \u2208^n. The data loader circuits are composed of recursive beam splitter (RBS) gates that are two qubit gates given as, \n\n    RBS(\u03b8) =  [               1       0       0       0;               0  cos(\u03b8)  sin(\u03b8)       0;               0 -sin(\u03b8)  cos(\u03b8)       0;               0       0       0       1 ].\n  \n\nThe logarithmic depth data loader circuit is illustrated in Figure <ref>, it outputs the state |x\u27e9 on input |0^n\u27e9. The data loader can be viewed as a circuit based realization of binary tree data structure for state preparation. \nThe angles for the beam splitter gates in the data loader are determined by the vector x that is being prepared by the circuit and are deterministic functions for quantum machine learning applications. \n\n\n\n\n\nFor the quantum simulation of stochastic processes, the data loader is used with stochastic input, that is the input vector x is not fixed but drawn from a distribution over the unit sphere. The angles in the data loader circuit are thus drawn from a specific distribution, the explicit calculation of the angle distribution for the Haar random vector on the unit sphere will be an important part of the quantum algorithm for simulating Brownian motion trajectories. \n\nMore explicitly, the angles for the data loader for vector x \u2208^n are computed using a binary heap data structure where each node stores the sum of squares of the values in its subtree and an angle \u03b8. \nDenoting the value stored at node j by r(j) and, the angle \u03b8 is given by \u03b8= arccos(\u221a(r(2j)/r(j))) where r(2j) is the sum of squares of the values stored in the left subtree for node j, \nthat is cos^2(\u03b8) = r(2j)/r(j) and sin^2(\u03b8) = r(2j+1)/r(j). This description is useful for computing the distribution on the data loader angles for a Gaussian random vector. \n\nThe data loader circuit produces a unary encoding for vector x using n qubits. It is further possible to convert the unary encoding into a binary encoding with a quantum circuit having depth poly-logarithmic in the dimension of the vector. The circuit for the unary to binary conversion is given in appendix <ref>. \n\n\n\n\n\u00a7 QUANTUM ENCODINGS OF STOCHASTIC PROCESSES\n \nA discrete-time stochastic process S(T) is a description of a probability distribution over values v_1, v_2,\u2026 v_T of a particular quantity at specified times 1,2,\u2026 T. \nThe differences between successive values v_i+1-v_i are referred to as the increments of the processes, which might be dependent on one another. A quantum simulation of a stochastic processes is a procedure to prepare quantum state \u03c8 representing the stochastic process. \n\nThe complexity of this task depends on the quantum representation of the stochastic process. We recall first the commonly used digital quantum encoding for a stochastic process and \nthen introduce two different types of analog encodings. \n\nA digital representation for a quantum stochastic processes is defined as the state, \n\n    \u2211_v_1,v_2,\u2026 v_T\u221a(p_v_1,v_2,\u2026 v_T)|v_1,v_2,\u2026 v_T\u27e9|g\u27e9\n\nwhere p_v_1,v_2,\u2026 v_T is the probability the process takes values v_1,v_2,\u2026 v_T while |g\u27e9 is a garbage state entangled with the values, and the sum is taken over all possible values of the tuples v_1\u2026 v_T.\n \nThe registers in the digital encoding store the entire trajectory of the process (i.e. (v_1,v_2,\u2026 v_T)), while the amplitude stores the probability that trajectory occurs.\nIf one traces out the garbage qubits, the diagonal entries of the reduced density matrix are precisely the probability distribution of the stochastic process. \n\n\nWe call this the digital representation of the stochastic process, because  it meshes well with classical digital simulation algorithms.\nNamely, if one has a classical algorithm to sample from v_1,v_2,\u2026 v_T in time f(T), then it immediately implies a quantum algorithm to produce the digital representation in time O(f(T)) \u2013 simply by compiling the algorithm down to Toffoli gates, and replacing its coin flips with |+\u27e9 states. There is no quantum slowdown for the digital simulation task, but to the best of our knowledge, nor are there any quantum speedups.\n\n\nIn this work we ask if quantum computation might admit faster algorithms for stochastic simulation tasks. \nWe begin by introducing the analog representation where the values of the stochastic process are stored in the amplitudes. \n  \nThe analog encoding of a single trajectory (v_1,v_2,\u2026 v_T) of the stochastic process S(T) is the quantum state, \n\n    |\u03c8_v_1,v_2,\u2026 v_T\u27e9=(1/v\u2211_i=1^T v_i|i\u27e9|0\u27e9).\n\nAn \u03f5-approximate encoding of the trajectory of the stochastic process trajectory is a state such that |\u03c8'_v_1,v_2,\u2026 v_T\u27e9 - |\u03c8_v_1,v_2,\u2026 v_T\u27e9^2\u2264\u03f5. \n \n\n\nHere the value of the process is encoded in the amplitude of the quantum state and the ket stores the time. This representation of the stochastic process manifestly takes advantage of the exponential nature of quantum states \u2013 as only O(log T) qubits are required to represent a T-timestep process. It is an analog representation as the values are stored in the amplitude of the state, rather than digitally in the value of the ket.\n\n\nPreparing the analog encoding of a single trajectory of S(T) is equivalent to the task of preparing copies of a density matrix \u03c1= \ud835\udd3c_v_1,v_2,\u2026 v_T[ |\u03c8_v_1,v_2,\u2026 v_T\u27e9\u27e8\u03c8_v_1,v_2,\u2026 v_T|]. Such a density matrix represents a single trajectory of the stochastic process sampled according to the correct probabilities.  \nHowever, for quantum Monte Carlo methods to estimate a function of a stochastic process, a stronger notion of coherent analog encodings for S(T) is required. \n\n\nThe coherent analog representation of the stochastic process S(T) is a superposition analog representation of the corresponding trajectories, \n\n    |S(T)\u27e9= \u2211_v_1,v_2,\u2026 v_T\u221a(p_v_1,v_2,\u2026 v_T)|\u03c8_v_1,v_2,\u2026 v_T\u27e9|g\u27e9\n\nAdditionally, there is a garbage register |g\u27e9 that encodes the randomness used to generate the corresponding trajectory.  An \u03f5 approximate analog encoding for |S_\u03f5(T)\u27e9 is a superposition over \u03f5 approximate trajectories  \u221a(p_v_1,v_2,\u2026 v_T)|\u03c8'_v_1,v_2,\u2026 v_T\u27e9 with \u03c8'_v_1,v_2,\u2026 v_T being \u03f5 approximate trajectories as in definition <ref>. \n\n\n\n\n\n\n\u00a7 QUANTUM SIMULATION OF BROWNIAN MOTION\n \nThe stochastic Fourier series representation of the Brownian motion (Theorem <ref>) provides a classical algorithm with complexity O(T log T) for simulating a Brownian path over T steps using the fast Fourier transform. It also suggests a quantum algorithm for generating analog encodings of Brownian trajectories on a quantum computer. The quantum algorithm first prepares the state |W\u27e9 = \u2211_i \u2208 [L]a_i/i|i\u27e9 obtained by truncating the Wiener series to a fixed number of terms L using a data loader circuit and then applies the quantum Fourier transform circuit.\n\nThe number of terms L required to obtain an approximate representation of the Brownian path are much smaller than the number of time steps, for example taking L=200 terms in the series leads to an \u2113_2-norm error of 0.3 percent. The quantum simulation algorithms use O(L) gates and have complexity poly-logarithmic in T, and achieve a speedup over the classical simulator in the regime T \u226b L,\n\n\nWe next describe an optimized algorithm for preparing analog encodings of Brownian motion with circuit depth O(log L) + log (T)), this algorithm will be used as a subroutine for generating the coherent analog encoding for fractional Brownian motions. \n  \nThere is a quantum algorithm for generating \u03f5-approximate analog encodings of Brownian motion trajectories on T time steps that requires O(L + log T) qubits, has circuit depth O( log L + log T) and gate complexity O(L + polylog(T)) for L=O(1/\u03f5). \n \nThe poly-logarithmic gate complexity of the quantum Fourier transform further leads to the possibility of a potentially significant quantum speedup in for generating analog encodings of Brownian motion trajectories\n over T time steps T. A classical algorithm that writes down the Brownian motion trajectory over T time steps has complexity O(T). \n\nThe quantum algorithm for simulating Brownian paths is presented as Algorithm <ref>. We describe the implementation of the different steps and then establish correctness of the algorithm. \n\n\n\nAn efficient procedure for generating the random Gaussian state required for step 2 of algorithm <ref> is described in Section <ref>, this procedure uses the data loader circuit but with angles drawn from a certain  \ndistribution to ensure that the vector prepared is the random Gaussian state. The discrete sine transform matrix can be implemented as a quantum circuit with depth O(log T) as shown in appendix <ref>. The total circuit depth for the algorithm is therefore O(log L + log T), the number of qubits used is O(L+ log T) and the gate complexity is O(L + polylog(T)) as claimed. The correctness of the Algorithm <ref> is established in Lemma <ref>. \nThe dependence of the \u2113_2 approximation error on the number of terms L retained in the Wiener series is examined in Section <ref>. \n\n\n\n\n \u00a7.\u00a7 Gaussian state preparation\n  \nIn order to prepare the Gaussian state in step 2 of the algorithm, we need to compute the distribution on the angles for a unary data loader for a uniformly random unit vector in S^n according to the Haar measure. Recall that a Haar random unit vector is obtained by choosing i.i.d. N(0,1) \nGaussian random variables for the coordinates and rescaling to unit norm. Further, we show that for Haar random vectors, the angle distributions for the different angles in the data loader are independent and that these distributions can be specified exactly in terms of the gamma and beta distributions. We begin by recalling some of the useful properties of the beta and gamma distributions and then establishing the independence of the angle distributions for a uniformly random vector and explicitly computing the angle distributions. \n\n \nThe Gamma distribution \u03b3(a) has support ^+, it is parametrized by a>0 and has cumulative distribution function, \n \nPr [ X \u2264x ] =  1/ \u0393(a) \u222b^x_0 t^a-1 e^-t dt. \n \n\u0393(a) is the Gamma function. \n  \n The Beta distribution can be defined in terms of the Gamma distribution, \n   \n The Beta distribution \u03b2(a,b) distribution is defined as Y_1/ Y_1 + Y_2 where Y_1\u223c\u03b3(a), Y_2\u223c\u03b3(b). \n The density function for the \u03b2(a,b) distribution is \u0393(a)\u0393(b)/\u0393(a+b) x^\u03b1-1(1-x)^\u03b2-1. \n  \n A sum of squares of k identically distributed N(0,1) Gaussian random variables can be expressed in terms of the Gamma distribution. \n \n\n \nThe sum of squares \u2211_i X_i^2/2 where X_i are k independent Gaussian random variables has distribution \u03b3(k/2). \n \nThis fundamental fact underlies the \n computation of the distribution for the data loader angles, a proof is provided in Appendix <ref> for completeness. \n In addition to the above fact, we require a lemma that computes the distribution of \u03b8 if sin^2(\u03b8) has a \u03b2(a, b) distribution. \n  \nIf sin^2(\u03b8) is distributed according to \u03b2(a,b), then \u03b8 has probability density function F(t)=  \u0393(a)\u0393(b)/\u0393(a+b)sin^2a-1(t) cos^2b-1(t).  \n \n \nAs sin^2(\u03b8) is distributed according to \u03b2(a,b), we have that [sin^2(\u03b8) \u2264  t] = \u0393(a)\u0393(b)/\u0393(a+b)\u222b^t_0 x^a-1(1-x)^b-1 dx.  \nThe function sin^2(\u03b8) is monotone on the interval [0, \u03c0/2], \n \n[\u03b8\u2264t] = [sin^2(\u03b8)<sin^2(t)] = \u0393(a)\u0393(b)/\u0393(a+b) \u222b^sin^2(t)_0 x^\u03b1-1(1-x)^\u03b2-1 dx.  \n \nSubstituting x= sin^2(z) so that dx= 2sin(z) cos(z) dz, the integral above reduces to, \n \n\u0393(a)\u0393(b)/\u0393(a+b) \u222b^t_0 sin^2a-1(z) cos^2b-1(z) dz.  \n \nIt follows that the density function for \u03b8 is F(t) = \u0393(a)\u0393(b)/\u0393(a+b)sin^2a-1(t) cos^2b-1(t) as claimed. \n \n \n Using the above probabilistic facts, we are now ready to compute the distribution of the data loader angles for a vector with coordinates given by i.i.d. Gaussian random variables. \n\n\n  \nIf the vector x\u2208^n stored in the binary data loader is uniformly random, the angle \u03b8 at node of height h has probability density function \n\u0393(2^h-2)^2/\u0393(2^h-1)sin^2^h-1-1(t) cos^2^h-1-1(t). \n \n \nThe binary data loader for vector x \u2208^n uses a binary heap data structure where each node stores the sum of squares of the values in its subtree and an angle \u03b8. \nDenoting the value stored at node j by r(j) and, the angle \u03b8 is given by \u03b8= arccos(\u221a(r(2j)/r(j))) where r(2j) is the sum of squares of the values stored in the left subtree for node j, \nthat is cos^2(\u03b8) = r(2j)/r(j) and sin^2(\u03b8) = r(2j+1)/r(j). \n\nIf x \u2208^n is a uniformly random vector then the values at the leaf nodes have distribution X_i^2 where X_i are independent N(0,1) random variables. The sum of squares 1/2\u2211_i \u2208 [k] X_i^2 for a k independent N(0,1) random variables X_i has distribution \u03b3(k/2) by Proposition <ref>. It follows from the definition of the beta distribution <ref> that for a node at height h (with the convention that the leaf nodes are at height 1), sin^2(\u03b8)=  r(2j+1)/r(j) \nhas distribution \u03b2(2^h-2, 2^h-2). Applying Lemma <ref>, the angle \u03b8 for a node at height h has probability density function \u0393(2^h-2)^2/\u0393(2^h-1)sin^2^h-1-1(t) cos^2^h-1-1(t). \n \nWe computed the distribution of the angles at the nodes for a  for a uniformly random vector the angles at the nodes of the binary data loader. The next Lemma shows that these angles are in fact independent for uniformly random vectors. \n  \nIf the vector x\u2208^n stored in the binary data loader is a Haar random unit vector, the angles \u03b8_i, \u03b8_j stored at different nodes i, j are independent. \n \n \nIf the nodes i,j are at the same height the angles are independent as they are functions of different i.i.d. Gaussian random variables. Without loss of generality let the h(i)\u2264 h(j) where h is the height of the nodes. If j \ndoes not lie on the path from the root to i, then the angles at i,j are independent as they are functions of different i.i.d. Gaussian random variables. It therefore suffices to show that for a given node j, the angles in the \nleft sub-tree rooted at j are independent of the angle at j. \n\nThe angles for the binary data loader are independent of the x, that is the angles are the same for x and cx for all c \u2208. The angle at node j is a function ratio of the norms of the left and right subtrees, \nthat is \u03b8= arctan(\u221a( r_2j+1/r_2j)). It follows that for i in the left-subtree rooted at j, the density function f(\u03b8_i|\u03b8_j)= f(\u03b8_i | r_2j)= f(\u03b8_i) establishing the independence of \u03b8_i and \u03b8_j.  \n\n\n \nWe are now ready to provide the procedure for generating the random Gaussian state in step 2 of Algorithm <ref>. \n \nThe quantum state |R\u27e9  = 1/ Z_2\u2211_i \u2208 [L] a_i|i\u27e9 where a_i are independent N(0,1) random variables can be prepared using the binary data loader \nconstruction with independent angles \u03b8_i at height h distributed according to the density function \u0393(2^h-2)^2/\u0393(2^h-1)sin^2^h-1-1(t) cos^2^h-1-1(t). \n \n \nThe result follows from the distribution of the angles \u03b8_i at height h computed in Lemma <ref> and the independence of the angles \u03b8_i established in Lemma <ref>.   \n \n\n\n\n\n  \u00a7.\u00a7.\u00a7 Correctness of the quantum algorithm\n \n\nWe have described the quantum circuits implementing the steps of Algorithm <ref>, we are now ready to show that the algorithm produces the quantum states corresponding to superpositions \nover Brownian paths as claimed. \n  \nThe output of Algorithm <ref> is the quantum state  |B_L\u27e9 = 1/Z_3\u2211_i \u2208 [T] B_L (i \u03c0 /T) |i\u27e9 representing the Brownian bridge with T time steps obtained by truncating the Wiener series to L terms. \n \n \nAlgorithm <ref> outputs the quantum state obtained by applying the discrete sine transform to the state 1/ Z_3\u2211_k \u2208 [L]  a_k \u2295 j/ k|k\u27e9|0^log T - log L\u27e9 where j is the \nresult of the measurement in step 3. The L dimensional vector a\u20d7 = (a_1, a_2, \u22ef, a_L) has i.i.d. coordinates distributed according to N(0,1). The i.i.d. property is preserved if an arbitrary permutation \n\u03c3\u2208 S_L is applied to a\u20d7. \n\nFor all j \u2208 [L] the mapping a_k\u2192 a_k \u2295 j is a permutation as k_1\u2295 j = k_2\u2295 j implies that k_1= k_2. The vector  a\u20d7_\u20d7j\u20d7 = (a_1\u2295 j, a_2 \u2295 j, \u22ef, a_L \u2295 j)\ntherefore has the same distribution as a\u20d7 for all j. By Wiener's Theorem, it follows that the discrete sine transform applied to 1/ Z_3\u2211_k \u2208 [L]  a_k \u2295 j/ k|k\u27e9|0^log T - log L\u27e9 \nproduces the state |B_L\u27e9 = 1/Z_3\u2211_i \u2208 [T] B_L (i \u03c0 /T) |i\u27e9. \n\n\n\n\n \n\n\n\n \u00a7.\u00a7 Coherent analog encoding for Brownian motion\n \nThe coherent analog encoding for the Brownian motion is a superposition over the analog representation of the corresponding trajectories, along with the garbage register that encodes the randomness used for generating these trajectories, \n\n    |S(T)\u27e9= \u2211_v_1,v_2,\u2026 v_T\u221a(p_v_1,v_2,\u2026 v_T)|\u03c8_v_1,v_2,\u2026 v_T\u27e9|g\u27e9\n\nThe algorithm for generating the coherent analog encoding for Brownian motion is a two step procedure, the first step creates the angle distributions in Lemma  such that angles from these distributions when used in a unary data loader generate a Haar random unit vector. As the angle distributions are independent, these distributions are created on independent registers using a unary data loader. After the first \nphase the following quantum state is obtained\n \n \u2211_\u03b8_i    \u220f_i \u2208[L-1]  \u221a(p(\u03b8_i)) |\u03b8_1, \u03b8_2, \u22ef, \u03b8_L-1 \u27e9.  \n step1 \nThe second step uses the angle registers to apply the rotations for a unary data loader in order to create the encoding of a L dimensional uniformly random vector on a second register. More precisely, the angles \n\u03b8_i are stored up to some qubits of precisions and controlled rotations conditioned on these bits are applied to get a uniformly random Gaussian vector on the second register. The algorithm can therefore \nbe viewed as 'data loading the data loader', the first step generates the angle distributions and the second step uses these angles to prepare a Gaussian state on an independent register. \nIn addition, the second step appends an independent register in state \u2211_k \u2208 [L]1/ k^\u03b1| k \u27e9 with exponent \u03b1 depending on the Hurst parameter. \nThe quantum state is obtained after the second step is,  \n \n1/ Z_1  \u2211_\u03b8_i    \u220f_i \u2208[L-1]  \u221a(p(\u03b8_i)) |\u03b8_1, \u03b8_2, \u22ef, \u03b8_L-1 \u27e9   \u2211_k \u2208[L] 1/ k^\u03b1  | k \u27e9   \u2211_i \u2208[L] a_i | i \u27e9  , \n step2 \nwhere the normalization factor 1/Z_1 ensures that the last two registers are normalized quantum states with unit norm. \nUsing this state in step 3-5 of Algorithm <ref> generates an \u03f5-approximate coherent analog encoding for Brownian motion, where \u03f5 depends on the number of terms L \nretained in the Wiener series. Assuming that the angles distributions for the \u03b8_i in step 1 of the algorithm are generated to a fixed K bits of precision, the number of \nqubits needed is O(2^K L)=O(L) and the asymptotic resource requirements for generating the coherent analog encoding of Brownian motion are the same as the requirements for generating \na single trajectory, \n\n \nThere is a quantum algorithm for generating \u03f5-approximate coherent analog encodings of Brownian motion with requires O(L + log T) qubits, \nhas circuit depth O( log L + log T) and has gate complexity O(L + polylog(T)) for L=O(1/\u03f5). \n \n\nThe angle distributions for the \u03b8_i are heavily concentrated at the higher levels of the tree, this can be used to further reduce the resource requirements for near term instantiations of the \ncoherent analog encoding preparation procedure for Brownian motion. The quantum Monte Carlo method for estimating expectations over Brownian paths using the coherent analog encoding \nis described in Section <ref>. \n\n\n \n\n\n \u00a7.\u00a7 Quantum runtime and error analysis\n  \nAlgorithm <ref> offers a potentially significant speedup over classical algorithms for the problem of preparing an analog quantum representations of Brownian motion. The classical algorithm using the discrete Fourier transform has complexity O(T log T) while the quantum algorithm has complexity O(L+ (T)). The extent of the quantum speedup thus depends on the number of terms L retained in the Wiener series. \n\n\n\nWe argue that choosing L to be a constant suffices to obtain good approximations of the Brownian path in the \u2113_2 norm. The expected \u2113_2 norm of the Brownian path E[ \u222b^\u03c0_0 B(t)^2 dt]  = 1/\u03c0 ( 1+ \u2211_k\u2265 12/k^2) \u22641/\u03c0 + \u03c0/3 \ncan be calculated explicitly using Euler's celebrated summation of the series \u03b6(2) = \u2211_k \u2208\u21151/k^2 = \u03c0^2/6. \n\nA more precise tail bound establishing the asymptotic rate of convergence of the \u03b6(2) series can be obtained as follows. \nThe \u03b6(2) power series truncated at L terms can be approximated by the integral \u222b^\u221e_L1/ x^2 dx = O(1/L). \nThe expected truncation error E[ B(t) - B_L(t)^2] when the Wiener series is truncated to L terms is O(1/L) and as the \nerror is a weighted sum of squares of Gaussian random variables B(t) - B_L(t)^2 is concentrated around O(1/L) with high probability. \nThus L=O(1/\u03f5) terms need to be retained to achieve \u03f5-approximate analog encodings (Definition <ref>) for Brownian trajectories\nwith high probability. The approximation of Brownian motion by a constant number of terms of the Wiener is illustrated in Figure 2.  \n \n\n\n\n\n \u00a7.\u00a7 Fractional Brownian motion\n  \nAlgorithm <ref> can be used to prepare quantum representations of Fractional brownian motion (Definition <ref>) with arbitrary Hurst parameter H \u2208 [0,1]. \nWiener's Fourier series representation for the Brownian motion can be viewed as arising from the fact that Brownian motion is an integral over white \nnoise where the white noise can be described as a stochastic Fourier series with i.i.d. Gaussian coefficients. Fractional Brownian motion in this view \nis a 'fractional' integral over the white noise, where the notion of fractional integral corresponds to the L\u00e9vy or the Mandelbrot definitions of the fBM \ngiven previously. \n\nFractional integrals can be given different formulations, it suffices to determine the fractional integral of sin(kt) and cos(kt) to define it for functions having a well \ndefined Fourier series. It can be shown that in the Fourier domain, the fractional integral with parameter \u03b1 corresponds \nto Hadamard product by k^-1-\u03b1 <cit.>. With the interpretation of fractional Brownian motion as a fractional \nintegral over white noise it follows that the Fourier coefficients of the fractional Brownian motion with Hurst parameter H decay according to the \npower law with the k-th coefficient scaling as k^-H- 0.5. The quantum algorithm for simulating Brownian motion <ref> can be generalized to simulate fBM \nfor an arbitrary Hurst parameter by changing the scaling of the power law exponent. \n\nThe number of terms L retained in the stochastic Fourier expansion for the fBM are given by the number of terms required to approximate the power series \u03b6(t) for t \u2208 [1,3]. \nFor H=0, the power series \u03b6(1) is divergent and thus an arbitrarily large number of terms would be needed, for other values of H the convergence rate is the number of \nterms needed to approximate the zeta power series. Comparing with the previous calculation for Brownian motion, for H>1/2 fewer than 200 terms suffice to approximate the fractional Brownian motion \nup to 99.7% variance while for H<1/2 the number of terms N required to achieve this accuracy will be larger. The exact number of terms needed can be calculated from the value of \u03b6(1+2H), \nSimilar to the case of Brownian motion, the dependence of the approximation error \u03f5 in the \u2113_2 norm can be computed by approximating the tail probability for \u03b6(1+2H) by the integral \u03f5 = \u222b_L^\u221e dx/x^1+2H = O(1/L^2H). \nThe asymptotic error dependence for fractional Brownian motion with H>1/2 is better than O(1/\u03f5). For example, only \nL=O(1/\u03f5^1/2H) terms of the stochastic Fourier series need to be retained to approximate fBM with Hurst parameter H to \u2113_2 error of \u03f5. \n\nThe quantum algorithm for simulating fractional Brownian motion with Hurst parameter H is identical to Algorithm <ref> with the state \n\u2211_k \u2208 [L]1/k^H+ 0.5|k\u27e9 in step 1 of the algorithm. Analogous to the results for Brownian motion (H=1/2) in Theorem <ref>, we have the following result on the running time and resource requirements for simulating fractional Brownian motion. \n\n  \nThere is a quantum algorithm for generating \u03f5-approximate analog encodings of fractional Brownian motion trajectories on T time steps\nthat requires O(L + log T) qubits, has circuit depth O( log L + log T) and gate complexity O(L + polylog(T)) for L=O(1/\u03f5^1/2H) where \nH\u2208 (0,1] is the Hurst parameter. \n \nFractional Brownian motions for varying H parameters simulated using stochastic Fourier series with power law decay are illustrated in Figure 2. \n\n \n\nFractional Brownian motion with H<1/2 is an important process in quantitative finance. In <cit.>, it is determined that via estimation of volatility from high frequency financial data that log-volatility time series behave like a fractional Brownian motion, with Hurst parameter of order 0.1. Modeling volatility this way allows one to reproduce the behavior of the implied volatility surface with high accuracy. This result is robust and has been demonstrated with thousands of assets.\n\n\n \n\nThe truncated stochastic Fourier series captures the large scale variations on the Brownian path while filtering out the high frequency components.For most Monte Carlo estimation applications, the finer scale oscillations on the Brownian path can be safely ignored. The method of retaining only the leading coefficients of the Wiener series to get good approximations is an analogous to principal components analysis where only the leading eigenvalues of the covariance matrix are retained. The generalization of this method to arbitrary stochastic processes is formalized as the Karhunen-Loeve Theorem <cit.> in the stochastic processes literature. \n\n\n\n\n\n\u00a7 QUANTUM SPECTRAL METHOD FOR STOCHASTIC INTEGRALS\n \n\n\n\n\n\n \u00a7.\u00a7 L\u00e9vy Processes\n \nThe most general formulation of the quantum spectral method is applicable to stochastic integrals over L\u00e9vy processes. \nWe begin with a definition of L\u00e9vy processes and stating some theorems about them. We assume we are given a filtered probability space (\u03a9, \u2119, \ud835\udd3d, \u2131_t). An adapted stochastic process X is called a L\u00e9vy Process if it satisfies the following criteria:\n\n\n\n\n\n  * X_t-X_s is independent of \u2131_s, 0 \u2264 s \u2264 t \u221e. \n\n\n\n\n  * X has stationary increments, i.e. X_t-X_s has the same distribution as X_t-s, 0 \u2264 s \u2264 t \u221e. \n\n\n  * X is continuous in probability, i.e. lim_t \u2192 s X_t=X_s, where the limit is taken in probability. \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nThe following theorem gives the characteristic function of any L\u00e9vy process:\n\n\nLet X be a L\u00e9vy process with L\u00e9vy measure \u03bd. Then,\n\n\n    E[e^iuX_t]=e^-t \u03c8(u),\n\n\n\nwhere \u03c8(u) is given by:\n\n\n\n    \u03c3^2 u^2/2 -i\u03b1 u + \u222b_|x| \u2265 1 (1-e^iux) \u03bd(dx) +  \u222b_|x|  1 (1-e^iux+iux) \u03bd(dx).\n \n\n \n\n\nIt is a consequence of the L\u00e9vy-Khintchine Theorem that any L\u00e9vy process X can be decomposed in the following manner, \n\n    X_t=\u03b1 t +\u03c3 B_t +Y_t + C_t,\n\nwith B being a Brownian motion, Y being a pure-jump martingale with jumps bounded in absolute value by 1, and C_t being a compound Poisson process, with jumps greater than absolute value 1.\nThe approach to quantum simulation of L\u00e9vy processes is to generate first the L\u00e9vy noise and then to apply to it an integration operator, which is then implemented efficiently using the Quantum Fourier transform. \nThe method is probabilistic and analysis requires bounds on the the Fourier spectrum of the L\u00e9vy noise, in particular it requires that the ratio of the maximum and the minimum Fourier coefficients is bounded. \n\n\nGiven a L\u00e9vy process X, we define L\u00e9vy white noise, Z, to be its generalized derivative:\n\n    Z_t:=dX/dt-E[X_1].\n\nNote that by the properties of L\u00e9vy processes, L\u00e9vy white noise is a zero-mean, stationary process, and Z_t || Z_s for s \u2260 t.\n\nIn order to establish the flatness of the Fourier spectrum of L\u00e9vy noises, we use the Wiener-Khintchine Lemma stated below to \nrelate the Fourier coefficients to the auto-correlation function for the process. \n\n\n\n[Wiener-Khintchine]\n\n\nLet F(\u03c9) be the Fourier Transform of Z, and G(\u03c9) be the Fourier Transform of its autocorrelation function, R(\u03c4). \n\n\n    S(\u03c9)=lim_T\u2192\u221e\ud835\udd3c|F(\u03c9)|^2/2T=G(\u03c9)\n\n \n\n\n\n\nWe have \n    S(\u03c9)=1/2T\u222b_-T^T\u222b_-T^T\ud835\udd3c(Z_uZ^*_v) e^-2\u03c0 i(u-v)dudv=1/2T\u222b_-T^T\u222b_-T^T R(u-v)e^-2\u03c0 i(u-v)dudv.\n  \n\nLet \u03c4=u-v.\n\n\nThen, the above equals \n    1/2T\u222b_-2T^2T R(\u03c4)e^-2\u03c0 i(\u03c4)(2T-\u03c4)d\u03c4\n\n\n\nNow, we let T \u2192\u221e, arriving at \n    S(\u03c9)=\u222b_-\u221e^\u221eR(\u03c4)e^-2\u03c0 i(\u03c4)d\u03c4=\u2131(R)[\u03c9]=G(\u03c9),\n the Fourier transform of R. \n \n\nThe next claim shows that the Fourier transform  \n \nThe power spectrum S(\u03c9) for L\u00e9vy white noise is flat, that is S(\u03c9)= E[(Z_t)^2] for all frequencies \u03c9.\n\n \nTo see this, recall the fact that the power spectrum S of L\u00e9vy White noise can be obtained by taking the Fourier transform of its autocorrelation function R:\n\n    S(\u03c9)= \u222b_-\u221e^\u221ee^- 2 i \u03c0\u03c4\u03c9R(\u03c4)d\u03c4\n\nThe autocorrelation function R(\u03c4) of the process Z is given by \n    E[Z_t+\u03c4Z_t].\n Now, given the properties of L\u00e9vy White noise, we have that  \n    R(\u03c4)=\u03c3^2\u03b4_0(\u03c4),\n\nwhere \u03c3^2=E[(Z_t)^2].\nTherefore, the power spectrum, S(\u03c9), \u2131[\u03c3^2\u03b4_0], which is just the constant \u03c3^2, for all \u03c9.\n\n \n\n\n\nApplying Chebyshev's Inequality, we have the following bound on on the supremum of the Fourier coefficients of L\u00e9vy Noise, i.e. \u1e90_k:\n\n\n\n    P(|\u1e90_k|  M) \u2264\ud835\udd3c|\u1e90_k|^2/M^2=C/M^2,\n \n\nwhere the constant C is given by C=\ud835\udd3c[\u1e90_k^2]\n\n\n\n\n\n\n \u00a7.\u00a7 Analog encodings for L\u00e9vy processes and stochastic integrals\n \n\n\nWe develop a quantum spectral method that can be used to prepare quantum states representing stochastic integrals, the method is applicable to generating analog representations of integrals over L\u00e9vy processes. \nThis includes integrals over time or over Brownian paths and It\u00f4 processes that are linear combinations of such integrals. The quantum spectral method is obtained by quantizing the classical spectral method for \ngenerating trajectories for the fractional Brownian motion <cit.>. \n\n\nThe spectral method for stochastic processes is based on the observation that the discrete analog of an integral kernel of the form \u222b^t_0  K(t-s) f(s) ds corresponds to multiplication of the vector f(x) by a lower triangular Toeplitz matrix in the discrete setting . We recall the definition of Toeplitz matrices and the closely related circulant matrices. \n \nA Toeplitz matrix T \u2208^n \u00d7 n is a matrix such that T_ij = f(i-j) for some function f: \u2192, that is the entries of T are constant along the main diagonals. \n \n\nThe integral \u222b^t_0  K(t-s) f(s) ds can be approximated by discretizing the vector f(S) into T time steps and then multiplying the vector f(s) by the lower triangular Toeplitz matrix (T_K)_ij:= K(i-j) if i>j and 0 otherwise. Further, this is also equivalent to discretizing the Kernel into T time steps and then multiplying by the lower triangular Toeplitz matrix  (T_f)_ij:= f(i-j).\n\nIn the quantum setting, we will be computing the \nstochastic integrals \u222b^t_0  K(t-s) \u03bc(s) ds against a L\u00e9vy noise \u03bc(s). This is achieved by multiplying the state corresponding to the amplitude encoding of the discretized kernel against the Toeplitz matrix T_\u03bc. \n, that is |K\u27e9 = 1/K\u2211_t K(t) |t\u27e9 by the Toeplitz matrix T_\u03bc generates the amplitude encoding for the function g(t) = \u222b^t_0  K(t-s) \u03bc(s) ds.  \n\nCirculant matrices defined below <ref> are matrices generated by the cyclic shifts of some vector c. \nThe spectral method for simulating stochastic integrals is based on the observation that Toeplitz matrices can be embedded into circulant matrices \nand that circulant matrices are diagonalized by the Fourier transform and  their eigenvalues can be computed explicitly. \n\n  \nA circulant matrix C \u2208^n \u00d7 n is a matrix such that C_ij = f((i-j)  n) for some function f: \u2192, that is the rows of the matrix C are generated by applying cyclic shifts to its first row. \n \nA Toeplitz matrix T_\u03bc of dimension n can be embedded into a circulant matrix C_\u03bc of dimension 2n as follows, \n \nC_\u03bc = ( \n \n    T_\u03bc     T_\u03bc^' \n\n    T_\u03bc^'     T_\u03bc \n  )\n circmult \nwhere T_\u03bc^'= (T_\u03bc^R)^T where T_\u03bc^R is the the reversed Toeplitz matrix with first column given by the reverse \u03bc^R of \u03bc. (The reverse x^R for x \u2208^n is the vector with entries (x^R)_j = x_n-j of the first column of T_x). \n\nIt is well known that circulant matrices are diagonalized by the Fourier transform, that is a circulant matrix C has a factorization of the form C=U (c) U^-1 where U is the unitary matrix \nfor the quantum Fourier transform and c= ( C e_1 ) is the Fourier transform of the first column of C. The eigenvalues of the matrix C_K are thus determined by taking the Fourier transform of the \nfirst column which by construction is the vector (K, 0^T). \n\n\n\n\nThe quantum representation of the stochastic integral \u222b^t_0  K(t-s) \u03bc(s) ds is obtained by multiplying the initial state | (K(s), 0^T)\u27e9 by the matrix C_\u03bc. \nMultiplication by the matrix C_mu can be in turn implemented using the spectral decomposition C_mu =U (\u03bc) U^-1, the unitaries U correspond to the quantum Fourier \ntransform while the multiplication by the diagonal matrix can be implemented probabilistically using a post-selection step similar to that used in the HHL algorithm. \n\n\n\nThe algorithm for preparing the representation of the stochastic integral is given as Algorithm <ref>. It is described for the case of integrals over a L\u00e9vy noise d\u03bc_s. In particular, integrals over the Brownian \nmotion can be obtained by taking \u03bc_s= dB_s. We next establish the correctness of the algorithm and bound its success probability, \n\n \nAlgorithm <ref> generates the amplitude encoding of \u222b^t_0 K(s, t) d\u03bc_s, requires O(T log T) resources and succeeds with probability at least 1/C^2 where C=  min_i b_i/max_i b_i is the \nratio of the maximum and minimum Fourier coefficients of the L\u00e9vy noise \u03bc_s. \n \n \nWe argue that Algorithm <ref> implements correctly the multiplication of the discretized kernel by the circulant matrix C_\u03bc, that is step 6 generates the amplitude encoding of the result of the following matrix multiplication, \n \n( \n \n    T_\u03bc     T_\u03bc^' \n\n    T_\u03bc^'     T_\u03bc \n  )\n(  \n    K  \n\n    0\n  )\n  \nThe result of this matrix multiplication is an amplitude encoding of  \u222b^t_0 K(s, t) d\u03bc_s concatenated with its reversal. Measuring the last qubit in step 7 yields either \nthe amplitude encoding of  \u222b^t_0 K(s, t) d\u03bc_s if the outcome is 0 and the amplitude encoding of the reversal of  \u222b^t_0 K(s, t) d\u03bc_s if the outcome is 1. Applying the \noperation |i\u27e9\u2192|T-i\u27e9 to the amplitude encoding of the reversal recovers the amplitude encoding for \u222b^t_0 K(s, t) d\u03bc_s. \n\nThe matrix multiplication by the circulant matrix is implemented using the relation C_\u03bc = (\u03bc) ^-1 in steps 3-5 of the algorithm, steps 3 and 5 are unitary while step 4 involves post-selection. \nThe success probability for the post-selection step 4 is  at least min_i b_i/max_i b_i^2\u22651/C^2. The analysis of the spectrum of L\u00e9vy processes in Section <ref> shows that for most L\u00e9vy processes C is\na constant. The resources required for the algorithm are O(T log T) to compute the Fourier transform of the L\u00e9vy noise classically and truncate to L terms, the quantum resources needed are O(L log L + log^2T) operations for steps 2-4 of the algorithm. \n\n \n\n\nNote that although more general and applicable to L\u00e9vy processes with flat Fourier spectrum, Algorithm <ref> generates the amplitude encodings of trajectories of L\u00e9vy processes. Generating the coherent amplitude encoding \nfor L\u00e9vy processes would  require additional quantum resources compared to Brownian motion as the coefficients in the Fourier expansion of L\u00e9vy process are not independent except for the case of Brownian motion and loading a multi-variate distribution over the angles of a data loader is computationally more expensive than individually loading independent angle distributions as in the case of Brownian motion.  \n\n\n\n\n\n\u00a7 QUANTUM MONTE CARLO METHODS. \n\n\n\n\nAnalog representations |S(T)\u27e9 of the stochastic process are compatible with standard quantum Monte Carlo methods and can be used as part of the simulation circuit (oracle) for estimating a function of the stochastic process using the quantum amplitude estimation algorithm. In this section, we provide a quantum Monte Carlo algorithm to estimate functions of stochastic processes given a coherent analog encoding. The method is described for fractional Brownian motion, but is applicable more generally to stochastic processes with coherent analog encodings. \n\nThe goal of the algorithm is to estimate a degree d function f: S(t)^d \u2192 of the stochastic process. A linear function with d=1 corresponds to the expectation of an inner product E_v(t) \u223c S\u27e8f(t)|v(t)\u27e9. Time averages over the stochastic process are examples of linear functions with f(t) being a step function. Quadratic functions with d=2 correspond to mean square averages and variances of linear functions, and  can be expressed as the inner product of a function with two copies of the trajectory of the stochastic process. The quantum Monte Carlo method is more efficient for low degree functions and for Hurst parameters H>1/2 for fractional Brownian motion. \n\nA general setting for which quantum Monte Carlo methods are applicable is that in which the function to be estimated can be encoded as an amplitude. That is, there is a circuit for unitary U such that, \n \nU |0\u27e9 = \u03b1|x\u27e9 |0\u27e9 + \u03b2|x^\u22a5 \u27e9 |1\u27e9 \n\nthe quantum amplitude estimation algorithm can then be used to estimate \u03b1 to additive error \u03f5 using O(1/\u03f5) queries, and further low depth variants of amplitude estimation can\nobtain a speedup that is proportional to the depth D to which the quantum circuit for U can be run on the quantum hardware. \n\nThe quantum Monte Carlo algorithm is given as Algorithm <ref> where the goal is to estimate either E_B_H(t) [\u27e8f(t)|B(t)\u27e9/B(t) ] or E_B'_H(t) [\u27e8f(t)|B(t)\u27e9   ]  where the expectation \nis over fractional Brownian motion trajectories and over trajectories B'_H(t) of bounded norm in the second case. Estimating E_B_H(t) [\u27e8f(t)|B(t)\u27e9/B(t)  ] requires less quantum resources but is likely to have an analytic closed form for simple functions f as this is equivalent to computing the Fourier transform for f and computing an inner product with the Wiener series in the Fourier domain. Estimating E_B_H(t) [ \u27e8f(t)|B(t)\u27e9 ] requires an additional norm computation and conditional rotation step in Algorithm <ref>, however the estimate produced does not have a closed form solution as the process in addition post-selects over Brownian paths of a certain norm, thus additional eliminating the additional structure in the Fourier domain arising from the Wiener series expansion. \n\n\n\n\n\n\n\n \u00a7.\u00a7 Proof of correctness\n\nThe correctness proof shows that the estimates produced by algorithm <ref> are \u03f5 close to the true values in additive error. The analysis \nproceeds by analyzing in turn the errors due to truncation of the Wiener series for L terms, tracing out the auxiliary registers and other \nsources of error due to finite precision that are poly-logarithmic. \n\n  \nIf L=O(1/\u03f5^1/2H) terms are retained in the stochastic Fourier series for fractional Brownian motion with Hurst parameter H, then E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t) ] is approximated to \nadditive error O(\u03f5) for all test functions f(t). \n \n \nThe Fourier series expansion for  fractional Brownian motion with Hurst parameter H is B_H(t) = \u2211_ka_k/k^H+0.5sin(k\u03b8) for i.i.d. Gaussian random variables a_k, k \u2208\u2115.  \n\nThe number of terms L that need to be retained in the stochastic Fourier series such that E[B_H(t) - B_L(t) ^2 ] \u2264\u03f5 can be calculated as follows. \nThe tail probability \u2211_k\u2265 L+1 a_k^2/k^2H+1 is approximated by the integral \u222b_L^\u221e dx/x^1+2H = O(1/L^2H). Setting the tail probability to O(\u03f5), it follows that L=O(1/\u03f5^1/2H) terms of the stochastic Fourier series are needed to ensure that E[B_H(t) - B_L(t) ^2 ] \u2264\u03f5. As E[B_H(t)] is a constant, we have that E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t) ] is approximated to additive error O(\u03f5) for all test functions f(t). \n \n\nThe second claim for the correctness of the quantum Monte Carlo method shows that tracing out the \u03b8 and j registers does not affect the expectations. \n  \n Tracing out the \u03b8 and j registers does not change the expectation of the quantity being estimated, that is, \n  \nE_B_H, j, \u03b8(t)  \u27e8B_H, j, \u03b8(t)|f(t)\u27e9 / B_H, j, \u03b8(t) f  = E_B_H(t)  \u27e8B_H(t)|f(t)\u27e9 / B_H(t) f  \n  \n\n \nThe claim is equivalent to showing that after tracing out the \u03b8 and j registers, the states \u2211_k \u2208 [L]\u00e3_\u0303k\u0303/k^\u03b1 in the last register in equation (<ref>) represent\nuniformly random fractional Brownian paths. As the \u03b8 are chosen so tracing out the \u03b8 registers ensures that the \u00e3_\u0303k\u0303 are i.i.d. Gaussian, it suffices to show that tracing out the j registers, \n the distribution the  \u00e3_\u0303k\u0303 remains spherically symmetric, \n \n\u2211_j Pr[j] Pr [ \u00e3  |  \u03b8, j] =   1/ L \u2211_k, j \u00e3_k \u2295j^2 / k^2\u03b1 = C\u00e3^2 \n \nIt follows that the states in the last register in equation (<ref>) when \u03b8 and j registers are traced out represent random fractional Brownian paths, so the quantity being estimated by the algorithm is E_B_H(t)\u27e8B_H(t)|f(t)\u27e9/B_H(t)f. \n \n\nWith these auxiliary claims, we can complete the runtime analysis of the quantum Monte Carlo method and resources required for it, \n\n \nAlgorithm <ref> estimates E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t)] to additive error \u03f5 using \nO(L + log T) qubits, O( (L+ polylog(T) + G)/\u03f5f)= O( polylog(T)/\u03f5^1+1/2H) gates where G is the number of gates in the \ncircuit V for preparing |f\u27e9.  \n \n \nClaim <ref> shows that  that the amplitude being estimated by algorithm <ref> is E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t) ]. There are two further sources of error, the first due to the finite precision for generating the distributions on the angles and the second due to \ntruncation of the Wiener series to L terms, claim <ref> shows that the truncation error is O(\u03f5) for L= O(1/\u03f5^1/2H). Choosing log (1/\u03f5) qubits to encode each angle further ensures that the errors due to the finite precision of the angle registers is O(\u03f5). \nThus, the estimate obtained in step 5 of the algorithm is an O(\u03f5) additive error estimate for E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t) ]. \n\nThe number of qubits used is O(L + log T) where the O absorbs potential logarithmic factors due to higher precision \non the angle registers. The oracle for the amplitude estimation circuit requires (L+ polylog(T) + G) gates and the amplitude estimation algorithm needs to simulate the oracle 1/\u03f5f times in step 5 of the algorithm to get the desired estimate, and the gate complexity bound follows. \n \nThe classical Monte Carlo method for the task requires resources O (T /\u03f5^2) while the quantum Monte Carlo method with using an oracle compiled from classical circuits would require  O (T /\u03f5).  The gate complexity of the quantum Monte Carlo method using the fBM simulator is O( polyLog(T)/\u03f5^c). It is incomparable to the black box quantum Monte Carlo method \nas it achieves an exponential speedup in T, the \u03f5 dependence is worse. It is more efficient than the classical Monte Carlo method in the regime c \u2208 [1,2], that is for estimating function averages over fractional Brownian paths with H>1/2. \n\nThe analysis of the quantum Monte Carlo method covers case 1 where E_B_H(t) [\u27e8f(t)|B_H(t)\u27e9/B_H(t) ]. The \nanalysis of the post-selected quantum Monte Carlo method for estimating E_B'_H(t) [\u27e8f(t)|B_H(t)\u27e9   ] is not carried out explicitly as it depends on the post-selection procedure, however the post-selected variant is expected to be more useful in practice due to the lack of an analytic closed form solution for the quantity being estimated. \n\n\n\n\n\n \u00a7.\u00a7 Applications to Monte Carlo methods\n \n\n\nIn this section, we provide two further examples of applications of the analog encoding of fractional Brownian motion to Monte Carlo methods. The first application is for pricing variance swap options, while the second is for statistical analysis of anomalous diffusion processes. In these end-to-end examples, we harness the O( polylog(T)/\u03f5^c) speedup. \n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Pricing Variance Swap options\n \nIn this section, we consider the problem of pricing a variance swap. \n\nWe assume we have a filtered probability space (\u03a9, \u2131, \ud835\udd3d, \u2119), where \u2131=(\u2131_t)_0\u2264 t \u2264 T. The filtration \u2131 represents the information available at a given time.\n\n\nWe consider a model such that the price S and volatility \u03c3, under a risk neutral measure \u211a, are given by \n    S_t=e^\u222b_0^t\u03c3_sdB_s+\u222b_0^t(r-1/2\u03c3^2_s)ds\n \nand \u03c3_t=B^H_t\nfor a Brownian motion B and an independent  Fractional Brownian motion B^H with Hurst parameter H.\n\nThe stochastic volatility \u03c3_t is itself a solution to a stochastic differential equation, for example the equation,\n\n    d\u03c3_t=\u03c3_tdB^H_t,\n\nwhere B^H is a fractional Brownian motion corresponds to the case where the log-volatility is a fractional Brownian motion. Another \ncommon model for the stochastic volatility is, \n\n    d\u03c3_t=b(\u03c3_t)dt+C(\u03c3_t)dW_t\n\nwhere W is a Brownian motion that is correlated with the Brownian motion B driving the stock price process. In the above equation, b and C are deterministic functions of the volatility process which satisfy the necessary conditions for non-negativity and non-explosion. \n\n\n\n\n\n\nThe log returns, R_i, are given by \n    R_i=ln S_t_i+1-ln S_t_i= \u222b_t_i^t_i+1(r-1/2\u03c3^2_s)ds+   \n      \u222b_t_i^t_i+1\u03c3_s dB_s \u223c N(\u222b_t_i^t_i+1(r-1/2\u03c3^2_s)ds , \u222b_t_i^t_i+1\u03c3^2_sds)\n.\n\n\nA variance swap is an over-the-counter derivative that allows its holder to speculate on the future volatility of the asset price, without any exposure to the asset itself. In such a swap, one party pays amount that is based on the variance of the asset. The other party pays a fixed amount, i.e. the strike price, which is set so that the present value of the payoff is equal to zero. \n\n\nThe realized variance of the asset price over a discretized time interval 0 \u2264 t_t \u2264 t_i+1\u2264 T is given by \n    \u03c3^2_realized = A/n\u2211_i=1^nR_i^2,\n where A is an annualization factor, and n+1 is the number of observed prices. \n\n\n\nThe payoff of a variance swap is given \n    N_var( \u03c3^2_realized-\u03c3^2_strike)\n\nIn the above, N_var is called the variance notional. If we assume that the volatility follows a Fractional Brownian motion, we can use  our analog encoding of Fractional Brownian motion, to compute the strike price, \n    \u03c3^2_strike=\ud835\udd3c_\u211a[\u03c3^2_realized| \u2131_t_0]\n since \n    \ud835\udd3c_\u211a \n     (\u03c3^2_realized| \u2131_t_0) = A/n\u2211_i=1^n\ud835\udd3c_\u211a ( R^2_i)=A/n\u2211_i=1^n\ud835\udd3c_\u211a\u222b_t_i^t_i+1\u03c3^2_sds.\n  \n\n Let \u03c0 denote the projective measurement onto time steps t_1  \u2264 t \u2264 t_n=T. The expectation value of \u03c0 is equal to \u2211_i=1^nR^2_i. and is thus equal to\n \ud835\udd3c_\u211a][\u03c3^2_realized| \u2131_t_0] up to constant factors. Note that the above quantity can be computed using a quantum Monte Carlo method by modifying Algorithm <ref> to tag the amplitudes for time steps 1 to T in step 3. \n \nIf the average is computed over all possible sample paths of the prices process S, then the realized variance has a closed form solution. Mild post-selection over the paths, for example choosing paths which whose norm is lies in the interval [B_min, B_max] suffices to ensure that \n\u2211_i=1^nR^2_i does not have a closed form solution. \n\nThe method described above prices the variance swap option assuming the volatility is an fBM. Pricing an option on realized variance where the log volatility is a fractional Brownian motion would require efficient quantum algorithms for generating analog encodings of geometric Brownian motion and more generally exponentiated fractional Brownian motions. Generating such encodings is an important open question for quantum finance. \n\n\n\n\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Anomalous Diffusion of Particles\n \n\nA second example is that of single-particle superdiffusion, an example of anomalous diffusion, in the context of molecular motion. Single-particle tracking is relevant for  particles in microscopic systems as well as animal and human motion. \nAnomalous diffusion is common in (super)crowded fluids, e.g. the cytoplasm of living cells. We next define anomalous diffusion in terms of the \nmean square averages. \n\n\n The time-averaged mean-square-deviation (TAMSD) of a particle is a measure of the deviation of the position of a particle with respect to a reference position over time. Let X_t denote the position of the single particle at time t with t \u2208 [T]. The TAMSD is then defined as:\n\n \n    M_T(\u03c4)= 1/T-\u03c4\u2211_j=1^T-\u03c4(X_j+\u03c4-X_j)^2\n \n\nThe mean-square-displacement (MSD) of a particle with position X_t at time t and with PDF of displacement P(t,x) at time t is given by: \n\n\n    \u27e8 X^2(t)\u27e9=  \u222b_-\u221e^\u221e x^2P(t,x)dx\n \n\n \nFor a particle following a fractional Brownian motion trajectory, the mean TAMSD has the following scaling: \n\n    \u27e8 M(\u03c4)\u27e9\u221d\u03c4^2H,\n\nwhere H is the Hurst parameter of the fractional Brownian motion. The constant of proportionality is the diffusion coefficient, D. \nThe TAMSD be used to classify anomalous diffusion behaviour of a single particle.  We write \n    M_T(\u03c4,D,H)\n to make explicit its dependence on the Hurst parameter H as well as D.  We assume that D is known. Calculating the TAMSD of the particles is telling of their diffusive behaviour; that is, it can distinguish between sub and super-diffusive behaviour. \n\n Superdiffusion is salient in the traveling behaviour of humans and spreading of infectious diseases <cit.>. It corresponds to fBM H 1/2, and long-range correlations between displacements and is thus well modeled by Fractional Brownian Motion with H>1/2.  \n\n\n Sikora et. al in <cit.> proposed a statistical test using the TAMSD to characterize anomalous diffusion. It is known that if the particle trajectory X_t follows an fBM, (T-\u03c4)M_T is distributed as generalized chi-squared, that is, as \n    Y=\u2211_j=1^T-\u03c4\u03bb_j(\u03c4,D,H)U_j,\n\nwhere the U_j are distributed as i.i.d  \u03c7^2(1) or \u03b3(1/2). \n\nThe \u03bb_j are the eigenvalues of the (T-\u03c4) \u00d7(T-\u03c4) covariance matrix of the (Gaussian) vector of fBM increments [(B^H_1+\u03c4-B^H_1), (B^H_2+\u03c4-B^H_2),........(B^H_N+\u03c4-B^H_T)]. This covariance matrix, \u03a3, that Toeplitz, has the following entries on the ith diagonal D/2[(i+\u03c4)^2H-2i^2H+|i-\u03c4|^2H]. The (100-\u03b1)% confidence interval for the test statistic M^T(\u03c4) is given by, \n\n\n    [DQ_\u03b1/2/T-\u03c4, DQ_1-\u03b1/2/T-\u03c4].\n \n\nIn the above, the Q_\u03b1/2 are quantiles such that Pr(Y  Q_\u03b1/2) \u03b1/2 and Q_1-\u03b1/2 is such that Pr(Y  Q_1-\u03b1/2) \u03b1/2. The null hypothesis H_0 such that X_t follows an fBM with given Hurst parameter, H_test. The alternative hypothesis, H_1, is such that the particle trajectory X_t is an fBM with a different Hurst parameter, or that the trajectory follows a continuous-time random walk. H_0 is rejected if the test statistic M^T(\u03c4) falls outside of the above confidence interval. \n\n\n\n\nThe authors in <cit.> use Monte Carlo Methods to estimate the power of this statistical test\u2013that is, the probability that it rejects the null hypothesis, given that the alternative hypothesis is true. The power of the test is defined as, \n    (M^T(\u03c4)) \u2209 [DQ_\u03b1/2/T-\u03c4, DQ_1-\u03b1/2/T-\u03c4].\n \n\nSuch a Monte Carlo test hinges on the calculation of the empirical probability that the test statistic M^T(\u03c4) does not lie in the above interval. \n\n\n\n\n\n\n\nWe can use our analog encoding of Fractional Gaussian noise (using that its spectrum, f(\u03c9), is proportional to \u03c9^1-2H) with given Hurst parameter H to output the following state: \n\n \n1/T-\u03c4 \u2211_j \u2208[T]( B^H(j+\u03c4)-B^H(\u03c4)) |j\u27e9.\n eq21 \n\n\nIf we assume the alternative distribution of X is a compound poisson process, a special case of a continous time random walk, we can use algorithm <ref> to obtain as output its amplitude encoding. \n\nBelow is quantum Monte Carlo procedure to calculate the power of the statistical test, based on the method in <cit.>: \n\n\n\n\n\n\n\n  * Calculate the eigenvalues \u03bb_j for the Covariance matrix \u03a3. \n\n  * Using the amplitude encoding for shifted fBM in equation (<ref>), generate R samples of \n    (T-\u03c4)M^T(D, H_test,\u03c4).\n \n\n\n  * Using the R above samples, calculate empirical quantiles Q_\u03b1/2 and Q_1-\u03b1/2\nand the confidence interval in (<ref>). \n\n  * Use the analog representation of wither fBM with a different Hurst parameter, or a Compound Poisson process, using algorithm <ref> to simulate the alternative distribution. \n\n\n  * Estimate the value of the test statistic M^T(\u03c4), using (<ref>) or (<ref>). \n\n\n  * Set a random counter z to 0. If the test statistic from the last step falls out of the interval (<ref>) computed in step 3, then add 1 to z, else, add nothing to it. \n\n\n  * Repeat the last 3 steps a total of L times, and the power of the test is given by z/L.\n\n    \n\n\n\n\n\nNote that we can take a projective measurement, \u03c0, onto times t_1  \u2264 t \u2264 t_n=T. The expectation value of \u03c0 is equal to \n    M_T(\u03c4)= 1/T-\u03c4\u2211_j=1^T-\u03c4(X_j+\u03c4-X_j)^2,\n that is, the TAMSD. We can then use a simple modification of the Quantum Monte Carlo algorithm in <ref>, to compute the expectation of\u00a0(<ref>). \n \n \n Our analog encoding can be used to distinguish between diffusive regimes where both the H_test and H under the alternative hypothesis are \u2248 0.4 and above, or if the alternative process is a Compound Poisson process. \nIt is an open problem to use our analog encoding for very small H in order to detect subdiffusive regimes (e.g. as is the case with telomere motion). \n\nAnother characterization of of single particle dynamics is its ergodicity, or lack thereof. Ergodicity is characterised by the equivalence of the MSD and the TAMSD in the limit of long trajectory times. That is \n    lim_T \u2192\u221e M^T(\u03c4)= \u27e8 X^2(\u03c4) \u27e9\n \n\n\n\n\nWe define \n\n\n\n\n\n    \u27e8 M^N(\u03c4)\u27e9 =1/N\u2211_i=1^NM^T_i(\u03c4).\n That is, the mean of the TAMSD over N trajectories of the process. \n\nWe also define \n    \u03be=\u27e8 M^N(\u03c4)\u27e9/M^N(\u03c4)\n\n\nThe ergodocity of a stochastic process is characterized by the Ergodicity-Breaking parameter (EB), defined below: \n\n\n    EB (\u03c4)=\u27e8\u03be^2\u27e9 -1\n \n\n \n\nWe can use the algorithm in <ref> via quantum amplitude estimation to estimate the EB for Levy Processes, as well as fBM for H 1/2.\n\n\n\nOne can in turn use these calculations as benchmarks to characterize observed data, for example, via the distibution of \u03be, or via large deviation statistics of \u03be.\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 ACKNOWLEDGMENTS\n\n\nWe thank Iordanis Kerenidis for helpful discussions and an anonymous referee for detailed feedback on the manuscript.\nAdam Bouland's contribution to this publication was as a paid consultant and was not part of his Stanford University duties or responsibilities.\n\n\nalpha \n\n\n \n\n\n\n\n\n\u00a7 QUANTUM CIRCUIT FOR THE DISCRETE SINE TRANSFORM.\n  \n\n\nWe next provide an implementation of the discrete sine transform as a depth O(log T) unitary matrix. The discrete sine transform is closely related to the Quantum Fourier Transform (QFT) and the logarithmic depth circuit for it uses a recursive decomposition similar to the QFT. We provide an implementation for the quantum Fourier transform as a quantum circuit of logarithmic depth using Hadamard and phase gates. \n\n  \nThe unitary matrix U_N for the N dimensional QFT with entries (U_N)_ij = \u03c9_N^ij for N=2^k and \u03c9_N= e^2\u03c0 i/N \ncan be implemented as a quantum circuit on 2k qubits with depth O(k log k). \n \n \nWe give a recursive description of the circuit for the quantum Fourier transform. The base case is N=2, for this case U_2 is the Hadamard gate. \nLet x= (x_0, x_2, \u22ef, x_N-1) be the input vector and let x_o = (x_1, x_3, \u22ef, x_N-1) and x_e = (x_0, x_2, \u22ef, x_N-2) be the even and \nodd components of x. Then the quantum Fourier transform satisfies the following recurrence for all j \u2208 [N/2], \n \n(U_N x)_j = (U_N/2 x_e)_j + \u03c9_N^j  (U_N/2 x_o)_j  \n\n(U_N x)_j+N/2 = (U_N/2 x_e)_j - \u03c9_N^j  (U_N/2 x_o)_j \n  recQFT \nThese recurrences allow us to give a recursive description for the quantum Fourier transform. Let H_i denote the Hadamard gate applied to the i-th qubit. \nLet CZ_k,l (\u03c9_N^j) be the controlled phase shift with qubit k acting as control qubit, with the phase gate \nZ= [     1     0;     0 \u03c9_N^j ] being applied to qubit l. Then, \n \nU_N =  \u03c3H_k  CZ_k,1 (\u03c9_N^2^k-2) CZ_k,2 (\u03c9_N^2^k-1) \u22efCZ_k,k-1 (\u03c9_N)  U_N/2\n \nLet us establish the correctness of this recursive decomposition. \nAfter the application of U_N/2 (on qubits 1 through k-1) on input state |x\u27e9, the quantum state \u2211_j (U_N/2 x_e)_j| j, 0\u27e9 +  (U_N/2 x_o)_j|j, 1\u27e9 is obtained. \nThe product of the phase gates \u03a0_j \u2208 [k] CZ_k,j (\u03c9_N^2^k-j)  controlled on qubit k transforms this state to \u2211_j (U_N/2 x_e)_j| j, 0\u27e9 +  \u03c9_N^j (U_N/2 x_o)_j|j, 1\u27e9. From equation (<ref>) it follows that the\napplication of H_k transforms it to \u2211_j (U_N x)_j| j, 0\u27e9 + (U_N x)_j+N/2|j, 1\u27e9. The permutation \u03c3 is a cyclic shift that moves the k-th qubit to the first position, \nthis can be implemented by swapping the wires in the circuit. The final state is \u2211_j (U_N x)_j| 0, j\u27e9 + (U_N x)_j+N/2|1, j\u27e9 which is the quantum Fourier transform of x.\n\nAs the phase gates can be applied in parallel by making O(log k) copies of the control qubits, the depth of the QFT circuit requires 2k qubits and has depth is O(k log k). \n \nThe discrete cosine and sine transforms are defined as DCT(x) = U_N/2 + U_N/2/2 x and DST(x) = iU_N/2 - iU_N/2/2 x. \nThe QFT circuit can be used to implement the DCT and DST with the same complexity. \n\n  \nThe unitaries for the discrete  cosine transform and the discrete sine transform can both be implemented as quantum circuits with 2k+1 qubits and depth O(k log k). \n \n \nThe conjugate of the Fourier transform U_N/2 can be applied by conjugating all the controlled phase gates in the QFT circuit. \nStarting with the state |0\u27e9| U_N/2 x\u27e9 + |1\u27e9|U_N/2 x\u27e9 and applying the iH gate the states corresponding to DCT(x) and DST(x) \nare each obtained with probability 1/2. As the success probability is known exactly, the probabilistic procedure can be made to succeed with probability 1 using the exact amplitude \namplification <cit.>.  \n \n\n\n\n\u00a7 THE SUM OF SQUARES OF K GAUSSIAN RANDOM VARIABLES\n  \n\nThe distribution of the the sum of squares of Gaussian random variables can be expressed in terms of the Gamma function. \n \n   \nThe random variable X^2/2 where X \u223c N(0,1) has distribution \u03b3(1/2). \n \n \nLet G(x) be the cumulative distribution function for X^2/2 where X \u223c N(0,1), then, \n \nG(x) = [ |X| \u2264\u221a(2x)] = 2/\u221a(2\u03c0)  \u222b^\u221a(2x)_0  e^-t^2/2  dt \n \nMaking the substitution so that t^2/2=y and t dt= dy \u21d2 dt = dy/\u221a(2y), \n \nG(x) \n=  1/\u221a(\u03c0)  \u222b^x_0  y^-1/2 e^-y  dy \n \nThus G(x) is identical to the cdf for the Gamma distribution with a=1/2. \n \n\nThe sum of squares \u2211_i X_i^2/2 where X_i are k independent Gaussian random variables has distribution \u03b3(k/2). \nThis distribution is more commonly named as the \u03c7^2 distribution with k degrees of freedom. \nThis follows from the next lemma on the additivity of the gamma distribution under convolution. \n  \nIf Y_1\u223c\u03b3(a), Y_2\u223c\u03b3(b) then Y_1 + Y_2\u223c\u03b3(a+b). \n \n The density function F for Y_1+ Y_2 is the convolution of the density functions for Y_1 and Y_2, that is, \n \n[ Y_1 + Y_2 = y] = F(y) = 1/ \u0393(a) \u0393(b) \u222b_t t^a-1 (y-t)^b-1 e^-y dt \n \nIntroducing variable z= t/y so that ydz= dt, \n \n F(y)    = 1/ \u0393(a) \u0393(b) \u222b_t>0 z^a-1 (1-z)^b-1 y^a+b-2 e^-y  y dz     =  y^a+b-1 e^-y / \u0393(a) \u0393(b) \u222b_z>0 z^a-1 (1-z)^b-1 dz    =  y^a+b-1 e^-y / \u0393(a+b) \n \nThe final step follows from the definition of the \u03b2(a,b) probability density function \u0393(a)\u0393(b)/\u0393(a+b) x^a-1(1-x)^b-1. We showed \nthat the density function for Y_1+ Y_2 is identical to the density function for \u03b3(a+b).  \n\nThe proposition below is an immediate consequence of Lemmas <ref> and <ref>. \n\n\n \nThe sum of squares \u2211_i X_i^2/2 where X_i are k independent Gaussian random variables has distribution \u03b3(k/2). \n \n \n\n\n\n\u00a7 THE UNARY TO BINARY CONVERSION CIRCUIT\n  \nWe provide a logarithmic depth circuit that converts the unary amplitude encoding |x\u27e9 = \u2211_i \u2208 [n] x_i|e_i\u27e9 for a unit vector x \u2208^n, x=1 to the binary encoding \n|x\u27e9 = \u2211_i \u2208 [n] x_i|i\u27e9. The unary encoding requires n qubits while the binary encoding uses only log n qubits, the convertor circuit operates on n+ log n qubits. \nThe action of the unary to binary convertor circuit on the n+ log n qubits is given as, \n \n(\u2211_i \u2208[n] x_i |e_i\u27e9 )  \u2297|0^logn \u27e9  \u2192|0^n\u27e9  \u2297(\u2211_i \u2208[n] x_i |i\u27e9 )\n convert \nThe next proposition shows that the unary to binary conversion circuit can in fact be implemented with logarithmic depth. \n \nThe unary to binary conversion circuit in equation (<ref>) can be implemented by a quantum circuit with depth O(log^2  n) and with O(n log n) gates and with O(n) \nancilla qubits. \n \n \nWithout loss of generality, let n=2^k be a power of 2. \nGiven the unary encoding (\u2211_i \u2208 [n] x_i|e_i\u27e9 ), the first bit of the binary encoding is given by the parity of the last n/2 qubits of the unary representation. \nThe parity of n/2=2^k-1 qubits can be computed by a circuit with n CNOT gates and with depth 2(k-1) using O(n) ancilla qubits. The ancilla qubits store the partial parities \nand are erased at the end of the computation. \n\nFollowing the computation of the parity, apply controlled swap gates on qubits (i,i+n/2) for the unary representation with the parity qubit acting as control. \nRecall the two qubit swap gate has the following representation in the standard basis, \n\n    SWAP =  [   1 0 0 0;   0 0 1 0;   0 1 0 0;   0 0 0 1 ].\n  \nThe effect of the controlled swap gates is to move the index that is equal to 1 to the first n/2 qubits of the unary representation. The last n/2 qubits of the unary representation are equal to 0 following this \nstep and are therefore erased at the end of the computation. The multiple controlled swap gates can be applied in parallel on n/2 qubits, this can be accomplished using the available O(n) ancilla qubits to copy the parity bits.  \n\nFollowing these computations, we have computed 1 bit of the binary representation and are left with a unary encoding of size n/2. Continuing iteratively, we obatin unary to binary conversion circuit with total depth \n\u2211_1\u2264 i < (k-1) (k-i) = O(k^2) = O(log^2n) is obtained. The number of gates needed for computing each bit of the binary representation is O(n), as there are O(log n) bits in the binary representation the \ntotal gate complexity is O(n log n). The maximum number of ancilla qubits O(n) are needed for computing the first bit of the binary representation, subsequent bits require fewer qubits. The claims on the resource requirements for the unary to binary conversion circuit follow. \n \n\n"}