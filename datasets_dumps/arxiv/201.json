{"entry_id": "http://arxiv.org/abs/2303.07077v1", "published": "20230313125953", "title": "Spatial Attention and Syntax Rule Enhanced Tree Decoder for Offine Handwritten Mathematical Expression Recognition", "authors": ["Zihao Lin", "Jinrong Li", "Fan Yang", "Shuangping Huang", "Xu Yang", "Jianmin Lin", "Ming Yang"], "primary_category": "cs.CV", "categories": ["cs.CV"], "text": "\n\n\n\nSS-TD\n\n\n\n\n\nZ.Lin et al.\n\n\n\nSouth China University of Technology, Guangzhou, China\nlinzihao2637@gmail.com, maxgundam@hotmail.com, eehsp@scut.edu.cn\nCVTE Research, Guangzhou, China\n\n{lijinrong, linjianmin, yangming}@cvte.com\n Pazhou Lab, Guangzhou, 510330, China\n\neehsp@scut.edu.cn\nGRGBanking Equipment Co. Ltd. Guangzhou, China\n\nyxu8@grgbanking.com\n\n\n\n\n\nSpatial Attention and Syntax Rule Enhanced Tree Decoder for Offline Handwritten Mathematical Expression Recognition\n    Zihao Lin1 Jinrong Li2 Fan Yang1Shuangping Huang13Xu Yang4\n\nJianmin Lin2Ming Yang2\n\n    March 30, 2023\n===================================================================================================================\n\n\n\n\nOffline Handwritten Mathematical Expression Recognition (HMER) has been dramatically advanced recently by employing tree decoders as part of the encoder-decoder method. Despite the tree decoder-based methods regard the expressions as a  tree and parse 2D spatial structure to the tree nodes sequence, the performance of existing works is still poor due to the inevitable tree nodes prediction errors. Besides, they lack syntax rules to regulate the output of expressions. In this paper, we propose a novel model called Spatial Attention and Syntax Rule Enhanced Tree Decoder (SS-TD), which is equipped with spatial attention mechanism to alleviate the prediction error of tree structure and use syntax masks (obtained from the transformation of syntax rules) to constrain the occurrence of ungrammatical mathematical expression. In this way, our model can effectively describe tree structure and increase the accuracy of output expression. Experiments show that SS-TD achieves better recognition performance than prior models on CROHME 14/16/19 datasets, demonstrating the \neffectiveness of our model. \n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\nOffline handwritten mathematical expression recognition (HMER) has many applications like searching for questions in education, recording payment in finance, and many other fields. However, it is a challenge to recognize handwritten mathematical expression (HME) due to ambiguity of handwritten symbols and complexity of spatial structures in the expression. It means HMER should not only correctly recognize the symbols but also analyze the relationship between them, which put forward great difficulties in the recognition performance.\n\nWith the rapid advancement of deep learning-based methods for HMER, some studies have proposed string decoder\u00a0<cit.>\u00a0with handwritten mathematical expression images as input and LaTeX strings of expression as predicted targets. However, their works emphasize symbol recognition but seldom consider structure information, which leads to the unsatisfactory result in the recognition of expressions with complex structures like \u221a(2+\u221a(2)) .\n\nMoreover, in recent years, research based on tree decoder\u00a0<cit.>\u00a0which focuses on the structure was emerging in the field of HMER. The methods based on tree decoder inherently represent expression as tree structures which is more natural for HMER. Among them, Zhang et al.\u00a0<cit.>\u00a0proposed a tree decoder (DenseWAP-TD) to predict the parent-child relationship of trees during decoding procedure, which achieved the best recognition performance at that time. Although the tree decoder models the tree structure of HMEs explicitly, the structure prediction accuracy may decrease as they only use the node symbol information to predict the node structure. What's more, as shown in Fig.1(c), the previous methods output an ungrammatical expression in which the symbol `2' can not have a `Subscript' relation with the symbol `\u2211'. It means the previous tree decoders may lack the syntactic rules to generate the grammatical expressions. \n\n\nIn order to solve the above problems, inspired by the DenseWAP-TD model\u00a0<cit.>\u00a0, we proposed a novel tree decoder (SS-TD) integrating spatial attention and syntax rules which is shown in Fig.2. First, we introduce spatial attention mechanism to predict the parent node, which effectively improves the structure accuracy. What\u2019s more, for purpose of reducing the generation of ungrammatical mathematical expressions, we transform the grammar of the relationship between expression symbols into the syntax mask and introduce it into the process of relation prediction. The comparison results shown in Fig.1 illustrate that our model can deal with the problems of the previous method. To further confirm the effectiveness of our model, we conduct the experiments on CROHME dataset. The results show that our model consistently achieves higher recognition rates over many other methods, demonstrating the effectiveness of our model for offline HMER.\n\nThe main contributions of this paper are as follows:\n\n\u2219 We proposed a new tree decoder (SS-TD) which can effectively adapt encoders of other methods to achieve higher recognition performance.\n\n\u2219 To improve the structure accuracy, we introduce spatial attention enhancement to predict node information. Besides, we introduce syntax masks to constrain the generation of ungrammatical mathematical expressions.\n\n\u2219 We demonstrate the advantage of SS-TD on the CROHME14/16/19 dataset by experiments and achieve very competitive results.\n\n\n\n\n\u00a7 RELATED WORKS\n\nEarly traditional methods\u00a0<cit.>\u00a0employed sequential approaches, which implemented symbol recognition and structural analysis separately. Recognition errors might be accumulated constantly in these methods. On the other hand, some studies\u00a0<cit.>\u00a0handled it as a global optimization to settle the problem of error accumulation, but made the process more inefficient.\n\nRecently, deep learning-based encoder-decoder approaches were investigated by many studies on offline HMER. Some of them used string decoder to generate LaTeX strings. WAP\u00a0<cit.>\u00a0proposed by Zhang et al. employs a fully convolutional network encoder and an attention-equipped decoder, which achieved state-of-the-art at that time on CROHME 14/16 datasets. Then, Zhang et al.\u00a0<cit.>\u00a0proposed a DenseNet encoder to improve the WAP, which is also employed in our model. Wu et al.\u00a0<cit.>\u00a0proposed an adversarial learning strategy to overcome the difficulty about writing style variation. However, these studies lack structure relationship awareness, which leads to inevitable errors in some complex mathematical expression recognition.\n\nSome works\u00a0<cit.>\u00a0employed tree decoder for various tasks, which is more natural to represent the structure. In this regard, some studies employed tree decoders to model the structure of mathematical expression. For online HMER, Zhang et al. proposed a tree decoder method SRD\u00a0<cit.>\u00a0to generate tree sequence of expressions. Wu et al.\u00a0<cit.> treated the problem as a graph-to-graph learning problem, which essential is the same as the tree decoder. On the other hand, for offline HMER, Zhang et al. proposed a tree-structured decoder (DenseWAP-TD), which decomposes the structure tree into a sub-tree sequence to predict the parent-child nodes and the relationship between them. However, the existing methods based on tree decoder attempt to take syntactic information into account, which still could not guarantee the grammatical accuracy of the output expression. Yuan et al.\u00a0<cit.>\u00a0incorporated syntax information into an encoder-decoder network, which gave us a lot of inspiration.\n\nAs described above, although some tree decoders have been proposed, there is still a great challenge on how to further improve the accuracy in offline HMER and effectively combine semantic information into the network. For the purpose of solving these problems, we integrate spatial attention mechanism and syntax rules into the tree decoder to deal with complex mathematical expressions and adapt to the syntactic rationality of expressions as much as possible.\n\n\n\n\n\u00a7 PROPOSED METHOD\n\nOur model takes the input HME images and yields the symbol tree structure as shown in Fig.2. We adopt an encoder to extract the feature vector sequence of the expression images. The decoder takes the feature sequence as input and then yields sequential triples step by step. Each triple which represents the sub-tree structure includes a child node, a parent node, and the relationship between parent-child nodes, represented as (y_t^c,y_t^p,y_t^rel). The child node y_t^c is composed of the predicted symbol and its tree sequence order. The predicted parent node y_t^p is one of the previous child nodes y_1,2...,t-1^c which has best match with current child node y_t^c in the semantic and spatial information. The connection relationship y_t^rel between current parent and child nodes is represented as 6 forms: Above, Below, Sup, Sub, inside, and Right.\n\n\n\nJust like the previous methods based on encoder-decoder\u00a0<cit.>\u00a0, we also employ DenseNet to  encode the HME images I\u2208 R^H\u00d7 W\u00d7 C and extract the feature vector sequence E={ h_i }\u2208 R^H'\u00d7 W'\u00d7 D, where h_i\u2208 R^D.\nThen, the feature sequence is input into the child decoder and the parent decoder respectively to recognize the symbol step by step. For the purpose of modeling the expression structure, the decoder of SS-TD consists of three prediction modules: 1)the child node prediction module shown as ChildN.P in Fig.2 and Fig.3 to predict the current child node information y_t^c; 2)the parent node prediction module shown as ParentN.P in Fig.2 and Fig.3 to predict the parent node y_t^p from the previous child nodes which has best match with current child node;\n3)the relationship prediction module shown as Relation.P in Fig.2 and Fig.3 to predict the relationships y_t^rel between parent and child nodes which are mentioned above. Consequently, the prediction modules yield the triples which can be transformed to the symbol tree structure. At last, we traverse the tree structure to obtain the  strings. \n\n\n \u00a7.\u00a7 Child Node Prediction Module\n\nLike the previous tree decoder-based method DenseWAP-TD, we also adopt a parent decoder and a child decoder to recognize the child node symbol in sequence as shown in Fig.3. These two decoders generate a tuple including the symbol and its recognition order, which is defined as child node information.  \n\nThe parent decoder consists of two Gated Recurrent Units (GRU) layers and an attention block as shown in the left part of Fig.3. It takes the previous child node y_t-1^c and its hidden state s_t-1^c as input, and outputs the parent context vector c_t^p and its hidden state s_t^p, which is also the input of the child decoder and the other two modules ParentN.P and Relation.P which shown in the right of Fig.3:\n\n    c_t^p=\u2211_i=1^L a_ti^p h_i\n\n\n    s_t^p=GRU_2^p(c_t^p,\u015d_t^p)\n\nwhere h_i is the i-th element of feature map E. L=H'\u00d7 W'. s_t^p is the prediction of current parent hidden state. a_t^p={ a_ti^p} is the current parent attention probabilities which is computed as follows: \n\n    \u015d_t^p=GRU_1^p(y_t-1^c,s_t-1^p)\n\n\n    a_t^p=f_att^p(\u015d_t^p,a_1,2...,t-1^p)\n\nwhere f_att^p represents attention function followed the DenseWAP-TD\u00a0<cit.>\u00a0. \n\nThe structure of child decoder is almost the same as the parent decoder. The decoder inputs the previous parent node y_t-1^p and its hidden state s_t^p, and outputs the child context vector c_t^c and its hidden state s_t^c. \n\nWe take the previous parent node y_t-1^p, the child node hidden state s_t^c and its context vector c_t^c as input to compute the probability of each output predicted child node p(y_t^c):\n\n    p(y_t^c)=softmax(W_out^c(W_ey_t-1^p+W_hs_t^c+W_cc_t^c))\n\nwhere W_out^c\u2208 R^S is a full connection layer parameter. S is the size of the recognition symbol set.\n\nThe classification loss of child node prediction module is:\n\n    L_c=-\u2211_t=1^Tlog(p(y_t^c))\n\n\nDuring the test process, we use the previous one-hot vector of the parent decoder and the child decoder in greedy algorithm to predict the child node:\n\n    \u0177_t^c=max_y^c p(y_t^c)\n\nwhere y^c represents all the symbols in the symbol set. \n\n\n\n \u00a7.\u00a7 Spatial Attention-based Parent Node Prediction Module\n\nWe treat predicting the parent node as finding previous child nodes which have the best match with current child node. We define the order of previous child nodes as the parent node position \u0177^pos, which is the predicted target in this module.\n\nWe first use the semantic information representing the hidden state of the nodes to predict the parent nodes. We employ Multilayer Perceptron (MLP) architecture to obtain the semantic energy factor e_ti^mem which is shown as the MLP_1 block in Fig.3:\n\n    e_ti^mem=v_mem^Ttanh(W_mems_t^p+U_mems_1,2...,t-1^c)\n\nwhere e_ti^mem is the semantic energy of i-th element at decoding step t. s_t^p is the hidden state of parent decoder. s_1...t-1^c are the hidden states of child nodes in history. \n\nHowever, only using semantic information to predict the parent node may lead to inevitable error especially when facing the identical symbols of expression. Thus, we introduce spatial attention mechanism to alleviate the prediction error of parent node.\n\nThe spatial information of the parent node and previous child nodes is represented as the attention distribution a_t^p and a_1,2...,t-1^c respectively. The spatial energy factor is computed as follows:\n\n    e_ti^alpha=v_alpha^Ttanh(W_alphap(a_t^p)+U_alphap(a_1,2...,t-1^c))\n\nwhere e_ti^alpha is the spatial energy of i-th element at decoding step t. p(\u00b7) represents\nadaptive pooling. The size of its output vector is 4\u00d732. \n\nWe further employ the gate mechanism to control the input of updated spatial position information as shown in the ParentN.P block of Fig.3. The gate mechanism is computed as follows:\n\n    g_t=\u03c3 (W_ygy_t-1^c+U_sgs_t-1^c)\n\n\n    e_ti^position=e_ti^mem+g_t\u2299 e_ti^alpha\n\n\n    G_ti^position=\u03c3 e_ti^position\n\nwhere \u2299 means the element-wise product.  \n\nThe loss of the parent node prediction module is defined as a cross entropy loss:\n\n    L_pos=-\u2211_t-1^T\u2211_i=1^L[G\u0305_ti^positionlog(G_ti^position)+(1-G\u0305_ti^position)log(1-G_ti^position)]\n\nwhere G\u0305_ti^position represent the ground-truth of the parent node. If i-th child node in history is the current parent node, G\u0305_ti^position is 1, otherwise 0.\n\nIn the testing stage, we compute the parent node position \u0177^pos:\n\n    \u0177^pos=max_g G^position\n\nAnd then the prediction of parent node \u0177^p is obtained by using the \u0177^pos which also represents the child node order. After that, we put it into the child decoder to predict the child node.\n\n\n\n \u00a7.\u00a7 Syntax Rule-based Relation Prediction Module\n\nIn order to predict the grammatical expression, we introduce syntax rules into the relation prediction module. Two crucial syntax rules related to conjunction relations are summarized as follows:\n\n\u2219 Different mathematical symbols have different restrictions of connection relation, like the `\u2211' can not have the `Inside' relation with other symbols. \n\n\u2219 Each mathematical symbol cannot have repeated connection relations at the same time, like one symbol can not have 'Right' relation with two other symbols.\n\n\nThen, to integrate these rules into the model training process, we creatively put forward the syntax mask representing the mathematical connection relationship. According to the two syntax rules, we define the syntax mask of mathematical symbols. If the mathematical symbols can be connected to its related symbol in a relation of Right, Sup, Sub, Above, Below, Inside, the corresponding syntax mask value is 1, otherwise 0. \n\nFor the first syntax rule which is regarded as the prior knowledge, the mask of it could be obtained in advance as shown in Table.1. For example, the mask of the symbol `+' is `100000' since it only has one relation `Right'. Besides, we group some symbols which have the same syntax mask, such as the Letter as shown in Table 1. In addition, we deal with the symbols which can be represented as different syntax masks by the logical `OR' operator. For example, the mask of symbol `e' is `111000' when it represents the lowercase letter, while the mask is `110000' when it represents the irrational constant. To sum up, the mask of `e' is `111000\u2225110000=111000', where `\u2225' is the logical `OR' operator.\n\nWe present the static syntax mask matrix as R_static\u2208 R^C\u00d7 6, and the static syntax mask of parent node as m_t^s\u2208 R^6:\n\n    m_t^s = y_t^pR_static\n\nwhere y_t^p is the one-hot vector of the symbol in the current parent node.\n\nOn the other hand, for the second syntax rule, we need to acquire information about the previous relations between parent-child nodes. To solve the problem, we propose a dynamic mask matrix R_dynamic^t which is initialized into an all-zero matrix to store the historical relations in step t. For example, when the parent node and its relationship are predicted to be `\u2216sqrt' and `Inside', the value of the corresponding row of `\u2216sqrt' and the corresponding column of `Inside' in R_dynamic^t should be updated as `1'. The dynamic syntax mask of parent node is represented as m_t^d\u2208 R^6:\n\n    m_t^d = y_t^pR_dynamic^t-1\n\n\n    m_t = m_t^s\u2297 m_t^d\n\nwhere \u2297 is the logical exclusive or operator. The update of dynamic mask matrix R_dynamic^t is computed as follows:\n\n    R_dynamic^t = R_dynamic^t-1 + y_t^p^Ty_t^rel\n\nwhere y_t^p^T represents the transposition of the parent node y_t^p.\n\nAs shown in Fig.3, We compute the probabilities of the relation prediction p(y_t^rel) as follows:\n\n    p(y_t^rel)=softmax(m_t\u2299 (W_out^rel(W_cpc_t^p+W_ccc_t^c)))\n\nwhere \u2299 represents multiplication element by element.\n\nThe classification loss of relation prediction module is computed as follows:\n\n    L_rel=-\u2211_t=1^Tlog(p(y_t^rel))\n\nIn the testing stage, we take the relation of maximum probability as final prediction relation:\n\n    \u0177^rel=max_y^rel p(y_t^rel)\n\nwhere y^rel represent the relations set.\n\n\n\n \u00a7.\u00a7 Total Loss\n\nWe use an attention self-regularization loss to speed up network convergence. Specifically, a Kullback-Leibler divergence is employed to measure the difference in the distribution of attention generated by parent and child decoder:\n\n    L_alpha=\u2211_t=1^T\u00e2_t^plog(\u00e2_t^p/a_t^p)\n\n\nThus, the training objective of the SS-TD is to minimize the loss as follows:\n\n    L=\u03bb_1L_c+\u03bb_2L_pos+\u03bb_3L_rel+\u03bb_4L_alpha\n\nwhere, \u03bb is the weight of each term.\n\n\n\n\u00a7 EXPERIMENTS\n\n\n\n \u00a7.\u00a7 Dataset\n\nWe verified our proposed model on the CROHME dataset\u00a0<cit.>\u00a0 which is the most widely used for HMER. The CROHME training set contains 8835 HMEs, 101 math symbol classes. There are 6 common spatial math relations (Above, Below, Right, Inside, Superscript and Subscript) in our implementation. We evaluate our model on CROHME\n14/16/19 test set. Among them, the CROHME 2014 test set contains 986 HMEs, which is evaluated by most advanced model. And CROHME 2016 and 2019 test sets are collected and labeled for research after that, which contain 1147 and 1119 HMEs.\n\n\n \u00a7.\u00a7 Implementation Details\n\nFor the training loss, we set \u03bb_1=\u03bb_2=\u03bb_3=1 in our experiment indicating the same importance for the modules, and set \u03bb_4=0.1.\n\nFollowing the DenseNet-WAP\u00a0<cit.>\u00a0, We employ DenseNet as the encoder, which is composed of three DenseBlocks and two Transition layers. Each DenseBlock contains 48 convolution layers. The convolution kernel size is set to 11\u00d711 for computing the coverage vector.\n\nOur model follows the previous tree decoder-based method DenseWAP-TD using two decoders to recognize the symbols, which has redundant parameters. We first simplify the parameters to optimize the model, where the dimensions of child attention, parent attention and memory attention are set to 128 instead of 512 and the embedding dimensions of both child node and parent node are set to 128 instead of 256. As shown in the second row of Table 2, the parameters are reduced by near half and the inference speed increases by more than 50 ms without affecting the recognition performance. Regarding this, we take the same parameters into SS-TD to pursue better performance. Due to the introduced syntax masks, the complexity of our model is quite more than the simplified DenseWAP-TD, in which the gap is still smaller than that between DenseWAP-TD and simplified DenseWAP-TD.\n\n\nWe utilized the Adadelta algorithm [29] for optimization and conduct on experiments. Besides, the framework was implemented in Pytorch. Experiments were conducted on 2 NVIDIA GeForce RTX 3090.\n\n\n \u00a7.\u00a7 Ablation Experiment\n\nIn order to verify the performance improvement of SS-TD brought by the integration of spatial attention and syntax rules, we conduct ablation experiments on CROHME 14 datasets.\n\n\n\nAs shown in Table 3, after we introduce spatial attention mechanism, the Exp.Rate_tree increases by 1.54% and the WER_pos decreases by 1.52%. To further prove the improvement is due to the spatial attention mechanism itself instead of the attention parameters, we compare the precision(%)/Params(M) of attention employed and attention not employed, in which the value of attention employed is 10.79 and 0.12 higher than attention not employed. In addition, as shown in Fig.4, the result predicted by only using semantic information is the symbol `1' which is incorrect obviously. And the attention distribution of child node symbols correctly indicate the right symbol `n'. Hence the spatial attention enhancement achieved improvements and this demonstrates the importance of spatial information for the parent node position.\n\nOn the other hand, as illustrated in the third row and the forth row of Table 3, the performance has a great improvement on the whole after adding static and dynamic syntax masks. It is worth noting that the gap between Exp.Rate_tree and Exp.Rate_latex becomes smaller, which indicates the grammar accuracy of the output tree structures has great improvement. \nIn general, after the enhancement we introduce into the model, Exp.Rate_tree and Exp.Rate_latex increase by 2.55% and 2.34%, WER_pos and WER_pos decrease by 1.92% and 1.41%, respectively, which validates the effectiveness of the spatial attention and syntax rules.\n\n\n\n \u00a7.\u00a7 Performance Comparison\n\n\nThe comparison among our model and the early algorithms on CROHME 14/16/19 is listed in the Table 4. All the experiment results in Table 4 are selected from published papers. Our model is implemented without using data enhancement and beam search strategies. Obviously, the Exp.Rate_latex of SS-TD is 52.48% on CROHME 2014, 55.29% on CROHME 2016, and 54.32% on CROHME 2019. Specifically, compared with the baseline model DenseWAP-TD, our model is 3.33% better on CROHME 2014 and 6.68% better on CROHME 2016 than DenseWAP-TD which demonstrates the effectiveness of our improvement.\n\nHowever, the competitive performance of our method is still lower than some string decoder-based methods, such as\u00a0<cit.>\u00a0and\u00a0<cit.>\u00a0. The former uses an additional weakly supervised branch to achieve 53.35% on CROHME 14, the latter uses large scale input images from data augmentation and beam search decoding to achieve 57.72%/61.38% ExpRate on CROHME 16/19 which take longer to decode iteratively. Indeed, our method pursues the expression spatial structure resolution too much and loses part of the recognition performance of the symbols, which is the main problem that we want to break through in the future. \n\n\n\n\u00a7 CONCLUSION\n\nIn this paper, we proposed a new tree decoder model integrating spatial attention and syntax rules, which not only improve the structure prediction accuracy, but also decrease the apparent grammar error of mathematical expressions. We illustrate the great performance of SS-TD for offline HMER through the ablation study and comparisons with the advanced methods on CROHME datasets. In the future work, we will further improve the generalization and performance of SS-TD.\n\n\n\n\u00a7 ACKNOWLEDGEMENT\nThis work has been supported by the National Natural Science Foundation of China (No.62176093, 61673182), the Key Realm Research and Development Program of Guangzhou (No.202206030001), and the GuangDong Basic and Applied Basic Research Foundation (No.2021A1515012282).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsplncs04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}