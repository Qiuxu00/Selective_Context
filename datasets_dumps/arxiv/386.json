{"entry_id": "http://arxiv.org/abs/2303.06795v1", "published": "20230313005442", "title": "Roadmap towards Meta-being", "authors": ["Tianyi Huang", "Stan Z. Li", "Xin Yuan", "Shenghui Cheng"], "primary_category": "cs.CY", "categories": ["cs.CY"], "text": "\n[\n    [\n    March 30, 2023\n==================\n\n\n\nCorrespondence to: Shenghui Cheng (chengshenghui@westlake.edu.cn)\n\n\n\n\n\n\n\nMetaverse is a perpetual and persistent multi-user environment that merges physical reality with digital virtuality.\nIt is widely considered to be the next revolution of the Internet.\nDigital humans are a critical part of Metaverse.\nThey are driven by artificial intelligence (AI) and deployed in many applications.\nHowever, it is a complex process to construct digital humans which can be well combined with the Metaverse elements, such as immersion creation, connection construction, and economic operation.\nIn this paper, we present the roadmap of Meta-being to construct the digital human in Metaverse.\nIn this roadmap, we first need to model and render a digital human model for immersive display in Metaverse. \nThen we add a dialogue system with audio, facial expressions, and movements for this digital human.\nFinally, we can apply our digital human in the fields of the economy in Metaverse with the consideration of security.\nWe also construct a digital human in Metaverse to implement our roadmap.\nNumerous advanced technologies and devices, such as AI, Natural Language Processing (NLP), and motion capture, are used in our implementation.\nThis digital human can be applied to many applications, such as education and exhibition.\n\n \n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\nSince the invention of the camera in 1839, photos have been used to present the appearances of great characters in history for nearly two hundred years.\nHowever, photos cannot satisfy our desire to interact with someone.\nWith the development of computers, Metaverse which is widely considered to be the next revolution of the Internet makes this desire come to the truth\u00a0<cit.>.\n\nMetaverse is a perpetual and persistent multi-user environment with the mergence of physical reality with digital virtuality\u00a0<cit.>.\nIt is based on the convergence of technologies such as Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR)\u00a0<cit.>, and thus enables multi-sensory interactions with virtual environments, digital objects, and people.\nOur desire to interact with someone can be implemented on the digital humans in Metaverse\u00a0<cit.>.\nThey are autonomously-animated virtual people driven by AI and deployed in many applications, such as healthcare, customer service, and education.\nHowever, it is complex to construct a digital human which can be well combined with the elements in Metaverse, such as immersion creation, connection construction, and economic operation.\n\nIn this paper, we present the roadmap of Meta-being to construct the digital human in Metaverse.\nIn this roadmap, we first need to model and render a digital human model for immersive display in Metaverse. \nThen we add a dialogue system with audio, facial expressions, and movements for this digital human.\nFinally, we can apply our digital human in the fields of the economy in Metaverse with the consideration of security.\nIn this way, we can appreciate the motions and speakings of digital humans and interact with them in Metaverse as in physical reality.\nMeta-being is a complex process.\nAs we can see from Fig.\u00a0<ref>, many advanced technologies and devices are used to perform our Meta-being.\n\n\n\n\n\n\n\nOur contributions are summarized as follows:\n\n    \n  * We present the roadmap for the Meta-being of digital humans.\n    \n  * We construct a digital human to implement Meta-being.\n\n    \n\nThe rest of this paper is organized as follows.\nSection 2 reviews the Metaverse and digital human beings.\nIn Section 3, we give the roadmap of Meta-being.\nIn Section 4, we construct a digital human to implement Meta-being.\nIn the end, we conclude the paper in Section 5.\n\n\n\n\n\n\n\n\u00a7 DIGITAL HUMAN BEINGS IN METAVERSE\n\n\n\n\n\nThe term Metaverse was invented and first appeared in Neal Stevenson\u2019s science fiction novel Snow Crash published in 1992\u00a0<cit.>.\nIt represented a parallel virtual reality universe created from computer graphics to make users worldwide access and connect through goggles and earphones.\nDigital humans as an important part of Metaverse are computer-generated and computer-controlled characters with a human-like appearance and can simulate human face-to-face interactions\u00a0<cit.>. \nAt the same time, with the development of artificial intelligence, intelligent digital human has become one of the new development directions.\nDigital humans are often used in education, movies, games, and other fields. Each application domain requires different attributes at different levels, such as autonomous behaviour, natural language communication, recognition of real people, etc. Different intelligent decision-making techniques, such as artificial neural networks, need to be used to build a virtual human framework. Noma et al.\u00a0<cit.> created a digital human presenter based on the JackTM animated agent system in 2000. The input to this system is in the form of spoken text with embedded commands (mostly related to the digital presenter's body language). \nThe system then has the digital humans as a presenter with presentation skills in real-time 3D animation synchronized with the voice output. However, due to technical limitations, their digital human cannot synchronize lip movement with sound, and the movements are not smooth and natural enough. \nIn 2012, Rizzo et al.\u00a0<cit.> developed a digital human, SimCoach, which could provide healthcare information and support, especially for military members, veterans, and their important ones.\nSpecifically, SimCoach breaks down barriers to online care by providing confidential assistance for military members and others in exploring and accessing healthcare content and facilitating on-site care. However, SimCoach's anthropomorphic degree is not high, and the interaction with users is insufficient. And he can only provide support for specific groups of people and specific medical problems. Due to technical limitations, these digital humans are not so much like virtual digital humans but like computer systems with human images. In recent years, a group of virtual people such as Miquela Sousa has appeared\u00a0<cit.>. \nThey exist in the network (e.g., social media), and the robot-focused representations are highly anthropomorphic and interactive.\nSome researchers think although they live in the virtual world as humans live in the real world, with \u201cjobs\", \u201cemotions\", and \u201cthoughts\",\nthey are neither real humans nor real phenomena, but over time digital humans will be considered human in social media, which is seen as a simulated environment\u00a0<cit.>.\nThough the ethical issues that come with it will be a considerable challenge to tackle.\n\n\n\n\n\n\n\n\n\n\u00a7 META-BEING\n\n\n\n\nThe digital cyberspace of Metaverse includes immersion creation, hardware support, text interpretation, audio processing, connection construction, economy operation, and security protection\u00a0<cit.>.\nTo create a digital human which can be well combined with the above elements, we propose the roadmap towards Meta-being as follows.\n\n    \n  1) The body and the face of our digital human should be modeled.\n    \n  2) The resulting model should be rendered in detail.\n    \n  3) We should give an immersive display of our digital human in Metaverse by some display technologies, like VR and holographic projection. \n    \n  4) We should generate a dialogue system with audio, facial expressions, and movements for this digital human.\n    \n  5) We can apply our digital human in the fields of the economy in Metaverse with the consideration of security.\n\n\nAs we can see, Meta-being is a complex process.\nMany advanced technologies and devices, such as 3D modeling, AI, and VR, are used to perform our Meta-being.\nThis roadmap is demonstrated in Fig.\u00a0<ref>.\n\n\n\n\n \u00a7.\u00a7 Modeling and Rendering\n\nFor a digital human in Meta-being, we should construct and then render a digital human model\u00a0<cit.>.\nTo this end, we first need a human body model as a reference.\nThis model can be an adult or a child with an athletic body with relevant muscle mass and no significant body fat\u00a0<cit.>.\nSome 3D scanning technologies, such as TEN24, can be used to capture the reference model\u00a0<cit.>.\nSecond, we can use 3D Face Modeling technologies, like triangulation\u00a0<cit.>,3D Morphable Model\u00a0<cit.>, to construct the face of our digital human by the reference photos in detail.\nFinally, in the rendering step, we add the hair and clothes to our modeling digital human and fine-tune the appearance structures, such as the color and texture of the skin. \nIn this modeling, the triangulation set, T={t_1,t_2,...,t_n} is along with a texture map set, A={a_1,a_2,...,a_n}, on all of the face triangles.\nThe photo set V'={v'_1,v'_2,...,v'_k} taken with a calibrated camera in Metaverse can be computed as\n\n    V' = f(T,A)\n\na_i for a given triangulation t_i can be estimated directly from the actual photo set, V={v_1,v_2,...,v_k}, where v_j is along with the same camera angle of v'_j, as follows. \n\n    A = f^-1(T,V)\n\nThus V' from equation\u00a0(<ref>) depends only on T and V.\nWith the assumption that the photos along with the triangulation constraints are sufficient to define a unique face, our goal is to get the maximum Similarity U for the actual photo set and the photo set from Metaverse as\n\n    max_t_i\u2211_j=1^k\u2211_i=1^nU(v_j,v'_j|t_i)\n\nFinally, in the rendering step, we add the hair and clothes to our modeling digital human of Turing and fine-tune the appearance structures, such as the color and texture of the skin. \nFig.\u00a0<ref> shows the modeling process and the resulting model with different poses.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Immersive Display\n\nFor the immersion creation in Metaverse, immersive VR mainly presents virtual environments using cave automatic virtual environments or head-mounted displays, which can provide users with a strong and immersive feeling of presence in a 3D virtual world.\nThe immersive display of digital humans is a critical part of immersion creation in Metaverse for us to interact with digital humans.\nExisting immersive display methods of digital humans are usually based on predefined elements, including body motions and facial expressions.\nThis could preclude the immersive feeling of human interaction with a digital human in the Metaverse since these elements may be different from the real ones with limited predefined elements.\nTo address this issue, we should capture many real scenes and use those images or videos to generate new ones and update the scenes in the metaverse within a short period of time, possibly in\nreal-time eventually.\nComputational imaging may provide a promising solution to capture scenes efficiently in a low-cost, low-bandwidth manner with the help of deep learning\u00a0<cit.>.\n\n\n\n\n \u00a7.\u00a7 Adding Operations\n\nFor a Meta-being digital human, we also need to create the dialogue system, body movements, and facial expressions for our model.\nThe dialogue of our digital human is mainly based on our QA system generated by NLP algorithms\u00a0<cit.>.\nThis system first classifies the questions from users by automatic speech recognition and then extracts the relevant answers\u00a0<cit.>.\nThe intent of the question could be understood by identifying the starting phrase or words of this question.\nTo answer the question, we can identify areas of interest from the voluminous content for this question and find the related paragraphs,\nand then score each sentence in the related paragraphs by the number of proper nouns, the similarity between this sentence and the question, and so on.\nA sentence can be considered a part of the answer if its score is above a particular threshold.\n\nHuman motion capture, like Xsens MVN motion capture, can be used to get the body motions and for digital human\u00a0<cit.>.\nIt tracks the motion of the human body defined by a biomechanical model consisting of some segments, like the neck, head, shoulders, feet, and so on.\nFor each body segment B, all kinematic quantities are expressed in a standard, local coordinate frame L, which is a right-handed Cartesian coordinate system.\nGiven the sensor S, we can obtain the position of each segment ^Lp_B and corresponding orientation ^LBq by\n\n    ^LBq = ^LSq \u2297   ^BSq^*\n\nand\n\n    ^Lp_B = ^Lp_S+ ^LBq \u2297 ^Br_BS\u2297 ^LBq^*\n\nwhere ^BSq denotes the relative orientation of the sensor w.r.t. the body, ^Br_BS denotes the position of the sensor w.r.t. the segment origin expressed in the segment\nframe, \u2297 denotes the quaternion multiplication, and * denotes the complex conjugate of the quaternion.\n\n\n\n \u00a7.\u00a7 Applied in Metaverse\n\nThe economic operation in Metaverse is for exchanging virtual goods through a blockchain digital system.\nDigital humans are one type of the most important virtual goods in Metaverse.\nThe applications of Meta-being digital humans are driven by interaction and social connection.\nFor example, interaction with digital recreations of historical figures has existed for almost a decade, e.g., an interactive life-size video of Abraham Lincoln that is used at the National Civil War Museum.\nIn this case, education has become an important application of Meta-being digital humans.\nBy Meta-being digital humans with an artistic style, the children\u2019s attention can be well attracted during the learning process. \nAlso, proposing a Meta-being digital human curriculum with a ready-to-use software package would also improve/update the engineering quality and provide a unique educational experience for students\u00a0<cit.>.\n\n\nWidespread adoption of the Metaverse comes with many unique threats to user privacy and security, especially in the interaction with digital humans.\nBiometric data reveals a host of personally identifiable information which can in turn be used to potentially manipulate users on a psychological level through the creation of avatars that are adaptable to user preferences\u00a0<cit.>.\nAI may have the capability of privacy protection through algorithms that automatically and dynamically detect user privacy references from diverse contexts in the Metaverse\u00a0<cit.>.\nAn AI-powered security system will emerge in the Metaverse.\n\n\n\n\u00a7 THE IMPLEMENTATION OF META-BEING\n\nAs an implementation of Meta-being, we have made a digital human of Alan Mathison Turing by modeling the digital human model of Turing and then creating dialogue and movement functions, including body motions and facial expressions.\nThen in Metaverse, we can appreciate the body motions, facial expressions, and speakings of digital Truing.\nWe also can talk to our digital Turing in Metaverse.\nOur digital Truing can be applied to many applications, such as education and exhibition.\nBy mixing VR and AR, our digital Truing can explain computer knowledge to students and introduce new products to consumers in an immersive environment.\nWe display three interesting action sequences of our Turing model in Fig.\u00a0<ref>-<ref>.\n \n\n\n\n\n\n \n\nHolographic projection technology breaks the traditional presentation of images by combining 3D technology and holographic technology\u00a0<cit.>.\nIt has become a hot application technology in the Metaverse for immersion display\u00a0<cit.>.\nBy holographic projection, we have presented our digital Turing at some expositions.\nFig.\u00a0<ref> shows an example of our presentation.\nAs we can see, our vivid digital Turing is well integrated with the stage\u2019s background.\n\n\n\n\n\u00a7 CONCLUSION\n\nIn this paper, we have presented the roadmap for the Meta-beings to make digital humans can be better combined with the elements in Metaverse.\nIn this roadmap, we model the body and face of a digital human in a 3D space.\nThen, in the rendering step, we add clothes and appearance details to our model.\nWe also need to create a dialogue system, body movements, and facial expressions for this model.\nIn this manner, we can appreciate its motions and speaking and interact with him in Metaverse as in physical reality.\nIt is a complex process to implement our Meta-being on a digital human.\nMany advanced technologies and devices, such as AI, NLP, and motion capture, are used to perform our Meta-being.\nAs an example, we implement our Meta-being on Turing, a great scientist of computer science.\n\n\n\nplainnat\n\n\n\n \n"}