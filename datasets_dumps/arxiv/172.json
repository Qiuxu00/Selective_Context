{"entry_id": "http://arxiv.org/abs/2303.07115v1", "published": "20230313134757", "title": "NeurEPDiff: Neural Operators to Predict Geodesics in Deformation Spaces", "authors": ["Nian Wu", "Miaomiao Zhang"], "primary_category": "cs.CV", "categories": ["cs.CV"], "text": "\n\n\n\n\nNeurEPDiff: Neural Operators to Predict Geodesics in Deformation Spaces\n\nWu and Zhang\nComputer Science, East China Normal University, Shanghai, China Electrical & Computer Engineering, University of Virginia, VA,USA Computer Science, University of Virginia,  VA, USA\n\nNeurEPDiff: Neural Operators to Predict Geodesics in Deformation Spaces\n    Nian Wu  1,2Miaomiao Zhang2,3\n    March 30, 2023\n=======================================================================\n\n\n\nThis paper presents NeurEPDiff, a novel network to fast predict the geodesics in deformation spaces generated by a well known Euler-Poincar\u00e9 differential equation (EPDiff). To achieve this, we develop a neural operator that for the first time learns the evolving trajectory of geodesic deformations parameterized in the tangent space of diffeomorphisms  (a.k.a velocity fields). In contrast to previous methods that purely fit the training images, our proposed NeurEPDiff learns a nonlinear mapping function between the time-dependent velocity fields. A composition of integral operators and smooth activation functions is formulated in each layer of NeurEPDiff to effectively approximate such mappings. The fact that NeurEPDiff is able to rapidly provide the numerical solution of EPDiff (given any initial condition) results in a significantly reduced computational cost of geodesic shooting of diffeomorphisms in a high-dimensional image space. Additionally, the properties of discretiztion/resolution-invariant of NeurEPDiff make its performance generalizable to multiple image resolutions after being trained offline. We demonstrate the effectiveness of NeurEPDiff in registering two image datasets: 2D synthetic data and 3D brain resonance imaging (MRI). The registration accuracy and computational efficiency are compared with the state-of-the-art diffeomophic registration algorithms with geodesic shooting. \n\n\n\n\n\u00a7 INTRODUCTION\n\nDeformable image registration is a fundamental tool in medical image analysis, for example, computational anatomy and shape analysis\u00a0<cit.>, statistical analysis of groupwise images\u00a0<cit.>, and template-based image segmentation\u00a0<cit.>. Among many applications, it is ideal that the transformation is diffeomorphic (i.e., bijective, smooth, and invertible smooth) to maintain an intact topology of objects presented in images. A bountiful literature has studied various parameterizations of diffeomorphisms, including stationary velocity fields\u00a0<cit.>, B-spline free-form deformations\u00a0<cit.>, and the large deformation diffeomorphic metric mapping (LDDMM)\u00a0<cit.>. In this paper, we focus on LDDMM, which provides a rigorous mathematical definition of distance metrics on the space of diffeomorphisms. Such distance metrics play an important role in deformation-based shape analysis of images, such as geometric shape regression\u00a0<cit.>, longitudinal shape analysis\u00a0<cit.>, and group shape comparisons\u00a0<cit.>. \n\nDespite the advantages of LDDMM\u00a0<cit.>, the substantial time and computational cost involved in searching for the optimal diffeomorphism on high-dimensional image grids limits its applicability in real-world applications. To alleviate this problem, a geodesic shooting algorithm\u00a0<cit.> was developed to reformulate the optimization of LDDMM (originally over a sequence of time-dependent diffeomorphisms) equivalently in the tangent space of diffeomorphisms at time point zero (a.k.a., initial velocity fields). The geodesic is then uniquely determined by integrating a given initial velocity field via the Euler-Poincar\u00e9 differential equation (EPDiff)\u00a0<cit.>. This geodesic shooting algorithm demonstrated a faster convergence and avoided having to store the entire time-varying velocity fields from one iterative search to the next. A recent work FLASH has further reduced the computational cost of geodesic shooting by reparameterizing the velocity fields in a low-dimensional bandlimited space\u00a0<cit.>. The numerical solution to EPDiff was rapidly computed with much fewer parameters in a frequency domain. In spite of a significant speedup, it still takes FLASH minutes to compute when the dimension of the bandlimited space grows higher. \n\nIn this paper, we present a novel method, NeurEPDiff, that can fast predict the geodesics in deformation spaces generated by EPDiff. Inspired by the recent achievements on learning-based partial/ordinary differential equation solvers\u00a0<cit.>, we develop a neural operator to learn the evolving functions/mappings of geodesics in the space of diffeomorphisms parameterized by bandlimited initial velocity fields. \nIn contrast to current deep learning-based approaches that are tied to the resolution and discretization of training images\u00a0<cit.>, our proposed method shows consistent performances on different scales of image resolutions without the need of re-training. We also define a composition of integral operators and smooth activation functions in each layer of the NeurEPDiff network to effectively approximate the mapping functions of EPDiff over time. To summarize, our main contributions are threefold: \n\n    \n  * We are the first to develop a neural operator that fast predicts a numerical solution to the EPDiff\u00a0<cit.>, which is a critical step to generate geodesics of diffeomorphisms.\n\n    \n  * A composition of integral operators and smooth activation functions is defined to approximate the mapping functions of EPDiff characterized in the low-dimensional bandlimited space. This makes the training and inference of our proposed NeurEPDiff much more efficient in high-dimensional image spaces. \n\n    \n  * The performance of NeurEPDiff is invariant to image resolutions. That is to say, once it is trained, this operator can be tested on multiple image resolutions without the need of being re-trained. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo demonstrate the effectiveness of our proposed model in diffeomorphic image registration, we run experiments on both 2D synthetic data and 3D real brain MRIs. We first show that a trained NeurEPDiff is able to consistently predict the diffeomorphic transformations at multiple different image resolutions. We then compare the registration accuracy (via registration-based image segmentation) and computational efficiency of NeurEPDiff vs. the state-of-the-art LDDMM with geodesic shooting\u00a0<cit.>. Experimental results show that our method outperforms the baselines in term of time consumption, while with a comparable registration accuracy. \n\n\n\n\n\n\n\n\u00a7 BACKGROUND: GEODESICS OF DIFFEOMORPHISMS VIA EPDIFF\n\n\n\nIn this section, we first briefly review the basic concepts of geodesic shooting, which generates geodesics of diffeomorphisms via EPDiff\u00a0<cit.>. We then show how to optimize the problem of diffeomorphic image registration in the setting of LDDMM\u00a0<cit.> with geodesic shooting\u00a0<cit.>. \n\n\n\n  \nGeodesic shooting via EPDiff. Let ^\u221e(\u03a9) denote the space of smooth\ndiffeomorphisms on an image domain \u03a9. The tangent space of diffeomorphisms is the\nspace V = \ud835\udd1b^\u221e(T\u03a9) of smooth vector fields on \u03a9. Consider a time-varying velocity field, {v_t} : [0,\u03c4] \u2192 V, we can generate diffeomorphisms {\u03d5_t} as a solution to the equation\n\n    d \u03d5_t/dt = v_t(\u03d5_t),   t \u2208 [0, \u03c4].\n\n\nThe geodesic shooting algorithm\u00a0<cit.> states that a geodesic path of the diffeomorphisms (in Eq.\u00a0(<ref>)) is uniquely determined by integrating a well-studied EPDiff\u00a0<cit.> with an initial condition. That is, given an initial velocity, v_0 \u2208 V, at t\n= 0, a geodesic path t \u21a6\u03d5_t \u2208^\u221e(\u03a9) in the space of diffeomorphisms can be computed by forward shooting the EPDiff equation\n\n    \u2202 v_t/\u2202 t =-K[(Dv)^Tm_t + Dm_t  v_t + m_t div v_t],\n\nwhere D denotes the Jacobian matrix. Here K is an inverse operator of L: V \u2192 V^*, which is a positive-definite differential operator that maps a tangent vector v \u2208 V into the dual space m \u2208 V^*. This paper employs a commonly used Laplacian operator L = (-\u03b1\u0394 + e)^c, where \u03b1 is a positive weight parameter, e denotes an identity matrix, and c is a smoothness parameters. A larger value of \u03b1 and c indicates more smoothness.\n\nA recent model FLASH has later developed a Fourier variant of the EPDiff and demonstrated that the numerical solution to the original EPDiff can be efficiently computed in a low-dimensional bandlimited space with dramatically reduced computational cost\u00a0<cit.>. Let (\u03a9) and \u1e7c denote the space of Fourier representations of diffeomorphisms\nand velocity fields respectively. The equation of EPDiff is reformulated in a bandlimited space as\n\n    \u2202\u1e7d_t/\u2202 t =-K\u0303[(\ud835\udc9f\u0303\u1e7d_t)^T \u22c6m\u0303_t + \u2207\u0303\u00b7 (m\u0303_t \u2297\u1e7d_t) ],\n\nwhere \u1e7d_t and m\u0303_t are the Fourier transforms of velocity fields v_t and momentum m_t respectively. The \ud835\udc9f\u0303 represents Fourier frequencies of a Jacobian matrix D with central difference approximation, \u22c6 is the truncated matrix-vector field auto-correlation with zero-padding, and \u2297 denotes a tensor product. The Fourier coefficients of a laplacian operator L is L\u0303(\u03be_1 , \u2026, \u03be_d) = (-2 \u03b1\u2211_j = 1^d (cos (2\u03c0\u03be_j) - 1 ) + 1)^c, where (\u03be_1 , \u2026, \u03be_d) is a d-dimensional frequency vector.\n\n\n\n  \nLDDMM with geodesic shooting. Given a source image S and a target image T defined on a d-dimensional torus domain \u03a9 = \u211d^d / \u2124^d (S(x), T(x):\u03a9\u2192\u211d). \nThe space of diffeomorphisms is denoted by (\u03a9).\nThe problem of diffeomorphic image registration is to find the shortest path, i.e., geodesic, to generate time-varying diffeomorphisms {\u03d5_t}: t \u2208 [0,\u03c4], such that a deformed source image by the smooth mapping \u03d5_\u03c4, noted as S(\u03d5_\u03c4), is similar to T. By parameterizing the transformation \u03d5_\u03c4 with an initial velocity field \u1e7d_0, we write the optimization of diffeomorphic registration in the setting of LDDMM with geodesic shooting in a low-dimensional bandlimited space as\n\n    E(\u1e7d_0) = \u03bb Dist(S(\u03d5_\u03c4), T ) + 1/2\u1e7d_0 _\u1e7c^2   s.t. Eq.\u00a0(<ref>) and \u00a0(<ref>)\n\nHere, Dist(\u00b7,\u00b7) is a distance function that measures the dissimilarity between images and \u03bb is a positive weighting parameter. The commonly used distance functions include the sum-of-squared intensity differences (L_2-norm)\u00a0<cit.>, normalized cross correlation (NCC)\u00a0<cit.>, and mutual information (MI)\u00a0<cit.>. In this paper, we will use the sum-of-squared intensity differences. The \u00b7_V represents a Sobolev space that enforces smoothness of the velocity fields. \n\nDespite a dramatic speed up of LDDMM with the reduced cost of Fourier EPDiff for shooting\u00a0<cit.>, the numerical solution operator in Eq.\u00a0(<ref>) does not scale well due to the introduced correlation and tensor convolutions. \n\n\n\n\u00a7 OUR METHOD: NEUREPDIFF\n\n\nWe introduce a novel network, NeurEPDiff, that learns the solution operator to EPDiff in a low-dimensional bandlimited space. Inspired by the recent work on neural operators\u00a0<cit.>, we propose to develop NeurEPDiff, \ud835\udca2_\u03b8 with parameters \u03b8, as a surrogate model to approximate the solution operator to EPDiff. Once it is trained, our NeurEPDiff can be used to fast predict the original EPDiff with a given initial condition \u1e7d_0 on various resolutions of image grids. \n\nGiven a set of N observations, {\u1e7d_0^n , \u1e7d^n }_n=1^N, where \u1e7d^n \u225c{\u1e7d_1^n, \u22ef, \u1e7d_\u03c4^n} is a time-sequence of numerical solutions to EPDiff. The solution operator can be learned by minimizing the empirical data loss defined as \n\n    E(\u03b8) = 1/N\u2211_n=1^N \u1e7d^n - \ud835\udca2_\u03b8(v_0^n) _\u1e7c^2  + \u03b2\u00b7Reg(\u03b8),\n\nwhere \u03b2 is a weighting parameter and Reg(\u00b7) regularizes the network parameter \u03b8. \n\nFollowing the similar principles in\u00a0<cit.>, we formulate \ud835\udca2_\u03b8 as an iterative architecture \u1e7d_0 \u21a6\u1e7d_1 \u21a6\u22ef\u21a6\u1e7d_\u03c4, which is a sequence of functions carefully parameterized in the hidden network layers. The input \u1e7d_0 is first lifted to a higher dimensional representation by a complex-valued local transformation P\u0303, which is usually parameterized by a shallow fully connected neural network. We then develop a key component, called iterative evolution layer, with operations designed in the bandlimited space to learn the nonlinear function of EPDiff. \n\n\n\n  \n*Iterative evolution layer. Let z\u0303\u2208\u2102^d be a d-dimensional complex-valued latent feature vector encoded from the initial velocity \u1e7d_0. An iterative evolution layer (with the number of J hidden layers) to update z\u0303_j \u21a6z\u0303_j+1, where j \u2208{1, \u22ef, J}, is defined as the composition of a nonlinear smooth activation function \u03c3 of a complex-valued linear transform W\u0303_j with a global convolutional kernel \u210b\u0303_j:   \n\n    z\u0303_j+1 := \u03c3 (W\u0303_jz\u0303_j + \u210b\u0303_j* z\u0303_j).\n\nThe * represents a complex convolution, which is efficiently computed by multiplying two signals in a real space. Similar to\u00a0<cit.>, we employ a complex-valued Gaussian error linear unit (CGeLU) that applies real-valued activation functions separately to the real and imaginary parts. With a smoothing operator K\u0303 to ensure the smoothness of the output signal, we have \u03c3 := K\u0303(GeLU (\u211b (\u00b7)) + i GeLU (\u2110 (\u00b7))), where \u211b (\u00b7) denotes the real part of a complex-valued vector, and \u2110 (\u00b7) denotes an imaginary part.   \n\nWe are now ready to introduce a formal definition of the NeurEPDiff \ud835\udca2_\u03b8 developed in a bandlimited space as follows. \n\nThe neural operator \ud835\udca2_\u03b8 is defined as a composition of a complex-valued encoder P\u0303 (a decoder Q\u0303) (a.k.a. local linear transformations) to project the lower dimension function into higher dimensional space and vice versa, and a nonlinear smooth activation function \u03c3 of a local linear transform W\u0303 with a non-local convolution kernel \u210b\u0303 parameterized by network parameters, i.e.,   \n\n    \ud835\udca2_\u03b8Q\u0303\u2218\u03c3(W\u0303_J, \u210b\u0303_J) \u2218\u22ef\u2218\u03c3(W\u0303_1, \u210b\u0303_1) \u2218P\u0303.\n\nThe \u2218 denotes function composition, and the parameter \u03b8 includes all parameters from {P\u0303, Q\u0303, W\u0303, \u210b\u0303}. \n\n\nThe network architecture of our proposed NeurEPDiff is shown in Fig.\u00a0<ref>.   \n\n\n\n\n \u00a7.\u00a7 NeurEPDiff For Diffeomorphic Image Registration\n\n\nThis section introduces a new diffeomorphic image registration algorithm with our developed NeurEPDiff. We will first train a neural operator \ud835\udca2_\u03b8 offline and then use it as predictive model in each iteration of the optimization of LDDMM (Eq.\u00a0(<ref>)), where the numerical solution of EPDiff is required. In this paper, we use a sum-of-squares-distance (SSD) metric for image dissimilarity. The optimization \n\n    E(\u1e7d_0) = 1/2\u03bb^2 (S(\u03d5_\u03c4=1) - T _2^2 + 1/2\u1e7d_0 _\u1e7c^2,   s.t. Eq.\u00a0(<ref>) & \ud835\udca2_\u03b8(\u1e7d_0).\n\nThe final transformation \u03d5_\u03c4=1 is computed by Eq.\u00a0(<ref>) after predicting {\u1e7d_t} from a well-trained network \ud835\udca2_\u03b8.\n\n\n\n  \n*Inference. Similar to\u00a0<cit.>, we employ a gradient decent algorithm to minimize the problem\u00a0(<ref>). The three main steps of our inference are described below:\n\n    \n  * Forward geodesic shooting by NeurEPDiff. Given an initialized velocity field \u1e7d_0, we compute the transformation \u03d5_\u03c4 by first predicting {\u1e7d_t} and then solving Eq.\u00a0(<ref>).\n    \n     \n   \n    \n  * Compute the gradient \u2207_\u1e7d_\u03c4 E at the ending time point t=\u03c4 as\n    \n    \u2207_\u1e7d_\u03c4 E = K\u0303\u2131( 1/\u03bb^2 (S(\u03d5_\u03c4) - T) \u00b7\u2207 (S(\u03d5_\u03c4))  ).\n \n    Recall that \u2131 denotes a Fourier transformation.\n   \n  * Backward integration to bring the gradient \u2207_\u1e7d_\u03c4 E back to t=0 by integrating the reduced adjoint Jacobi field equations defined in\u00a0<cit.>. \n\n\nFig.\u00a0<ref> visualize the process to optimize image registration with NeurEPDiff. \n\n\n\n\n\n\n\u00a7 EXPERIMENTAL EVALUATION\n\nTo evaluate the effectiveness of our proposed model, NeurEPDiff, for diffeomoprhic image registration, we compare its performance with the original LDDMM with geodesic shooting\u00a0<cit.> and a fast variant of LDDMM (FLASH)\u00a0<cit.> on both 2D synthetic data and 3D real brain MR images with different levels of resolution. \n\nThe training of NeurEPDiff in all our experiments is implemented on Nvidia GeForce GTX 1080Ti GPUs. We use ADAM optimizer\u00a0<cit.> with the batch size as 20, learning rate of 1e^-3, and weight decay as 1e^-4, and the number of epochs as 500. For a fair comparison with the baseline algorithms that are optimized by gradient decent on CPU, we also test our model on CPU once it is trained.  \n\n\nWe evaluate the registration accuracy by performing registration-based segmentation and examine the resulting segmentation accuracy and runtime. To evaluate volume overlap between the propagated segmentation A and the manual segmentation B for each structure, we compute the dice similarity coefficient DSC(A, B) = 2(|A| \u2229 |B|)/(|A| + |B|), where \u2229 denotes an intersection of two regions\u00a0<cit.>.\n\n\n\n \u00a7.\u00a7 Data\n\n\n\n  \n*2D synthetic data. We first simulate 2200 \u201cbull-eye\u201d synthetic data (as shown in Fig\u00a0<ref>) with the resolution 192^2 by manipulating the\nwidth a and height b of an ellipse, formulated as\n(x-96)^2/a^2 + (y-96)^2/b^2 = 1. We draw the parameters a, b\nrandomly from a Gaussian distribution \ud835\udca9(40, 4.2^2) for the outer\nellipse, and a, b \u223c\ud835\udca9(17, 1.6^2) for the inner ellipse. We then carefully down-sample the images to different resolutions of 64^3 and 128^3. \nThe dataset is split into training (2000 volumes of resolution 64^2) and testing part (200 volumes of resolution 64^2, 128^2, and 192^2 respectively). \n\n3D brain MRI. We include 2200 T1-weighted 3D brain MRI scans from Open Access Series of Imaging Studies (OASIS)\u00a0<cit.> in our experiments. We randomly select 2000 of them and down-sampled to the resolution of 64^3 for training. The remaining 200 are re-sampled to the resolution of 64^3, 128^2, and 192^2 for testing separately. The 200 testing volumes include manually delineated anatomical structures, i.e., segmentation labels, which also have been  carefully down-sampled to the resolution of 64^3, 128^3, and 192^3.\nAll of the MRI scans have undergone skull-stripping, intensity normalization, bias field correction, and affine alignment. \n\nGround truth velocity fields. We use numerical solutions to Fourier EPDiff in Eq.\u00a0(<ref>) (i.e., computed by a Euler integrator) as the ground truth data for network training. More advanced integration methods, such as Runge\u2013Kutta RK4, can be easily applied. In all experiments, we first run pairwise image registration using FLASH algorithm\u00a0<cit.> on randomly selected images with lower resolution of 64^2 or 64^3. We then collect all numerical solutions to Fourier EPDiff as ground truth data. We set all integration steps as 10, the smoothing parameters for the operator K\u0303 as \u03b1=3.0, c=3.0, the positive weighting parameter of registration as \u03bb=0.03, and the dimension of the bandlimited velocity field as 16.\n\n\n\n \u00a7.\u00a7 Experiments\n\nWe first test our NeurEPDiff-based registration methods on 2D synthetic data and compare the final estimated transformation fields with the baseline algorithms. To validate whether our model is resolution-invariant, we train NeurEPDiff on images with lower resolution of 64^2, and then test its prediction accuracy on different levels of higher resolution (i.e., images with 128^2 and 192^2). We examine the optimization energy and compare it with all baseline algorithms.  \n\nWe further analyze the performance of NeurEPDiff on real 3D brain MRI scans. The convergence graphs of NeurEPDiff-based registration are reported at different image resolutions. To investigate the predictive efficiency of NeurEPDiff in terms of both time-consumption and accuracy, we compare the actual runtime of solving the original EPDiff by our method and all baselines. \n\nThe registration accuracy is validated through a registration-based segmentation. Given a source image, we first run pairwise image registration with all algorithms and propagate segmentation labels of the template image to the number of 100 target images. We then examine the resulting segmentation accuracy by computing dice scores of the propagated segmentations and manually delineated labels. We report averaged dice scores of all images on four brain structures, including cortex, subcortical-gray-matter (SGM), white-matter (WM), and cerebrospinal fluid (CSF).\n\n\n\n \u00a7.\u00a7 Results\n\nFig.\u00a0<ref> visualizes examples of registration results on 2D synthetic images with the size of 192^2. The comparison is on deformed source images and transformation fields estimated by our NeurEPDiff, FLASH\u00a0<cit.>, and the original LDDMM with geodesic shooting\u00a0<cit.>. Note that even though our method is trained on a low image resolution of 64^2, the predicted results are fairly close to the estimates from registration algorithms of both FLASH and LDDMM on a higher resolution of 192^2.\n\n\nThe top panel of Fig.\u00a0<ref> displays an example of the comparison between the manually labeled segmentations and propagated segmentations on 3D brain MRI scans (at the resolution of 192^3) generated by our algorithm NeurEPDiff and the baseline models. The bottom panel of Fig.\u00a0<ref> reports the statistics of average dice scores over four brain structures from 100 registration pairs at different scales of image resolution. It shows that our method NeurEPDiff produces comparable dice scores. More importantly, the pre-trained NeurEPDiff at a lower resolution of 64^3 also achieves comparable results when tested on higher resolutions.   \n\n\nThe left panel of Tab.\u00a0<ref> compares the runtime of solving the EPDiff equation with all methods on a CPU machine. It indicates that our method gains orders of magnitude speed compared to other baselines, while maintaining a comparable registration accuracy evaluated through the averaged dice (shown on the the right panel of Tab.\u00a0<ref>). Overall, NeurEPDiff is approximately more than 10 times faster than FLASH and 100 times faster than LDDMM with geodesic shooting.\n\n\nFig.\u00a0<ref> demonstrates the convergence graphs of optimized total energy by our developed NeurEPDiff on different levels of resolution. It shows that our method consistently converges to a better solution than LDDMM at multiple different resolutions. However, it achieves a slightly worse but fairly close solution to FLASH\u00a0<cit.>. Please refer to Sec.\u00a0<ref> for more detailed discussions. \n\n\n\n\n\u00a7 DISCUSSION AND CONCLUSION\n\n\nWe presented a novel neural operator, NeurEPDiff, to predict the geodesics of diffeomorphisms in a low-dimensional bandlimited space. Our method is the first to learn a solution operator to the geodesic evolution equation (EPDiff) with significantly improved computational efficiency. More importantly, the prediction capability of a pre-trained NeurEPDiff can be generalized to various resolutions of image grids because of its special property of resolution-invariance. To achieve this, we developed a brand-new network architecture, inspired by recent works on neural operators\u00a0<cit.>, to approximate the nonlinear EPDiff equations as time-series functions carefully parameterized in the network hidden layers. A composition of network operators were defined in a complex-valued space to process the bandlimited signals of the velocity fields. \n\nWe validated NeurEPDiff on both simulated 2D and real 3D images. Experimental results show that our method achieves significantly faster speed at different scales of image resolution. Interestingly, we also find out that the NeurEPDiff-based registration algorithm converges to an optimal solution with slightly higher energy compared to FLASH\u00a0<cit.>. This may be due to a relaxed regularization on the smoothness of the velocity fields parameterized in the network, which often happens in learning-based approaches. A possible solution is to enforce a smooth convolutional kernel \u210b\u0303\u00a0<cit.> for each iterative evolution layer of our developed network architecture. This will be further investigated in our future work. Another potential future direction could be applying the network architectures developed in NeurEPDiff to learn another solution operator to predict transformations (Eq.\u00a0(<ref>)), which will further speed up optimization-based and learning-based diffeomorphic registration algorithms\u00a0<cit.>.\n\n\n\n  \n*Acknowledgement. This work was supported by NSF CAREER Grant 2239977.\n\nsplncs04\n\n\n\n"}