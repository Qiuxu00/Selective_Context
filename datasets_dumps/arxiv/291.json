{"entry_id": "http://arxiv.org/abs/2303.06937v1", "published": "20230313091154", "title": "Addressing Catastrophic Forgetting in Federated Class-Continual Learning", "authors": ["Jie Zhang", "Chen Chen", "Weiming Zhuang", "Lingjuan Lv"], "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAddressing Catastrophic Forgetting in Federated Class-Continual Learning\n    Jie Zhang^1   Chen Chen^2  Weiming Zhuang^2  Lingjuan Lv^2\n\n^1Zhejiang University     ^2Sony AI \n    March 30, 2023\n====================================================================================================\n\n\nempty\n\n\n\n\nThis paper focuses on an under-explored yet important problem: Federated Class-Continual Learning (FCCL), where new classes are dynamically added in federated learning. \nExisting FCCL works suffer from various limitations, such as requiring additional datasets or storing the private data from previous tasks. In response, we first demonstrate that non-IID data exacerbates catastrophic forgetting issue in FL. Then we propose a novel method called TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation), which alleviates catastrophic forgetting in FCCL while preserving client data privacy. Our proposed method leverages the previously trained global model to transfer knowledge of old tasks to the current task at the model level. Moreover, a generator is trained to produce synthetic data to simulate the global distribution of data on each client at the data level. Compared to previous FCCL methods, TARGET does not require any additional datasets or storing real data from previous tasks, which makes it \nideal for data-sensitive scenarios. \n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\nFederated Learning (FL) is a \nprivacy-aware \nlearning paradigm that facilitates \ncollaborations among multiple entities (e.g., edge devices or organizations) \u00a0<cit.>. Each entity or client in FL retains data locally and transfers only training updates to the central server for aggregation. \n\n\n\n\n\nConventional FL studies assume that the data classes and domains are static, but the new classes could emerge and data domains could change over time in reality \u00a0<cit.>. For example, multiple health institutions could use FL to collaborate and train models to identify COVID-19\u00a0<cit.> strains; new COVID-19 strains, however, continue to emerge due to high mutation rate of virus. An intuitive solution to this issue of continuously emerging data classes is training new models from scratch, but this is impractical as it would require significant extra computation cost. Another method is transfer learning from the previously trained model, but this method suffers from catastrophic forgetting\u00a0<cit.>, degrading performance on the previous classes.\n\n\n\n\n\nTo address these issues, recent research\u00a0<cit.> has introduced the concept of Continual Learning (CL)\u00a0<cit.> within the FL framework. These methods, collectively referred to as Federated Continual Learning (FCL), aim to mitigate the problems of catastrophic forgetting in FL. \n\n\nIn most FCL scenarios, new classes are dynamically added, which we call Federated Class-Continual Learning (FCCL). FCCL allows local clients to continuously collect new data, and new classes can be added at any time. \n\n\n\n\n\n\n\n\n\nUnfortunately, existing FCCL works \nsuffer from various limitations. \nFor example, Ma et al.\u00a0<cit.> utilize an unlabeled surrogate dataset to address the catastrophic forgetting problem, which may be difficult to obtain in some data sensitive scenarios. Furthermore, the usage of an unlabeled surrogate dataset may not be ideal for certain types of data, as it may not capture the full complexity of the original data.\nIn CL, exemplar-based methods\u00a0<cit.> have achieved leading performance. An exemplar refers to a sample or instance of a previously seen data point that is retained in a memory buffer for future use in the learning process.\nDong et al.\u00a0<cit.> propose a exemplar-based method that stores historical data to address catastrophic forgetting. However, in many privacy-sensitive scenarios (e.g., hospitals and medical research institutions), users are not permitted to store data from previous tasks due to privacy and policy concerns and data will not be kept for a long time\u00a0<cit.>. \nIn summary, the majority of FCCL methods train the global model with additional datasets or previous task data, which could potentially violate data privacy regulations. This dilemma prompts us to consider the following question:\n\nQuestion: How to effectively alleviate the catastrophic forgetting problem in the FCCL without storing the local private data of the client or any additional datasets?\n\nTo address this question, we conduct a systematic analysis and observe that the imbalanced distribution of data among clients in FL exacerbates the catastrophic forgetting problem (see Section\u00a0<ref>). \n\nIn order to fix this problem: 1) at the model level, we leverage the previously trained global model to transfer knowledge of the old tasks to the current task. 2) at the data level, we train a generator to produce synthetic data that aims to simulate the global distribution of data on each client. Drawing on these insights, we present a method called TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation) that mitigates catastrophic forgetting in FCCL without compromising clients' data privacy.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur contributions can be concluded as follows:\n\n    \n    \n  * We are the first to demonstrate that non-independent and identically distributed (non-IID) data exacerbates catastrophic forgetting issue in FL.\n    \n    Then we propose a novel method called TARGET, which alleviates the catastrophic forgetting in FCCL by leveraging global information.   \n    \n    \n  * Compared to previous FCCL methods, TARGET doesn't require extra datasets or data from previous tasks, it can be applied in data sensitive scenarios. \n    \n    \n  * \n    Extensive experiments demonstrate the efficacy of our proposed method. For example, when partitioning the CIFAR-100 dataset into five tasks, our method achieves an accuracy of 36.31%, which is about 6% higher than the best baseline method.\n    \n\n\n\n\n\n\u00a7 CATASTROPHIC FORGETTING IN FCCL\n\n\nThis section conducts an in-depth analysis of catastrophic forgetting problem in federated class-continual learning (FCCL). We start by providing a formal definition of the problem. \n\nThen, we investigate the forgetting issue in FCCL and discuss potential methods to mitigate it.\n\n\n\n\n \u00a7.\u00a7 Problem Definition\n\n\nFederated Class-Continual Learning (FCCL) focuses on the problem of learning models for new classes over time in FL.\nAn FCCL framework consists of a central server and multiple clients. All clients do not share their raw data with any other client or the central server.\n\n\nEach client learns from a sequence of n tasks, where k-th task contains non-overlapping subsets of classes C_k\u2208 C , where C is the set of all possible classes.\n\n\n\n\n\n\nIn our privacy-aware scenario, the task stream is presented in an unknown order, and each client can only access its local data from task k during that task's training period, which is no longer accessible thereafter.\nNote that the models are trained in a distributed manner, where each party has access to only a subset of the classes C_k (non-IID).\n\n\nWe also consider a more challenging and practical setting where the data in each client is heterogeneous. \nIn this paper, we assume the label distribution of data in each client is skewed\u00a0<cit.>. Please see detailed related work in Appendix.\n\n\n\n\n  \nForgetting Issue in FCCL\nThe goal of the global model optimization problem at task k is to minimize the overall classification error on the current set of classes C_k. \nHowever, when a new task arises, clients are not able to access data from previous (old) tasks due to privacy concerns and can only update their local model with data from the new task. \nThis often leads to a significant decrease in performance on previous tasks, which is known as catastrophic forgetting\u00a0<cit.>.\nTo mitigate catastrophic forgetting in the global model, we aim to\n\nminimize the overall classification error on the current set of classes C_k, while simultaneously minimizing the changes to the previously learned classes. Formally, the objective function can be written as:\n\n    min_\u03b8_k\u2211_c \u2208 C_k\u2211_i=1^m_c L(f_k(x_i,c; \u03b8_k), c) + \u03b1 R(\u03b8_k, \u03b8_k-1)\n\nwhere \u03b8_k is the model parameter at round k, L is a loss function that measures the classification error, R is a regularization term that penalizes changes to the previous model parameters, m_c is the number of data in class c, and \u03b1 is a hyper-parameter that controls the strength of the regularization. \nIn this formula, f_k(x_i,c; \u03b8_k) represents the classification model that takes as input a data point x_i,c associated with class c and outputs a probability distribution over the set of classes in C_k. \nThe regularization term R encourages the new model parameters to be close to the previous model parameters \u03b8_k-1, in order to prevent catastrophic forgetting of the previously learned classes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Heterogeneous Data Exacerbates Forgetting\n\nWe argue that the degree of data heterogeneity has a substantial impact on catastrophic forgetting. To verify this, we conduct an experiment on CIFAR-100 dataset\u00a0<cit.> with different degrees of data heterogeneity.\n\nInspired by Backward Transfer (BwT)\u00a0<cit.>, we derive the following formula to measure the severity of forgetting, a popular forgetting measure in CL\u00a0<cit.>:\n\n\n\n    \u2131_k=1/k-1\u2211_j=1^k-1 f_j^k,\n\nwhere \u2131_k denotes the average forgetting at k-th task and f_j^k quantifies forgetting for the j-th (j  k) task after the model has been continually trained up to task k. Specifically, for a given data distribution, f_j^k can be expressed as follows:\n\n    f_j^k=1/|\ud835\udc9e^j |\u2211_c\u2208\ud835\udc9e^jmax _t \u2208{1, \u2026 . N-1}(\ud835\udc9c_c^(n)-\ud835\udc9c_c^(N)),\n\nwhere \ud835\udc9e^j is a set of classes\n\nrelated to the j-th task, \ud835\udc9c_c^(n) is the accuracy on class c at round t, and \ud835\udc9c_c^(N) is the final accuracy on class c after learning all tasks. Note that f_j^k captures the average gap between the peak accuracy and the final accuracy for each class of the j-th task after learning the k-th task. \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe further extend the catastrophic forgetting measurement \u2131 in Equation\u00a0<ref> to FL under different data partitions and introduce a relative metric \u211b to measure forgetting as follows:\n\n\n    \u211b_k=\u2211_j=1^k-1 f_j^k/\u2211_j=1^k-1\ud835\udc9c_(j,k),\n\nwhere \ud835\udc9c_(j,k) is the accuracy on task j after learning task k. \nFor different data partitions, an increased \u211b_k indicates a more serious forgetting of previous tasks. \n\n\n\nFigure\u00a0<ref> illustrates the impact of catastrophic forgetting under independent and identically distributed (IID) and different levels of non-independent and identically distributed (non-IID) data partitions. \nIn particular, we employ the Dirichlet distribution, which is widely used in FL\u00a0<cit.>, to simulate the imbalanced label distribution among different clients.\n\nFigure\u00a0<ref> shows that the accuracy of the model degrades as training proceeds to new tasks in the IID setting. The performance is even worse in the non-IID settings. These results suggest that FCCL faces significant challenge on extreme non-IID settings. We further analyze the forgetting phenomenon in the Figure\u00a0<ref>. The higher degree of non-IID exacerbates the forgetting phenomenon in FCCL. These empirical studies motivate us to further investigate the catastrophic forgetting issue in \nFCCL. \n\n\n\n\n\n\n \u00a7.\u00a7 Alleviating Forgetting via Global Information\n\n\n\nTo tackle the issue of catastrophic forgetting in the FCCL, we argue utilizing global information to improve performance. The global information can derive from the global model. We explore this approach and empirically demonstrate that the integration of global information can effectively mitigate catastrophic forgetting.\n\n\n\n\n\n  \nLearn from the Global Model\nInspired by LwF\u00a0<cit.>, we leverage the knowledge from the previously trained global model to the current task via Knowledge Distillation (KD), using only the data from the current task. \nWe conduct experiments on CIFAR100 dataset with 5 continual tasks, where each task contains data of 20 classes. We evaluate the accuracy of the model on each previous task after training on all five tasks and report the final accuracy as the average of these results. Table\u00a0<ref> shows that FCCL without knowledge from the global model (i.e., FedAvg\u00a0<cit.>) suffers severely from catastrophic forgetting under both IID and non-IID data partitions. Although FedAvg achieves competitive performance on Task 5, it results in 0% accuracy on previously trained tasks (Task 1, 2, and 3). \nIn contrast, FedLwF \nachieves better accuracy on Tasks 1, 2, 3, and 4 and final accuracy.\nThe experiments demonstrate that the global model can indeed alleviate the forgetting issue.\n\n\n\n\n\n\n\n\n\n\n\n  \nLearn From Global Exemplar\nIn continual learning, an exemplar refers to a sample from a previous task that is stored in a memory buffer for future training. \nAssuming that data stored in clients are compliant to use for future training, we adopt the idea proposed in iCaRL\u00a0<cit.> to save a small proportion of prior training data in memory. The selection of this small proportion of data assumes that the data distribution pertaining the old task is known, but this assumption does not hold in FL because clients are unable to know the data distributions of others due to data privacy concerns. Nevertheless, we employ two exemplar selection methods to illustrate the utility of global data: global exemplar and local exemplar. Global exemplar assumes that the server aggregates a subset of data from clients and distribute these data to clients in training (Note that this method does not conform to FL and is only used for comparison). Local exemplar means that each client retains a subset of data from local data in the previous tasks for future training.\n\n\n\nAs shown in Figure\u00a0<ref>, we show the performance on the current and all previous tasks after learning the current task by using only the new task data, with local exemplar, and with global exemplar. It can be clearly observed that using exemplars can significantly improve the model performance, especially when using global exemplars, which can achieve much higher accuracy than using local exemplars. However, this raises a critical challenge of how to select such exemplars without violating the data privacy.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        \n\n\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        \n\n\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\u00a7 OUR METHOD: TARGET\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Overview\n\n\n\nTo \nutilize the global information without touching on the real exemplars from clients, we present a method called TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation), which utilizes global information without storing any real data. \nA detailed procedure is provided in Algorithm\u00a0<ref>.  Figure\u00a0<ref> presents an illustration of TARGET, wherein we synthesize data by inverting the global model \u03b8_k-1 (which was trained on task k-1), followed by combining the synthesized data with real data for local model update on task k.\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Server Side: Synthesizing Data for Old Tasks\n\nAs demonstrated in Figure\u00a0<ref>, data with global distributional information is more effective in mitigating the problem of catastrophic forgetting. Therefore, we propose a method of synthesizing data that can model the data distribution of the global model, without the need to preserve any client's privacy data. Specifically, given a global (teacher) model \u03b8_k-1 trained on task k-1, we first initialize a generator G and a student model \u03b8_S . We then repeatedly perform the following two training steps (see line 19\u223c28 in Algorithm\u00a0<ref>): 1) update the generator by continuously optimizing it to generate data that conforms to the global model distribution; 2) update the student model by distilling knowledge from the teacher model with the synthetic data, hoping that the student model can learn the knowledge of the teacher model sufficiently, which demonstrates the effectiveness of the synthesized data.\n\n\n\n  \nData Generation\n\n\n\n\n\n\n\n\n\n\n\nFirst, we utilize G to generate synthetic data from noise z, we need to ensure that the synthetic data x\u0302=G(z) is similar to the training dataset. If the synthetic data is similar to the training dataset, their predictions should also be similar. We minimize the cross-entropy (CE) loss on the output of global model \u03b8_k-1(x\u0302) and random labels \u0177,\n\n    \u2112_G^ce=CE(\u03b8_k-1(x\u0302), \u0177).\n\n\nIt is expected that the synthetic data generated by generator can be classified into a particular class with a high degree of confidence. However, utilizing only the CE loss will cause the generator overfitting to the synthetic data that are far away from the decision boundary (of the global model)\u00a0<cit.>, thus \nfailing to deliver a good performance. \nIn order to generate samples that are closer to the decision boundary (of the global model) with better transferability, following previous work\u00a0<cit.>, we introduce a boundary support loss. Additional weight is given to the data \non which the global model and the student model diverge in decision making.\n\n    \u2112_G^div=-\u03c9 KL(\u03b8_k-1(x\u0302),\u03b8_S(x\u0302)), and \n       \u03c9=1(\u03b8_k-1(x\u0302)\u2260\u03b8_S(x\u0302)),\n\n\nwhere KL denotes the Kullback-Leibler (KL) divergence loss, 1(a) output 1 if a is true and output 0 if a is false. By maximizing the KL divergence loss, the generator can generate more representative data.\n\nMotivated by\u00a0<cit.>, in order to further improve the stability of generator training, we introduce Batch Normalization (BN) loss to make synthetic data conform with the batch normalization statistics.\n\n    \u2112_G^bn=\u2211_l(||\u03bc_l(x\u0302)-\u03bc_l||+||\u03c3_l^2(x\u0302)-\u03c3_l^2||),\n\nwhere \u03bc_l(x\u0302) and \u03c3_l^2(x\u0302) are the batch-wise mean and variance estimate of the l-th BN layer of the generator, \u03bc_l and \u03c3_l^2 are the mean and variance of the l-th BN layer of f_S(\u00b7). \n\nCombining the above losses, we can obtain the loss of the generator as follows,\n\n    \u2112_G = \u2112_G^ce + \u03bb_1 \u2112_G^div + \u03bb_2 \u2112_G^bn,\n\nwhere \u03bb_1 and \u03bb_2 is the weight for different loss functions.\n\n\n\n  \nModel Distillation \nIn Equation\u00a0<ref>, we introduce a student model to assist in training the generator to produce data with greater diversity. A better student model should lead to a better generator. Therefore, after training the generator for several rounds, we subsequently train the student model using the saved synthesized data and the output of the teacher model, using KL loss for knowledge distillation:\n\n    \u2112_S=KL(\u03b8_k-1(x\u0302),\u03b8_S(x\u0302)).\n\nIn this way, we can train a student model with better performance, and then further use it to update the generator. An ideal synthetic dataset should be able to efficiently enable student \u03b8_S to fully learn the knowledge of teacher model.\n\nNote that when the training of the whole process is over (the student model can use the synthesized data to obtain high performance), we only retain the synthetic dataset X_syn and transfer it to the clients, without saving the generator and student model.\n\n\n\n\n\n \u00a7.\u00a7 Client Side: Update with Global Information\n\nOn the client side, we can obtain the data synthesized for the previous task X_syn and the real training data of the current task X_local, then we train the local model \u03b8_k for task k on the two datasets at the same time. We showed in Section\u00a0<ref> that the use of global models and global data can alleviate forgetting. Thus we distill the knowledge of global teacher model and global synthetic data by minimizing the following objective function,\n\n    \u2112_client = CE(\u03b8_k(x), y)_for current task + \u03b1\u00b7KL(\u03b8_k-1(x\u0302), \u03b8_k(x\u0302))_for previous tasks,\n\nwhere (x,y)\u2208X_local and (x\u0302)\u2208X_syn. \n\n\n\n\n\n\n\n\n\n\nThe utilization of the distillation loss facilitates efficient transfer of knowledge from the previous task to the current task model. And \u03b1 is a hyper-parameter that controls the strength of the regularization for the previous tasks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 EXPERIMENTS\n\n\n\n \u00a7.\u00a7 Experimental Settings\n\n\n\nWe experiment on two datasets, namely\nCIFAR-100\u00a0<cit.>, and Tiny-ImageNet\u00a0<cit.>\n, to evaluate the performance of our proposed approach. \nTo establish the order of the continual tasks, we adopt the widely used protocols\u00a0<cit.>. Specifically, we divide all classes of each dataset equally into \nmultiple tasks by default, we evenly divide the classes into 5 and 10 tasks to simulate class continual \nlearning scenarios. \nWe employ ResNet18\u00a0<cit.> as the backbone for the classification model. \n\n\n\n\nTo evaluate our approach, we employ the standard continual learning metrics, as used in prior works\u00a0<cit.>, which include average accuracy across all tasks and a forgetting measure\u00a0<cit.> (see Equation\u00a0<ref>). For a fair comparison with the baseline class continual learning\nmethods in the FCCL setting, we implement three types of baselines: 1) Finetune, \nin which each client\nsimply learns tasks in sequence;\n2) FedWeIT\u00a0<cit.>, a regularization-based method in Federated Continual Learning that maximizes the knowledge transfer between\nclients; 3) Examples of typical continual learning methods that do not store training data for rehearsal, including EWC\u00a0<cit.> and LwF\u00a0<cit.>. In addition, we compare our method with methods that store real training data of old tasks, such as iCaRL\u00a0<cit.>. We implement these traditional continual learning algorithms in the FCCL scenario and name them as FedEWC, FedLwF, and FedIcaRL. For detailed information on the task configuration, default hyper-parameters and additional experimental results, please refer to the Appendix. \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Experiments on CIFAR-100\n\n\nFor CIFAR-100 dataset, we conduct experiments on two sets of tasks consisting of 5 and 10 tasks, respectively. \nWe run the experiment on both IID and non-IID scenarios.\nFor non-IID setting, the Dirichlet parameter is set to 0.5 and 1, NIID(0.5) and NIID(1).\n\nTable\u00a0<ref> \nshows the final average accuracy of the FL model trained on all tasks, along with the corresponding forgetting measure for each experiment. It is important to emphasize that an optimal method is characterized by \nhigh average accuracy and low forgetting measure. \n\n\n\nTable\u00a0<ref> indicates that Finetune exhibits the poorest performance when attempting to learn the continuously incoming tasks sequentially, thereby experiencing the issue of catastrophic forgetting. Moreover, we observed that methods based on regularization constraints, such as FedEWC and FedWeIT, were often ineffective in preventing the model from forgetting old tasks due to the lack of available data. On the other hand, we found that distillation-based approaches such as FedLwF and our proposed method were capable of improving the final average accuracy while simultaneously mitigating the issue of catastrophic forgetting. This is due to the transfer of model knowledge learned from the old task to the new task in a distillation manner, enabling the model to prevent catastrophic forgetting. Obviously, we found that applying our proposed method to generate synthetic datasets for the federated models trained on old tasks and subsequently performing model distillation on these synthetic datasets can lead to a substantial improvement in the average accuracy and reduction in the forgetting measure. This observation underscores the ability of our synthetic data to capture the distribution characteristics of historical task data accurately.\nFor example, in IID setting, when partitioning the CIFAR-100 dataset into five tasks, our method achieves an accuracy of 36.31%, which is about 6% higher than the best baseline method FedLwF. It is worth noting that we observed a decrease in the average accuracy of all methods to varying degrees as the number of tasks increased from 5 tasks to 10 tasks due to increased task complexity and the associated forgetting phenomenon. Nonetheless, our proposed method maintains the highest average accuracy and the lowest forgetting measure even under these more demanding conditions.\n\n\n\nFigure\u00a0<ref> illustrates the performance of the models trained by various methods on all previously learned tasks after the completion of each task. Specifically, it shows the average accuracy of the model on both the current and previous tasks after the completion of each task (e.g., after learning the second task, the average accuracy of the model on both the first and second tasks is measured). Based on these curves, it is evident that our proposed model outperforms other competing baseline methods in all incremental tasks, regardless of the number of tasks involved. This finding underscores the effectiveness of our approach in facilitating multiple local clients to learn new classes in a streaming manner while mitigating the forgetting problem. \n\n\n\n\n \u00a7.\u00a7 Experiments on Tiny-ImageNet\n\nWe also evaluated the performance of our proposed method on the more challenging Tiny-ImageNet dataset and obtained similar results to those observed in the CIFAR-100 experiments. Specifically, in Figure\u00a0<ref>, we present the final average accuracy and forgetting measure for all learned tasks in both IID and non-IID settings for the case of 5 tasks. The Dirichlet parameter  is set to {0.05, 0.1, 0.5, 1}. Based on Figure\u00a0<ref>, it is evident that our proposed method consistently outperforms FedLwF in terms of average accuracy across all data partitions. Moreover, our method demonstrates a significantly lower forgetting measure than FedLwF under both IID and non-IID settings. Our proposed method achieves an average accuracy that is approximately 3% higher than that of FedLwF even in the most challenging scenario (NIID(0.05)). \nThis result highlights the effectiveness of our method in mitigating catastrophic forgetting in the presence of extreme data distributions.\n\n\n\n\n\n \u00a7.\u00a7 Comparison with Exemplar-based Method\n\nIn CL, the most successful approaches to alleviate forgetting require extensive replay of previously seen data, which can be problematic when data legality and privacy concerns exist. \n\nAmong them, iCaRL\u00a0<cit.> is a classic but unrealistic algorithm that relies on the stored exemplars in addition to the network parameters, and it is intuitive that using  old task's real data could be beneficial to alleviate forgetting problem. \nTo further understand the performance gap, we compare our proposed TARGET (which uses synthetic data) with iCaRL (which \nrequires storing exemplars from old task's real data), \n\nand study the effects of different exemplar memories on the performance of our method and iCaRL in Figure\u00a0<ref>. We set the stored exemplar size to {1000, 1500, 2000} for iCaRL, and {2000, 3000} for our method on the CIFAR-100 dataset. \n\nThe accuracy curve in Figure\u00a0<ref> represents the average accuracy rate measured over all 100 classes learned by the model during the last learning task. While our method can achieve similar performance to storing 1k real training data by storing 2k synthetic data, it still cannot outperform storing 2k real training data. \nHowever, it is worth noting that our method does not require storing any real training data, which can be a significant advantage in scenarios where storing real data is difficult or not allowed due to privacy or legal concerns. Additionally, our method achieves better performance than storing only 1k real training data, which indicates that our synthetic data is effective in mitigating catastrophic forgetting. We observed that when our method stores 3k synthetic data, it achieves better accuracy than when it stores 2k synthetic data. However, surpassing iCaRL in performance with an equal amount of data remains a challenge for our method. \nHow to effectively use fewer synthetic data \nwith more valuable knowledge from previous tasks will be left as a future research direction.\n\n\n\n \u00a7.\u00a7 Analysis of Our Method\n\n\n\n\n\n  \nTrade-off between Backward and Forward Transfer.\nContinual learning presents a challenge in balancing the trade-off between maintaining high accuracy on old tasks (backwards transfer) and achieving high accuracy on new tasks (forward transfer). In Table\u00a0<ref>, we evenly split the CIFAR-100 dataset into two tasks and test the average accuracy of our proposed method under different values of \u03b1. We observe that the trade-off between backward and forward transfer is not always balanced. In order to achieve good backward transfer, a large value of \u03b1 should be used to prevent the model from forgetting previous tasks and to encourage it to focus more on the old synthetic data. Conversely, to achieve good forward transfer, a small value of \u03b1 should be used, allowing the model to learn quickly and effectively from new tasks while still maintaining some knowledge from the old tasks. The experimental results in Table\u00a0<ref> indicates that when the value of \u03b1 is between 10-15, the model achieves a good balance between accuracy on new tasks and accuracy on old tasks. We alspo partition the CIFAR-100 dataset into 5 equal tasks and test our method's performance on all previous tasks after learning each new task (refer to Appendix). \n\n\n\n\n\n\n\n  \nMemory of Synthetic Data.\nThe optimal amount of synthetic data generated for the old task plays a crucial role in determining the final performance of our method. Insufficient synthetic data may not adequately facilitate knowledge transfer from the old tasks, while excessive data generation can lead to increased memory and communication costs. Therefore, determining an appropriate amount of synthetic data that strikes a balance between knowledge transfer and computational cost is critical for the effectiveness and efficiency of our approach. As shown in Figure\u00a0<ref>, we test our method on CIFAR-100, which is divided into 5 tasks with different data \nsizes ranging from 2k to 16k. \nIt can be observed that when the data volume is relatively small, such as 2k and 4k, the performance of the model is poor, especially when the data volume is 2k, the testing curve in task 4 shows a later decline. This is because when the data volume is too small, the model is unable to effectively learn knowledge from old tasks. Increasing the data volume to 8k can effectively alleviate the forgetting phenomenon and achieve good performance. However, continuously increasing the data volume to 12k and 16k do not result in significant improvement in the model's performance.\n\nIt is important to note that the size of the data volume alone does not guarantee the effectiveness of synthetic data in improving machine learning models. The quality and relevance of the synthetic data must also be carefully considered to ensure that it accurately represents the underlying distribution of the real-world data. \n\n\n\n\n  \nVisualization on Synthetic Data.\nTo demonstrate the effectiveness of the synthetic data, we present in Figure\u00a0<ref> the visualization results of the synthesized images generated by our method after the model learns the penultimate task on Tiny-ImageNet (CIFAR-100 in Appendix) for 5 tasks. These data have the potential to efficiently enable the student model to approach the performance of the teacher model rapidly. However, it is worth noting that these data exhibit visual dissimilarities from the actual training data.\n\n\n\n\n  \nAnalysis on Distillation. \nBased on the synthetic data, we distill the knowledge of the model trained on old tasks into a student model. The effect of distillation is further demonstrated in Figure\u00a0<ref>. It can be observed that even without accessing any \nprivate training data from clients, our method can quickly distill the student model on the server to approach the performance of the global model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\nIn conclusion, this paper introduces a novel method, TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation), to alleviate the catastrophic forgetting problem in Federated Class-Continual Learning (FCCL). \n\n\n\nUnlike all the previous methods, our proposed method leverages global knowledge, without \nrequiring any additional datasets or data from previous tasks, making it ideal for privacy-sensitive scenarios. Extensive experimental results \ndemonstrate the effectiveness of our proposed method in comparison to existing FCCL methods.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nieee_fullname\n\n\n\n"}