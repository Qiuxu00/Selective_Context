{"entry_id": "http://arxiv.org/abs/2303.07001v1", "published": "20230313105938", "title": "Neural Group Recommendation Based on a Probabilistic Semantic Aggregation", "authors": ["Jorge Due\u00f1as-Ler\u00edn", "Ra\u00fal Lara-Cabrera", "Fernando Ortega", "Jes\u00fas Bobadilla"], "primary_category": "cs.IR", "categories": ["cs.IR"], "text": "\n\n\n\n1,3]Jorge Due\u00f1as-Ler\u00edn\n2,3]Ra\u00fal Lara-Cabrera\n2,3]Fernando Ortega\n2,3]Jes\u00fas Bobadilla\n\n[1]Universidad Politecnica de Madrid, Madrid, Spain\n[2]Departamento de Sistemas Informaticos, Universidad Politecnica de Madrid, Madrid, Spain\n[3]KNODIS Research Group, Universidad Politecnica de Madrid, Madrid, Spain\n\n\n\nNeural Group Recommendation Based on a Probabilistic Semantic Aggregation\n    [\n    \n=========================================================================\n\n\n\n\nRecommendation to groups of users is a challenging subfield of recommendation systems. Its key concept is how and where to make the aggregation of each set of user information into an individual entity, such as a ranked recommendation list, a virtual user, or a multi-hot input vector encoding. This paper proposes an innovative strategy where aggregation is made in the multi-hot vector that feeds the neural network model. The aggregation provides a probabilistic semantic, and the resulting input vectors feed a model that is able to conveniently generalize the group recommendation from the individual predictions. Furthermore, using the proposed architecture, group recommendations can be obtained by simply feedforwarding the pre-trained model with individual ratings; that is, without the need to obtain datasets containing group of user information, and without the need of running two separate trainings (individual and group). This approach also avoids maintaining two different models to support both individual and group learning. Experiments have tested the proposed architecture using three representative collaborative filtering datasets and a series of baselines; results show suitable accuracy improvements compared to the state-of-the-art.\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nPersonalization is one of the fields of AI that has a greater impact on the lives of individuals. We can find a multitude of services that provide us with a personalized choice of news, videos, songs, restaurants, clothes, travels, etc. The most relevant tech companies make extensive use of personalization services: Amazon, Netflix, Spotify, TripAdvisor, Google, TikTok, etc. These companies generate their personalized recommendations using RS\u00a0<cit.> applications. RS provide to their users personalized products or services (items) by filtering the most relevant information regarding the logs of items consumed by the users, the time and place that took place, as well as the existing information about users, their social networks, and the content of items (texts, pictures, videos, etc.). We can classify RS attending to their filtering strategy as demographic\u00a0<cit.>, content-based\u00a0<cit.>, context-aware\u00a0<cit.>, social\u00a0<cit.>, CF\u00a0<cit.> and filtering ensembles\u00a0<cit.>. Currently, the MF\u00a0<cit.> machine learning model is used to obtain accurate and fast recommendations between input data (votes). MF translates the very sparse and huge matrix of discrete votes (from users to items) into two dense and relatively small matrices of real values. One of the matrices contains the set of short and dense vectors representing users, whereas the second matrix vectors represent items. Each vector element (real value) is called the `hidden factor value\u2019, since it represents some complex and unknown relationship between the input data (votes).\n\nWhereas MF machine learning models are fast and accurate, they also present a remarkable drawback: they cannot detect, in their hidden factors, the complex non-linear relationships between the input data. NN can solve this problem through their non-linear activation functions. NN based RS\u00a0<cit.> make a compression of information by coding the patterns of the rating matrix in their embeddings and hidden layers\u00a0<cit.>. These embeddings play the role of the MF hidden factors, enriching the result by incorporating non-linear relations. The most well-known NN base RS approaches are GMF and MLP\u00a0<cit.>.\n\nGR\u00a0<cit.> is a subfield of the RS area where recommendations are made to sets of users instead of to individual users (e.g.: to recommend a movie to a group of three friends). As in the regular RS, the goal is to make accurate recommendations to the group. In this case, several policies can be followed; the most popular are: a) to minimize the mean accuracy error: to recommend the items that, on average, most like to all the group members, and b) to minimize the maximum accuracy error: to recommend the items that does not excessively dislike to any of the group members. It is important to state that there are not open datasets containing group information to be used by group recommendation models; for this reason, generally randomly generated groups are used for training and testing research models. \n\nRegardless of the machine learning approach used to implement GR RS, the most notable design concept is to establish where to locate the aggregation stage to convert individual information to group information. The general rule is: the sooner the aggregation stage, the better the performance of GR\u00a0<cit.>. There are three different locations where group information can be aggregated into a unified group entity: a) before the model, b) in the model, and c) after the model. The most intuitive approach is to combine individual recommendations into a unified group recommendation (option c)\u00a0<cit.>. This approach is known as IPA and requires processing several individual recommendations followed by rank aggregation. However, the process is slow and not particularly accurate. On the other hand, to consider the entire group for the recommendation, we should work before or inside the model (options a or b). These approaches are known as GPA. Aggregating group information before the model requires working with the user-item interaction matrix in a higher-dimensional space, which can lead to misinformation problems. To aggregate group information in the model, we need to work with the user`s hidden vector in the low-dimensional space.\n\nAggregating several hidden vectors from individual users into a unified virtual user hidden vector\u00a0<cit.> avoids compute the model predictions several times and makes the rank aggregation stage unnecessary. In addition, it takes advantage of operating with condensed information coming from the MF compression of information: the virtual user can be obtained simply by averaging the representative short and dense vectors of the users group; this is efficient and accurate. An interesting question is: Can NN operate the same way that MF does to obtain virtual users and generate recommendations? First, note that many NN based RS models compress the user embedding in a different latent space than the item embedding, and it can be a problem; then, the NN non-linear ensemble representations are more complex than the MF hidden factor representations; consequently, simply averaging the ensembles of the users in the group does not automatically ensure a representative virtual user embedding. Furthermore, model-based aggregations (option \u2018b\u2019 in the previous paragraph) are model dependent, and then it is necessary to design and test different solutions for different NN based RS models. Whereas the NN latent spaces are the state-of-the-art to catch users and items relations, some other machine learning approaches have been designed, such as the use of the random walk with restart method\u00a0<cit.> providing a framework to relate users, items, and groups, and to exploit the item content and the profiles of the users. A three-stage method\u00a0<cit.> is proposed to increase the precision and fairness of GR, where binary MF, graphs and the dynamic consensus model are processed sequentially. Some relevant and current GR research aims to make use of the concept of member preference (influence or expertise) concept, based on similarity and trust. The key idea is to detect the group leaders as group members that are trusted more than others and have more influence than others. In\u00a0<cit.>, fuzzy clustering and an implicit trust metric are combined to find neighborhoods. GR based on an average strategy applied to user preference differences\u00a0<cit.> has been combined with trusted social networks to correct recommendations. An aggregation approach for GR mimics crowd-sourcing concepts to estimate the level of expertise of group members\u00a0<cit.>; it is implemented using parameters of sensitivity and specificity. The impact of social factors on a GR computational model is evaluated in\u00a0<cit.>, using the expertise factor, the influences of personality, preference similarities, and interpersonal relationships.\n\nIn this paper, we present how we can generate GR using NN based RS by training the model using raw CF data (i.e., the ratings of individual users to the items without any additional information). The GR have been tested using the two most popular implementations of NN based RS: GMF and MLP. As stated previously, to make recommendations to groups using NN based RS, information of the individual users must be aggregated. The chosen information aggregation design is to merge the users of the group in the input vector that feeds the user embedding of the NN. This aggregation design is not novel, since it has been used by <cit.> applied to a MLP architecture. However, our approach combines several innovative aspects in comparison to the state of the art. On the one hand, the aggregation of the users in the group is a probabilistic function rather than a simple multi-hot encoding\u00a0<cit.>; this better captures the relative importance of users in the input vector that feeds the NN, moreover: this aggregation approach serves as front-end for any NN GR model. On the other hand, we propose the use of a simple RS NN model (GMF) instead of the deepest MLP one\u00a0<cit.>; the hypothesis is that complex models overfit GR scenarios, since they are designed to accurately predict individual predictions, whereas GR must satisfy an average of the tastes in the group of users, that is, GR should be designed to generalize the set of individual tastes in the group. Furthermore, the proposed architecture just needs a single training to provide both individual recommendations and group recommendations; particularly, the model is trained by only using individual recommendations (as in regular RS). Once the model is trained to return individual predictions, we can fill the input vector by aggregating all the users in the group, then feed-forward the trained model and finally obtain the recommendation for the group of users. Anyway, the impact of these innovative aspects can be evaluated in <ref>, where we empirically compare the proposed aggregation designs with respect to the main baseline\u00a0<cit.>\n \nIn summary, the GR state-of-art presents the following drawbacks: a) Some research relies on additional data to the CF ratings, such as trust or reputation information that is not available on the majority of datasets, b) different proposals make the aggregation of individual users before (IPA) or after (Ranking) the model, making it impossible to benefit from the machine learning model inner representations (GPA), and c) The proposed GR neural model solutions tend to apply architectures designed to make individual recommendations, rather than group ones; this leads to the model overfitting and to a low scalability referred to the number of users in a group. To fill the gap, our proposed model: a) Acts exclusively on CF ratings, b) Makes user aggregation in the model, and c) Its model depth and design enables adequate learning generalizations. Additionally, the provided experiments test the proposed model according to different aggregation strategies to set the group labels used in the learning stage. In contrast, a notable limitation of our architecture and the experiments is the lack of testing on particularly demanding scenarios such as cold start in groups users, extremely sparse data sets, impact of popular item bias, and fear GR.\n\nThe rest of the paper is structured as follows: <Ref> introduces the tested models and aggregation functions; <Ref> describes the experiment design, the selected quality measures, the chosen datasets and shows the results obtained; <Ref> provides their explanations; and <Ref> highlights the main conclusions of the article and the suggested future work.\n\n\n\n\u00a7 PROPOSED MODEL\n\n\nIn CF interactions (purchase, viewing, rating, etc.) between users and items are stored in a sparse matrix since it is common for users to interact only with a small proportion of the available items and, in the same way, only a small percentage of existing users interact with the items. The sparsity levels of this matrix is around 95-98% as shown in <ref>. To handle this sparsity, current CF models based on NN\u00a0<cit.> work with a projection of users and items into a low-dimensional latent space using Embedding layers. Embedding layers are a very popular type of layer used in NN that receive as input any entity and return a vector with a low-dimensional representantion of the entity in a latent space. These vectors are commonly named latent factors. In order to transform the entity into its low-dimensional representation, the embedding layer first transforms the entity into a one hot encoding representation (typically using a hash function). <Ref> sumarizes this process.\n\nIn the context of CF, two Embedding layers are required: one for the users and the other for the items. Later, both Embedding layers are combined using a NN architecture (see\u00a0<Ref>). For example, the aphormented models GMF and MLP uses a Dot layer and a Concatenate layer followed by some fully connected dense layers as architectures, respectively. \n\n\n\nFormally, we define a NN model \u03a6 that predicts the rating that a user u will give to an item i (r\u0302_u,i) combining the latent factors provided by the Embedding layer (Emb_L) of the user u (l\u20d7_\u20d7u\u20d7) and the the item i (l\u20d7_\u20d7i\u20d7):\n\n\n    Emb_L(u) = l\u20d7_\u20d7u\u20d7\n    \n        Emb_L(i) = l\u20d7_\u20d7i\u20d7,\n    \u03a6 (l\u20d7_u, l\u20d7_i) = r\u0302_u,i\n\n\nAs stated in\u00a0<ref>, when working with GR, a straightforward strategy is IPA\u00a0<cit.>. This strategy makes a prediction for each member of the group and then performs an aggregation. This strategy does not treat the group as a whole. If we have a group of users G = {u_1, u_2, ..., u_n}, the prediction of the rating of this group G to an item i (r\u0302_G,i) is computed as the average value of the individual predictions:\n\n\n    r\u0302_G,i = 1G\u2211 _u \u2208 Gr\u0302_u,i = 1G\u2211 _u \u2208 G\u03a6(l\u20d7_\u20d7u\u20d7, l\u20d7_\u20d7i\u20d7)\n\n\n\nOn the other hand, the GPA strategies take into account the group as a whole. It should be noted that the order of users within the group and the length of it should not affect the aggregation; thus, the aggregations should meet the constraints of: permutation invariant and fixed result length\u00a0<cit.>. Our goal with the GPA strategy is to be able to obtain a prediction r\u0302_G,i with a single forward propagation and to treat the group as a whole entity. We can achieve this by aggregating the latent factors of each user that belongs to the group to obtain the latent factor of the group l\u20d7_G. Once the latent factors of the group are aggregated, the model \u03a6 can be used to compute the predictions:\n\n\n    Emb_L(G) = l\u20d7_G\n    r\u0302_Gi = \u03a6(l\u20d7_G, l\u20d7_i)\n\n\nThe aggregation of group latent factors in embedding layers can be achieved by modifying the input of the NN. As mentioned previously, Embedding layers have as input a one hot representation of the entities. This approach is adequate when performing individual predictions, however, for group recommendations, we need to apply a multi-hot representation to the users Embedding layer, i.e., we encode the group by setting multiple inputs of the user Embedding layer (the inputs related with the users that belong to the group) to a value higher than 0. This encoding allows us to take into account all group users at the same time for the extraction of latent factors of the group l\u20d7_G.\n\nThe simplest aggregation, which is used by the DeepGroup model\u00a0<cit.>, is to use as input for embedding a constant value proportional to the size of the group. We define the input of the user's Embedding layer for the user u as\n\n\n    EmbeddingInput_Average(u) = 1/G    if u \u2208 G\n    \n            0     if  u \u2209 G\n\n\nWe call this aggregation `Average' since the embedding layer will generate the group latent factor equal to the average of the latent factors of all users in the group.\n\nRS can give better predictions the more information they have about users, so to take advantage of this fact, we have tested the `Expertise' aggregation in which we give a weight to the users proportional to the number of votes they have entered into the system. Let R_u the number of ratings of the user u, the input of the users' Embedding layer for the user u is defined as\n\n\n    EmbeddingInput_Expertise(u) = R_u/\u2211 _g \u2208 GR_g    if u \u2208 G\n    \n            0     if  u \u2209 G\n\n\nIn addition to the `Expertise' aggregation, we also proposed the `Softmax aggregation as a smooth version of the `Expertise' aggregation. In this case, the input of the users' Embedding layer for the user u is defined as\n\n\n    EmbeddingInput_Softmax(u) = e^R_u/\u2211 _g \u2208 G e^R_g    if u \u2208 G\n    \n            0     if  u \u2209 G\n\n\nIn <Ref> we can see where the equations fit in the group recommendation process. The first step is to generate the multi-hot vector with some of the described aggregation (<ref>). This vector (multi-hot representation of the group) is fed into the embedding layer to obtain a vector of the latent factors of the groups l\u20d7_G (<ref>). Once the latent factors of the group and the item are obtained, they are used to feed the model \u03a6 (GMF or MLP) and produce the rating prediction for the group G on the item i (<ref>).\n\n\n\nIn <Ref> we can find an example with some users (13, 24, 30 and 42) with different rating counts (<Ref>), their input values to the users' Embedding layer in a multi-hot fashion (<Ref>), their individual latent factors (<Ref>), and the final group latent factors with different aggregations (<Ref>).\n\n\n\n\n\n\n\n\n\u00a7 EXPERIMENTAL EVALUATION\n\n\nIn this section, we show the experiments carried out to validate the aggregation proposed in this manuscript. As previously stated, the experiments have been performed using the most popular NN based RS architectures: GMF and MLP. We have chosen these two architectures because they are the best known and offer the best results for individual predictions. However, the aggregation strategies proposed can be applied to any NN architecture based on Embedding layers.\n\nThe choice of datasets has been made considering that: a) there are no open datasets containing information on group voting; and b) GMF and MLP models should be trained using individual voting, since the proposed aggregations allow computing predictions for groups on already trained models. For these reasons, we have chosen the following gold standard datasets in the field of RS: \u00a0<cit.>, the most popular dataset in the research of RS; \u00a0<cit.>, a dataset smaller than  to measure the performance of the aggregation in datasets with a lower number of users, items, and ratings; and , a dataset with a range of votes higher than the . Other popular datasets such as  or  have not been selected due to the high computational time required to train and test the models. The main parameters of the selected datasets can be found in <Ref>. \n\n\n\nThe generation of synthetic groups has been carried out in such a way that all groups have voted at least 5 items in test. In this way, it is possible to evaluate both the quality of the predictions and the quality of the recommendations to the groups as detailed below. Groups of different sizes (from 2 to 10 users) have been generated. For each group size, 10000 synthetic groups have been generated. The generation of a group has been carried out following the following algorithm:\n\n\n    \n  * Define the size of the group S.\n    \n  * Random select 5 items rated in test by at least S users.\n    \n  * Find all users who have rated the 5 items selected in 2.\n    \n  * If we found fewer than S users, go back to 2. Otherwise, random select S users and create a group.\n\n\nTo measure the quality of the predictions for the group, we have calculated the mean absolute error \n\n\n    MAE = 1/#groups\u2211_G1/G\u00b7I_G\u2211_u \u2208 G\u2211_i \u2208 I_G|r\u0302_G,i - r_u,i|,\n\n\nthe mean squared error \n\n\n    MSE = 1/#groups\u2211_G1/G1/G\u00b7I_G\u2211_u \u2208 G\u2211_i \u2208 I_G( r\u0302_G,i - r_u,i)^2,\n\n\nand mean maximum group error\n\n\n    MAX = 1/#groups\u2211_Gmax_u \u2208 Gmax_i \u2208 I_G|r\u0302_G,i - r_u,i|,\n\n\nwhere I_G denotes the items rated by the group G\n\nTo measure the quality of the recommendations for the group, we have calculated the NDCG score\n\n\n    NDCG@N = 1/#groups\u2211_GDCG_G@N/IDCG_G@N,\n\n\n\n    DCG_G@N = \u2211_i \u2208 X_G^Nr\u0305_G,i/log_2(pos_G(i)+1),\n\n\n\n    IDCG_G@N = \u2211_i \u2208 T_G^Nr\u0305_G,i/log_2(ipos_G(i)+1),\n\n\nwhere N is the number of items recommended to the group (in our experiments N=5 according to the generation of synthetic groups), X_G^N is the set of N items recommended to the group G, pos_G(i) is the position of the item i in the group's G recommendation list, T_G^N is the set of the top N items for the group G, ipos_G(i) is the ideal rank of the item i for the group G, and r\u0305_G,i is the average rating of the users belonging to the group G for the item i.\n\nWe can see the results of the experiment executed with these scores in <ref> (MAE), <ref> (MSE), <ref> (Max), and <ref> (NDCG). The cells with the best results have been highlighted, while the standard deviation of each metric is in parentheses. All results are analyzed in\u00a0<ref>.\n\nAll experiments have been run using an NVIDIA Quadro RTX 8000 GPU with 48 GB GDDR6 of memory, 4,608 NVIDIA Tensor Cores and a performance of 16.3 TFLOPS. We are committed to reproducible science, so the source code of all experiments with the values of the parameters used and their random seeds have been shared on GitHub[<https://github.com/KNODIS-Research-Group/neural-cf-for-groups>]. \n\n    \n    \n\n    \n    \n\n    \n    \n\n    \n\n\n\n\n\n\n\n\n\n\u00a7 DISCUSSION\n\n\n\n\nThe main goal of this research is to evaluate different aggregation techniques to make recommendations to groups. As shown in\u00a0<Ref>, we can see different trends according to: a) the models used; b) the way group information is aggregated; c) the datasets on which they act; and d) the size of the groups.\n\n\nFocusing on the models, we can see how MLP, which has several hidden layers, obtains a lower MAE; however, GMF, a simpler model, obtains a lower MSE. Although the MLP model has great power in these types of problem, it seems to overfit, generating very good recommendations for some users in the group but bad ones for the rest, hence achieving higher MSE values. On the other hand, the GMF model can obtain smaller maximum errors in each group, which means that no user in the group is badly affected by the recommendation. In the results, we can also observe how the models with higher maximum errors lead to a poorer order of items according to user preferences and obtain worse performance in the NDCG metric.\n\n\n\nLooking at the aggregation of users, we can see that the best performing user aggregation is the average, followed by a very similar performance by the Softmax. However, the use of expert user weighting without softmax produces worse results. Based on the results, we can observe that in models that do not use a deep architecture, with several hidden layers, the IPA and GPA strategies produce similar results when the aggregation function is a linear transformation of latent factors (GMF). However, we can see how the non-linearity of MLP produces different results between both two strategies.\n\n\n\nRegarding the different datasets, we can see that there is a clear trend in the models that achieve the best results in complex datasets with a large number of users, items, and votes, such as Movilens or MyAnimeList, while in the FilmTrust dataset, with a smaller number of votes, there is no clear trend.\n\n\nIn terms of group size, as more users have the group, the probability of finding discrepancies between user preferences increases. Therefore, we can see how a larger group size leads to higher values in all error metrics.\n\n\n\n\n\u00a7 CONCLUSIONS AND FUTURE WORK\n\n\n\n\nWith the irruption of NN in the world of CF, the possibilities of their ability to find non-linear patterns within user preferences to generate better predictions are opening up. To use these systems to generate a recommendation for a group of users, we need to aggregate their preferences. As we have seen in this research, there are several key points at which aggregation can be performed. GPA strategies do the aggregation before or inside the model, so they have the advantage of taking into account the preferences of the entire group and that a single feedforward step generates the prediction. Unlike the IPA strategy, which requires multiple predictions for each user and performs the aggregations after the model. In this study, we have tested how different approaches to perform GPA work in different datasets comparing different metrics.\n\nAs future work, there are two key factors to consider. First, in this research, the researchers have designed user aggregation techniques presented to the models; in future work, these functions will be explored by different machine learning models. The second key point is that in this work models perform a knowledge transfer from the model trained for individuals to make group predictions; it is shown that although the models have high performance (MAE improvement), they tend to overfit when working in groups (larger errors in group prediction leading to worse MSE). To solve this problem, future work will try to perform a specialization training stage for groups after individual training.\n\n\n\n\u00a7 DECLARATIONS\n\n\nThe authors of this paper declare that they have no conflict of interest.\n\n\nThis work has been co-funded by the Ministerio de Ciencia e Innovaci\u00f3n of Spain and the European Regional Development Fund (FEDER) under grants PID2019-106493RB-I00 (DL-CEMG) and the Comunidad de Madrid under Convenio Plurianual with the Universidad Polit\u00e9cnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario.\n\n\n\n\u00a7 DATA AVAILABILITY STATEMENT\n\n\nThe ,  and  dataset along with the source code of the experiments that support the findings of this study are available in  GitHub's repository [<https://github.com/KNODIS-Research-Group/neural-cf-for-groups>].\n\nplain\n\n\n"}