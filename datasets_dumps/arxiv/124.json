{"entry_id": "http://arxiv.org/abs/2303.07185v1", "published": "20230313152817", "title": "Joint Behavior and Common Belief", "authors": ["Meir Friedenberg", "Joseph Y. Halpern"], "primary_category": "cs.MA", "categories": ["cs.MA", "cs.AI", "cs.LO"], "text": "\nAudio-based Roughness Sensing and Tactile Feedback for Haptic Perception in Telepresence\n\n\n    \nBastian P\u00e4tzold,\nAndre Rochow,\nMichael Schreiber,\nRaphael Memmesheimer,\n\nChristian Lenz,\nMax Schwarz, and\nSven Behnke\nAutonomous Intelligent Systems\n\nUniversity of Bonn, Germany\n\n\n\n    March 30, 2023\n=========================================================================================================================================================================================\n\n\n\n\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tFor over 25 years, common belief has been widely viewed as\n\tnecessary for joint behavior.  But this is not\n\tquite correct.  We show by example that what can naturally be thought\n\tof as joint behavior can occur without common\n\tbelief.  We then present two variants of common belief that can lead\n\tto joint behavior, even without standard common belief ever\n\tbeing achieved,\n\t\n\tand show that one of them, action-stamped common belief, is in\n\ta sense necessary and sufficient for joint behavior.\n\t\n\t\n\t\n\t\n\t\n\tThese observations are significant because, as is well known, common\n\tbelief is quite difficult to achieve in practice, whereas these\n\tvariants are more easily achievable.\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\nThe past few years have seen an uptick of interest in studying\ncooperative AI, that is, AI systems that are designed to be effective\n\n\nat cooperating.  Indeed, a number of influential researchers recently\nargued that \u201c[w]e need to build a science of cooperative\n\n\nAI \u2026 progress towards socially valuable AI will be stunted unless\n\n\n\nwe put the problem of cooperation at the centre of our research\u201d \n\u00a0<cit.>.\n\nOne type of cooperative behavior is what we might call \n\n\n\n\njoint behavior, that is, collaboration scenarios where the success of\n\n\n\n\n\nthe joint action is dependent on all agents doing their\nparts; one agent deviating can cause the efforts of others to be\nineffective.\n\n\n\n\n\n\nThe notion of joint behavior has been studied (in much detail) under\nvarious names such as \u201cacting\ntogether\u201d, \u201cteamwork\u201d, \u201ccollaborative plans\u201d, and \u201cshared\n\n\n\nplans\u201d,\nand highly influential models of it were developed \n\n\n\n\n\n\n\n\n(see, e.g., \u00a0<cit.>). Efforts\nwere also made to engineer some of these theories into\n\n\nreal-world joint planning systems\u00a0<cit.>.  \nExamples of the types of scenarios these works considered include\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndrivers in a caravan, where if any agent deviates it might lead the\nentire caravan to get derailed, and a company of military helicopters,\n\n\nwhere deviation on the part of some agents can lead to the remaining\nagents being stranded or put in unnecessarily high-risk scenarios. \n\nOne conclusion arrived at by all of these efforts was the importance of beliefs for this type of cooperation.  \n\n\n\n\n\n\nIn particular, because each agent would do her part only if she\nbelieved that all of the other agents would do their part as well,\nthey determined that common belief (often called mutual\n\tbelief) of how \n\n\nthe agents would behave was necessary.   That is to say, not only did\neveryone have to believe all of the agents would act as desired, but\neveryone had to believe everyone believed it, and everyone had to\nbelieve that everyone believed everyone believed it, etc.  This, they\n\n\nargued, followed from the fact that everyone acts only if they believe\neveryone else will. \n\n\n\n(See, e.g., <cit.> for\nexamples of this claim.) \n\n\n\n\n\nAs we show in this paper, this conclusion is not quite right.  We do\n\n\nnot need common belief for joint behavior; weaker variants suffice.\nIndeed, we provide a variant of common belief that we call \naction-stamped common belief that we show is, in a sense,\n\n\nnecessary and sufficient for joint behavior.  The key insight is that\n\n\nagents do not have to act simultaneously for there to be joint behavior.\nIf agent 2 acts after agent 1, agent 1 does not have to believe, when\nhe acts, that agent 2 currently believes that all agents will carry\nout their part of the joint behavior.  Indeed, at the point that agent\n1 acts, agent 2 might not even be aware of the joint action.  It\nsuffices that agent 2 believes at the point that she carries out\n\ther part of the joint behavior that all the other agents will\n\n\nbelieve at the points where they are carrying out their parts of the\n\n\njoint behavior \u2026 that everyone will act as desired at the\nappropriate time.\n\nIf actions must occur simultaneously, then common belief is necessary;\nthe fact that we do not require simultaneous actions is what allows us\nto consider weaker variants of common belief.\n\n\n\n\n\n\n\n\nWhy does this matter?  Common belief may be hard to obtain (see\n\n\n\n<cit.>); it may be possible to obtain action-stamped common belief\nin circumstances where common belief cannot be obtained.   Thus, if we\n\n\nassume that we need common belief for joint behavior, we may end up mistakenly\ngiving up on cooperative behavior when it is in fact quite feasible.  \n\n\n\n\n\n\n\nThe rest of the paper is organized as follows.  In the next section,\nwe provide the background for the formal (Kripke-structure based)\n\n\nframework that we use throughout the paper.\nIn Section\u00a0<ref>, we give our first example\n\n\nshowing that agents can have joint behavior without common belief, and\n\n\n\t\ndefine a variant of common belief that we call time-stamped\n\tcommon belief which enables it to happen.  In\n\n\n\n\n\t\nSection\u00a0<ref>, we give a modified version of the\n\n\n\n\n\t\nexample where time-stamped common belief does not suffice for joint behavior, but action-stamped common belief, which is yet more general, does.\n\n\n\nIn general, the group of agents involved in a joint behavior need not be static; it may change over time.\n\n\n\n\n\n\n\n\n\nFor example, we would like to view the firefighters at the scene of a fire\nas acting jointly, but this group might change over time as\nadditional firefighters arrive and some firefighters leave.\nIn Section\u00a0<ref>, we show how action-stamped (and\ntime-stamped) common belief can be extended to deal with\n\n\nthe group of agents changing over time.\n\n\n\nIn Section\u00a0<ref>, we go into more detail regarding the\nsignificance of these results.  \n\n\n\n\nIn Section\u00a0<ref>, we show that there is a sense in\n\n\n\nwhich action-stamped common belief is necessary and sufficient for\njoint behavior.  Finally, in Section\u00a0<ref>, we conclude. \n\n\n\n\u00a7 BACKGROUND\n\n\n\n\n\n\nTo make our claims precise, we need to be able to talk formally\nabout beliefs and time.  To do so, we draw on standard ideas from\nmodal logics and the runs-and-systems framework of Fagin et\n\n\nal. FHMV. \n\n\n\nOur models have the form M=(R, \u03a6, \u03c0, _1, \u2026,\n\n\n_n). \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR is a system, which, by definition, is a set of\nruns, each of which describes a way \n\n\n\nthe system might develop over time.  Given a run r \u2208 R and a time n\n\u2208\u2115_\u2265 0 (for simplicity, we assume that time ranges\nover the natural numbers), we call (r,n) a point in the\nmodel; that is, it describes a point in time in one way the system\nmight develop.  \u03a6 is the set of variables.  In general, we will\n\n\n\ndenote variables in \u03a6 with uppercase letters (e.g., P) and\nvalues of those variables with lowercase ones (e.g., p). \u03c0 is an\ninterpretation that maps each point in the model and each\nvariable P \u2208\u03a6 to a value, denoting the value of P at that\npoint.\n\n(Thus, the analogue of a primitive proposition for us is a formula of\nthe form P=p: variable P takes on value p.)\n\n\n\n\tFinally, for each agent i, there is a binary\n\t\trelation _i over the points in the model.  Two points (r_1,\n\t\n\t\n\t\n\t\n\t\n\t\n\tn_1) and (r_2, n_2) are related by _i (i.e.,\n\t(r_1,n_1),(r_2,n_2)) \u2208_i) if the two points are\n\tindistinguishable to agent i; that is, if, at the point (r_1,n_1),\n\tagent i cannot tell if the true point is (r_1,n_1) or (r_2,n_2).\n\tWe assume throughout that the _i\n\trelations satisfy the standard properties of a belief relation:\n\tspecifically, they are serial (for all points (r,n), there\n\texists a point (r',n') such that ((r,n),(r',n')) \u2208_i),\n\t\n\t\n\tEuclidean (if ((r_1,n_1),(r_2,n_2)) and\n\t((r_1,n_1),(r_3,n_3)) are in _i, then so\n\t\n\t\n\tis ((r_2,n_2),(r_3,n_3))), and transitive.\n\t\n\tThese assumptions ensure that the standard axioms for belief hold; see\n\t\n\t\n\t<cit.> for further discussion of these issues.\n\t\n\tSyntactically, we can talk about these models using a language\n\tgenerated by the following context-free grammar: \n\t\n    \u03c6 := P=p  | \u03c8 | \u03c8_1 \u2227\u03c8_2  |  B_i\u03c8 |  E_G\u03c8 |  C_G\u03c8,\n\n\t\n\t\n\twhere P is a variable in \u03a6, p is a possible value of P, and\n\tG is a non-empty subset of the \n\tagents.  The intended reading of B_i \u03c8 is that agent i believes\n\t\n\t\n\t\n\t\u03c8; for E_G\u03c8 it is that \u03c8 is believed by everyone in\n\tthe group G; and for C_G\u03c8 it is that \u03c8 is common belief\n\tamong the group G. \n\t\n\tWe can inductively give semantics to formulas in this language relative to points in the above models.  The propositional operators  and \u2227 have the standard propositional semantics.  The other operators are given semantics as follows:\n\t\n\t\t\n  * (M,r,n)  P=p if \u03c0((r,n),P) = p, \n\t\t\n  * (M,r,n)  B_i \u03c8 if (M,r',n') \u03c8 for\n\t\t\n\t\t\n\t\tall points (r', n') such that ((r,n), (r', n')) \u2208_i, \n\t\t\n  * (M,r,n)  E_G \u03c8 if (M,r,n)  B_i \u03c8 for all i \u2208 G\n\t\t\n  * (M,r,n)  C_G \u03c8 if (M,r,n)  E^k_G \u03c8 for all k \u2265 1, where E^1_G \u03c8 := E_G \u03c8 and E^k+1_G \u03c8 := E_G(E^k_G \u03c8).\n\t\n\t\n\t\n\t\n\t\n\t\n\tThere are a number of axioms that are valid in these models.  Since they are\n\tnot relevant for the points we want to make here, we refer the reader\n\tto <cit.> for a discussion of them.\n\t\n\t\n\n\u00a7 TIME-STAMPED COMMON BELIEF\n\n\t\n\t\n\t\n\t\n\t\n\tWe now give our first example showing that\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tjoint behavior does not require common belief.\n\t\n\t\n\t\n\t\n\t\n\t\n\tWe do not define joint behavior here; indeed, as we\n\tsaid, there are a number of competing definitions in the literature\n\t<cit.>.  But we hope the reader will agree\n\tthat, however we define \n\t\n\t\n\t\n\tit, the example gives an instance of it.\n\t\n\t\n\t\t\n\t\tGeneral Y and her forces are standing on the top of a hill.\n\t\tBelow them in the valley, the enemy is encamped.  General Y\n\t\tknows that her forces are not single-handedly strong enough to\n\t\tdefeat the enemy.  But she also knows that General Z and his\n\t\ttroops are expected to arrive on the hill on the opposite side\n\t\tthe next day at noon, though she and her troops must move on\n\t\tbefore then.  Thankfully, all generals are trained for how to\n\t\t\n\t\t\n\t\t\n\t\tdeal with this situation.  Just as her training recommends,\n\t\tGeneral Y sets up traps that will delay\n\t\tthe enemy's retreat, and leaves one soldier behind to go to\n\t\tthe opposite hill and inform General Z of the traps upon his\n\t\tarrival.  At 11:30 the next morning, General Y receives a\n\t\t(false) message informing her that General Z and his troops\n\t\thave been captured, and thus (incorrectly) surmises that the\n\t\t\n\t\t\n\t\t\n\t\tenemy will live to fight another day.  What in fact happens\n\t\tis that General Z's troops arrive at noon and attack\n\t\tthe enemy, the enemy attempts to retreat and is stopped by\n\t\tGeneral Y's traps, and the enemy is successfully defeated. \n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tClearly, Generals Y and Z jointly defeated the enemy.  \n\t\n\t\n\t\n\t\n\tYet they never achieved common belief\n\tof what they were doing.  Before noon,\n\tGeneral Z didn't even think that the enemy was there, and \n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tfrom 11:30 on, General Y thought that General Z would never arrive.  It\n\tfollows that there was no \n\tpoint at which they could have had common belief.  \n\tSo what is going on here? \n\t\n\tWhat this example suggests is that there are times when a type of\n\t\n\t\n\ttime-stamped common belief (cf., <cit.>) suffices\n\t\n\t\n\tto enable joint \n\t\n\t\n\tbehavior.  Intuitively, on the first day, General Y believed that at\n\tnoon on the second day General Z would act, attacking the enemy.\n\t\n\t\n\t\n\t\n\tSimilarly, at noon on the second day, General Z believed that General Y had\n\tacted the day before, setting up the necessary traps.  They also\n\t\n\t\n\thold higher-order beliefs; for example, at the time she set the traps,\n\tgeneral Y believed that at noon the next day general Z would believe\n\tthat she had set the traps, otherwise she wouldn't have wasted the\n\tresources to set them, and so on.\n\t\n\t\n\tMuch as in the usual case of common\n\t\n\t\n\tbelief, these nested beliefs extend to arbitrary depths.\n\t\n\t\n\t\n\t\n\t\n\t\n\tWhat sets this example apart from those considered by earlier work is\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tthat, whereas in the earlier work agents needed to believe others would act as\n\t\n\t\n\tdesired at the same point, here the agents need to believe only that\n\tothers will act as desired at the points where they're supposed\n\t\t\n\t\t\n\t\n\t\n\tto act for the joint behavior.  This suggests that time-stamped\n\n\ncommon belief can suffice for joint behavior.\n\n\n\nOur notion of time-stamped common belief can be viewed as a\ngeneralization of the notion of time-stamped common knowledge\n\n\ndeveloped by Halpern and Moses FHMV,HM90 for scenarios\nwhere agents have internal clocks that may not be synchronized.\nWe discuss the exact relationship between these notions at the end of\nthe section.\n\nFormally, we can capture this type of time-stamped common belief\n\n\nwith the following additions to the logic and semantic models above.\nSyntactically, we add two \n\n\nmore operators to the language, E^t_G\u03c8 and C^t_G\u03c8,\n\n\n\n\n\n\nwhere G is a set of agents.  \n\n\n\n\n\n\nWe then add to the semantic model a function t \n\n\n\nthat maps each agent and run to a\n\n\n\n\nnon-negative integer.\n\n\n\n\n\n\nThe intended reading of these is \u201ceach agent i \u2208 G believes at\nthe time t(i,r) that \u03c8\u201d and \u201cit is\ntime-stamped-by-t common belief among the agents in G that\n\n\n\u03c8\u201d, respectively.  We give semantics to these operators as follows: \n\n\t\n\t\n\t\n\t\n  * (M,r,n)  E^t_G\u03c8 if (M,r,t(i,r)) \n\tB_i\u03c8 for all i \u2208 G \n\t\n  * (M,r,n)  C^t_G\u03c8 if (M,r,n)  E^t,k_G \u03c8 for all k \u2265 1, where E^t,1_G \u03c8 := E^t_G \u03c8 and E^t,k+1_G \u03c8 := E^t_G(E^t,k_G \u03c8).\n\n\n\nThese definitions are clearly very similar to the (standard)\n\n\ndefinitions given above for E_G\u03c8 and C_G\u03c8,\n\n\n\nexcept that the beliefs of each agent i \u2208 G in run r is\n\n\n\nconsidered at the time t(i,r).\n\n\n\n\n\nIt follows from the semantic definitions that  E^t_G \u03c8 and C^t_G\n\u03c8 hold at either all \npoints in a run or none of them.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example above, this notion of time-stamped common\nbelief is achieved if we take t(Y,r) to be the time in run\nr that Y laid the traps (which may be different times in different\nruns) and take t(Z,r) to be the time that Z arrived in run r\n(which was noon in the actual run, but again, may be different times\nin different runs), \n\n\n\n\n\n\n\n\n\n\n\nprovided that it is (time-stamped) common belief that both Y and Z\nwill follow\ntheir training.\nThat is, when Y lays the\n\n\n\n\ntraps, Y must believe that Z will believe when he arrives that Y\nlaid the\ntraps, Z will believe when he arrives that Y\nbelieved when she laid the traps that he\nwould believe when he arrived that Y laid the traps, and so on.  \nThe key point here is that time-stamped common\nbelief can sometimes suffice for achieving cooperative behavior, even\nwithout standard common knowledge. \n\n\nAs we suggested above,  our notion of time-stamped common belief is a\ngeneralization of (and was inspired by) Halpern and Moses' notion of\n\n(time-T)\ntime-stamped common knowledge.\n\n\n\nRoughly speaking, for them, time-T time-stamped common knowledge\n\nof \u03d5\nholds among the agents \n\n\n\n\n\n\n\n\nin a group G if every agent i in G knows \u03d5 at\ntime T on her clock, all agents in G know at time T on\ntheir clock that all agents in G know \u03d5 at time T on their clock,\n\n\n\n\nand so on (where T is a fixed, specific time).  If it is common knowledge\nthat clocks are synchronized, then time-stamped common knowledge\nreduces to common knowledge.  If we take t(i,r) to be the time in\nrun r that i's clock reads time T (and assume that it is\n\n\ncommonly believed that each agent's clock reads time T at some point\n\n\n\nin every run), then their notion of time-stamped common knowledge\nbecomes a special \ncase of our time-stamped common belief.  But note that with time-stamped\ncommon belief, we have the flexibility of referring to different times\nfor different agents, and the time does not have to be a clock\nreading; it can be, for example, the time that an event like laying\ntraps occurs.  \n\n\n\n\n\u00a7 ACTION-STAMPED COMMON BELIEF\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere is an even more general variant of common belief that can\n\n\n\n\nsuffice for joint behavior.  \n\n\n\n\n\n\n\n\nWhat really mattered in the previous example is that everyone had the\nrequisite beliefs  \n\n\n\n\n\nat the times that they were acting.  But there need not necessarily\n\n\nbe only one such point per agent per run; an agent might act multiple\ntimes \nas part of the plan, as the following modified version of the\nstory illustrates: \n\n\n\n\n\n\t\n\t\n\t\tGeneral Y and her forces are standing on the top of a hill.\n\t\tBelow them in the valley, the enemy is encamped.  General Y\n\t\tknows that her forces are not single-handedly strong enough to\n\t\tdefeat the enemy.  But she also knows that General Z and his\n\t\ttroops are expected to arrive on the hill on the opposite side\n\t\t\n\t\t\n\t\tat some time in the near future, although she and her troops\n\t\tmust move on before then.  Thankfully, all generals are\n\t\t\n\t\t\n\t\t\n\t\ttrained for how to deal with this situation.  Just as her\n\t\ttraining recommends, General Y sets up traps \n\t\tthat will delay the enemy's retreat, and leaves one soldier\n\t\tbehind to go to the opposite hill and inform General Z of the\n\t\ttraps upon his arrival.  The next morning, General Y receives\n\t\ta (false) message informing her that General Z and his troops\n\t\thave been captured, and thus (incorrectly) surmises that the\n\t\tenemy will live to fight another day.  What in fact happens,\n\t\tthough, is that General Z's troops arrive later that day and\n\t\tare informed by the remaining soldier that at some point\n\t\t\tnot too long ago General Y's troops set traps. They attack\n\t\tthe enemy, the enemy attempts to retreat and is stopped by\n\t\tGeneral Y's traps, and the enemy is successfully defeated. \n\t \n\t\n\tGeneral Y and her forces arrive to the south of the town where \n\tthe enemy forces are encamped.  General Y\n\tknows that her forces are not single-handedly strong enough to\n\tdefeat the enemy.  But she also knows that General Z and his\n\ttroops are expected to arrive to the north of the city\n\t\n\t\n\tsome time in the near future, though she and her troops\n\t\n\t\n\t\n\tmust move on before then. The swiftly-coursing river\n\tprevents the enemy from escaping to the east.  But\n\tunfortunately, they can \n\tstill escape inland to the west. \n\tThankfully, all generals are\n\ttrained for how to deal with this situation as well.  Just as her\n\ttraining recommends, General Y sets up traps \n\t\n\t\n\t\n\tthat will delay the enemy's southward retreat and then, as she\n\theads inland, \n\talso sets up traps to the west, finally leaving one soldier\n\tbehind to go north and inform General Z of the\n\ttraps upon his arrival.  The next morning, General Y receives\n\ta (false) message informing her that General Z and his troops\n\thave been captured, and thus (incorrectly) surmises that the\n\t\n\t\n\t\n\tenemy will live to fight another day.  What in fact happens\n\tis that General Z's troops arrive later that day and\n\t\n\t\n\t\t\n\tare informed by the remaining soldier that, not\n\ttoo long ago, General Y's troops set traps to the south \n\tand west. They attack the enemy, the enemy attempts to retreat\n\tand is stopped by General Y's traps, and the enemy is successfully defeated. \n\n\n\n\n\n\n\n\n\nAgain, Generals Y and Z jointly and collaboratively \ndefeated the enemy,  \n\n\n\n\n\n\nbut time-stamped common belief doesn't suffice for this version of the story,\nbecause we cannot specify a single time for General Y's actions.\n\n\n\n\tInstead, what really matters is that when they are acting as \n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\n\n\n\n\n\npart of a joint plan they hold the requisite (common)\n\n\n\n\n\n\nbeliefs. The joint plan need not be known upfront;\n\n\n\nGeneral Z does not know what he will need to do to achieve the\ncommon goal until he arrives at the scene.  To capture this new\nrequirement, we define a notion of action-stamped common\nbelief.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe begin by adding a special Boolean variable ACTING_i, G for\nany group G and agent i \u2208 G.  This variable is true (i.e., takes value 1, as\nopposed to 0) at a point (r,n) if the agent\ni is acting towards the group plan of G at (r,n) and false otherwise.\n\n\n\n\n\n\n\nSo for the generals, ACTING_Y, G = 1 would be true when she lays the\ntraps, ACTING_Z, G = 1 would be true at the point when he attacks,\nand they'd both be false otherwise (where G = { Y, Z }).\n\nWe often write ACTING_i,G and ACTING_i,G instead of ACTING_i,G = 1 and ACTING_i,G = 0, and similarly for other Boolean variables.\n\n\n\nBy using ACTING_i,G, we can abstract away from what actions are\nperformed; we just care that some action is performed by agent i\ntowards the group plan, without worrying about what that action is.\n\n\n\n\nAs in the case of time-stamped common belief, we add two modal operators to the\n\n\nlanguage (in addition to the variables ACTING_i,G).  Let G be\n\n\n\n\n\n\n\na set of agents.  E^\ud835\udc1a_G\u03c8 \nthen expresses that, for each agent i \u2208 G, \n\n\nwhenever ACTING_i,G holds (it may hold several\ntimes in a run, or never), i\n\n\nbelieves \u03c8. C^\ud835\udc1a_G\u03c8 then\n\n\ndefines the corresponding notion of common belief for the points at\nwhich agents act at part of the group. \n\n\n\nWe give semantics to these modal operators as follows:\n\n\n  * (M,r,n)  E^\ud835\udc1a_G\u03c8 if\n\n\n\n\n\nfor all n' and all i \u2208 G such that (M,r,n') \n\nACTING_i,G = 1, it is also the case that (M,r,n') \nB_i\u03c8.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  * (M,r,n)  C^\ud835\udc1a_G\u03c8 if (M,r,n)\n E^\ud835\udc1a,k_G \u03c8 for all k \u2265 1, where\nE^\ud835\udc1a,1_G \u03c8 := E^\ud835\udc1a_G \u03c8 and\nE^\ud835\udc1a,k+1_G \u03c8 :=\nE^\ud835\udc1a_G(E^\ud835\udc1a,k_G \u03c8). \n\n\n\nFormally, we give semantics to each of these as follows:\n\n\n  * (M,r,n)  E^\ud835\udc1a\u20d7_G\u03c8 if for\nall 1 \u2264 i \u2264 len(G) there exists an n' \u2265 0 such\nthat (M,r,n')  A_G_i = a' for some a' \u2208\ud835\udc1a\u20d7_\u20d7i\u20d7 and (M,r,n')  B_i\u03c8. \n\n  * (M,r,n)  C^\ud835\udc1a\u20d7_G\u03c8 if (M,r,n)  E^\ud835\udc1a\u20d7,k_G \u03c8 for all k \u2265 1, where E^\ud835\udc1a\u20d7,1_G \u03c8 := E^\ud835\udc1a\u20d7_G \u03c8 and E^\ud835\udc1a\u20d7,k+1_G \u03c8 := E^\ud835\udc1a\u20d7_G(E^\ud835\udc1a\u20d7,k_G \u03c8).  (Actually, I'm not quite sure if this is the right way to define it.  It seems at least plausible that this leaves open the possibility, that different levels of the Es could in fact be at different points where actions in those sets are taken \u2013 i.e. the base level beliefs might hold while taking one action while the higher level beliefs might hold while taking a different action.  I can't quite tell for sure whether we want to allow that, but my inclination is probably not.  If that's the case then we can avoid the problem by defining C in terms of if there exist times where those actions are taken such that time-stamped common belief holds.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReturning to the example, although the agents do not have time-stamped common\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbelief at all the points when they act, they do have action-stamped\n\ncommon belief.\n\n\n\n\nGeneral Z acted believing that General Y had acted as expected,\n\n\nand also believing that General Y acted believing that he would act as\nexpected, and so on.\n\n\n\n\n\n\nIt is easy to see that time-stamped common belief can be viewed as a\nspecial case of action-stamped common belief: Given a time-stamping\nfunction t, we simply take \n\n\nACTING_i,G to be true at those points (r,n) such that\nt(i,r) holds.\n\n\nIt is worth noting that, in both this and the previous section, the\nagents having a protocol in advance for how to deal with the situation\nis not really necessary for them to succeed.  In the examples,\nconsider a scenario where generals are in fact not trained for how to\nhandle the situation, but instead General Y has the brilliant idea\n\n\nto lay traps and send a messenger to meet General\n\n\nZ upon arrival. As long as message delivery is reliable,\naction-stamped common belief can be achieved and they can successfully\ndefeat the enemy. \n\n\n\n\n\n\u00a7 JOINT BEHAVIORS AMONG CHANGING GROUPS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn practice, \n\n\n\n\nthe members of groups change\nover time.  For example, a group of firefighters may work together to\nsafely clear a burning building, but (thankfully!) they don't need to\n\n\n\nwait until all the firefighters are on the scene, or even until it is known\nwhich firefighters are coming, in order for the first\nfirefighters to begin. Instead, structures and guidelines allow the\n\n\n\nset of firefighters who are on the scene to act cooperatively, even\nwithout each firefighter knowing who else will show up.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe formalisms of the two previous sections assumed a fixed group G,\nso cannot capture this kind of scenario.  But the changes necessary to\ndo so are not \ncomplicated.  Rather than considering (some variant of) common belief \nwith respect to a fixed set G of agents, we consider it with respect to an\nindexical set S, one whose interpretation depends on the\npoint.  More precisely, an indexical set S is a function from points\nto sets of agents; intuitively, S(r,n) denotes the members of the\nindexical group S at the point (r,n).  We assume that a model is\nextended so as to provide the interpretation of S as a function.\n\nOur semantics for action-stamped common belief \n\n\nwith indexical sets are now a straightforward generalization of the\nsemantics for rigid (non-indexical) sets: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  * (M,r,n)  E^\ud835\udc1a_S\u03c8 if\n\n\n\n\nfor all n' and all i \u2208 S(r,n') such that\n\n\n(M,r,n')  ACTING_i,S, it is also the case\nthat (M,r,n')  B_i\u03c8. \n\n  * (M,r,n)  C^\ud835\udc1a_S\u03c8 if (M,r,n)\n E^\ud835\udc1a,k_S \u03c8 for all k \u2265 1, where\nE^\ud835\udc1a,1_S \u03c8 := E^\ud835\udc1a_S \u03c8 and\nE^\ud835\udc1a,k+1_S \u03c8 :=\nE^\ud835\udc1a_G(E^\ud835\udc1a,k_S \u03c8). \n\n\n\n\n\n\n\nThe only change here is that in the semantics of E^\ud835\udc1a_S, \nwe need to check the agents in S(r,n) for each point.\n\n\nOf course, we can also allow indexical sets in time-stamped common\nbelief in essentially the same way.  \n\n\n\nWhereas\nin the semantics of E_G^t\u03c8, we required that\n(M,r,n)  E_G^t\u03c8 if, for all i \u2208 G, (M,r,t(i,r)) \nB_i\u03c8, now we require that\n(M,r,n)  E_S^t\u03c8 if, for all agents i, if i \u2208\n\nS(r,t(i,r)), then (M,r,t(i,r))  B_i\u03c8.  We care about what agent\ni  believes at (M,r,t(i,r)) only if i is actually in group S\nat the point (r,t(i,r)).  \n\n\n\n\nWhile we think of the action-stamped version of common belief as more\ninteresting and important for cooperation, it is worth noting that we\ncan make a similar extension of time-stamped common belief to allow\nfor dynamic groups.  To start though, we extend our time-stamped\ndefinition in a different manner, allowing t to be a function of\nboth runs and agents.  Letting t depending on the run allows for\nagents to have uncertainty regarding the plan, and brings it closer to\nwhat can be captured in the action-stamped setting, where an agent\nacting as part of the cooperative plan at time n in one run may not\nbe doing so in some other run.  (We could of course have allowed t\nto depend on runs from the start in Section\u00a0<ref>,\nbut chose to start with the simplified version for ease of\nunderstanding.) \n\nIn the dynamic setting, the intuition for t is slightly different,\n\n\nsaying only that agent i will act with the requisite beliefs at\npoint (r, t(r, G_i)) if she is in the group G at (r, t(r,\nG_i)).  Formally the semantics then become the following: \n\n\n  * (M,r,n)  E^t_G\u03c8 if for all n' and all G_i \u2208\u03c0((r,n'),G), if t(r, G_i) = n' then (M,r,n')  B_G_i\u03c8.\n\n  * (M,r,n)  C^t_G\u03c8 if (M,r,n)  E^t,k_G \u03c8 for all k \u2265 1, where E^t,1_G \u03c8 := E^t_G \u03c8 and E^t,k+1_G \u03c8 := E^t_G(E^t,k_G \u03c8).\n\nIn essence, for E^t_G\u03c8, at every point all agent's who are in the group and whose time it is must believe \u03c8.  Note that the semantics laid out here look much more similar in structure to those we gave for action-stamped common belief than our original definition of time-stamped common belief.  Of course, it would have been possible to give a definition for fixed groups that uses this structure and is equivalent to our original definition, but we chose to give that definition above to ease the reader in.\n\nThough we haven't emphasized it until now, it is worth noting that all of our definitions specify run properties; that is, for any of the above notions, they hold true at a point in a run if and only if they hold at all points in the run.  This is intentional.  Time-stamped and action-stamped common belief are both properties of whole runs, specifying that agents hold certain beliefs at all the times when they're supposed to act / points when they do act, rather than properties of particular points.\n\n\n\n\nt then must also be a variable, as the set being assigned to times will change between points. We can now make the following changes to account for changing groups:\n\nFor \u201ceveryone believes\u201d we get\n\n\n  * (M,r,n)  E^t_G\u03c8 if, for all G_i \u2208\u03c0((r,n),G), it is the case that G_i \u2208\u03c0((r,t^n_G_i),G) and (M,r,t^n_G_i)   B_G_i\u03c8 , where t^n_G_i is \u03c0((r,n),t)(G_i).\n\n\n\n\n\n\nWhat this says is that for everyone in the group at time n, they are each still in the group at the time that was assigned to them at time n (that is, t^n_G_i), and they believe \u03c8 at that time.  In essence, E^t_G is a statement about the members of the group at time n and their group-membership and beliefs at the times designated for each of them.\n\nWe also introduce a simple temporal operator to the language, .\n\n\n  * (M,r,n) \u03c8 if (M,r,n') \u03c8 for all n'.\n\n(Is there a standard symbol for this...? It seems like something that must be standard, but I'm not sure I've seen it.)  Note that this is not quite the standard  operator;  is usually that \u03c8 is true for all times from n and on, whereas we're using  here to mean it is true for all times, including those before n.\nE^t_G\u03c8, for example, then means something along the lines of \u201cfor all times n, the group members at (r,n) each believe \u03c8 at the time they're assigned at (r,n).\u201d\n\nFinally, time stamped common belief then becomes\n\n\n  * (M,r,n)  C^t_G\u03c8 if (M,r,n)  ( E^t_G)^k \u03c8 for all k \u2265 1, where ( E^t_G)^1 \u03c8 :=  E^t_G \u03c8 and ( E^t_G)^k+1\u03c8 :=  E^t_G(( E^t_G)^k \u03c8). \n\n\nWe note two important aspects of these definitions.\nThe first is that -formulas express run properties rather than point properties; that is, if (M,r,n) \u03c6 then \u03c6 must in fact be true at all points in the run r.\n\nThough we didn't emphasize it before, our definitions of time-stamped common belief in Section\u00a0<ref> and action-stamped common belief in Section\u00a0<ref> are in fact run properties; because G and t are fixed, if C^t_G was satisfied at any point in a run then it was satisfied at every point in that run.  \n\nFor our definitions in this section, in the case of dynamic groups, had we defined C^t_G in the obvious way simply by nesting E^t_G it would in fact not have been a run property.  E^t_G at point (r,n) is always a statement about the beliefs of the particular agents who are in the group at (r,n), but intuitively we don't want the current group members to have this \u201cspecial role\u201d in the determination of time-stamped common belief \u2013 time-stamped common belief ought to be a run property, dependent on the beliefs of the different group members over time, not just the beliefs of those in the group at (r,n) about the beliefs of others.\n\nThere are at least three natural-seeming ways to go from our notion of \u201ctime-stamped everyone believes\u201d to a notion of time-stamped common belief that is a run property.  The first is what we have specified above, by repeated nesting of E^t_G.  The second is by prepending  to repeated nesting of E^t_G, giving semantics in terms of (E^t,k_G) for all k \u2265 1.  The third option would be to define time-stamped common belief and everyone believes relative to a fixed time-stamp t that maps a set of agents G^* to times, such that G^*_i \u2208 G at (r, t(G^*_i)) for each G^*_i \u2208 G^* and all runs r.  All three of these options seem natural, and we saw no definitive reason to use any one of them.  That said, we decided not to use the third option because it seemed to preclude the type of \u201cdynamic plans\u201d scenarios that dynamic groups intuitively ought to help us be able to model.  Between the first two options, we decided to use the first one because it seemed to more directly parallel the earlier definitions of common belief and its variants, defining it solely in terms of repeated nesting of the exact same operator (here E^t_G).\n\nThe second important thing to note about these definitions is that getting the modeling right, and in particular specifying the right G, is very important.  Let's return to the example we started this section with, of firefighters showing up to a scene over time.  If you specified G to be the set \u201cfirefighters at that building\u201d then there very well might not be time-stamped common belief, because there might be a firefighter who had been at the scene two years earlier to buy a coffee and who at the time had no beliefs about any future fires that might occur there.  On the other hand, if you specified G to be \u201cthe set of firefighters present at the scene to fight that fire\u201d, time-stamped common belief might well be achieved.  This actually seems correct to us \u2014 the set of all firefighters at the building during the course of the run did not have time-stamped cooperative behavior, but those present to fight that fire did.  Our point is only that the modeling choices are important, as they often are in these types of frameworks.\n\nLastly, we can of course define a notion of action-stamped common belief for dynamic groups, much the same way we have done here for time-stamped common belief.\n \n\n\n\n\u00a7 SIGNIFICANCE\n\n\n\n\nIn Sections\u00a0<ref>-<ref> we showed that\n\n\naction-stamped common belief can suffice to enable joint\nbehavior, whereas the prior work on the topic had assumed common\nbelief was necessary.  So what?  Why does this matter?  We argue that\nit is important for two reasons:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1) because misunderstanding the type\nof belief necessary can lead to mis-evaluation of cooperative\ncapabilities, and 2) because requiring common belief can unnecessarily\nmake cooperation impossible in scenarios where it is in fact possible\nand could be quite beneficial. \n\n\n\n\nAs part of the recent push for more research on cooperative AI, some\nhave argued that we should  \n\u201cconstruct more unified theory and vocabulary related to problems of\n\n\ncooperation\u201d \n\n\n<cit.>.  \n\n\n\n\nOne important step in this program is (in our opinion)\n\n\nformalizing the requirements for various types of cooperation,\nincluding joint behavior.   This, in turn, \n\n\nrequires understanding the level and type of (common) belief needed for\n\n\njoint behavior.  As our examples have shown, full-blown common belief is\nnot necessary; weaker variants that are often easier to achieve\n\n\ncan suffice.\nRelatedly, there has been a push to develop methods for\nevaluating the cooperative capabilities of agents, as a way of\n\n\n\n\ndeveloping targets and guideposts for the community\u00a0<cit.>.\n\n\n\n\n\n\nAgain, this will require understanding (among other things) what type\n\n\nof beliefs are necessary for cooperation.  \n\n\n\n\nIncorrect assumptions about the types of beliefs\nnecessary can lead to incorrect conclusions about the feasibility of\ncooperation.  For \nexample, if an evaluation system takes as given the assumption that it\nis impossible for agents that cannot achieve common belief to behave\ncooperatively, it may in fact lead to effective cooperative agents\nbeing scored badly, leading to misdirected research. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA second reason that it is important to clarify the types of beliefs\n\n\nnecessary for joint behavior is that misunderstanding them can lead to\nsystems unnecessarily aborting important cooperative tasks.  As\n\n\nis well known, achieving true common knowledge can be\nremarkably difficult in real-world systems, often requiring either a\ncommunication system that guarantees truly synchronous delivery or\nguaranteed bounded delivery time together with truly synchronized\n\n\nclocks <cit.>.\n\n\nAction-stamped common belief can sometimes be achieved when common\nbelief cannot.  To demonstrate the importance of this, we consider an\nexample from the domain of urban search and rescue, a domain where 1)\nthe use of multi-agent systems consisting of humans and AI agents has\n\n\nlong been considered and advocated for, 2) the types of teamwork\nnecessary can be complex, and 3) there is some evidence of potential\nadoption, having been used, for example, at a small scale in the\n\n\n\naftermath of September 11th\u00a0<cit.>.\n\n\n\n\n\n\nThough the example we give is a simple, stylized case, the domain is sufficiently complex that we would expect these types of issues to arise in practice if systems were deployed at scale.\n\n\nAn earthquake occurs, causing a large building to collapse.\nThe nearest search and rescue team arrives on scene, and the\nincident commander has to decide how to proceed.\n\n\n\n\nAfter evaluating the scene, the incident commander determines that\nthere are two reasonable options:\n\n\n  * Wait for a heavy piece of machinery that will certainly\nbe able to safely lift the roof of the collapsed building on\nits own and allow rescuers safe access to the building, but\nbecause there are only a few of them it will take a week for\nthe machine to be available and brought to the scene. \n\n\n\n\n\n\n\n\n\n  * Take a joint-behavior-based approach:  While \nsizing up the situation, the team has determined that the\nstructure is stable and will not collapse, and so is safe to\n\n\nenter. However, attempting to exit the building may disrupt\nthe structure and cause harm.  This allows for a team to\n\n\n\n\n\n\n\n\nsafely enter the building and restabilize parts of the roof.\nThe restabilization would not be enough to make it safe to exit\u2014in\nfact, it would require adjusting the structure in ways that would make\nan attempt to exit even more risky\u2014but it would be enough that a more easily\naccessible robotic system would be able to safely remove the\nroof piece by piece, allowing the rescuers and anyone trapped\ninside to safely escape. \n\n\n\n\nOut of concern for the safety of anyone trapped inside, the\n\n\nincident commander decides it is best not to wait, and so takes\n\n\n\n\nthe joint-behavior-based approach.  He sends the team of\nrescuers in to \nbegin the necessary process, and tells them to do the one part\n\n\n\n\n\n\n\n\n\nthat is visible from the outside last, so that \nwhen the robot arrives it is possible to tell from the outside that \nthe team of rescuers has finished restabilizing the roof and \nit is safe to proceed. \nHe also tells them the full plan for the robot to\n\n\ncome and lift the roof piece by piece, and that he expects it\nwill be 2-3 hours before the robot arrives on scene. \n\nThe group enters the wreckage and secures it in the necessary\nways, completing the part that is visible from the outside\nlast, as planned.  But it turns out that the earthquake\n\n\naffected many buildings, so the robot is in high demand.  It\nends up taking close to 8 hours for the robot to arrive on\n\n\n\n\n\n\n\n\nscene.   For safety reasons, the robot is designed so that,\nbefore it undertakes a task, it \n\n\n\n\nautomatically assesses whether the plan is safe, and will not\nproceed unless it determines that it is. \n\n\n\n\nBecause these types of plans are sometimes\nnecessary in search and rescue, the robot has a built-in\njoint-plan module with a theory of joint behavior.\nWhen the robot arrives, the incident commander can therefore\neasily enter the information for the robot to start assessing\n\n\n\n\nand undertaking the specified joint behavior.\n\n\n\n\n\nIf the robot's model of joint behavior requires\ncommon belief, a problem will arise.  At no point is there\n\n\n\n\never common belief of the joint behavior.  Before the robot\n\n\n\n\n\n\narrives, the robot certainly has no belief about the joint\nbehavior.  And \nwhen the robot arrives, it must consider the\npossibility that, because of the delay, the rescuers have given\nup hope of the robot arriving and concluded that they may have\nto wait a full week until the larger piece of machinery is\n\n\navailable.  Even if this isn't actually the case, the robot\nwill consider it possible that they are in a run where it is\n\n\nthe case, and so common belief will not be achieved.  And\n\n\n\n\n\nbecause its theory of joint behavior assumes common belief, the robot\n\n\nwill determine that the joint behavior cannot be\n\n\n\n\ncarried out. Thus, everyone will have to wait a week for\nthe heavier machinery, risking the lives of anyone trapped\ninside with the six extra days of delay. \n\n\n\n\n\nIf, on the other hand, the robot's theory of joint behavior is\nbased on action-stamped common belief, the task will be able\n\n\n\n\n\n\nto be properly and safely carried out.  When the rescuers\nperform their part, they believe that the robot will arrive soon\nand perform its part of the task.  Similarly, the\nrobot, seeing the part of the work that is visible from the\n\n\noutside, believes that the rescuers held those beliefs when acting\n(and therefore performed the required adjustments).  The\nrescuers believed that the robot would hold these beliefs when\n\n\nit arrived, the robot believed they would, and so on.  The\nfact that the robot \narrived later than expected and the rescuers may have started\n\n\n\n\n\nto have uncertainty about the plan doesn't affect the\nrequisite beliefs because all that matters are the beliefs of\nthe agents at the points where they act.  Having the \n\n\ntheory of joint behavior require action-stamped common belief\ninstead of common belief allows the rescuers and the robot to\n\n\n\n\n\n\n\ncarry out their joint task in a safe manner, as they\nclearly ought to, saving anyone trapped far earlier than\nmight otherwise be possible. \n\n\nThis example highlights the value of getting the types of beliefs\nnecessary right; getting the theory right, and basing it on\naction-stamped common belief instead of standard common-belief, can\nenable cooperation in a range of important scenarios where standard\ncommon belief is impossible or difficult to achieve, whereas\naction-stamped common belief may be easily attainable. \n\n\n\n\n\n\n\n\u00a7 SHARED PLANS AND JOINT INTENTIONS\n\n\n\n\n\n\n\n\nSo if standard common belief isn't strictly necessary for achieving cooperative behavior, why was it used in all the previous work?  The answer seem to us to be, simply, that they weren't trying to define cooperative behavior.  Instead, they were trying to engineer collaborative or cooperative behavior.  And to do that, they tried to come up with mental states that could be used to ensure agents would behavior cooperatively, with one group for example focusing on the notion of joint intentions as a way to ensure cooperative behavior and another developing a framework of SharedPlans.  And indeed, had we been formalizing these notions we too would likely have formalized them using common belief.  For both of them, after all, it seems natural to ask \u201cwhen did it happen?\u201d  \u201cWhen did the agents have a joint intent?\u201d  \u201cWhen did the agents have a shared plan?\u201d  And in order to have a specific point in time when it occurred, neither of the notions we developed in this paper would suffice.  However, when addressing the question \u201cwhen did the agents behave cooperatively?\u201d the answer may well be \u201cthis one did his part at time t and this one did hers at time t'\u201d.  And similarly, it needn't inherently be the case that agents collectively have some sort of atomic mental state that is necessary for cooperation and occurs at a single time.  \n\nFrom an engineering perspective, the prior work may well have been right, that common belief is an important component for effectively ensuring cooperation.  But as we more and more frequently consider what it means for AI systems to cooperate with humans and how we can assess how cooperative an agent is, it seems important to recognize that standard common belief need not necessarily be a component.\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 ON THE NECESSITY AND SUFFICIENCY OF ACTION-STAMPED COMMON\n\n\nBELIEF FOR JOINT BEHAVIOR\n \n\n\n\n\nWe've argued in this paper that the prior work was incorrect in\n\n\nasserting that common belief was necessary for joint behavior, and shown\nby example that action-stamped common belief can suffice.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now argue that an even stronger statement is true: there is a sense\nin which action-stamped common belief is necessary and sufficient for\n\n\n\njoint behavior.  We say \u201cin a sense\u201d here, because much depends on the\nconception of joint behavior being considered.  So what we do in this\n\n\nsection is give a property that we would argue is one that we would\n\n\nwant to hold of joint behavior, and then show that action-stamped common belief is\nnecessary and sufficient for this property to hold.\n\n\n\n\n\n\n\n\n\n\n\n\nWhat does it take to go from a collection of individual behaviors to a\n\n\njoint behavior?  The following example may help illuminate some of the\nrelevant issues.\n\nJasper and Horace are both crooks, though neither is an evil\ngenius by any stretch of the imagination.  Having never met\n\n\neach other, they both happen to decide to rob the Great Bank\nof London \n\n\n\non exactly the same day.\nAs it turns out, neither of them did a good job preparing, and\n\n\nthey each knew about only half of the bank's security systems,\n\n\n\n\nand so made plans to bypass only that half.  By sheer dumb\nluck, between them they know about all the bank's security\nsystems.  So when each bypasses the part that they know about\n(at roughly the same time), the bank's security systems go down. \nThey each make it in, steal a small fortune, and escape, none\n\n\nthe wiser as to the other's behavior or that their plan was\ndoomed to fail on its own. \n\n\n\n\n\nIs Jasper and Horace robbing the bank an instance of joint behavior?  We\nthink not.  One critical component that distinguishes this from a\njoint behavior is the beliefs of the agents.  Joint behaviors are\ncollective actions where people do their part because they believe\nthat everyone else will do their part as well.  Here, Jasper and\n\n\n\n\nHorace have no inkling that the other will help disable the\nsystem. \n\n\nWe now want to capture these intuitions more formally.\n\n\n\n\nWe start by adding another special Boolean variable SHOULD_ACT_i,s for\neach agent i and indexical group S, specifying the points in each\nrun where agent i is \n\n\n\n\nsupposed to act towards the plan of group S. \n\n\nWe then add a special formula \u03c7_S to the language:\n\n[As long as the set of agents is finite (which we implicitly\n\n\nassume it is), we can express \u03c7_S in a language that includes a\n\n\n\n\nstandard modal operator \u22a1, where \u22a1\u03c6 is true at a\n\n\npoint (r,n) iff \u03c6 is true at all points (r,n') in the run.\nFor ease of exposition, we do not introduce the richer modal logic here.]\n\n\n\n\n\n\n\n\n\n  * (M,r,n) \u03c7_S if for all n' and all agents\n\n\ni \u2208 S(r,n'), (M,r,n')  SHOULD_ACT_i,s\u2192\nACTING_i,S \n\n\n\n\n\n\n\n\n\n\n\n\nThe formula \u03c7_S is thus true at a point (r,n) if, at all points in\nrun r, each agent i in the indexical group S plays its part in\nthe group plan whenever it \nis supposed to.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we think of ACTING_i,S as \u201ci is taking part in the\n\n\n\n\n\n\n\n\njoint behavior of the group S\u201d, then the property COOP_S that we\nnow specify \nessentially says that to have truly joint behavior, each agent\n\n\nin S must believe when she acts that all of the members of the\n(indexical) group\nS will\ndo what they're supposed to; if they don't all have that belief,\n\n\nthen\nit's not really cooperative behavior.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFormally, COOP_S is a property of an indexical group S in a model M: \n\n\n\n\n\n[COOP_S:]\tFor all points (r,n) and agents i \u2208 S(r,n), (M,r,n)\n\n\n ACTING_i,S\u2192 B_i \u03c7_S.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRequiring COOP_S for joint behavior makes action-stamped common\nbelief of \u03c7_S necessary for joint behavior.\n\n\n\n\n\n\n\n\n\n\n\nIf COOP_S holds in  a model M,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthen (M,r,n)  C^a_S \u03c7_S for all points (r,n).\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe begin by defining a notion of a-reachability: A\n\n\npoint (r',n') is S-a-reachable from (r,n) in k steps\n\n\nif there exists a sequence (r_0, n_0), \u2026, (r_k, n_k) of\n\n\npoints such that (r_0, n_0) = (r,n), (r_k, n_k) = (r', n'),\n\n\n\nand for all 0 \u2264 l < k, there exists a point\n\n\n(r_l, n'_l) and an agent i \u2208 S(r_l,n'_l) such that\n(M, r_l, n'_l) \n\n\n\n\nACTING_i,S and ((r_l, n'_l),(r_l+1, n_l+1)) \u2208_i. \n\n\n\n\n\nBy the semantics of C^a_G, C^a_G \u03c7_S holds at (r,n) iff\n\u03c7_S holds at every point (r', n') that is\n\n\nS-a-reachable from (r,n) in 1 or more steps.  Consider\n\n\nany such point (r', n').  Then, by the definition of reachability,\n\n\n\n\nthere exists some point (r\u201d, n\u201d) and some agent i \u2208\nS(r\u201d,n\u201d) such that \n\n\n(M, r\u201d, n\u201d)  ACTING_i,S and ((r\u201d, n\u201d), (r',\nn')) \u2208_i.  Because (M, r\u201d, n\u201d) \n\n\n\n\nACTING_i,S, we get by COOP_S that\n(M, r\u201d, n\u201d)  B_i \u03c7_S.  Then by the semantics of\nB_i and the fact that ((r\u201d, n\u201d), (r', n')) \u2208_i we\n\n\nget that (M, r', n') \u03c7_S.  But (r',n') was an\n\n\narbitrary point S-a-reachable from (r,n) in 1 or more\n\n\nsteps, so \u03c7_S holds at all such points, and we have that\n\n\n\n\n\n\n(M,r,n)  C^a_S \u03c7_S.  But (r,n) was also\narbitrary, so C^a_S \u03c7_S holds at all points. \n\n\t\n\n\n\nConsider an arbitrary n.  Our proof proceeds by induction to show that M,r,n  E^a,k_G\u03c7 for all k.\nFor the base case, note simply that\nproperty\u00a0<ref> holds at all points and so it\nimmediately follows that at all points where GROUP_ACTING_i\nholds for an agent i it is also the case that B_i \u03c7, so\nwe have that M,r,n  E^a,1_G\u03c7. \n\nFor the inductive case, we'll assume that M,r,n  E^a,k_G\u03c7, and show that M,r,n  E^a,k+1_G\u03c7.  This is equivalent to assuming \u03c7 is true at every point that is G-a-reachable from (r,n) in k steps and showing that it is true at every point that is G-a-reachable from (r,n) in k+1 steps.  Assume for the sake of contradiction that there is a point G-a-reachable from (r,n) in k+1 steps where \u03c7 isn't true, that is, there is an agent i, a point (r_k+1, n_k+1), and a point (r_k, n_k) that is G-a-reachable from (r,n) in k steps such that (M, r_k, n'_k)  GROUP_ACTING_i,  ((r_k, n'_k),(r_k+1, n_k+1)) \u2208_i, and (M, r_k+1, n_k+1) \u22ad\u03c7.  Choose an arbitrary such (r_k+1, n_k+1) and (r_k, n'_k). But because property\u00a0<ref> holds at all points, (M, r_k, n'_k)  GROUP_ACTING_i implies (M, r_k, n'_k)  B_i \u03c7, which combined with the fact that ((r_k, n'_k),(r_k+1, n_k+1)) \u2208_i implies that (M, r_k+1, n_k+1) \u03c7.  But this contradicts our assumption that \u03c7 isn't true at (r_k+1, n_k+1), and it was an arbitrary such point, so we get that \u03c7 is true at all points G-a-reachable from (r,n) in k+1 steps, completing the proof.\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe converse to Theorem\u00a0<ref> also holds; that is,\naction-stamped common belief of \u03c7_S suffices for COOP_S to\n\n\n\n\n\n\n\n\nhold.  Put another way, action-stamped common belief is\nexactly the ingredient that we need to meet the belief requirements \n\nof the property that we used to characterize\njoint behavior. \n\n\nIf (M,r,n)\n\n\n C^a_S \u03c7_S for all points (r,n), then\nCOOP_S holds in M.\n\n\n\n\n\n\n\n\nConsider an arbitrary point (r,n) and agent i \u2208 S(r,n) such\nthat (M,r,n) \n\n\n ACTING_i,S.  By assumption, (M,r,n)  C^a_S\n\n\n\u03c7_S.  So, by the semantics of C^a_S, it follows that\n(M,r,n)  E^a_S \u03c7_S.  In turn, it follows from the\nsemantics of E^a_S that (M,r,n)  B_i \u03c7_S\n\n\n\n\n(because (M,r,n)  ACTING_i,S).  \nBut r, n, and i were\narbitrary, so we have that (M,r,n)  ACTING_i,S\u2192 B_i \u03c7_S for all such points and agents.\nThus, COOP_S holds in M.\n\n\n\n\n\n\n\n\nThe astute reader will have noticed that  the\n\n\nproofs of   Theorem\u00a0<ref> and <ref>\ndid not\n\n\ndepend in any way on \u03c7_S.  The formula \u03c7_S in these\ntheorems can be replaced by an arbitrary\n\n\n\n\n\n\n\n\n\n\n\n\nformula \u03c6.  \n\n\n\n\nIn other words, if all the agents in S\nbelieve \u03c6 at the point when they act,\n\n\n\n\n\n\n\nthen \u03c6 is\naction-stamped common belief, and if \u03c6 is action-stamped\ncommon belief, then all agents in S must believe \u03c6 at\n\n\n\n\n\nthe point when they act.\n\n\n\nFormally, the proofs of Theorem\u00a0<ref> and\n\u00a0<ref> also show the\nfollowing: \n\n\n\n\nIf (M,r,n)\n\n\n\n\n\n ACTING_i,S\u2192 B_i \u03c6 for all points (r,n)\n\n\n\n\nand agents i \u2208 S(r,n), then (M,r,n)  C^a_S\n\n\n\u03c6 for all points (r,n). \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf (M,r,n)\n\n\n C^a_S \u03c6 for all points (r,n), then\n\n\n(M,r,n)  ACTING_i,S\u2192 B_i \u03c6 for\n\n\n\n\nall points (r,n) and agents i \u2208 S(r,n). \n\n\n\n\n\n\n\nThese results show that if we viewed a property other than COOP_S as\ncharacterizing joint behavior, as long as that property required\n\n\nagents to hold a certain belief when acting, action-stamped common\nbelief will be necessary and sufficient for that property to hold.\n\n\n\n\n\n\n\n\n\n\n\nConsider an arbitrary r, n, and i \u2208 S(r,n) such that (M,r,n)\n\n\n ACTING_i,S.  By assumption (M,r,n)  C^a_S\n\u03c6.  So by the semantics of C^a_S it follows that\n(M,r,n)  E^a_S \u03c6.  In turn, it follows from the\nsemantics of E^a_S that (M,r,n)  B_i \u03c6 for all i\n\u2208 S(r,n) (because\n(M,r,n)  GROUP_ACTING_i).  But r, n, and i were\narbitrary, so we have that (M,r,n)  GROUP_ACTING_i\n\u2192 B_i \u03c6 for all such points and agents. \n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now briefly sketch an even stronger sense in which action-stamped\ncommon belief suffices for joint behavior.   The idea is that if, for\nall point (r,n) and \nagents i, i  act at (r,n) if  (a) i \u2208 S(r,n),\n(b) i is supposed to act at that point (i.e., SHOULD_ACT_i,s holds),\nand (c) i believes C^a_S \u03c7, then the agents will be acing\njointly.  So, roughly speaking, if agents act when they have\naction-stamped common belief they are acting jointly, they really wil\nbe acting jointly.  To make this precise, we need to use the idea of a\nknowledge-based program <cit.>.  A knowledge-based\nprogram, as the name suggests, has explicit tests for knowledge (or\nbelief).  For example, the following is a knowledge-based program for\nan agent i:\n\n\n\n    .\n\nAccording to this program, if i believes that j believes \u03c6,\nthen i should perform action a.\n\n\nA knowledge-based program for agent i consists of a collection of\nsuch statements, where each belief formula in a test starts with B_i (so the\noutermost modality involves i's beliefs).\n\nWe can associate with each knowledge-based program  a set of models\nthat represent .  The details are beyond the scope of this\npaper (and can be found in <cit.>); we just give the high-level\nidea here.  We need to assume that poins of a run have more structure;\nspecifically, they have the form (s_1, \u2026, s_n), where s_i is\nthe local state of agent i.  Intuitively, agent i's local\nstate encodes all the information that agent i has access to.  A\nprotocol for agent i is a function from agent i's local\nstates to actions; intuitively, a protocol for agent i tells agent\ni what to do in each local state.  Given a program _i for agent\ni and a model M, we can define a protocol P_i for agent; in\nlocal state s_i.  The truth of a formula of the form B_i \u03c6\ndepends only on i's local state at the point (r,n).   Given a\nlocal state s_i for agent, we determine P_i(s_i) by finding a\npoint (r,n) such that i's local state at that point is s_i (if\nsuch a point exists), and deternining which of the tests in _i\nare true at the point (r,n).  Since the truth of a formula B_i\n\u03c8 depends only on i's local state, it doesn't matter which point\n(r,n) we choose.  According to P_i(s_i), agent i performs the\naction at the first line of _i where the corresponding test is\ntrue at (r,n).  If none of the tests are true, or if there is no\npoint (r,n) where i's local state is s_i, then i performs some\ndefault action.  \n\n\n\n\n\n\u00a7 CONCLUSION AND FUTURE WORK\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have argued here that, contrary to what was suggested in earlier work,\ncommon belief is not necessary for joint behavior.\n\n\nWe have presented a new notion, action-stamped common\nbelief, and shown that it is, in a sense, necessary and sufficient for\njoint behavior, and can be\nachieved in scenarios where standard common belief cannot.  \nThis is important because modelling the conditions needed for joint\nbehavior correctly can enable \ncooperation in important scenarios, such as search and rescue, where\nit might not otherwise be possible. \n\n\n\n\nWe chose to use the term joint behavior in this paper because\nit sounded to our ears like it most accurately captured the notion we\nwere considering; no doubt to some readers other terms will sound like\na better fit.\n\n\n\nAs we showed in Section\u00a0<ref>, action-stamped common\n\n\nbelief will in some sense be the right type of belief for a\ngroup behavior where individuals do their part only if they believe\nothers will do the same,  \n\n\n\nwhatever terminology we use.\n\n\n\n\n\n\nWe suspect that, for some readers, the idea that action-stamped common\nbelief is sufficient for joint behavior will seem obvious.\nIn a certain sense, we agree; in retrospect, it\ndoes feel like the obviously correct notion for joint\n\n\n\nbehaviors.  That said, despite there being thousands of papers following up on\nthose we cited in the introduction, no one seems to have had that\nrealization.  Similarly, while action-stamped common belief seems\nquite natural, it has not been explored before in the literature. \n\n\n\nThis work suggests two areas that are ripe for future work.   \nThe first is to more fully explore the logical aspects of\naction-stamped common belief.  Can a sound and complete axiomatization\nbe provided?  What is the complexity of various questions one might\nask, such as model checking whether agents have action-stamped common\nbelief in a model?  How can we practically engineer systems that rely\non action-stamped common belief?\nThe second area we think worth exploring is other aspects of joint\nbehavior, as well as other types of cooperation.  We've argued that\none property of joint behavior is based on the beliefs of the agents,\nand zoomed in to closely examine that belief aspect, revealing a\nnuanced but important error in earlier thinking.  We think that there\nmay well be other aspects of cooperation that are worth digging into\nin this fine-grained way. \n\n\nGiven the importance of cooperative AI, we hope that others will join\nus in exploring these questions. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neptcs\n\n\n\n"}