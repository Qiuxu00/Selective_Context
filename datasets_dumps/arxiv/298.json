{"entry_id": "http://arxiv.org/abs/2303.06927v1", "published": "20230313084430", "title": "Analytics for \"interaction with the service\": Surreptitious Collection of User Interaction Data", "authors": ["Feiyang Tang", "Bjarte M. \u00d8stvold"], "primary_category": "cs.SE", "categories": ["cs.SE"], "text": "\n\n\n\n\nSurreptitious Collection of User Interaction Data\n\n\n\n\n\n\n\n\n\nNorwegian Computing Center, Oslo, Norway \n\n{feiyang, bjarte}@nr.no\n\nAnalytics for \u201cinteraction with the service\u201d: Surreptitious Collection of User Interaction Data\n    Feiyang Tang, Bjarte M. \u00d8stvold\n    March 30, 2023\n===============================================================================================\n\n\n\n\n\nThe rise of mobile apps has brought greater convenience and customization for users. However, many apps use analytics services to collect a wide range of user interaction data purportedly to improve their service, while presenting app users with vague or incomplete information about this collection in their privacy policies. Typically, such policies neglect to describe all types of user interaction data or how the data is collected.\n\nUser interaction data is not directly regulated by privacy legislation such as the GDPR. However, the extent and hidden nature of its collection means both that apps are walking a legal tightrope and that users' trust is at risk.\n\n\nTo facilitate transparency and comparison, and based on common phrases used in published privacy policies and Android documentation, we make a standardized collection-claim template.\n\nBased on static analysis of actual data collection implementations, we compare the privacy policy claims of the top 10 apps to fact-checked collection claims. Our findings reveal that all the claims made by these apps are incomplete.\n\nBy providing a standardized way of describing user interaction data collection in mobile apps and comparing actual collection practices to privacy policies, this work aims to increase transparency and establish trust between app developers and users.\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nMobile apps have enabled us to interact with technology in new ways, allowing app developers to collect large amounts of user interaction data with the help of analytics services such as AppsFlyer, Flurry, and Firebase Analytics. \n\n\n\nUser interaction data includes actions taken by users, such as tapping buttons, scrolling through pages, and watching videos. Unfortunately, in their privacy policies apps often use vague phrases like \u201cuser's interaction with the service\u201d to describe data collection without providing any further details. \nThis lack of granularity exacerbates the problem of transparency, leaving users unsure of the scope and nature of the data being collected and the ways in which it is being used.\nAs a result, users may feel a sense of mistrust towards apps, leading to a loss of confidence in their use.\n\nThe relationship between transparency of data collection and user trust is crucial\u00a0<cit.>. \nWithout transparency, users cannot make informed decisions about what data they share and how it is used\u00a0<cit.>, which can result in a sense of invasion of privacy. \nAdditionally, data collected without proper transparency and control can be used for various purposes, including targeted advertising and user profiling, further eroding user trust.\n\nAn example is the Yr app, which is the most popular weather app in Norway, developed by the Norwegian Broadcasting Corporation (NRK). The app collects user interaction data to understand which features are frequently used, such as when users set their location to get localized forecasts.\nBy analyzing this data, the app could potentially infer that a user is a frequent traveler, has family living in different locations, or is interested in travel-related products or services. \nSuch profiling and inference could be used to target the user with location-based advertising, without the user's knowledge.\nHowever, the app's privacy policy[<https://hjelp.yr.no/hc/en-us/articles/360003337614-Privacy-policy>] is vague regarding the collection of user interaction data, as it lacks specific details on the types of data collected, as displayed below in the gray box.\n\n\n\n!\nPrivacy Policy of Yr\n\u22ef\n\nWe use different tools to track the use on our app and website. This information gives us valuable information such as most popular pages and on what times Yr is being used the most. No information that can identify persons are available for Yr.\n\n\u22ef\n\n\n\n\n\n\nOur reading of NRK's privacy policy[<https://info.nrk.no/personvernerklaering/>] did not yield any specific information on Yr's data collection practices, as the policy is primarily focused on NRK's news services and their \u201cinteraction with the services\u201d collection practices. \nThis lack of transparency regarding the data collection practices of the Yr app is concerning, as it can erode user trust in the app and NRK as a whole.\n\nRecent studies have shown that even seemingly innocuous user interaction data can reveal sensitive information about individual users. For instance, emoji use and pages visited can be used to infer a user's preferred pool and political orientation, respectively <cit.>. Additionally, mobile biometric data associated with keystrokes and touchscreen gestures can be used to estimate soft attributes like age, gender, and operating hand <cit.>. \nThese findings highlight the potential risks associated with collecting user interaction data, which can be used to infer sensitive information about individual users and subsequently be used for user profiling.\nMoreover, interaction data is not directly linked to identifying an individual and therefore may not be covered by major data protection regulations such as the GDPR.\n\n\nMost current research studying the privacy implications of analytic services has focused on determining whether personally identifiable information (PII) is being collected and transmitted to external analytics services\u00a0<cit.>. Studies have also examined log data to understand user behavior\u00a0<cit.>, and high-level analyses of user behavior data collection in mobile apps have been conducted\u00a0<cit.>.\n\n\n\n\n\n\n \u00a7.\u00a7 Research Questions\n\n\nBuilding upon the introduction, the aim of this paper is to provide a more standardized and structured way of describing user interaction data and how is collected and used in mobile apps and furthermore to increase transparency by comparing the claims made by mobile apps in their privacy policies to their actual implementation of collection. This approach is motivated by the need to build user trust. \nIn order to achieve this aim, we have devised a set of research questions:\n\n\n   \n  *  What do apps say about their collection of user interaction data in their privacy policies? We refer to this as their privacy policy collection claims.\n   \n  *  What types of user interaction data do apps actually collect in their implementations, and what are the means used for this collection?\n   \n  *  How do the collection claims from the policies match up with the realities of the implementations? We shall refer to this as checking the claims.\n\n\n\n\n\n \u00a7.\u00a7 Contributions\n\nIn this paper, we made several contributions to the understanding of user interaction data collection practices in mobile apps:\n\n    \n  * We analyze a corpus of privacy policies in mobile apps to identify the common phrasing used to describe the collection of user interaction data. \n    \n\n\n    We then create a standardized collection claim template for user interaction data based on the common phrasing and a vocabulary derived from Android documentation (Section\u00a0<ref>).\n    \n  * We use static analysis to extract collection evidence from Android apps, identifying data types, relevant code and means of collection in layout files and bytecode (Section\u00a0<ref>).\n    \n  * \n    We provide an overview of user interaction data collection practices in 100 popular apps on Google Play, representing the top 10 popular categories. From this sample, we selected the most popular app from each category, 10 apps in total, and conducted a fact-check of their privacy policy collection claims using collection evidence (Section\u00a0<ref>).\n\n\n\n\n\n\n\u00a7 BACKGROUND\n\n\nBefore delving into the specifics of our investigation, it is important to establish a foundation of knowledge on the topic of user interaction data collection in Android apps. \nThis involves examining the human aspects of this issue, understanding the basic components of an Android app, and exploring common reverse engineering techniques used to analyze app behavior. \nAdditionally, we will discuss what user interaction data entails, and how apps collect this data through various means such as logging interactions, timing interactions, and recording series of interactions. \n\n\n\n \u00a7.\u00a7 User Trust and Transparency\n\n\nEnsuring user trust and transparency in mobile app data collection is crucial. Clear, transparent, and reversible procedures can help establish user confidence and control over their data, leading to better user experiences and app adoption. Conversely, a lack of transparency can erode trust, create privacy concerns, and lead to user dissatisfaction or abandonment of the app. \n\nResearch has shown that increased transparency is positively correlated with higher levels of trust among participants\u00a0<cit.>, whereas low transparency can impede the adoption of mobile apps\u00a0<cit.>. Given the importance of building trust and confidence among users, it is in the interest of app makers to prioritize transparency and user control. Such efforts can ultimately result in a better user experience and increased uptake of their apps.\n\n\n\n \u00a7.\u00a7 Android Reverse Engineering and Analytics Services\n\n\nAPK files contain all the resources and bytecode necessary for Android apps to function, with several activities providing the user interface. Tools like apktool[<https://ibotpeaches.github.io/Apktool>] and Dex2Jar[<https://github.com/pxb1988/dex2jar>] can be used to decompile APKs and analyze analytics libraries.\n\nAnalytics services like Firebase Analytics and Flurry Analytics enable developers to gather data on user behavior, engagement, and preferences. \nHowever, these services have raised concerns about data protection as they often automatically collect user data, thereby raising privacy concerns. Thus far, countries such as France, Italy, Austria, Denmark, and Norway have clearly stated that the use of Google Analytics violates GDPR\u00a0<cit.>.\nAndroid apps can use these services by directly invoking third-party APIs or customizing their own analytics service by extending these APIs. The first approach involves calling third-party API methods directly in activities to log user engagement events, while the second approach enables developers to tailor data collection to their specific needs.\n\n\n\n\n\u00a7 MAKING SENSE OF APP POLICIES ABOUT DATA COLLECTION\n\n\nTo address RQ<ref>, we investigate how mobile apps disclose their collection practices for user interaction data in their privacy policies. \nTo make sense of app policies we propose a standardized template of \u201cdata collection claims\u201d as a single sentence in a restricted vocabulary. This sentence gives the essence of interaction data collection: the specific data types collected and the means of collection.\n\n\n\n \u00a7.\u00a7 Collection Vocabulary\n\nOur restricted collection vocabulary was developed by analyzing the Android system implementation documentation, as well as the APIs of the top 20 analytic services for Android apps listed on AppBrain\u00a0<cit.>.\n\n\n\n  \u00a7.\u00a7.\u00a7 Terms for Types of User Interaction Data\n\nThe user interface of an Android app collects a variety of data types, such as touch events, sensor data, and text input.  Based on a manual inspection of every single type of Android UI widget, we identified the following six types of interaction data and named them:\n\n\n\n    \n  * App presentation interaction data: This data arise from the consumption of content provided by the app. For example, the user plays a certain video for a period of time, spends minutes reading one specific page of the news. These interactions are often recorded by a logging system to keep track of the user's consumption habits. \n    \n  * Binary interaction data: This data arise from discrete user actions, such as tapping on a button or icon, or selecting a checkbox. \n    \n  * Categorical interaction data: This data arise from a selection from a set of predefined options or categories, such as choosing a value from a dropdown menu, selecting a radio button, or rating a product. \n    \n  * User input interactions data: This data arise from user input through an on-screen keyboard or another input method, such as entering text or numbers into a form field, or using voice input to perform a search or command. \n    \n  * Gesture interactions data: This data arise from gesture inputs and smooth and continuous movements of the user's finger on the screen, such as scrolling through a list, swiping left or right, pinching or zooming, or shaking the device. \n    \n  * Composite gestures data: This data arise from a combination of multiple gestures, such as tapping and holding, double tag, or drag and drop. \n\n\n\n\n  \u00a7.\u00a7.\u00a7 Terms for Means of Collection\n\n\n\n\nWe use the following terms to describe the means of user interaction data collection.\n\n    \n  * Frequency: This type of collection involves logging the frequency of the occurrence of a particular interaction. For example, an app might log the number of times a user taps on a specific button or selects a certain option from a drop-down menu. \n    \n  * Duration: This type of collection involves tracking the time a user spends engaging in a particular interaction. For example, an app might log the amount of time a user spends watching a particular video or reading a specific article. \n    \n  * Motion details: This type of collection involves monitoring the specific details of a user's interaction, such as the speed, direction, or angle of their finger movements on the screen. This type of data can be collected for interactions such as scrolling, swiping, or dragging. \n\n\n\n\n \u00a7.\u00a7 From Policies to Standardized Collection Claims\n\n\n\nWe start by examining the privacy policies of publicly available mobile apps. \n\nWe used the APP-350 Corpus\u00a0<cit.>, which consists of 350 mobile app privacy policies that are annotated with privacy practices. \nSince APP-350 focuses on identifying personally identifiable information (PII) related sentences from the privacy policies, we only used their raw privacy policy HTML files for our analysis.\n\n\n\n  \u00a7.\u00a7.\u00a7 Identifying Relevant Policy Parts\n\n\nTo identify sentences related to user interaction data collection in privacy policies, a simple pre-trained language model was adopted. The model processes HTML files of privacy policies and extracts sentences that contain specific keywords and their synonyms. Natural language processing is performed using the spaCy\u00a0<cit.> library with the  model. This model is pre-trained on web text, which includes web forums, web pages, and Wikipedia. It can identify named entities, parts of speech, dependency parsing, and more. The WordNet module from the Natural Language Toolkit (NLTK\u00a0<cit.>) is also used to find synonyms for the extracted keywords.\n\nTo validate the effectiveness of the model, we randomly selected 50 privacy policies from the APP-350 dataset and manually annotated them to identify sentences containing relevant information, the verbs used to describe data collection (e.g., \u201ccollect\u201d, \u201ctrack\u201d), and the terms used to describe user interaction data (e.g., \u201cusage of the app\u201d, \u201cinteraction with the service\u201d).\nBy identifying the verb and the terms most commonly used to describe user interaction data\n\nwe ensure that our privacy policy claim vocabulary is consistent with prevailing industry practices.\n\nThe model successfully identified sentences related to user interaction data collection in 37 of the 38 files that contained such sentences, using keywords such as interaction, usage, statistics, experience, and analytics. We confirmed that the 37 identified files contained relevant sentences. Identifying the verbs used to describe data collection was more challenging, with 92% recall but only 84% precision\n\ndue to similar verbs appearing in sentences that were not related to the context.\n\n\n\nAfter running the model on the 350 privacy policies and performing manual checks to eliminate any false positives, we identified common phrases used in these policies to describe the collection of user interaction data. From the 1411 identified sentences, we selected only the relevant verbs and nouns to compile the list of keywords shown below in Table\u00a0<ref> and Table\u00a0<ref>.\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 A Template for Standardized Collection Claims\n\nIn privacy policies, it is common for apps to use convoluted language to describe how user data is collected. \nTo make these collection claims in privacy policy easier to read and compare across different apps, we created a standardized template that utilized the most frequently used verb, \u201ccollect\u201d, and the most frequently used noun phrase, \u201cuser interaction data\u201d.\nThe resulting structure is as follows:\n\n\n\n\n!\nTemplate for Standardized Collection Claims\nWe collect the following types of user interaction data: \u27e8types of data collected\u27e9, along with their \u27e8means of collection\u27e9.[Refer to the claim vocabularies in Section\u00a0<ref>]\n\n\n\n\n\n\n\nThis standardized collection claim template can be combined with the collection evidence gathered through static analysis to check and the accuracy of privacy policy collection claims made by various apps. Also, the standardized language facilitates transparency and comparison between policies. \nWe return to the subject of checking policy claims in Section\u00a0<ref>.\n\n\n\n\n\u00a7 DATA COLLECTION EVIDENCE\n\nTo understand what user interaction data apps actually collect (RQ<ref>) and to check the apps' privacy policy collection claims (RQ<ref>) we analyze the Android apps' implementations:\nFirstly, we identified the data collection methods used in the app package (APK). \nNext, we extracted the relevant evidence from the app and mapped it to our collection vocabulary in Section\u00a0<ref>. \nLastly, we compared the evidence extracted from the app with the claims made in the privacy policy to evaluate the level of agreement between the two, which we refer to as claim checking. \n\n\n\n \u00a7.\u00a7 Identifying Data Collection Methods\n\n\nData collection methods (DCMs) are methods defined by analytics services, such as Firebase Analytics, that allow app developers to log user interaction data. \nDCMs provide a standardized way for app developers to collect user interaction data and track app usage in order to analyze and understand user behavior.\n\nFor example, the Firebase Analytics API provides the  method to log user events, such as button clicks or screen views.\nSuppose we have a button  in the app's UI, and we want to track when the user clicks on it. \nWe can do this using Firebase Analytics by adding the following code to the button's :\n\n\n\n    \n\n\n\nHere  returns an instance of the Firebase Analytics object, and  collects the button click interaction data with the string  to Firebase Analytics. \n\n\n\n\nTo determine how Android apps use analytics services, we identified DCMs from the top 20 Android analytic services, cf. Section\u00a0<ref>.\nMatching the full signature of these methods in bytecode allows us to find direct invocations to analytics services. \nHowever, some apps use customized analytics services to do a more fine-grained collection, such as collecting motion details and duration. To do this, the apps implement their own analytics classes by extending the analytic services.\n\nTo identify customized analytics, we use static analysis to identify the classes that invoke external DCMs. \nWe then check whether these classes are invoked in any of the app's declared activities. \nIf they are, we mark these classes as customized analytics services classes. \n\n\n\n\n\n \u00a7.\u00a7 Extracting Collection Evidence\n\nNext, we extracted evidence of actual data collection from the APK. \nSpecifically, we analyze three types of information: (1) invocations to analytics services that logged user interaction data collection, (2) associated UI widgets, and (3) the callbacks triggered by registered listeners on these UI widgets.\n\nWe utilized static analysis with FlowDroid\u00a0<cit.> to associate DCM invocations with callbacks, listeners, and activities in the bytecode. \nWe then compared the layout IDs of the associated UI widgets defined in the layout XML files to identify the relevant collection data types and means. \n\n\n\nThe relationships between different parts of the extracted collection evidence in an Android app are shown in Fig.\u00a0<ref>.\nThe UI-related parts, such as layout files and defined UI widgets, provide information on the types of user interaction data (red section), while the bytecode provides details on the means of collection (blue section)[Note: The figure notation is as follows: 1-M means one-to-many, 1- means one-to-any (zero or more), and 1-1 means one-to-one.].\n\n\n\nWe return to the Yr weather app, the example app from Section\u00a0<ref>. Based on the collection evince extracted from Yr's bytecode and layout files, we discovered that it collects detailed user interaction data using various types of UI widgets such as SearchView and Textfield. This data collection is linked to features such as changes in location, enabling forecast summary notifications, and opening the forecast graph. Building on this finding from static analysis, we propose the following more specific checked standardized collection claim:\n\n\n\n\n!\nChecked Standardized Collection Claim for Yr\n\u22ef\n\nWe collect the following types of user interaction data: app presentation, binary and categorical interactions, and user input interactions, along with their frequency.\n\n\u22ef\n\n\n\n\n\n\n\n\u00a7 FINDINGS\n\n\nTo address RQ<ref>, we conducted a manual inspection of 1411 sentences that described user interaction data collection in all 350 privacy policies within the APP-350 corpus, as outlined in Section\u00a0<ref>.\n\nWe examine whether the sentences in one privacy policy provide clear descriptions of the types of user interaction data collected and the means of collection.\n\n\nOur findings revealed that only 37% of the identified sentences contained clear statements on both the data types and means of collection, while 41% only discussed the means of collection and 22% mentioned only the data types.\n\n\nHere are the relevant sentences from two policies in the corpus. DAMI[<https://play.google.com/store/apps/details?id=com.blappsta.damisch>] states: \u201cWe may work with analytics companies to help us understand how the Applications are being used, such as the frequency and duration of usage.\u201d Wish[<https://play.google.com/store/apps/details?id=com.contextlogic.wish>] states: \u201cWe may collect different types of personal and other information based on how you interact with our products and services. Some examples include: Equipment, Performance, Websites Usage, Viewing and other Technical Information about your use of our network, services, products or websites.\u201d\n\nDAMI's privacy policy only discloses the means of collection, such as the frequency and duration of usage, without clearly explaining which type of user interaction data is collected. In contrast, Wish's privacy policy does mention some specific types of data collected, such as equipment and performance data, but it is unclear about which means of collection are used. \n\n\nThe majority of identified sentences discuss the means of collection rather than specific data types, suggesting that organizations use the tactic of avoiding or minimizing disclosures about the types of user interaction data they collect in order to collect more data than users are aware of or comfortable with. \n\n\nTo investigate RQ<ref>, we performed a static analysis on a sample of 100 free Android apps downloaded from the top 10 most popular categories on the German Google Play store[<https://play.google.com/store/apps?gl=DE>], as identified by AppBrain.\nIn cases where the same app appeared in several categories, we moved to the next popular app in the second category to get a total of 100 distinct apps. \n\n\n\n\n\n\nOur analysis of the top 100 Android apps revealed that app developers placed a great deal of emphasis on understanding how frequently users interacted with different UI elements (which may correspond to different features or functionalities in the app), as frequency was the top means of collecting user interaction data across all UI types. We also found that the average number of interaction data collected varied significantly across different types of UI. It was also interesting to see that the high number of interaction data collected for the button UI type (also found in 76% of the apps), indicated that understanding button usage was a particularly important metric for app developers.\n\n\n\n\nTable\u00a0<ref> compares collection practices across various app categories. \nGaming apps collect a high percentage of Gesture data and send it to the analytics services later, likely due to the importance of tracking user finger motions for an optimal gaming experience. \nEntertainment, Shopping, and Travel apps tend to collect a high percentage of View data, indicating the importance of visual design customization and its consequences for the revenue stream of the app's service.\n\nSocial and Utility apps concentrate on Button and Textfield data, reflecting their dependence on user input to perform actions and provide information. \nIn summary, the result reveals differences in the app categories that prioritize understanding user interaction data depending on the UI type. \nThis suggests that app developers may be focusing their efforts on understanding certain aspects of user behavior, such as how users view content, interact with buttons, or use gestures, depending on the specific goals and requirements of their app. \nSuch insight could help app developers better tailor their data collection and analysis strategies to achieve their specific objectives.\n\nTo address RQ<ref>, we manually inspected the privacy policy claims of the most popular app in each of the 10 categories on Google Play. We generated our checked collection claims by analyzing the actual data collection practices of each app and comparing them to the privacy policy claims published by the app.\nOur checked collection claims are made by combining the evidence gathered through static analysis and the proposed standardized claim template.\nThe results are fact-check collection claims presented in Table\u00a0<ref>.\n\n\nOur study uncovered inconsistencies between the claims made in privacy policies and the actual data types and means of collection used by popular apps on Google Play. Many apps do not fully disclose the types of data collected or the means of collection, often using vague language such as \u201ccollecting user interactions to improve the service\u201d. \n\n\nNotably, some apps that may be perceived as having questionable data collection practices, such as TikTok and Amazon Prime Video, actually provided more detailed information on the types of data collected and the means of collection used. TikTok and Duolingo even provided specific examples of their data collection practices.\n\nHowever, we found that some apps from less controversial categories, such as the photography editing app Picsart and the payment platform PayPal, used opaque language in their privacy policies, leaving a large gap between their claims and our findings. The most extreme example was Booking.com, which extensively collects user interactions within the app, yet discloses almost no information in its privacy policy. These findings highlight the need for clearer and more comprehensive disclosures in privacy policies, particularly for apps that collect sensitive user data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Threats to Validity\n\n\nFirstly, our analysis is based on the invocation of the top 20 analytics services, so if an app uses a service outside of this list or develops its own analytics service from scratch, we will not detect it.\n\nSecondly, it is worth noting that our study is limited to analyzing data collection practices in Android apps. The information regarding claims on data types and means of collection were derived from the documentation of Android and related analytics libraries.\n\n\nAnother limitation is that the APP-350 corpus is three years old, and privacy policies may have since changed. \nA more recent policy corpus could have led to new insights about current practices in user interaction data collection. \nAdditionally, we only manually fact-checked 10 apps due to the complexity of fitting different UI types and callbacks into the fixed six data types and three means of collection. \n\n\n\n\n\u00a7 RELATED WORK\n\nThe related work can be categorized into two themes: code analysis, privacy policy analysis, policy generation, and the privacy implications of analytics services.\nVarious studies have examined the extent to which information can be extracted from privacy policies\u00a0<cit.>, particularly related to opt-out mechanisms\u00a0<cit.>, purposes for app permission usages\u00a0<cit.>, and sections relevant under the GDPR\u00a0<cit.>. PrivacyFlash Pro\u00a0<cit.> was proposed as a privacy policy generator for iOS apps that leverages static analysis to identify privacy-related code features.\n\nOther studies have focused on how analytics services can be used to capture user data. \nAlde\u00a0<cit.> proposed a solution that uses both static and dynamic analysis to detect the key information analytics libraries collect, mostly on device-level information. \nOn the other hand, PAMDroid\u00a0<cit.> identifies personal data that flows into analytics services and defines it as a misconfiguration.\n\nThese studies have contributed to the understanding of privacy policies and data collection practices in mobile apps. \nHowever, there is a lack of research specifically on the practices of user interaction data collection and the transparency of related claims in privacy policies. That is the subject of this paper.\n\n\n\n\u00a7 CONCLUSION AND FUTURE WORK\n\nThis paper addresses the lack of transparency in user interaction data collection practices in mobile apps. \nWe proposed a standardized claim template for user interaction data collection and utilized static analysis to extract evidence of these claims from Android apps. \nOur analysis of 100 popular apps revealed that 89% of them collected user interaction data using various types and means. \nHowever, when we manually fact-checked the top 10 apps, we found incompleteness in all of their claims about such collection.\nThis highlights the importance of clear and comprehensive claims related to user interaction data collection and the potential of standardized claims to increase transparency. \n\n\n\n\nThere are limitations to our approach that point toward future work: \nOur analysis only included the top 20 analytics services, and our study was limited to Android apps. \nMoreover, our manual fact-checking of the 10 top apps relied on our interpretation of their policies. \nTo address these limitations, future research could employ machine learning models to further automate the fact-checking process and get more comprehensive results.\n\nIn conclusion, our study underscores the significance of complete claims related to user interaction data collection in mobile apps. \nThe findings of our study provide a foundation for future research and policy efforts aimed at increasing transparency in mobile app data collection practices.\n\n\n\n\n\u00a7 ACKNOWLEDGEMENTS\n\nThis work is part of the Privacy Matters (PriMa) project. \nThe PriMa project has received funding from European Union\u2019s Horizon 2020 research and innovation program under the Marie Sk\u0142odowska-Curie grant agreement No. 860315.\n\n\n\n\n\n\n\n\n splncs04\n \n\n"}