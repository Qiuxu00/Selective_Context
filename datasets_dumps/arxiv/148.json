{"entry_id": "http://arxiv.org/abs/2303.07151v1", "published": "20230313142539", "title": "Am\u00e9lioration de la qualit\u00e9 d'images avec un algorithme d'optimisation inspir\u00e9e par la nature", "authors": ["Olivier Parisot", "Thomas Tamisier"], "primary_category": "cs.CV", "categories": ["cs.CV"], "text": "\n\nL'am\u00e9lioration de la qualit\u00e9 des images est un sujet d'int\u00e9r\u00eat dans le domaine de la vision par ordinateur.\nDe nouvelles techniques sont r\u00e9guli\u00e8rement propos\u00e9es afin de traiter efficacement le flou, le bruit, les probl\u00e8mes de contraste et m\u00eame la faible r\u00e9solution (<cit.>).\nAinsi, la s\u00e9lection et l'application de transformations appropri\u00e9es est une t\u00e2che complexe qui n\u00e9cessite un savoir-faire et des outils sp\u00e9cifiques pour le traitement d'images.\nDans un premier temps, il est essentiel d'utiliser des m\u00e9triques pour guider le processus: \u00e0 cet \u00e9gard, l'\u00e9valuation de la qualit\u00e9 des images (IQA \u2013 Image Quality Assesment) vise \u00e0 estimer automatiquement la qualit\u00e9 d'une image de mani\u00e8re \u00e0 ce qu'elle corresponde \u00e0 une \u00e9valuation humaine subjective (<cit.>).\n\nPar ailleurs, en recherche scientifique et en ing\u00e9nierie, il est plus que jamais utile voire n\u00e9cessaire de garantir la reproductibilit\u00e9 des exp\u00e9riences sur les jeux de donn\u00e9es \u00e0 base d'images en disposant de la trace des transformations effectu\u00e9es (<cit.>).\n\nUn travail r\u00e9cent a montr\u00e9 qu'une information compl\u00e8te et rigoureuse au sujet des traitements effectu\u00e9s sur les images fait d\u00e9faut dans une grande proportion d'articles scientifiques, ce qui peut compromettre l'interpr\u00e9tation des r\u00e9sultats obtenus (<cit.>).\nNous pouvons faire une analogie avec l'apprentissage automatique lorsqu'il est appliqu\u00e9 sur des donn\u00e9es num\u00e9riques ou cat\u00e9gorielles: le pr\u00e9traitement des donn\u00e9es doit \u00eatre document\u00e9 de mani\u00e8re pr\u00e9cise pour aboutir \u00e0 des mod\u00e8les pr\u00e9dictifs significatifs et de confiance (<cit.>).\n\nL'approche que nous pr\u00e9sentons proc\u00e8de par optimisation inspir\u00e9e de la nature pour am\u00e9liorer une image: elle s'appuie sur des m\u00e9thodes standard d'\u00e9valuation de la qualit\u00e9 et elle construit la trace explicite de la s\u00e9quence de transformations successivement op\u00e9r\u00e9es.\nLe reste de cet article est organis\u00e9 comme suit. \nTout d'abord, les travaux connexes sur l'\u00e9valuation de la qualit\u00e9 et l'optimisation inspir\u00e9e par la nature pour les images sont bri\u00e8vement pr\u00e9sent\u00e9s (Section <ref>). \nEnsuite, notre approche pour am\u00e9liorer la qualit\u00e9 des images est introduit (Section <ref>). \nUn prototype est d\u00e9crit (Section <ref>) et les r\u00e9sultats des exp\u00e9riences r\u00e9alis\u00e9es sont discut\u00e9s (Section <ref>).\nPour finir, nous concluons en ouvrant quelques perspectives (Section <ref>).\n\n\n\n\n\u00a7 ETAT DE L'ART\n\n\n\n\n\n \u00a7.\u00a7 Evaluation de la qualit\u00e9 d'image\n\n\nDe nombreuses approches d'\u00e9valuation de la qualit\u00e9 d'image ont \u00e9t\u00e9 d\u00e9velopp\u00e9es ces derni\u00e8res ann\u00e9es et une liste exhaustive a d\u00e9j\u00e0 \u00e9t\u00e9 compil\u00e9e par <cit.>. \nOn peut distinguer deux grandes familles de techniques: \n\n\n  * Les m\u00e9thodes \u00e0 r\u00e9f\u00e9rence compl\u00e8te (Full Reference IQA \u2013 FR-IQA) et \u00e0 r\u00e9f\u00e9rence r\u00e9duite (Reduced Reference IQA \u2013 RR-IQA) sont bas\u00e9es sur un r\u00e9f\u00e9rentiel d'images (brutes/d\u00e9form\u00e9es). \n\n  * Les techniques sans r\u00e9f\u00e9rence (No Reference IQA \u2013 NR-IQA) et \u00e0 l'aveugle (Blind-IQA) visent \u00e0 estimer la qualit\u00e9 de mani\u00e8re non supervis\u00e9e (<cit.>).\n \n\nDans cet article, nous nous concentrons sur l'utilisation d'approches NR-IQA et Blind-IQA et parmi lesquelles nous pouvons citer:\n\n\t\n  * BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator) propos\u00e9 par <cit.>: un score entre 0 et 100 est produit (0 pour une image de bonne qualit\u00e9, 100 pour une qualit\u00e9 m\u00e9diocre) .\n\t\n  * NIMA (Neural Image Assessment) introduit par <cit.>: un ensemble de mod\u00e8les de Deep Learning pour estimer la qualit\u00e9 esth\u00e9tique et technique des images: un score entre 0 et 10 est produit (0 pour une image de mauvaise qualit\u00e9, 10 pour une image de bonne qualit\u00e9).\n\n\nEn pratique, ces m\u00e9thodes d'\u00e9valuation sont largement utilis\u00e9es dans les benchmarks pour comparer l'efficacit\u00e9 des algorithmes de traitement d'images, comme d\u00e9crit par <cit.>.\nElles permettent de d\u00e9tecter avec une efficacit\u00e9 certaine les images de mauvaise qualit\u00e9.\n\n\n\n\n \u00a7.\u00a7 Optimisation inspir\u00e9e par la nature pour le traitement d'images\n\n\nA l'instar des r\u00e9seaux neuromim\u00e9tiques, de nombreuses approches de r\u00e9solution de probl\u00e8mes ou d'optimisation sont inspir\u00e9es par des processus naturels, notamment les algorithmes \u00e9volutionnaires et l'optimisation par essaims de particules (<cit.>).\nCes techniques sont fr\u00e9quemment appliqu\u00e9es en vision par ordinateur pour diverses t\u00e2ches telles que la r\u00e9duction du flou et du bruit, la restauration et la segmentation (<cit.>).\nEn particulier, <cit.> propose un algorithme g\u00e9n\u00e9tique pour mettre en valeur automatiquement une image en la modifiant de mani\u00e8re progressive.\n\nDans la suite de cet article, nous proposons une solution pour la g\u00e9n\u00e9ration de s\u00e9quences ordonn\u00e9es de transformations d'images en appliquant avec un algorithme guid\u00e9 par les techniques d'\u00e9valuation de la qualit\u00e9 des images pr\u00e9c\u00e9dement cit\u00e9es.\n\n\n\n\n\u00a7 APPROCHE\n\n\n\nL'\u00e9l\u00e9ment central de l'approche est d\u00e9fini de la mani\u00e8re suivante:\n\n\t\n  * Une image initiale.\n\t\n  * Une s\u00e9quence ordonn\u00e9e de transformations appliqu\u00e9e sur l'image initiale (exemples: ajustement du contraste puis suppression du brouillard, suivi d'un ajustement de l'histogramme et d'un d\u00e9bruitage par variation totale, etc.). Au d\u00e9part, cette s\u00e9quence est vide.\n\t\n  * Un score de qualit\u00e9 est \u00e9valu\u00e9 avec les m\u00e9thodes d'\u00e9valuation de la qualit\u00e9 de l'image BRISQUE ou NIMA (esth\u00e9tique ou technique). Cette \u00e9tape est critique et pilote l'algorithme (la qualit\u00e9 sert ici de fitness de la solution, dans la terminologie utilis\u00e9e pour les algorithmes \u00e9volutionnaires).\n\n\nPour une image d'entr\u00e9e donn\u00e9e (I), en consid\u00e9rant une m\u00e9thode d'\u00e9valuation de la qualit\u00e9 de l'image (M) et un nombre maximum d'\u00e9poques (E), l'algorithme suivant calcule un ensemble de s\u00e9quences ordonn\u00e9es de transformations \u00e0 appliquer sur l'image: \n\n\t\n  * Une population est g\u00e9n\u00e9r\u00e9e avec P images: chaque image est un clone de l'image initiale I sur laquelle une transformation al\u00e9atoire a \u00e9t\u00e9 appliqu\u00e9e ou non. En effet, pour s'assurer que l'algorithme ne conduit pas \u00e0 une image de moindre qualit\u00e9, il est important de conserver au moins un clone non modifi\u00e9 de l'image initiale dans la population dans le cas o\u00f9 l'algorithme ne produit pas de meilleure solution.\n\t\n  * Pendant E it\u00e9rations :\n\t\n\t\t\n  * La meilleure image pr\u00e9sente dans la population ainsi qu'une autre image choisie au hasard sont clon\u00e9es, puis une transformation al\u00e9atoire est appliqu\u00e9e pour chacune: les images nouvellement cr\u00e9\u00e9es sont \u00e9valu\u00e9es avec M et ajout\u00e9es \u00e0 la population.\n\t\t\n  * Une autre image est s\u00e9lectionn\u00e9e al\u00e9atoirement dans la population et est empil\u00e9e avec l'image initiale (avec un poids al\u00e9atoire): l'\u00e9l\u00e9ment nouvellement cr\u00e9\u00e9 est \u00e9valu\u00e9 avec M et ajout\u00e9 \u00e0 la population.\n\t\t\n  * Selon l'\u00e9valuation avec M des images pr\u00e9sentes dans la population, les plus mauvaises images sont s\u00e9lectionn\u00e9es puis retir\u00e9es de la population (pour toujours garder P images dans la population).\n\t\n\t\n  * Le r\u00e9sultat final est l'image de la population consolid\u00e9e ayant la meilleure estimation de qualit\u00e9. La sortie de l'algorithme est alors une s\u00e9quence ordonn\u00e9e de transformations qui conduit \u00e0 une am\u00e9lioration de l'\u00e9valuation de la qualit\u00e9 de l'image.\n\n\nPour \u00e9viter que l'image ne diff\u00e8re trop de l'image initiale, nous avons ajout\u00e9 un test comparant la similarit\u00e9 entre l'image produite et l'image initiale: si la similarit\u00e9 est trop faible (c'est-\u00e0-dire inf\u00e9rieure \u00e0 un seuil pr\u00e9d\u00e9fini T), alors le score de l'image est fortement p\u00e9nalis\u00e9 et la derni\u00e8re transformation appliqu\u00e9e n'est donc pas consid\u00e9r\u00e9e comme acceptable.\nLe test est ici bas\u00e9 sur l'indice de similarit\u00e9 structurelle (Structural Similarity Index): en pratique, la valeur est proche de 1 lorsque les deux images sont similaires alors que la valeur est proche de 0 lorsque les images sont vraiment diff\u00e9rentes.\n\n\n\n\n\u00a7 IMPLEMENTATION ET EXP\u00c9RIENCES\n\n\n\nL'algorithme a \u00e9t\u00e9 impl\u00e9ment\u00e9 dans un prototype Python.\nDivers composants open-source standards ont \u00e9t\u00e9 int\u00e9gr\u00e9s.\nLe chargement et la transformation des images sont r\u00e9alis\u00e9s \u00e0 l'aide de divers packages Python d\u00e9di\u00e9s tels que openCV [<https://pypi.org/project/opencv-python/>] et scikit-images. [<https://pypi.org/project/scikit-image/>].\nLe score BRISQUE est calcul\u00e9 gr\u00e2ce au package image-quality [<https://pypi.org/project/image-quality/>] et les scores NIMA sont fournis par une impl\u00e9mentation de Tensorflow [<https://github.com/idealo/image-quality-assessment>].\n\nEn utilisant ces composants, les transformations d'images suivantes peuvent \u00eatre appliqu\u00e9es et combin\u00e9es \u00e0 la vol\u00e9e via notre prototype:\n\n\t\n  * D\u00e9bruitage via diff\u00e9rentes m\u00e9thodes: variation totale, moyennes non locales, ondelettes, bilat\u00e9ral.\n\t\n  * Ajustement du contraste et de la luminosit\u00e9 notamment via des algorithmes comme CLAHE (Contrast Limited Adaptive histogram equalization, <cit.>). \n\t\n  * Traitement du background, notamment pour am\u00e9liorer les images \u00e0 faible luminosit\u00e9 (<cit.>).\n\t\n  * Att\u00e9nuation du brouillard via des mod\u00e8les de Deep Learning comme Cycle-Dehaze (<cit.>).\n\t\n  * Transformations morphologiques comme erosion et dilatation (<cit.>).\n\t\n  * Reconstruction des d\u00e9tails avec des mod\u00e8les comme Noise2Noise (<cit.>).\n\t\n  * Empilage pond\u00e9r\u00e9 et/ou soustraction d'images.\n\n\nCe code Python a \u00e9t\u00e9 d\u00e9velopp\u00e9 de mani\u00e8re \u00e0 pouvoir \u00eatre ex\u00e9cut\u00e9 sur une infrastructure haute performance ayant la configuration mat\u00e9rielle suivante: 40 c\u0153urs et 128 Go de RAM (CPU Intel(R) Xeon(R) Silver 4210 @ 2,20 GHz) et NVIDIA Tesla V100-PCIE-32 Go.\nPlus pr\u00e9cis\u00e9mment, les librairies CUDA [<https://developer.nvidia.com/cuda-zone>] et NUMBA [<http://numba.pydata.org/>] ont \u00e9t\u00e9 utilis\u00e9es autant que possible pour acc\u00e9l\u00e9rer l'ex\u00e9cution de code sur cette infrastructure.\n\n\n\n\n\u00a7 EXP\u00c9RIENCES\n\n\n\n\n\nL'algorithme a d'abord \u00e9t\u00e9 test\u00e9 sur des photographies telles que Figure <ref> [<https://commons.wikimedia.org/wiki/Main_Page>].\nDans l'exemple de l'image de la fus\u00e9e, les transformations suivantes ont \u00e9t\u00e9 appliqu\u00e9es sur une version volontairement alt\u00e9r\u00e9e de la photographie initiale: d\u00e9sembrumage, empilement avec image initiale (avec poids \u00e0 0.8), d\u00e9bruitage par filtrage bilateral, augmentation du contraste, traitement de la nettet\u00e9 (avec beta \u00e0 0.95), augmentation du contraste, d\u00e9bruitage par filtrage bilateral, suppression du fond, augmentation du contraste, traitement de la nettet\u00e9 (beta: 1.05).\nCette s\u00e9quence ordonn\u00e9e d'op\u00e9rations permet d'am\u00e9liorer la qualit\u00e9 mesur\u00e9e de l'image d\u00e9grad\u00e9e (en se r\u00e9f\u00e9rant aux scores BRISQUE et NIMA).\n\nDans un second temps, plusieurs jeux de donn\u00e9es de r\u00e9f\u00e9rence en traitement d'images ont \u00e9t\u00e9 consid\u00e9r\u00e9es durant nos exp\u00e9rimentations: TID2013 avec 500 images d\u00e9form\u00e9es choisies au hasard (<cit.>) et LIVE avec 175 images bruit\u00e9es (<cit.>).\nDe plus, nous avons test\u00e9 l'approche sur les benchmarks CID2013 et LOL: le premier contient 475 images captur\u00e9es avec des appareils grand public comme les smartphones (<cit.>) et le second consiste en 485 images \u00e0 faible luminosit\u00e9 (<cit.>).\n\nLes r\u00e9sultats du Tableau <ref> ont \u00e9t\u00e9 obtenus avec les hyperparam\u00e8tres suivants: NIMA-esth\u00e9tique comme score d'\u00e9valuation de la qualit\u00e9 d'image cibl\u00e9e, une population initiale de 20 images, 50 \u00e9poques maximum et 0,5 comme similarit\u00e9 minimale.\nSelon nos diff\u00e9rents essais, cette configuration de l'algorithme offre le meilleur compromis entre l'am\u00e9lioration de la qualit\u00e9 et le temps d'ex\u00e9cution. \nLe score BRISQUE a \u00e9t\u00e9 calcul\u00e9 par la suite pour estimer d'une autre mani\u00e8re et \u00e0 posteriori la qualit\u00e9 des r\u00e9sultats de l'algorithme et la variance du bruit (Noise Variance) a \u00e9t\u00e9 calcul\u00e9e pour mettre en \u00e9vidence le niveau de bruit dans les benchmarks.\n\n\n\n\nD'apr\u00e8s ces premi\u00e8res exp\u00e9riences, les scores de qualit\u00e9 (NIMA-esth\u00e9tique et BRISQUE) sont meilleurs pour les images provenant des benchmarks TID2013 et LIVE apr\u00e8s l'ex\u00e9cution de notre algorithme.\nIdem pour le bruit: notre algorithme tend \u00e0 le r\u00e9duire dans les images transform\u00e9es pour ces benchmarks.\n\nNous notons cependant que les r\u00e9sultats pour les images \u00e0 faible luminosit\u00e9 sont partiellement satisfaisants (benchmark LOL).\nM\u00eame si les transformations calcul\u00e9es par notre algorithme augmentent le score NIMA-esth\u00e9tique comme souhait\u00e9, elles ont tendance \u00e0 d\u00e9grader le score BRISQUE et \u00e0 augmenter le bruit.\nCe probl\u00e8me montre les limites de NIMA et BRISQUE pour l'\u00e9valuation de la qualit\u00e9 des images \u00e0 faible luminosit\u00e9: ces m\u00e9thodes ne devraient pas \u00eatre utilis\u00e9es pour guider la transformation de telles images.\n\nEn ce qui concerne les performances de calcul, le temps n\u00e9cessaire pour ex\u00e9cuter le prototype Python \u00e9tait raisonnable en utilisant l'infrastructure d\u00e9crite ci-dessus (de quelques secondes \u00e0 plusieurs dizaines de secondes par image, en fonction de leur r\u00e9solution). \nLe temps d'ex\u00e9cution du prototype d\u00e9pend pour l'essentiel de la m\u00e9thode d'\u00e9valuation de la qualit\u00e9 appliqu\u00e9e: par exemple, l'\u00e9valuation NIMA-esth\u00e9tique est r\u00e9alis\u00e9e en moyenne en moins de 100 millisecondes tandis que l'\u00e9valuation du score BRISQUE peut prendre plusieurs secondes.\nEn pratique, ce temps peut \u00eatre r\u00e9duit en diminuant la taille des images avant \u00e9valuation (mais cela affecte \u00e9galement la pr\u00e9cision des \u00e9valuations, ce qui n'est pas forc\u00e9ment souhaitable).\n\n\n\n\n\n\n\u00a7 CONCLUSION AND PERSPECTIVES\n\n\n\nCet article pr\u00e9sente un algorithme d'optimisation inspir\u00e9e de la nature am\u00e9liorant la qualit\u00e9 mesur\u00e9e d'une image avec le calcul d'une s\u00e9quence ordonn\u00e9e et reproductible de transformations \u00e0 appliquer.\nUn prototype Python bas\u00e9 sur les m\u00e9thodes d'\u00e9valuation de la qualit\u00e9 des images a \u00e9t\u00e9 mis en oeuvre et test\u00e9 sur diverses bases de donn\u00e9es d'images de l'\u00e9tat de l'art.\n\nDivers partenaires acad\u00e9miques et op\u00e9rationnels permettront de mettre en place des cas d'utilisation r\u00e9els de l'approche (notamment en bio-informatique).\nEn parall\u00e8le, nous am\u00e9liorons le prototype en g\u00e9n\u00e9rant automatiquement le code source Python permettant de transformer les images, en nous inspirant de ce qui est propos\u00e9 dans les approches AutoML (Automated Machine Learning).\nDe plus, les futurs cas d'utilisation seront \u00e9galement utilis\u00e9s pour am\u00e9liorer le prototype propos\u00e9 sur les images \u00e0 faible luminosit\u00e9.\nEnfin, les performances d'ex\u00e9cution seront renforc\u00e9es en distribuant les calculs via des frameworks comme Spark.\n\n\n\n\n\n\n\u00a7 REMERCIEMENTS\n\n\nCe travail a \u00e9t\u00e9 r\u00e9alis\u00e9 en utilisant la plateforme Artificial Intelligence, Data Analytics op\u00e9r\u00e9e par le Luxembourg Institute of Science and Technology.\nDans ce cadre, nous remercions tout particuli\u00e8rement Jean-Fran\u00e7ois Merche et Raynald Jadoul pour leur support.\n\n\nrnti\n\n\n\n\n\n\n\n"}