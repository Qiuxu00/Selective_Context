{"entry_id": "http://arxiv.org/abs/2303.07176v1", "published": "20230313151755", "title": "Reduced order model of a convection-diffusion equation using Proper Orthogonal Decomposition", "authors": ["Neelakantan Padmanabhan"], "primary_category": "math.NA", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "text": "\n\n\nProbabilistic Uncertainty-Aware Risk Spot \n Detector for Naturalistic Driving\n    Tim Puphal, Malte Probst and Julian Eggert\n\n\n The authors are with the Honda Research Institute (HRI) Europe, Carl-Legien-Str. 30, 63073 Offenbach, Germany \n\t(e-mail: tim.puphal@honda-ri.de; malte.probst@honda-ri.de; julian.eggert@honda-ri.de) \n\n    March 30, 2023\n=========================================================================================================================================================================================================================================================\n\n\n\n\u00a7 ABSTRACT\n\nIn this work, a numerical simulation of 1D Burgers' equation is developed using finite difference method and a reduced order model (ROM) of the simulation is developed using proper orthogonal decomposition (POD). The objective of this work is to provide an introduction of the POD method to researchers interested in computational fluid dynamics (CFD). This work discusses a physical interpretation of the POD method, its strengths and shortcomings and an implementation of the algorithm that may be extended to 2D, 3D Burgers' equation and other non-linear partial differential equations (PDE) of this class, to develop models for more complex systems.\n\n\n\n\u00a7 INTRODUCTION\n\nBurgers' equation is a fundamental nonlinear partial differential equation that finds applications in the areas of thermo-fluids and CFD <cit.>. It is a generalized convection-diffusion equation and falls under the same category of equations as the Navier-Stokes equations. Numerical solution and reduced order modeling of Burgers' equation, is of great interest in the CFD community. Numerical solution of Burgers' equation and other PDEs of this class can be computationally very expensive <cit.>. Thus, reduced order models are highly desirable since they can capture the essence of the phenomenon with a fraction of the computational resources. POD / PCA (principal component analysis) is a well established approach to develop reduced order models <cit.>. For a given data, POD extracts the modes that contain the most dominant characteristics of the data. In a function space, these modes form the orthonormal basis that can be used to reconstruct the data. Ideally, POD modes can be constructed from any simulation or experimental data and if the governing equations of the system are known, Galerkin projection may be applied on a subset of this basis to create a ROM, to predict the time evolution of the system. While this approach results in accurate ROM for systems with high diffusivity, the predictions for systems with low diffusivity especially for long simulation times are observed to be less accurate. A number of improvements to this method have been proposed, that help in developing more accurate models. Some of these include a large eddy simulation like approach <cit.>, where the large scale effects are modeled by POD and the small scale effects are modeled by eddy viscosity type model <cit.>, goal-oriented POD <cit.>, and discrete empirical interpolation method (DEIM) <cit.>. \n\n\n\n\u00a7 NUMERICAL SIMULATION OF BURGERS' EQUATION\n\n1D Burgers' equation of the form presented in Eq.<ref> is solved using finite difference approach. \n\n    \u2202 U/\u2202 t = - U \u2202 U/\u2202 x + \u03bd\u2202 ^2 U/\u2202 x^2 + Q,\n\nwhere, U=U(x,t) represents a field variable, t represents time, x represents the spatial vector, \u03bd represents the diffusivity, and Q a source term. The generic Burgers' equation incorporates a non-linear convection term, and a linear diffusion term. An additional source term is considered in this work. A second order central finite difference scheme is used for spatial discretization of the diffusion term, while a second order upwind scheme is employed for the nonlinear convection term. An explicit forward Euler scheme is used for time stepping. \n\n    U(x,t+\u0394 t) - U(x,t)/\u0394 t = -U(x,t) 3 U(x,t)-4 U(x-\u0394 x,t) + U(x-2\u0394 x,t)/2\u0394 x\n     + \u03bdU(x+\u0394 x,t) - 2 U(x,t) + U(x-\u0394 x,t)/\u0394 x^2 + Q\n\nThe equations are solved on an equally spaced Cartesian grid. Constant diffusivity values are used in the simulations. CFL conditions for velocity and diffusivity are used to determine the minimum time step. Periodic boundary conditions are used in the domain. The following initial conditions are used for the field variable and source term, \n\n    U(x,0) = U_0 sin(x),\n    \n        Q(x,0) = Q_0 sin(x),\n\nwhere, u_0=0.01, Q_0=0.1. Simulations are run for various configurations of number of grid points and duration (t_final). The results from the numerical simulations are presented in Figs. <ref>-<ref>.\n\n\n\u00a7 REDUCED ORDER MODELING\n\nAn overview of a few concepts of linear algebra that are central to the POD method is presented in Appendix <ref>. A brief review of this section might be useful in developing a better understanding of the method. \n\n\n \u00a7.\u00a7 A physical interpretation of POD\n\nSolutions of Burgers' equation (U(x,t)=U \u2208\u211d^m \u00d7 n, with m spatial points and n temporal points), can be expressed analytically in terms of the basis vectors x and t, in a physical space. While it is desirable, it is not always convenient or viable to obtain an analytical solution in this space. Alternatively, this solution can be also expressed in terms of a different set of basis vectors in a function space. This alternative basis can be determined by singular value decomposition (SVD) of the solution matrix U or by eigen decomposition of the covariance matrices of the solution matrix (Cov_1(U)=UU^* and Cov_2(U)=U^*U). The covariance matrices, represent the variance exhibited by the elements of the solution matrix U and the covariance between the pairs of dataset. It is useful in separating structured relationships in a matrix of random variables. When eigen decomposition of the covariance matrix is performed, it results in a factorization of the form Cov(U)=V\u039b V^-1. Here, V represents the eigenvectors or the principle components and \u039b represents the eigenvalues of the covariance matrix. Geometrically, this can be interpreted as a linear transformation represented by Cov(U) which when applied to the vectors V, only results in V scaling up or down by a factor of \u039b. Since Cov(U) represent the variance in the data, the vectors V indicate the directions along which the variance in the data is the highest or the lowest and \u039b represents the magnitude of significance of the given eigenvector. In other terms, the variance indicates how the energy or information of the solution is distributed and the eigenvectors indicate the directions in which the distribution is significant. A graphical illustration of this is presented in Fig.<ref>. In a function space, the vectors V form an orthonormal basis. In many cases (except the cases with very low diffusivity in the Burgers' equation), it is observed that the first few basis vectors (or modes) typically contain most of the energy of the solution. Hence, by projecting U on these first few modes, the highest energy solutions can be recovered. By Galerkin projection of a weak form of the governing equation onto a sub-space of this basis, a reduced order model can be obtained, from which the time evolution of the system can be predicted.\n\n\n\n\n\n \u00a7.\u00a7 Formal description of POD\n\nSnapshots of the field variable, U \u2208\u211d^m \u00d7 n of m spatial points and n temporal points are obtained from the numerical simulation of 1D Burgers' equation. Singular value decomposition of this matrix, decomposes the solution into,\n\n    SVD(U) = \u03a6\u03a3\u03a8^*,\n\nwhere, the matrix \u03a6\u2208\u211d^m \u00d7 m represents the left singular vector and \u03a8^* \u2208\u211d^n \u00d7 n the conjugate transpose of the right singular vector. These matrices are composed of the eigenvectors \u03d5 (columns of \u03a6), \u03c8 (rows of \u03a8^*) of the covariance matrices U^*U and U U^*. The matrix \u03a3\u2208\u211d^m \u00d7 1 represents the singular values of U. The singular values are ordered as \u03c3_1 \u2265\u03c3_2 \u2265...\u2265\u03c3_m. The i^th row of the solution matrix thus can be written as,\n\n    u_i = \u2211_i ^m \u03c3_i \u03d5_ij\u03c8_ik.\n\n\u03c3_i represents the magnitude of significance of the modes. The relative significance of the modes can be estimated as,\n\n    r = \u03c3_i/\u2211_i=1\u03c3_i,\n\nwhere, \u2211 r=1. As observed in Figs. <ref>-<ref>, when the diffusivity coefficient (\u03bd) is high, the first three to five modes contain upto 99 % of the energy. A reduced solution can then be obtained by choosing a few dominant modes (r). Once the low dimensional basis set has been determined, it can be used to reformulate the Burgers' equation to create a reduced order model. Separation of variable and basis expansion is applied to Eq.<ref>, where the field variable is expressed as\n\n    U(x,t)= A(t) \u03a6(x) = \u2211_i=1 ^m a_ik (t) \u03d5_ij(x),\n\nwhere, \u03d5_ij(x) represents the orthonormal basis functions obtained by SVD of the data matrix, a_ik(t) the temporal coefficients, and i index of number of modes. It is to be noted that the basis function and temporal coefficients exist in a function space, where the continuous function U(x,t) is discretized into a system of finite dimensions. By substituting Eq.<ref> into Eq.<ref>, the PDE for U(x,t) can be transformed into an ordinary differential equation (ODE) for A(t). \n\n    d/dt\u2211 a_ik\u03d5_ij = - \u2211 a_ik\u03d5_ijd/dx\u2211 a_ik\u03d5_ij + \u03bdd ^2/dx^2\u2211 a_ik\u03d5_ij + Q,\n\nSince the basis functions are orthogonal they hold the property,\n\n    \u222b\u03d5_ij(x) \u03d5_il(x)^* dx =\n        \u2211\u03d5_ij(x) \u03d5_il (x) = \n        \n          1     j=l\n    \n          0     j \u2260 l\n\nThe final form of equation is obtained by multiplying both sides of Eq.<ref> by \u03d5_ij^T(x), \n\n    d/dt\u2211 a_ik = - \u03d5_ij^T \u2211 a_ik\u03d5_ijd/dx\u2211 a_ik\u03d5_ij + \u03d5_ij^T \u03bdd ^2/dx^2\u2211 a_ik\u03d5_ij + \u03d5_ij^T Q.\n\nTo build a reduced order model, a small number of modes (i<<m) are considered in Eq.<ref> and Eq.<ref>. The spatial derivatives in Eq.<ref> are solved using finite difference approach. Periodic boundary conditions are applied and the same initial condition (as the one used in the finite difference simulation), is imposed for the temporal coefficient a_0=U(x,0) \u03a6. This equation is then solved for a(t) using a standard ODE solver and a ROM is created by projection of this solution on \u03a6. The results from the ROM are compared against the numerical simulation and presented in Figs. <ref>-<ref>. It is observed that the ROM is very accurate in predicting the field variable's evolution in space and time with a few modes (i \u2264 5). For new initial and boundary conditions, it is sufficient to assemble a snapshot matrix considering different instances of initial and boundary conditions and compute the POD at an offline stage. The ratio of computation time required to run the finite difference simulation and the POD-ROM for various cases are presented in Table <ref>. In most cases, POD-ROM requires a smaller fraction of computation time when compared to the finite difference simulation. The costs of determination of POD basis and Galerkin projection increases with increase in number of dimensions, resolution and simulation run times.\n\n\n \u00a7.\u00a7 Implementation of POD\n\n\n     Compute the instantaneous field variable (U(x,t) \u2208\u211d^m \u00d7 n) from the finite difference solution of 1D Burgers' equation.\n     Decompose the instantaneous field variable via Singular value decomposition,\n    \n    SVD(U)=U_L \u00b7 S \u00b7 V_\u211d^*.\n\n    U_L \u2208\u211d^m \u00d7 m: Spatial modes (left singular vector), S \u2208\u211d^m \u00d7 1: Magnitude of the modes (singular values), V_\u211d^* \u2208\u211d^n \u00d7 n: Temporal coefficients (complex conjugate of the right singular vector). Note: The singular values and vectors are ordered in a descending order.\n     Determine the number of significant modes by computing the relative magnitude of the singular values,\n    \n    r_k=S_k^2/\u2211_k S_k^2,k=1,2,\u2026,m.\n\n     Choose a small number of modes (i) based on the values of r (i \u226a m).\n     \tCreate new matrices with the reduced number of spatial modes and their corresponding temporal coefficients.\n    \n    \u03d5=U_L \u2208\u211d^m \u00d7 i,\n\n    \n    \u03c8=V_\u211d^T \u2208\u211d^i \u00d7 n,\n\n    \n    \u03c3= S \u2208\u211d^i \u00d7 1.\n\n     Specify initial condition (same initial condition as the numerical simulation). The initial temperature is projected onto the reduced basis,\n    \n    a_0=\u03d5\u00b7 U(x,0).\n\n     Compute first derivative \u03d5_x (upwind scheme) and second derivatives \u03d5_xx (central finite difference) of the spatial modes.\n     Assemble the parameters: modes, temporal coefficients, derivatives, initial conditions, boundary conditions, source, and diffusivity coefficients\n    \n    Parameters=[\u03d5^T,\u03d5,\u03d5_x,\u03d5_xx,Q,\u03bd].\n\n     Perform Galerkin projection by applying separation of variable to the data matrix and combining it with the governing equation,\n    \n    U(x,t)=A(t) \u03a6(x),\n\n    \n    d/dt\u2211_i \u03d5_i a_i = -\u2211_i \u03d5_i a_i d/dx\u2211_i \u03d5_i a_i + \u03bdd^2/dx^2\u2211_i \u03d5_i a_i + Q.\n\n     Invoke the orthogonality property,\n     \n    \u222b\u03d5_i \u03d5_j dx = \n        \n          1,     i=j\n    \n          0,     i \u2260 j\n\n     Multiply both sides of the equation by \u03d5_i ^T\n     \n    d/dt\u2211_i a_i = -\u03d5_i ^T \u2211_i \u03d5_i a_i d/dx\u2211_i \u03d5_i a_i + \u03d5_i ^T \u03bdd^2/dx^2\u2211_i \u03d5_i a_i + \u03d5_i ^T Q.\n\n      Compute the right hand side of the equation: \n     \n    RHS = rhs_C + \u03bd\u00b7 rhs_D + rhs_S,\n\n     where,\n      U=\u03d5\u00b7 a, which is equivalent to \u2211_i \u03d5_i a_i,\n      rhs_C = -\u03d5^T \u00b7 U \u00b7\u03d5_x \u00b7 a, which is equivalent to -\u03d5_i ^T \u2211_i \u03d5_i a_i d/dx\u2211_i \u03d5_i a_i,\n      \u03bd\u00b7 rhs_D = \u03d5^T \u00b7\u03bd\u00b7\u03d5_xx, which is equivalent to \u03bdd^2/dx^2\u2211_i \u03d5_i a_i,\n      rhs_S = \u03d5^T Q, which is equivalent to \u03d5_i ^T Q.\n     Compute the temporal coefficient using a standard ODE solver,\n    \n    a(t) = Standard.ODE.Solver(RHS,a_0,t,Parameters).\n\n     Compute the time evolution of the reduced order model of the system,\n    \n    U_ROM (t) = a(t) \u03d5.\n\n\n\n\n\u00a7 RESULTS\n\nThe results presented in this section evaluate the accuracy of POD-ROM for the following cases, Case 1: simulation with high diffusivity and short simulation run time (t_final), Case 2: simulation with high diffusivity and longer simulation run time, Case 3: simulation with low diffusivity and short run time, Case 4: simulation with low diffusivity and longer run time, and Case 5: heat equation with only diffusion term (Burgers' equation without convection term). For each case, the percentage error between the simulation and the model data is computed. For the case with high diffusivity and short simulation time (Fig.<ref>), it is observed that a satisfactory ROM can be created with as few as 1-3 dominant modes. However, with 5 dominant modes, the original data can be reconstructed with negligible error. At longer simulation times as in Case 2 (Fig. <ref>), a larger number of modes are required to reconstruct the data. For Case 1, it is observed that the POD-ROM constructed with 1 dominant mode between t=0 s and t=0.5 s captures the fluctuation in the field, but the POD-ROM constructed with 1 dominant mode in Case 2 does not capture the fluctuations between t=0 s and t=0.5 s. This occurs because the POD modes are constructed from the data obtained from a specific simulation. As a result the POD modes and the distribution of energy across the modes vary for different data. At lower diffusivities and shorter simulation times as in Case 3 (Fig. <ref>), the trends similar to Case 1, where the data can be reconstructed with a few dominant modes, are observed. However, with increase in simulation time as in Case 4 (Fig. <ref>), large transient fluctuations are observed. At low diffusivity, Burger's equation is driven primarily by the convection term. If a parallel between this equation and the Navier Stokes equation is drawn, this is similar to a case at high Reynolds number. In such a scenario a large range of spatial and temporal scales exist, and the energy distribution is no longer dominated by a few modes. As a result, the POD-ROM constructed even with a large number of modes (i= 5 or i= 30) is inaccurate. The differences between the original data and ROM are observed to accentuate at simulation times t > 10. For 1D heat equation (Burgers' equation without the convection term), it is observed that POD-ROM can be constructed with only 1-3 modes even when the diffusivity is very small. Convection term is the primary source of non-linearity and fluctuations in Burgers' equation and POD is a great tool for construction of ROM for linear PDEs. An additional case (Case 6 - Fig.<ref>) is evaluated where a highly diffusive first order upwind scheme is used for discretization of the convection term. In this case, the fluctuations in the original data are observed to dissipate at longer simulation times. As a result, the energy distribution has a few dominant modes and the POD-ROM reconstructed with the limited number of modes is still accurate. This however is not an elegant solution since the original data from the simulation is highly diffusive and unreliable. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSIONS\n\nThis work explores the development of ROM for 1D Burgers' equation using POD method. POD is very useful in creating fast and accurate ROM for a wide range of linear and non-linear equations. The primary idea of this work is to provide a feel for the method and present the material in an accessible format. It is the hope of the author that the reader is able to develop an appreciation for the approach and is able to apply it to more complex systems for reduction of computational times. \n\n\n\nunsrt\n\n\n\n\n\u00a7 BACKGROUND IN LINEAR ALGEBRA AND RELEVANT TERMINOLOGIES\n \n(Excerpts of lectures on the topic of linear algebra <cit.>)\n\n    \n  * Vector space: A non-empty set V, of objects called vectors on which two operations (linear combinations) can be performed. Vector addition (u+v \u2208 V) and scalar multiplication (\u03bb u \u2208 V).\n    \n  * Span: A set of all possible vectors that can be formed by a linear combination of a set of vectors and scalars.\n    \n  * Space: For a given vector space, if the tails of the vectors are at the origin and the tip of the vectors point at different locations, a grid space can be created such that each grid point is located at the tip of a given vector.\n    \n  * Linear dependency: When two vectors point in the same coordinate direction and their span is restricted to a line or a plane, the vectors are called linearly dependent.\n    \n  * Basis: A set of linearly independent vectors that span the full space. An infinite set of basis vectors exist, however physically only three vectors are perceived. For example, in a Cartesian coordinate the coordinate directions x,y,z are defined as the basis.\n    \n  * Linear transformation / Matrix-Vector multiplication: An operation, which when applied to a vector, it either rotates, scales, or performs a combination of the two to move it to a new location in space. A linear transformation is performed via matrix-vector multiplication (Ax=b), where the matrix A is the linear transformation applied to vector x to form a new vector b. For a transformation to be defined as linear, the grids formed by the vector tips must remain parallel, evenly spaced and the origin must not move.\n    \n  * Matrix multiplication: A linear transformation that is defined as a combination of two linear transformations. \n    \n  * Change of Basis: A linear transformation that translates a vector representation in one basis to a representation of the same vector in a new basis. \n    \n  * Eigenvector and Eigenvalue: When a linear transformation A changes the basis, some of the vectors v in the space, remain on their span as an effect of the transformation. These vectors only scale in magnitude. This is defined as Av=\u03bb v, where v is defined as the Eigenvector and \u03bb is defined as Eigenvalue, which is a scaling factor. \n\t\n  * Eigen decomposition: A factorization of a matrix (A=V \u039b V^-1), where the matrix A is represented a product of its Eigenvalues \u039b and Eigenvectors V. Eigen decomposition can only be applied to square matrices. \n\t\n  * Singular value decomposition: A factorization of a real or complex matrix (A=U \u03a3 V^T) that is a generalization of Eigen decomposition but is applicable to non-square matrices as well. These factors may be physically interpreted as U (orthogonal matrix - rotation), \u03a3 (diagonal matrix - stretching), and V^T (orthogonal matrix - rotation)\n\t\n  * Function spaces : A set of all mathematical functions that have the same properties as vectors and vector spaces. For example, a function f(x) that can be expressed a sum of two other functions f(x)=u(x)+v(x) and a scalar product of another function f(x)=\u03bb w(x). From an abstract point of view, these functions are mathematically similar to a vectors and linear combinations can be applied to them to determine distance between them or to project them on one another. The difference in the analogy appears in the physical interpretation of the number of dimensions. It can be shown that an infinite number of linearly independent functions can be built from an infinite number of vectors to span the space. Therefore, functions exist in an infinite dimensional vector space. For example, a function f(x) specified in the interval [a,b], sampled at intervals x_1,x_2,\u2026,x_N with corresponding function values of f_1,f_2,\u2026,f_N, can be expressed as, \n    f(x)=[ f_1;   \u22ee; f_N ] =f_1 e_1+f_2 e_2+\u2026+f_N e_N,\n\nwhere, e_i represents the basis of the function that takes the value of 1 at the corresponding sampling point and 0 elsewhere. A Dirac delta function may be used as a basis function. This product gives an approximation of the original function, and the approximation gets better as the number of samples are increased. In the limit N \u2192\u221e, the basis functions become infinitely thin and infinitely many. Thus, the function over the interval is defined as,\n\n    f(x)=\u222b_a ^b f(\u03bb) e_\u03bb (x) d\u03bb.\n\nIt must be noted that rectangular function is only one possible set of basis function. Other basis functions may also be used here to express the function, however not all basis functions exhibit the property of orthogonality. Using this definition of function space, a number of useful properties may be obtained such as projection of a function onto subspace span of another set of functions and determination of orthogonality of two functions. For an orthonormal basis e_1,e_2,\u2026,e_N,\n\n    a = \u2211_i a_i e_i.\n\nInner product of two vectors: \u27e8 a,b \u27e9=a_1 b_1^*+a_2 b_2^*+\u2026+a_N b_N^*. Projection of a vector into a subspace of an orthonormal basis W=span[w_1,w_2,\u2026,w_M],\n\n    w=\u27e8 a,w_1 \u27e9 w_1+\u27e8 a,w_2 \u27e9 w_2+\u2026+\u27e8 a,w_M \u27e9 w_M.\n\n\n"}