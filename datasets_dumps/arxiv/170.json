{"entry_id": "http://arxiv.org/abs/2303.07119v1", "published": "20230313135130", "title": "Theory prediction in PDF fitting", "authors": ["Andrea Barontini", "Alessandro Candido", "Juan M. Cruz-Martinez", "Felix Hekhorn", "Christopher Schwan"], "primary_category": "hep-ph", "categories": ["hep-ph"], "text": "\n\n\n\n\n  1 TIF Lab, Dipartimento di Fisica, Universit\u00e0 degli Studi di Milano and INFN\n  Sezione di Milano, Via Celoria 16, 20133, Milano, Italy\n\n  2 CERN, Theoretical Physics Department, CH-1211 Geneva 23, Switzerland\n\n  3 Universit\u00e4t W\u00fcrzburg, Institut f\u00fcr Theoretische Physik und\n  Astrophysik, 97074 W\u00fcrzburg, Germany\n\n\n\nContinuously comparing theory predictions to experimental data is a common task in analysis of particle physics such as\nfitting parton distribution functions (PDFs). However, typically, both the computation of scattering amplitudes and the\nevolution of candidate PDFs from the fitting scale to the process scale are non-trivial, computing intesive tasks.\nWe develop a new stack of software tools that aim to facilitate the theory predictions by computing FastKernel (FK)\ntables that reduce the theory computation to a linear algebra operation. Specifically, I present PineAPPL, our workhorse\nfor grid operations, EKO, a new DGLAP solver, and yadism, a new DIS library. Alongside, I review several projects that\nbecome available with the new tools.\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nParton distribution functions\u00a0<cit.> (PDFs) describe the dynamics of the elementary partons, such as quarks and gluon,\ninside hadrons, such as the proton. PDFs are defined in factorization theorems in high-energy scattering\nand they encode the non-perturbative physics reigning inside hadrons.\nThe extraction of PDFs relies on three pillars: first, the precise measurements of observables at experiments, such as the LHC,\nsecond, the reliable theoretical predictions of the associated observable, and, third, combining the former two inside\na fitting framework. While either of these three steps poses several computational challenges,\nwe discuss here only the efficient computation of the theory predictions.\n\nThe computation of the various high-energy observables that enter a PDF fit are pursuit by different groups\napplying a range of strategies using several dedicated programs tailored to the specific case at hand.\nYet, in a PDF fit one wants to include consistently all predictions available, which can be up to\n4500 data points across almost 100 different datasets (as is the case, e.g., in <cit.>).\n\nTo achieve this goal we develop a framework of software tools, dubbed \u00a0<cit.>, that provides a\neasy accessible way to include theory prediction in QCD fitting applications such as PDF fits.\nWe put an explicit emphasis on the scalability of the procedure to ensure future measurements\nform new or existing experiments\u00a0<cit.> can be included\nseamlessly. We also strive to track all runcards and meta data in the generated objects to ensure,\nwe are able to reproduce the existing results. Finally, we stress that all participating\nprograms are developed Open Source to facilitate the interaction with users and\ndevelopers (following the efforts of the NNPDF fitting code\u00a0<cit.>).\n\n\n\n\u00a7 TECHNICAL OVERVIEW OF THE \n\n\nWe refrain here from repeating all technical details from the previous\npublication\u00a0<cit.>, but give in the following just a\nbrief overview of the framework and its the participating programs.\n\nThe core part of the framework is to use PDF independent interpolation grids, as provided by\n\u00a0<cit.> to be able to reuse\npredictions for any candidate PDF. We then extend the idea to the concept of FastKernel (FK) tables\u00a0<cit.>\nwhere we now include also the perturbative evolution of PDFs inside the interpolation grid.\nFK tables can then be used efficiently inside a PDF fit as the usually complicated\nconvolution between candidate PDF and object is now replaced by a simple linear algebra\noperation. To accomplish the various steps we develop the following programs:\n\n  \n  *  acts as an interface to existing Monte Carlo generators to produce  grids\n    containing the partonic information\n  \n  *  provides structure functions in deep-inelastic scattering\u00a0<cit.> (DIS) (and is interfaced to )\n  \n  *  provides the solution to the (perturbative) evolution equations in term of evolution kernel operators\u00a0<cit.>\n  \n  *  combines partonic grids and evolution kernel operator into an FK table\n\nThe flow of programs is summarized in <ref>.\n\n\n\n\n\n\u00a7 BENCHMARKING\n\n\nThe major focus of the is to join several dedicated programs into a consistent framework for\ntheory predictions. However, it is relying on those programs to provide the necessary physical ingredients\nas the framework itself is (almost) physics agnostic and can indeed not only be applied to PDF fitting,\nbut also the determination of other factorized objects, such as fragmentation functions\u00a0<cit.>,\nor beyond standard model (BSM) searches\u00a0<cit.>.\n\nStill, it is convenient to develop some new programs which are tailored for the specific needs and concepts\nof the . Specifically, we develop \u00a0<cit.>, a new solver\u00a0<cit.>, and \u00a0<cit.>,\na new provider of deep-inelastic structure functions. Either of these tasks is an already solved problem\nfor which several implementation exist\u00a0<cit.>, yet none of them provide the\nexact deliverable that we require here.\n\nIn order to benchmark and to former implementations we develop \u00a0<cit.>.\nprovides a convenient benchmarking framework that turned out very useful during the development of both codes.\nIt features a full-fledged database system (based on ) to map input runcards to the respective outputs\nof both programs, the one to be benchmarked and the reference implementation. This allows a seamless comparison between the\nongoing development and the reference implementation, such as investigating the difference in certain regions of the\nparameter space (which often can be mapped back onto a certain region in physics space). Since the reference implementation\nis fixed we implement a caching algorithm which ensures a fast iteration in the development process. Keeping a history\nof the runs allows us also to easily compare our program in two different version which again simplifies the development\nsignificantly.\n\nIn order to facilitate the access to the database we provide an interface built on top of \u00a0<cit.>,\ndubbed , that allows to easily query and retrieve records from the database.\nMoreover, being embedded into a live Python interpreter makes the  flexible and powerful.\n\nWe also add a few simple operations to the  such as the difference between program outputs. This was very helpful e.g. in the implementation\nof the FONLL prescription\u00a0<cit.> for DIS structure function, which can be boiled down to the line\n\n    F^ FONLL = F^(n_l+1) + F^(n_l) - F^(n_l,0)\n\nwhere F refers to any DIS structure function and the various expressions on the right hand side refer to specific\nphysical prescriptions. Each of these prescriptions are well-defined on their own, but already non-trivial, composite objects.\nThus, having the possibility to benchmark them one at a time and subtracting either from the combination\nis very beneficial.\n\nWhile provides the necessary framework that abstracts most tasks away, and have to implement each\na specialization of the framework, dubbed  and  respectively, as indeed they compute\ndifferent, but related objects. These specialized programs are developed in unison together with the main programs.\n currently provides interfaces to the LHA benchmark tables\u00a0<cit.>,\n\u00a0<cit.>, \u00a0<cit.>, and to\nany LHAPDF\u00a0<cit.> set.  currently provides interfaces to \u00a0<cit.>,\n\u00a0<cit.>, and \u00a0<cit.>.\nIn <ref> we show an application of the  benchmarks using the\n\u00a0framework.\n\n\n\n\n\n\u00a7 CONCLUSION AND OUTLOOK\n\nWith the we aim to provide an simple framework to generate theory predictions\nfrom a common input and to deliver a unified output. This can be beneficial for the fitting\nof parton distribution functions\u00a0<cit.> (PDF) or any factorized function such as fragmentation\nfunctions\u00a0<cit.>. We split the necessary tasks to produce FastKernel tables\u00a0<cit.>\ninto separate programs, namely , , and , each focusing only on the specific part.\nThis allows to extend the framework to more involved physics cases such as the determination of the\nphoton PDF\u00a0<cit.>, the inclusion of missing higher order uncertainties into\nPDF fits <cit.>, or the extension to next-to-next-to-next-to-leading order (N3LO) perturbation\ntheory\u00a0<cit.>.\n\nWhile developing the , we also develop two participating programs: and .\nEither one is reimplementing algorithms and ingredients from already known calculations.\nIt is thus imperative to ensure the new code reproduce previous implementations in a\nbenchmarking process. To achieve this task we also develop which provides\na sophisticated benchmarking framework tailored for the case at hand which allows\na reliable and repeated execution of benchmarks.\n\n\n\n\u00a7 ACKNOWLEDGMENTS\n\nA.C. and F.H. are supported by the European Research Council under the\nEuropean Union's Horizon 2020 research and innovation Programme (grant\nagreement number 740006).\nC.S. is supported by the German Research Foundation (DFG) under reference\nnumber DE 623/6-2.\n\n\n\n\u00a7 REFERENCES\n\niopart-num\n\n\n\n\n\n\n"}