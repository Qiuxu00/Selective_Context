{"entry_id": "http://arxiv.org/abs/2303.06947v1", "published": "20230313093120", "title": "A Multi-Modal Simulation Framework to Enable Digital Twin-based V2X Communications in Dynamic Environments", "authors": ["Lorenzo Cazzella", "Francesco Linsalata", "Maurizio Magarini", "Matteo Matteucci", "Umberto Spagnolini"], "primary_category": "eess.SP", "categories": ["eess.SP", "cs.LG", "cs.NI"], "text": "\n\n\nReconfigurable Distributed Antennas and Reflecting Surface (RDARS): A New Architecture for Wireless Communications \n    Chengzhi Ma,\n        Xi Yang,\n        Jintao Wang,\n        Guanghua Yang,\n        and Shaodan Ma,\u00a0Senior Member,\u00a0IEEE\n        \nC. Ma, J. Wang and S. Ma are with the State Key Laboratory of Internet of Things for Smart City and the Department\nof Electrical and Computer Engineering, University of Macau, Macao SAR, China (e-mails: yc07499@um.edu.mo; \nwang.jintao@connect.um.edu.mo;\nshaodanma@um.edu.mo).\nX. Yang is with the Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai 200241, China (e-mail: xyang@cee.ecnu.edu.cn).\nG. Yang is with the School of Intelligent Systems Science and Engineering and GBA and B&R International Joint Research Center for Smart Logistics, Jinan University, Zhuhai 519070, China (e-mail: ghyang@jnu.edu.cn).\n\n    \n============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n\n\n\n\nDigital Twins (DTs) for physical wireless environments have been recently proposed as accurate virtual representations of the propagation environment that can enable multi-layer decisions at the physical communication equipment. At high frequency bands, DTs can help to overcome the challenges emerging in the high mobility conditions featuring vehicular environments. In this paper, we propose a novel data-driven workflow for the creation of the DT of a Vehicle-to-Everything (V2X) communication scenario and a multi-modal simulation framework for the generation of realistic sensor data and accurate mmWave/sub-THz wireless channels. The proposed method leverages an automotive simulation and testing framework based on the Unreal Engine game engine and an accurate ray-tracing channel simulator.\nSimulations over an urban scenario show the achievable realistic sensor and channel modelling both at the infrastructure and at an ego-vehicle.\n\n\n\n\n\nDigital Twin, V2X, data-driven, mmWave/sub-THz\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nThe sixth generation (6G) technology targets to revolutionize the mobility industry enhancing the role of wireless connections in car manufacturing. Indeed, connected vehicles can utilize the vehicle-to-everything (V2X) technology to communicate with other road users by means of cellular networks. The communication module of a connected vehicle working at high frequencies\u2014in the mmWave and sub-THz bands\u2014can offer a true Gb/s experience and deliver information more efficiently than through sensor detection and processing <cit.>.\n\n\n\nHowever, the use of higher frequency bands makes the wireless links prone to line-of-sight (LOS) blockages. The vehicles' movement and the rising density of urban buildings, which mostly determine the signal degradation, are the primary causes of discontinuous connectivity in the V2X environments <cit.>. As a possible countermeasure, the latest 6G paradigm envisions merging the physical and digital worlds <cit.>. It is widely acknowledged that the Digital Twin (DT) will be a key enabling technology to achieve this goal <cit.>.\n\nThe DT aims at providing a high-fidelity digital representation of physical phenomena. This is obtained not only by integrating simulations and available data, but also by accounting for the entire phenomenon life-cycle, which provides up-to-date insights about the physical entity. Thus, a DT-enabled V2X network can get meaningful knowledge of the surrounding environment by collecting and processing a huge amount of data, providing real-time accurate channel estimation <cit.>. To create an accurate real-time digital reproduction of the physical environment, the envisioned DT has to use high-definition 3D maps and combine multi-modal sensory data from scattered devices and infrastructure nodes. The model needs to be continuously improved to enhance its decision accuracy and to refine its approximation of the physical world, as depicted in Fig. <ref>. Indeed, the demands for data reliability are stricter in dynamic scenarios than in static ones. Particularly, in scenarios with stringent time requirements and severe tolerance constraints, as in the case of V2X networks, where even a small model inaccuracy can have a remarkable impact on the decision process <cit.>.\n\nReal-time DTs have been researched in a variety of fields, including real-time remote monitoring and control in industry, risk assessment in transportation, and smart scheduling in smart cities <cit.>. The use of DT in the network has mostly concentrated on operation issues for wireless communications, including edge computing, network optimization, and service management <cit.>. By contrast, this paper focuses on simulating the real vehicular world using the real-time DT, with attention to the environment's physical modelling and wireless signal propagation.\nThe main contributions can be summarized as follows:\n\n    \n  * a workflow for the creation of the DT of a vehicular urban/suburban environment from multi-sensor data acquired at the communication infrastructure or at an ego-vehicle;\n    \n  * a data-driven multi-modal simulation framework for V2X wireless communications leveraging a realistic automotive 3D simulation and testing software based on the renowned Unreal Engine game engine for the generation of realistic sensor data, and on an accurate ray-tracing wireless channel simulator. We present simulation results over an urban environment showing the sensing and channel generation realism achievable through the proposed framework.\n\n\n\n\n\n\u00a7 DIGITAL TWIN-AIDED COMMUNICATIONS\n\n\n\n\nWe consider a multi-user V2X communication system in which the communication infrastructure and the vehicular user equipment (VEs) are capable of multi-modal sensing, as they are equipped with multiple sensors (e.g., camera, LiDAR, radar) to perceive their surroundings. VEs can be also equipped with sensors to estimate their state\u2014e.g., positioning systems and inertial measurement units (IMUs),\u2014in terms of acting forces, position and orientation. The aim of each sensing entity is to build a digital replica of the real world from the perceived data.\n\nOwing to highly dynamic environments, V2X communications experience rapidly varying communication link conditions, which can greatly affect the communication performance and call for novel channel estimation techniques. As an example, Fig. <ref> shows the deep change in electromagnetic wireless propagation between a road-side unit and a VE when affected by vehicular blockage.\n\nRecent contributions in the literature, e.g., <cit.>, have emphasized the advantages of integrated communication and multi-modal sensing to provide effective solutions over a wide variety of tasks, including beam prediction, channel estimation, blockage prediction/hand-off, UE positioning and object detection.\nWe believe that the availability of multiple sensors at the communication infrastructure and/or at VEs, and the challenging channel estimation conditions can benefit from the automotive simulation and testing framework <cit.>\u2014commonly used for the validation of Autonomous Vehicles (AV) and Advanced Driver Assistance Systems (ADAS),\u2014for the construction of the DT of vehicular scenarios aimed at controlling physical communication equipment based on virtual sensors simulation and accurate channel generation.\n\n\n\n\u00a7 A MULTI-MODAL SIMULATION FRAMEWORK FOR V2X COMMUNICATIONS\n\n\nIn this section, we propose a workflow for the construction of the DT of physical urban/suburban environment and a multi-modal simulation framework to enable wireless communications. Fig. <ref> depicts the proposed workflow.\nThe procedure is intended as an iterative approach, which constantly updates the DT from the acquired and preprocessed data.\n\n\n\n \u00a7.\u00a7 Digital Twin construction\n\n\nIn the following, we briefly describe the sensory data acquisition, preprocessing and digital reconstruction steps, focusing on multi-sensor simulation and ray-tracing channel generation in the reconstructed 3D environment, which are the target of this contribution.\n\nSensory data acquisition  (a, b): the environment surrounding a sensing-capable network component (a VE or at the communication infrastructure) is perceived by means of multiple sensors, e.g., camera, LiDAR, and radar. Positioning and inertial measurement systems are also common on automated vehicles, providing information on the forces acting on the vehicle and on its position and orientation.\n\nPreprocessing of the acquired data  (c, d): the acquired data is preprocessed by means of sensor fusion techniques to leverage the joint availability of diverse sensor data. Semantic instance segmentation is then performed to determine the 3D scene components\u2014e.g., buildings, vehicles, fences, lamp posts, road marks, and vegetation. An effective method for LiDAR 3D point-cloud semantic segmentation is proposed by Zhuang et al. in <cit.>, where the authors exploit perceptual information from RGB images and spatio-depth information from point clouds to devise a collaborative fusion scheme.\n\n\n\nDigital 3D reconstruction  (e): the identified 3D scene components are mapped to known 3D object models by means of procedural 3D reconstruction. Nishida et al. propose in <cit.> a system to generate a procedural model of a building from a single camera image, automatically estimating camera parameters and generating the building windows and doors geometry. A more general survey on accurate procedural modelling of virtual twins is provided in <cit.>.\n\nMaterials matching  (f): a material is associated to each 3D component class to enable the reconstructed 3D scenario for electromagnetic (EM) propagation simulations. For a thorough description of the EM relative permettivity and conductivity properties of several materials, we refer the reader to the ITU-R recommendation P.1238 <cit.>.\n\nMulti-modal simulation (g): the reconstructed 3D environment is integrated within the Midgard automotive software framework, designed by AnteMotion <cit.> for testing, simulating and validating Autonomous Vehicles (AV) and Advanced Driver Assistance Systems (ADAS). In particular, Midgard provides state-of-the-art realistic urban/suburban 3D simulation over different weather conditions relying on the Unreal Engine <cit.> real-time game engine.\n\nMidgard allows the simulation or integration of a wide variety of sensors\u2014both static (for simulations at the communications infrastructure) and dynamic (moving jointly with the simulated vehicles):\n\n    \n    \n  * RGB camera, provides standard coloured images and is defined for both a pinhole camera model and for real-life ultra wide-angle lenses (fisheye camera);\n    \n  * identification/segmentation cameras, identify objects perceived in the camera image, classifying each pixel based on the object type (semantic segmentation), separating pixels belonging to different observed objects (instance segmentation), or providing the bounding boxes associated to each object (multi-object identification);\n    \n  * optical flow camera, allows to represent the object movements associating to each image pixel its vertical and horizontal velocity and encoding them into RGB channels;\n    \n  * LiDAR, provides a 3D point cloud for a given number of channels (stacked vertical lasers) and a specified horizontal angular resolution;\n    \n  * inertial measurement unit, provides information on the state of the vehicle to which it is attached;\n    \n  * mmWave radar, for propagation on sensing that can be simulated through specialized ray-tracing software, e.g. <cit.>.\n\n\nAccurate wireless channel simulation (h): to achieve an accurate simulation of the wireless propagation channel, we utilized the Remcom Wireless InSite <cit.> specialized ray-tracing simulation software. A ray-tracing channel simulation software leveraging GPU hardware acceleration has also been introduced by Hoydis et al. in <cit.>. \nRay-tracing propagation models have been proven to effectively simulate multi-path propagation and space-time channel dispersion <cit.>.\nThe considerable progresses in computing architectures and the formulation of improved computational methods enable real-time performance for multi-sensor simulations and ray-tracing wireless propagation simulation.\nThe reconstructed 3D model of the urban/suburban environment is imported within Wireless InSite, associating the corresponding material to each environment component.\nFor each propagation ray between transmitter and receiver, the information provided by Wireless InSite includes the punctual details on received power, phase, direction of departure (DoD), direction of arrival (DoA), delay and Doppler shift (for moving Tx or Rx equipment).\n\nIn the case of mmWave/sub-THz frequencies, the MIMO channel impulse response h at time instant t can be modelled as the sum over P paths <cit.>:\n\n    h(t) = \u2211_p=1^P\u03b1_p e^j2\u03c0\u03bd_p ta_Rx(\u03d1_p) a_Tx^T(\u03c6_p) g(t - \u03c4_p),\n\nwhere the amplitudes \u03b1_p are defined by path-loss and interactions with the propagation environment, \u03bd_p is the Doppler shift of the pth path, a_Tx and a_Rx are, respectively, the Tx and Rx antenna array response vectors as a function of directions of arrival \u03d1_p and directions of departure \u03c6_p, and g(t) is the equivalent impulse response delayed by the path delay \u03c4_p.\n\n\n\n\n \u00a7.\u00a7 Datasets generation\n\n\nBesides controlling physical equipment, the proposed simulation framework enables the generation of realistic datasets of synchronized multi-sensor data and accurate communication channels at the infrastructure and at the ego-vehicle, allowing realistic benchmarks definition and machine/deep learning algorithms training. To generate realistic vehicular traffic data, we utilized the Simulation of Urban MObility (SUMO) simulation software <cit.>. SUMO is an open-source microscopic traffic simulation package that can efficiently handle large vehicular networks. The use of a vehicular traffic simulator requires the availability of an accurate map of the road network. To this aim, we propose to extend the preprocessing phase proposed in Fig. <ref> with a further step for road marks identification and HD lanes reconstruction, as in <cit.>.\n\nWe notice that procedural 3D generation allows to build a wide variety of combinations of 3D and environmental features (e.g., building 3D structures, textures, weather conditions) to generate several diversified datasets.\n\n\n\n\n\u00a7 SIMULATION RESULTS\n\n\n\n\nIn this section, we present the results obtained over an urban scenario for the proposed multi-modal simulation framework. We assume that the sensory data acquisition, preprocessing and digital reconstruction procedures have already been performed, and the model of the 3D simulation scenario  model is available.\n\nThe first three columns of Fig. <ref> present the simulation results for three different virtual sensors\u2014i.e., RGB camera (pinhole camera model), LiDAR unit and semantic segmentation camera\u2014in Midgard from the point of view of a road-side unit (RSU) and of a vehicle moving in the scenario in the neighborhood of the RSU. The camera resolution has been set-up to 1920\u00d71080 pixels, while the focal length is 16 mm and the camera sensor size is 36 mm x 20.25 mm. The semantic segmentation camera annotates each RGB camera pixel with a different color for each object type, distinguishing vehicles, buildings, curbs, pavements, fences and vegetation. The LiDAR unit emulates a realistic radar with 64 channels, a rotation frequency of 10 Hz and an horizontal resolution of 0.6 deg, providing a 3D point cloud of the RSU and vehicle surroundings. The figure shows the real-time realism and accuracy reached by the Midgard Unreal Engine-based automotive framework during simulation.\n\nThe generation of the ray-tracing channel by means of Remcom Wirless InSite is presented in the last column of Fig. <ref> for both a transmitter at the infrastructure and at an ego-vehicle. During the materials matching phase, concrete has been selected for buildings structures, glass for vehicle and building windows, wood for fences, perfect electric conductor (PEC) for lamp posts, vehicle bodies, vehicle bumpers and wheel rims, and rubber for vehicle tires.\n\n\n\n\u00a7 CONCLUSION\n\nIn this paper, we proposed a novel workflow and a multi-modal simulation framework for the construction of a realistic DT of a physical scenario from multi-sensor acquisitions in dynamic vehicular environments. The developed DT is aimed at improving existing V2X communications by controlling physical equipment based on accurate virtual sensors and channel data. Moreover, the proposed multi-modal simulation framework allows the generation of realistic multi-sensor and ray-tracing channel datasets, enabling the definition of realistic benchmarks and the training of machine/deep learning algorithms. Simulations over an urban vehicular environment show the sensing realism achievable through the Unreal Engine-based automotive simulation framework and ray-tracing channel generation results both at the communication infrastructure and at an ego-vehicle.\n\n\n\n\u00a7 ACKNOWLEDGMENT\n\nThis paper was supported by the European Union under the Italian National Recovery and Resilience Plan (NRRP) of NextGenerationEU, partnership on \u201cTelecommunications of the Future\u201d (PE00000001 - program \u201cRESTART\u201d, Structural Project 6GWINET).\n\nIEEEtran\n\n\n\n"}