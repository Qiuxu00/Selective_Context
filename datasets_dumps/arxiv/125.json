{"entry_id": "http://arxiv.org/abs/2303.07182v1", "published": "20230313152406", "title": "Mobile Mapping Mesh Change Detection and Update", "authors": ["Teng Wu", "Bruno Vallet", "C\u00e9dric Demonceaux"], "primary_category": "cs.CV", "categories": ["cs.CV", "65D19", "I.4.5"], "text": "\t\n\t\nAudio-based Roughness Sensing and Tactile Feedback for Haptic Perception in Telepresence\n\n\n    \nBastian P\u00e4tzold,\nAndre Rochow,\nMichael Schreiber,\nRaphael Memmesheimer,\n\nChristian Lenz,\nMax Schwarz, and\nSven Behnke\nAutonomous Intelligent Systems\n\nUniversity of Bonn, Germany\n\n\n\n    March 30, 2023\n=========================================================================================================================================================================================\n\nempty\nempty\n\n\n\nMobile mapping, in particular, Mobile Lidar Scanning (MLS) is increasingly widespread to monitor and map urban scenes at city scale with unprecedented resolution and accuracy. The resulting point cloud sampling of the scene geometry can be meshed in order to create a continuous representation for different applications: visualization, simulation, navigation, etc. Because of the highly dynamic nature of these urban scenes, long term mapping should rely on frequent map updates. A trivial solution is to simply replace old data with newer data each time a new acquisition is made. However it has two drawbacks: 1) the old data may be of higher quality (resolution, precision) than the new and 2) the coverage of the scene might be different in various acquisitions, including varying occlusions.\nIn this paper, we propose a fully automatic pipeline to address these two issues by formulating the problem of merging meshes with different quality, coverage and acquisition time. Our method is based on a combined distance and visibility based change detection, a time series analysis to assess the sustainability of changes, a mesh mosaicking based on a global boolean optimization and finally a stitching of the resulting mesh pieces boundaries with triangle strips. Finally, our method is demonstrated on Robotcar and Stereopolis datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\nBenefiting from the development of 2D and 3D cameras and ranger devices such as RGB-D cameras and laser scanners, 3D point cloud of both indoor and outdoor environments can be easily and efficiently acquired <cit.> and processed to generate 3D maps which have many applications such as visualization, simulation and (autonomous) navigation. In dynamic environments such as cities, changes might happen at very different time scales: instantaneous (pedestrians, moving vehicles), hours (parked vehicles, garbage cans), days (temporary changes such as markets, road works,...), years (structural changes). We consider that a map should only contain sustainable objects/geometries, defined in this paper as having an expected lifespan greater than some application specific sustainability threshold T_s (for mapping purposes we consider T_s=1 month to be a good threshold between temporary and structural changes).\n\n\n\n\n\n\n\n\nThis paper addresses the issue of change detection, sustainability assessment and map updating from heterogeneous (geometric) data with arbitrary quality (resolution and precision) coverage/viewpoint and acquisition dates. The updated mesh is a mosaic of the input meshes optimally exploiting their heterogeneity. The pipeline is shown in <Ref>.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 RELATED WORK\n\n\nLong term localization <cit.> and mapping <cit.> are research topics in both robotics and computer vision communities. For long term mapping, the work presented here is related to three research areas as listed below:\n\n\n\n  \n3D change detection is widely researched <cit.>. For mobile mapping, there are two levels about change analysis, motion analysis along the sequences and changes detection during a long time. For motion analysis, the input data is a sequence, and for change detection, the inputs are several sequences from different times. For point cloud sequence, 3D Vector field based object analysis is used to get the motion and static objects <cit.>.\nRay tracing is used to define dynamic and motion analysis based on iterated closest point is used to obtain the velocity <cit.>.\nRay tracing and Dempster\u2013Shafer Theory are used for change detection in <cit.>. In indoor environment, low cost RGB-D sensors are used for long term mapping, extend truncated signed distance function (TSDF) to handle changes during reconstruction<cit.>.\nFocus on point cloud analysis, occlusion and change analysis is proposed for long term mapping, and clustered objects are used to analyze, instead of single point<cit.>.\n\n\n\n  \nMap update For 2D map update, considering seam line, difference geometry and illumination between different image, seam line optimization is widely researched <cit.>. But in 3D space, the problem becomes complicate, points or triangles are not grid and overlap is not regular. Point cloud is used to describe the map in most work <cit.>. And it is easy to update the map, add the new point cloud to the old point map. After all the dynamic objects are removed, the mesh can be generated <cit.>. In SLAM application, moving object is also an issue, use deep learning method to detect and remove dynamic objects in LiDAR-based SLAM <cit.>, semantic mapping based on Recurrent-OctoMap is proposed for a long-term semantic mapping on 3D-Lidar Data<cit.>, and boosted particle filter based change detection method is applied on definition digital maps <cit.>. \n\n\n\n  \nMesh stitching is a recurrent need in 3D model reconstruction, due the necessity to combine several individual data acquisitions to cover a whole scene. The Zippering algorithm <cit.> can be used to obtain a seamless representation with no overlap.\nTo handle large scale reconstruction, after 3D constrained Delaunay triangulation, Graphcut is used to fuse several meshes <cit.>, but the result should be watertight, at the same time, the overlap area should be detected and the buffer is the non-overlap area.\nJoint alignment and stitching of non overlapping meshes method is proposed to stitch two part of meshes which do not have overlap areas <cit.>, after aligned, the vertices are linked using order assignments.\nHole filling is also a way to link vertices to obtain a whole mesh <cit.>.\n\nThe previous work most related to ours <cit.> tackles the three issues and proposes a pipeline similar to ours, but the focus is on scene reconstruction and the objective is simply to aggregate LiDAR point collected by two 2D range scanners with the same quality mounted on the same platform and acquired during a single acquisition. Our contributions relative to this work and the more specific works cited above can be summarized as follows:\n\n\t\n  * A mesh based 3D change detection method based on combining distance and ray tracing criteria.\n\t\n  * A time series analysis to define and assess the sustainability of changes on 3D meshes.\n\t\n  * A global quadratic pseudo boolean optimization(QPBO) framework to create a mesh mosaic maximizing novelty and quality and minimizing seam lines that are then stitched by triangle strips. \n\n\n\n\n\n\n\n\n\n\n\u00a7 CHANGE DETECTION\n\n\n\n\n \u00a7.\u00a7 Preprocessing\n\n\nThe input of change detection method should be well registered surface meshes with viewpoint information: either a single viewpoint for all triangles (depth images, image space dense matching or fixed panoramic Lidar) or an optical center per point(Mobile, Aerial or Drone Lidar Scanning). In practice we used sensor meshing, creating triangles based on the pixel grid structure for image based point clouds or the regular scan structure (creating triangles based on successive points and successive scanlines) for Lidar (most Lidar sensors give access to this information which is can be preserved during the export). Because Lidar scans are at a very hugh frequency (typically \u00a0300kHz), the three viewpoints for each vertex of a triangle are always very close so choosing their barycenter is a good approximation to provide a triangle viewpoint.\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Consistency analysis\n\n\nChange detection in 3D space is more complex than in 2.5D space: in 2.5D (depth map on a regular grid), if depths disagree between the olde and newer depth maps, they are conflicting and the newest is kept. In 3D, using viewpoint information, each triangle of each mesh defines an empty volume of space (the tetrahedras formed by the triangle and its viewpoint), and intersection of a tetrahedra of one mesh with a triangle of the other can be conflicting or not, as shown in <ref>, such that conflict is an asymmetric relation. Note that because our inputs may have different resolutions, intersecting triangles with rays is not a robust conflict assessment as a small triangle could simply fit between rays, which justifies out choice for tetrahedra based visibility assessment. This justifies our choice for to define consistency for each triangle of each mesh by three possible cases illustrated in <ref>:\n\n    \n  * consistent: the triangle is close enough to a triangle of the other mesh. This is computed by thresholding (Kd tree accelerated) distance computation, and the list of close enough overlapping triangles from the other meshes is stored for each triangle. \n    \n  * conflicting: the triangle is not consistent and intersects the empty space of at least one newer triangle from another mesh, as areas 3 and 5.This is computed by ray tracing on non consistent triangles.\n    \n  * single: the triangle is neither consistent nor conflicting, meaning it has no counterpart in any other meshes, as areas 1, 2, 4 and 6. This is also computed by ray tracing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor conflicting situation, if mesh A is collected after mesh B, only delete triangles which correspond to the orange area 5, and area 3 is kept in <Ref>.\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Time series analysis\n\n\n\nTo analyze time series, we update time information of each triangle incrementally by processing our input meshes in acquisition order. Triangles conflicting with a newer acquisition are systematically removed as they correspond to an object that has disappeared. In the other cases, we simply list for each triangle all the consistent triangles from the other meshes, and the time information of consistent triangle is updated.\nWe propose to assess the sustainability of a new object by requiring it to be confirmed by a new data source more than the sustainability threshold T_s after its first appearance in the data. After all meshes are processed, for each triangle, we know the time of first appeared, and the time of last observation. Thus we keep the sustainable  triangles which are consistent for time T_s.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 3D MESH MOSAIC\n\n\nIn this section, we aim at creating a mesh mosaic from the sustainable triangles defined in the previous section(cf <Ref>).\n\n\n\n\n\n\n \u00a7.\u00a7 Seam line optimization\n\n\n2D mosaicking is a widely used method to stitch several images (possibly resampled) in the same geometry into a larger one in a way that minimizes radiometric jumps across seam lines <cit.>. To extend this concept into 3D meshes, the main issue is that 3D triangles do not coincide exactly as 2D pixels do, so what we want to keep as many non overlapping triangles as possible while minimizing the length of seams in the final mosaic. So while 2D mosaicking is a pixel labeling problem, 3D mosaicking is a boolean optimization problem to decide whether we keep each triangle or not.\nIn our method, we construct a graph where nodes are triangle and having two types of edges: consistency edge between consistent triangles (of different meshes) and neighboring edges between neighbor triangles (of the same mesh). In order to obtain a mesh with maximum triangle area without overlap, and minimum seam lines, we minimize: \n\n    E(\ud835\udc31) = \u2211_p \u2208\ud835\udca2\u03d5_p(x_p) + \u03bb\u2211_(p, q) \u2208\ud835\udca9\u03c8_pq(x_p, x_q)\n\nIn <Ref>, \ud835\udc31 is the label result, \ud835\udca2 is the graph, \ud835\udca9 is neighbor, q and q are the nodes in the graph. For the data term, in order to keep maximum triangles and less minimum seam line, the nodes are divided into two types: boundary triangles and normal triangles. We keep less boundary triangles and more normal triangles.\nFor the smooth term, there are two type of link between the nodes: triangle from the same mesh and triangle from different meshes.  For the first situation, the neighbor triangles should have the same label; for the second situation, to avoid the overlap, these neighbor triangles should not selected both.\nTo expand the formula with information from meshes, we write the mesh mosaic problem as minimizing optimization:\n\n    E(\ud835\udc31) =    \u03bb_1 \u2211_M_i\u2211_T^i_j \u2208 M_i Q(T^i_j) x_i,j + \u03bb_2 \u2211_M_i\u2211_T^i_j\u2208\u212c_i L(T^i_j) x_i,j\n    \n    +    \u03bb_3 \u2211_(T^i_1_j_1,T^i_2_j_2)\u2208\ud835\udc9e x^i_1_j_1\u00b7 x^i_2_j_2\n    \n    +    \u03bb_4 \u2211_M_i\u2211_(T^i_j_1,T^i_j_2)\u2208\ud835\udc9c_i L(T^i_j_1,T^i_j_2) \u00b7 XOR(x_i,j_1,x_i,j_2)\n\nTo define the optimization problem proposed, in <Ref>, we will use the following notations:\n\n    \n  * x_i^j \u2208{0,1} is a boolean label on each triangle T^i_j of mesh M_i, indicating if the triangle is kept (1) or removed (0) in the mosaic. \n    \n  * Q(T^i_j) is the quality of triangle T^i_j, this can be a constant number, triangle area size, etc.\n    \n    \n  * \u212c_i is the set of triangles of mesh M_i with at least one boundary edge. For a triangle T_i^j\u2208\u212c_i, we call L(T_i^j) the length of its boundary edge(s).\n    \n  * For two triangles T^i_j_1,T^i_j_2 of the same mesh M_i sharing an edge, L(T^i_j_1,T^i_j_2) is the length of their common edge.\n    \n  * \ud835\udc9e is the set of all consistent pairs of triangles from two different meshes, which means they are below the distance threshold and that they overlap.\n    \n  * XOR(x_1,x_2)=x_1+x_2-2x_1 \u00b7 x_2 the exclusive OR logical operator.\n\n\nwhere \u03bb_1, \u03bb_2, \u03bb_3 and \u03bb_4 are the weight balance, \u03bb_3 is a large constant discouraging overlaps.\n\n\nThe first two terms are the extension of data term, and the lats two terms are the extension of smooth term in <Ref>. The first term ensures that it takes as many input triangles as possible, and it encourages to keep triangles of highest quality. The second term counts the boundary triangle from the mesh, and we want to keep fewer boundary triangle, the third term make triangles from different mesh should have different labels, i.e. no overlap, and the last term encourage the result has less seam lines.\nA straightforward approach to the definition of quality is through resolution: higher resolution means more information on a given area in a scene.\nIn the framework, seam lines and overlaps should be minimized, quality should be maximized (\u03bb_1 is minus sign). Choosing a constant quality measure will naturally favor higher resolution as it will favor maximizing the number of triangles, thus the higher resolution mesh can be obtained.\nHowever other choices can be made for the quality metric to take into account other factors such as precision or certainty.\nNote that in our framework, quality has the priority over novelty only on parts of the scene that have not changed, but novelty has priority by construction on changing parts of the scene as the optimization runs on sustainable triangles only.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Seam line stitching\n\n\nAfter seam line optimization, the result is a set of individual mesh parts (connected components of triangles selected by the seam line optimization). Thanks to the optimization minimizing seam length, these parts are quite compact, but they are not continuous across seams. To obtain a continuous mesh, stitching the parts across seams is necessary, which is performed in two steps: match the boundaries of each connected component, and then link the adjacent boundaries, more detail can be found in our previous paper <cit.>.\n\n\n\n\n\n\n\u00a7 EXPERIMENTS\n\n\nWe conducted our experiment on Robotcar dataset <cit.>, the laser sensors are mounted on the mobile car, and a long time series dataset is collected. Meshes can be generated from LiDAR point cloud from a 2D sensor, based on sensor topology <cit.>, and the sensor position can be retrieved after reconstruction.\nAfter mesh generation, meshes are registrated using global ICP method <cit.>. \n\n\n\n\n \u00a7.\u00a7 Change detection\n\nFor Robotcar dataset, because the 2D range sensor is mounted on the bottom of the car, the ray to the road edge is nearly parallel to the road plane which bring large errors to the intersection in ray tracing.\nTo overcome the shortage of intersection, the distance base method and visibility based method are combined. \nThe distance based method is symmetrical, but the visibility analysis is not symmetrical. To make the method symmetrical, each triangle will store a time stamp, triangle is kept or removed depends the time and change detection result, so change detection method doesn't rely on the input order, both meshes are processed symmetrically. In the experiment, the occlusion is decided using the timestamp of the two triangles.\n\nIn <ref>, using distance based method can only know the differences, as shown in <ref> and <ref>. Visibility analysis can tell the changed areas, as the red areas shown in <ref>. \nBecause t_1 is after t_0, single area because of occlusion in magenta in time t_1 as shown in <ref>, we can not decide the areas are sustainable or not only with two inputs. After pair based change detection, time series analysis is used to know the consistent parts. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Seam line optimization\n\nAfter change detection and time series analysis, unsustainable objects are removed, the seam line is optimized using QPBO <cit.>. A result is shown in <ref>, the meshes which are from 7 meshes. \nTo proof the effective of optimization method, an updated model is used for comparison. The updated model is common used in point cloud change detection <cit.>. The updated model is just keeping the first observation.\nAs shown in <ref>, the result of updated model depends on the input order of the mesh, the occluded hole is filled by several parts from different times shown in <ref>. The optimization method selects a whole piece avoid increasing seam line shown in <ref>.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Mesh accuracy\n\nFor Robotcar dataset, the used dataset is collected by a 2D sensor mounted on one car, when the car moves fast, triangles are large. Considering the property of 2D sensor(scan angle of the sensor has a big influence on point density), triangles on road boundary are large. Mesh accuracy(triangle size) is influence by the speed and trajectory of the car. For update model, result relies on the input order, and our method can select result with small triangles. As shown in <Ref>, area (a) means the out method obtain a result with less stitch area, and area (b) shows that even for the same area, the selection result can obtain a higher accuracy, triangles are smaller.\n\n\n\n\n\n \u00a7.\u00a7 Implement detail\n\nThe pipeline is implemented using c++, based on CGAL library <cit.>. Computation speed is mainly influenced by the triangle number of the mesh and number of meshes. Considering there are several steps in the pipeline, the time for each step is shown. For the number is 2 or 6 means the first 2 or 6 mesh. The computer system is Ubuntu18.04, with 15.4G memory and CPU is Inter core i7-10510U. In <Ref>, if the number of triangles is large, then the QPBO improve optimization will take a long time, but when the number is 2, QPBO can solve the problem without improve method. Time 0s in <Ref>, means the running time is smaller than 1s. Seam line optimization step takes most to the time.\n\n\n\n\n\n \u00a7.\u00a7 Mesh stitching result\n\nAfter seam line optimization, the mesh is made of by several parts. The boundaries are stitched to obtain a whole mesh, a result is shown in <ref>. Considering point distance, some vertices are merged to avoid small triangle.\n\n\n\n\n\n \u00a7.\u00a7 St\u00e9r\u00e9opolis dataset\n\nSt\u00e9r\u00e9opolis dataset <cit.> is also tested in the experiment. Due to the high accuracy of GPS and inertial measurement unit(IMU), the system produces a higher accuracy of the trajectory. \nSt\u00e9r\u00e9opolis just collects same area dataset from two different times, in this situation, time series analysis can not be performed, to proof the third and forth steps of the workflow, we just removed the changed areas, the unsustainable objects are kept. \nAs shown in <ref>, the results of distance base method and ray trace base method are listed. Because there are only two sequences, the changed objects base on ray trace method are removed in the mesh t_0, and all the triangles in mesh t_1 are kept. In the experiment, to avoid the influence of trees, in this example, the triangle in leaf areas are removed. \nBecause the range sensor is on the top of the car, in the experiment, ray trace method obtains the same result as using both methods.\n\n\n\nAfter seam line optimization, the two parts are stitched together, the result as shown in <ref>. This example shows, the first mesh is more complete on the building facades and the second mesh is more complete on the ground. For the stitch step, the boundary line distance also considered, some points are merged as show in the yellow ellipses.\n\n\nFor St\u00e9r\u00e9opolis dataset, it has a higher resolution, means has more triangles, the update model is also compared. In the experiment, points in leaf area are remained. For only two meshes, because the input order is fixed, it will not influence much the filling parts.\nAs shown in <Ref>, compare to the update model, the optimization method can obtain more complete result, small area missing because occlusion as shown in (a), and less stitch area as shown in (b).\n \n\n\n\n\u00a7 CONCLUSION AND FUTURE WORK\n\nIn the paper, we propose an automatic pipeline for mesh map sustainable update. Using time series analysis to detect unsustainable changes, seam line is optimized using QPBO based method, all the remain sustainable parts are stitched to obtain a complete mesh. Our method can improve the sustainability and novelty of the map. \n\nIn the method, only the meshes are used, no semantic information from images. In the scene, some unsustainable objects things, like cars, which are parking for a long time, in these cases, they can not be removed in the map.\n\nIn this way our method can even handle data acquired simultaneously by multiple platforms at the same scene.\nIn the current experiment, all the meshes are form LiDAR point cloud, because our inputs are meshes with sensor information, image sensors also can produce 3D model reconstruction result with lower expense. We can combine the mobile mapping system(MMS) with a stereo agent to improve the novelty with lower expense.\nMesh processing depends on the 3D reconstruction method, in the current method, only a 2D range sensor is used to reconstruct the scene. Use 3D range sensors or multi sensors to reconstruct the scene to have a better mesh map.\nFor 3D visualization, to consider the texture stitching is also an interesting topic.\n\nIEEEtran\n\n\n"}