{"entry_id": "http://arxiv.org/abs/2303.07067v1", "published": "20230313124202", "title": "Cross-device Federated Learning for Mobile Health Diagnostics: A First Study on COVID-19 Detection", "authors": ["Tong Xia", "Jing Han", "Abhirup Ghosh", "Cecilia Mascolo"], "primary_category": "cs.LG", "categories": ["cs.LG", "cs.DC", "cs.SD", "eess.AS"], "text": "\nTopology optimization with physics-informed neural networks: \n application to noninvasive detection of hidden geometries\n    Ken Kamrin\n    March 30, 2023\n========================================================================================================================\n\n\nFederated learning (FL) aided health diagnostic models can incorporate data from a large number of personal edge devices (e.g., mobile phones) while keeping the data local to the originating devices, largely ensuring privacy. \nHowever,  such a cross-device FL approach for health diagnostics still imposes many challenges due to both local data imbalance (as extreme as local data consists of a single disease class) and global data imbalance (the disease prevalence is generally low in a population). \nSince the federated server has no access to data distribution information, it is not trivial to solve the imbalance issue towards an unbiased model.  \nIn this paper, we propose FedLoss, a novel cross-device FL framework for health diagnostics. \nHere the federated server averages the models trained on edge devices according to the predictive loss on the local data, rather than using only the number of samples as weights. As the predictive loss better quantifies the data distribution at a device, FedLoss  alleviates the impact of data imbalance.  \nThrough a real-world dataset on respiratory sound and symptom-based COVID-19 detection task, we validate the superiority of FedLoss. It achieves competitive COVID-19 detection performance compared to a centralised model with an AUC-ROC of 79%. It also outperforms the state-of-the-art FL baselines in sensitivity and convergence speed. Our work not only demonstrates the promise of federated COVID-19 detection but also paves the way to a plethora of mobile health model development in a privacy-preserving fashion.\n\n\n\nFederated learning, Privacy-preserving, Mobile health, COVID-19 detection, Acoustic modelling\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\nPervasive mobile devices along with on-device machine learning enable continuous sensing of individual health signals and cost-effective health screening at population scale\u00a0<cit.>. \nHowever, traditional machine learning methods need the data from all the devices to be aggregated at a central server, raising privacy concerns as the health status and other personally identifiable information can potentially be leaked from the untrusted server or during data sharing\u00a0<cit.>.\nFederated learning (FL) avoids aggregating the data and thus promise privacy by iteratively learning models at the participating devices using their local data and then aggregating the local models at a central server\u00a0<cit.>. This opens a new way for privacy-preserving diagnostic model development.\n\n\n\nMost existing diagnostic FL frameworks consider cooperation among hospitals or health institutions with each participant containing clinical data from multiple individuals (also known as cross-silo FL setting)\u00a0<cit.>. While such settings have boosted accuracy over participating institutions learning in isolation and improved privacy over centralising the data from all institutes, they still fall short in scaling to more distributed settings where the data of each participant resides on their mobile devices. \nThe cross-silo FL algorithms do not trivially transfer to cross-device FL settings mainly because the latter has many orders of magnitudes more client devices.\n\nIn this paper, we push the envelope of decentralisation by considering cross-device FL, where the data resides in users' (clients') edge devices. The learning works in rounds and at every round, each client's edge device trains a model using locally collected health signals and disease labels, while the federated server aggregates the local models into a global one. Finally, the trained model is used for population health screening by any client device using its local sensing data (Fig.\u00a0<ref>). \n\nCross-device FL imposes the following challenges:\ni) An individual's health status changes very slowly generally. Therefore, most personal devices will only present a single class, i.e., the current health status of the device owner. It is infeasible to balance the data distribution on the device, and thus learning from such data, the local model is likely to over-fit and be biased.\nii) Due to the generally low disease prevalence, the data is also globally imbalanced, with a large proportion of healthy individuals. Without accessing the label distribution, the global aggregation could introduce an unwanted bias in the classification. \nYet, failing to detect the disease may come at a heavy price in healthcare applications. \n\n\n \n\n\n \nTo address the local and global class imbalance, this paper proposes an efficient federated training algorithm, FedLoss. The novelty of FedLoss lies in its adaptive model aggregation: only a small number of clients are required to participate in each round, and their models are aggregated according to adaptive weights proportional to the predictive loss on their local data. Such an adaptive aggregation strategy alleviates the impact of data imbalance and speeds up global model convergence. \nThe performance of FedLoss is validated in a COVID-19 detection task, where respiratory sounds (cough, breathing, and voice) and symptoms are leveraged to diagnose COVID-19.\nA dataset is crowd-sourced from around 3,000 users through a mobile application\u00a0<cit.>. We learn a COVID-19 diagnostic classifier where the data stays on the devices, i.e., our experiments consider each user to be a single federated client.\n\n\n\nThere are two main contributions in this paper. First, we propose a novel federated training algorithm to enable cross-device FL for mobile health diagnostics and tackle the challenge resulting from data imbalance. Further, we conduct extensive experiments in a real-world COVID-19 detection task. Results demonstrate the superiority of our method over the start-of-the-art baselines.\n\n\n\n\n\n\n\n\u00a7 RELATED WORK\n\n\n\n\n\nSkewed label distribution across edge devices is natural in real-world applications, particularly in the healthcare domain\u00a0<cit.>. It poses a challenge in FL: due to privacy constraints, class distribution cannot be handled by explicitly identifying the minority class\u00a0<cit.> and thus it makes the solutions explored in classical centralised settings invalid. Some efforts have concentrated on client clustering\u00a0<cit.>, adapting the global model based on auxiliary data\u00a0<cit.>, and adaptive client training by monitoring the loss from a global perspective\u00a0<cit.>. Yet, they either are inefficient when the number of clients is large or require additional centralised data.  A close work to our study\u00a0<cit.> (FedCluster) considered a cross-device setting in FL to diagnose arrhythmia from electrocardiograms. To improve the performance for the rare phenotype, FedCluster clusters the clients based on a global shared dataset. Then the local models are first merged within clusters and then cluster models are aggregated into the global model. On the contrary, we aim to solve the imbalance problem without any global data.\n\n \n \n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-silo FL has been explored for health diagnostics including COVID-19. For example, Feki\u00a0et al. proposed FL frameworks allowing multiple medical institutions to screen COVID-19 from Chest X-ray images without sharing patient data\u00a0<cit.>. \nVaid\u00a0et al. explored electronic medical records to improve mortality prediction across hospitals via FL\u00a0<cit.>. In these settings, the number of clients is small and the size of the local data is relatively large. To the best of our knowledge, we are the first to propose a cross-device federated learning framework for detecting COVID-19 from personal sounds and symptoms. This is more challenging than cross-silo FL due to the extreme data heterogeneity from the thousands of clients.\n\n\n\n\n\n\u00a7 METHODOLOGY\n\n\n\n\n\n \u00a7.\u00a7 Problem Formulation\n\n\n\n\nConsider a system with N federated clients with each client, n owning a private local dataset \ud835\udc9f^n= {(x^n_1,y^n_1),(x^n_2,y^n_2),...}, where x^n_j is a health signal sample and y^n_j denotes the health status, i.e., if the associated disease is identified in the sample, y^n_j=1, otherwise y^n_j=0.  y^n_j is locally extremely imbalanced with most clients presenting a single class, and it is also globally imbalanced with y^n_j=0 (healthy) being the majority class.\nAs shown in Fig.\u00a0<ref>, we aim to train a federated model parameterised by \u03b8 that can predict y for any given x  to achieve population health screening.\n\n\n\n\n\n\n \u00a7.\u00a7 Basics of Federated Learning\n\n\n\nFederated learning is an iterative process consisting of the following steps at every round:\n(1) At every round, t, each participating client, i receives a copy of the global model from the previous round, \u03b8_t-1 and updates it using its private local data to \u03b8_t^i. (2) Each participating client sends updated  model parameters, g_t^i = \u03b8_t^i - \u03b8_t-1 to the server. (3) The server updates the global model to \u03b8_t by aggregating g_t^is. (4)  Steps (1) to (3) are repeated until the global model converges.\n\nThe most popular aggregation strategy (step 3) is Federated Averaging (FedAvg)\u00a0<cit.>, where the aggregation is an  average of the model updates weighted by \u03b1^i_t, the fraction of the data samples at client i w.r.t. to the total samples available in the system,\n\n\n\n    \u03b8_t = \u03b8_t-1 - \u03b7\u2211_i \u03b1^i_t g_t^i,\n\nwhere \u03b7 is the global updating rate. \n\n\n[t]\n    FedLoss Algorithm\n    \n    Global model update rate \u03b7, global training rounds T, local update rate \u03bb, local training epochs E, the number of clients each round M. \n    Global model \u03b8_T.  \n    Server executes: \n\n    Initialise \u03b8_0 \n\n    each round t = 1,2,...,T   \n     S_t \u2190 A  random  set   of  M  clients \n\n      each client i \u2208 S_t in parallel   \n       \n       l_t^i, g_t^i \u2190  i-th  client  executes\n\n     \n    w_t = softmax(l_t^1,...,l_t^M) # Different from FedAvg \n\n    \u03b8_t \u2190 \u03b8_t-1 - \u03b7\u2211_i=1^M w_t^i g_t^i  \n  \n  \n\n  Client executes: \n\n  Received a global model \u03b8_t-1 \n\n  Initialise loss l^i_t = 0 \n\n  sample j = 1,2,..., |\ud835\udc9f^i|  \n     l^i_t \u2190 l^i_t + CrossEntropy(\u03b8_t-1;\ud835\udc9f_j^i)  # Returning loss\n    \n  Synchronise local model \u03b8_t,0^i =  \u03b8_t-1 \n\n  local epoch e = 1,2,...,E  \n     \u03b8_t,e^i \u2190\u03b8_t,e-1^i - \u03bb\u2207_\u03b8 CrossEntropy(\u03b8_t,e-1^i;\ud835\udc9f^i) \n  Calculate the overall update: g^i_t=\u03b8_t,E^i - \u03b8_t-1\n\n  Return l_t^i, g_t^i \n\n \n\n\n\n\n\n \u00a7.\u00a7 FedLoss\n\n\n\nFedAvg is vulnerable to class imbalance as \u03b1_t^i ignores the label imbalance among the clients. \nTo overcome this, we propose FedLoss (Algorithm\u00a0<ref>) to achieve adaptive aggregation.\n\nAt each round of FedLoss, M clients are randomly selected to participate in training. Each selected client, i, optimises the received model for E epochs using the local data \ud835\udc9f^i. \nThe major difference between FedLoss and FedAvg is that at each round t in addition to sharing models, client i provides the predictive loss, l_t^i to support a weighted aggregation. l_t^i denotes the total cross-entropy loss incurred by the global model, \u03b8_t on its local data, D^i. Note that l_t^i is computed prior to the local training step and thus it does not suffer from over-fitting at a client with small data. \n\nSince unhealthy clients are under-represented (globally minority class), intuitively they are more likely to yield relatively higher predictive loss. Thus, FedLoss will assign a higher weight to their model updates, rendering the data on such clients to be more predictable by the global model.\nFinally, the server normalises the received losses using a softmax function to get the client-wise weights for aggregation. The adaptive aggregation in t-th round is denoted as,\n\n    w_t = softmax(l_t^1,...,l_t^M), \n       \u03b8_t =\u03b8_t-1- \u03b7\u2211_i=1^M w_t^i g_t^i,\n where w_t^i denotes the weight for the participating  client i.\nThe overall process is summarised in Algorithm\u00a0<ref>.\n\n\n\n\n\n\n\n\u00a7 EXPERIMENTAL SETUP\n\n\n\n\nThis section empirically evaluates FedLoss for COVID-19 detection.\n\n\n\n\n \u00a7.\u00a7 Data Details\n\n\n\nWe use the data collected by a crow-sourced mobile application, COVID-19 Sounds[<www.covid-19-sounds.org>].\nAt registration, the app assigns each user a unique anonymous ID. Users record their symptoms (cough, fever, etc.), three respiratory sound recordings (breathing, coughing, and speech), and the COVID-19 testing status on the corresponding day\u00a0<cit.>. \nAfter data cleaning (i.e., excluding non-English speakers, samples without COVID-19 test results and poor audio quality samples),  there are 482 users with positive status and 2,478 users with negative status with a total of 4,612 samples. An overview of the statistics of the data is in Fig.\u00a0<ref>: (a) The data represents a typical demographic distribution in a population. (b) There are more negative than positive users, with many asymptomatic positive users while a great proportion of the negative users report respiratory disease-related symptoms. (c) User data is sparse with over 70% of users only recording one sample. (d) The data accumulation procession spanned one year.\n  \n \n \n\n  \n\n\n\n\n \n\n \u00a7.\u00a7 Backbone COVID-19 Detection Model\n\n \n\nFollowing the previous works\u00a0<cit.>, a VGGish framework is employed to extract acoustic features from the spectrogram of audio samples. Additionally, Han et al. reported that fusing the symptoms and acoustic features in an early stage of the deep model can achieve better COVID-19 detection performance than using a single modality. Inspired by this, we use a multi-modal deep learning model to predict COVID-19 status from audio and symptoms jointly, as illustrated in Fig.\u00a0<ref>. Symptoms are represented by a multi-hot vector, which is concatenated with the dense feature from VGGish network outputs. The concatenated feature vector is then fed to a multi-layer fully connected network for classification. The final layer outputs a Softmax based binary class probabilities.\n\n\n\n\n\n \u00a7.\u00a7 Settings\n\n\n\nThis paper considers each app user as a federated client to examine FedLoss. Out of 2,960 users in the dataset we randomly held out 20% clients for testing and use the rest 80% of the clients for federated training. We experiment with two training settings:\n\n    \n  * Randomly: The recorded data is assumed to be kept on the client device during the whole training period. We run T=2000 federated rounds and M=30 clients are randomly selected at each round.\n    \n  * Chronologically: The recorded data is assumed to be cleared monthly by the user, which is practical.  Regarding this, we design a multi-period training strategy: every month, only the clients with data recorded in this period can be selected and we run 100 rounds with each round sampling M=30 clients for training (100 rounds can guarantee the convergence of the model on the incremental data).\n    \n\n\n All the experiments are implemented by Pytorch on a GPU with 64G memory. To avoid over-fitting on the client, a pre-trained VGGish is utilised\u00a0<cit.>, and the local training epoch is set to E=1.  A local learning rate of 0.008 for VGGish and 0.015 for the rest parameters are used for the SGD optimiser. The global update rate \u03b7=1.\n\n\n\n\n\n\n\n \u00a7.\u00a7 Baselines and Metrics\n\n\n\nIn addition to FedAvg, we also compare with FedProx\u00a0<cit.>. FedProx handles non-identically distributed data across federated clients by regularising the local training loss at the clients so that the local models incur limited  divergence from the global model. \n \n\n\n\nFor evaluation, we first use AUC-ROC (short for AUC) to show the overall rationality of the estimated diagnostic probability. \nFollowing the rule that for a sample if the predictive probability of  being positive  is larger than being negative, i.e., p_pos > p_neg, it will be diagnosed as positive, we also present sensitivity (SE) - the ratio between the correctly identified COVID-19 positive samples and overall positive samples,  and specificity (SP)  - the correct ratio for the healthy class.\nAdditionally, we report sensitivity with a specificity of 80% (SE@80%SP) by tuning the decision threshold, i.e., a sample will only be diagnosed as positive when p_pos > p_neg + \u03c4, where \u03c4 is searched to guarantee a SP of 80%.\nA 95% Confidence Interval (CI) for all metrics is reported by using bootstrap\u00a0<cit.>.\n\n\n\n\n\n\n\n\u00a7 RESULTS\n\n\n\n\n\n \u00a7.\u00a7 Results and Discussion under Randomly Training Setting\n\n\n\nCOVID-19 Detection Performance. The overall performance comparison is summarised in Table\u00a0<ref>. All federated learning based approaches achieve competitive AUC-ROC against centralised training. However, the federated baselines are unable to effectively detect COVID-19 positive users with sensitivity lower than 20%, although their specificity is very high. In contrast, our FedLoss yields a sensitivity of 50% while maintaining the specificity around 90%. In other words, FedLoss achieves the best trade-off for detecting positive and negative users, as proved by the highest average value of sensitivity and specificity (70%).\n When fixing the specificity of 80% uniformly, our FedLoss achieves sensitivity up to 62%, which is as good as the centralised model. \n All those validate the superiority of our weighted aggregation strategy in handling the data imbalance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvergence Comparison. System efficiency is another important metric for cross-device FL. To compare the convergence speed of FedAvg,  FedProx and FedLoss, we show the testing AUC-ROC during the training process in Fig.\u00a0<ref>. It can be observed that the AUC-ROC of our FedLoss gets converged significantly faster than the baselines: FedLoss needs about 250 rounds while FedAvg and FedProx requires about 1000 rounds. Therefore, FedLoss is 4\u00d7 more efficient than baselines. Note that fewer communication rounds to convergence saves both computation and communication costs at the resource constraint edge clients.\n\n\n\nAnalysis of Weights. We conduct additional analysis on the adaptive weight during the training process. Since our FedLoss shows a superior sensitivity against the baselines, we particularly look at how the weights changed for COVID-19 positive and negative clients, for a comparison. Fig.\u00a0<ref> displays the average weight for positive and negative clients in each round. It is observed that in the beginning 100 rounds, the weight of positive clients is 4\u223c6 times of negative clients. This suggests the system can detect the potentially minority class as those clients are more difficult to predict. In the later rounds, the weights for positive and negative clients gradually become more balanced, since the global model has already learned the COVID-19 features, to a great extent. \n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Discussion under Chronologically Training Setting\n\n\n\nThe second setting aims to evaluate the performance of long-term FL with limited client participation in batches.  \nAs illustrated by the SE@80%SP in different periods in Fig.\u00a0<ref>, all methods are inaccurate and unusable at the early stage with SE@80%SP lower than 50%. The poor performance is mainly attributed to the limited number of clients (i.e., the limited data), which leads to poor generalisation.\nGradually, with more training rounds, from November 2020 our FedLoss starts to show a convergence trend with the SE@80%SP reaching 60%. Finally, our model achieves an AUC-ROC of 79%, a sensitivity of 45% and specificity of 90%, as summarised in Table\u00a0<ref>. \nOn the contrary,  SE@80%SP of FedAvg and FedProx has slower convergence rate, converging two months later than FedLoss. We also note that in November 2020, all three approaches present a remarkable performance gain, which is mainly because the quantity of data reaches a peak in that month (refer to Fig.\u00a0<ref>(d)).\nOverall, our final SE@80%SP (62%) significantly surpasses that of FedAvg (56%) and FedProx (53%), and our SE (45%) is quite competitive compared with centralised model (46%).\nThe above comparison further verifies that our proposed FedProx can achieve a more generalised global model with fewer clients involved.\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\n\n\nIn this paper, we studied the feasibility of cross-device federated mobile health using a COVID-19 detection task as an example. To handle the natural challenge of data imbalance, a novel federated aggregation algorithm FedLoss has been proposed. Experimental results demonstrate the superiority of our approach in both effectiveness and efficiency. FedLoss aggregation scheme is general and can be extended to other mobile health applications, e.g., heart sound-based arrhythmia prediction, and smartwatch-enabled sleep quality monitoring. This paper also facilitates the change from traditional crowdsourcing of data to crowdsourcing of models on a large scale for privacy-preserving mobile health applications. While this study is a beginning of an exciting direction of cross-device federated mobile health, many challenges lie ahead, for example, the sparsity of labelled data at the devices, addressing which will be future work.\n\n \n\n\n\n\n\n\n\n\n\n\n\n \nIEEEbib\n\n"}