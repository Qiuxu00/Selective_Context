{"entry_id": "http://arxiv.org/abs/2303.06879v1", "published": "20230313055401", "title": "Spacecraft Anomaly Detection with Attention Temporal Convolution Network", "authors": ["Liang Liu", "Ling Tian", "Zhao Kang", "Tianqi Wan"], "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "text": "\n\n\n\n\n\n\n\n\n\n\nZhao Kang\n\nZkang@uestc.edu.cn\n\n\n\n\n\n\n 1 School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China.\n 2 Beijing Aerospace Institute for Metrology and Measurement Technology, Beijing, China.\n\n\n\n             \n              \n             \n\n\n\n\n\n\n\n\n\n\n\n\nSpacecraft Anomaly Detection with Attention Temporal Convolution Networks\n\n\n\n    \n        Liang Liu \n        1 \n        Ling Tian 1 \n         Zhao Kang 1 \n        Tianqi Wan 2\n\n    Received: date / Accepted: date\n===================================================================================================\n\n\n\n\nSpacecraft faces various situations when carrying out exploration missions in complex space, thus monitoring the anomaly status of spacecraft is crucial to the development of the aerospace industry. The time series telemetry data generated by on-orbit spacecraft contains important information about the status of spacecraft. However, traditional domain knowledge-based spacecraft anomaly detection methods are not effective due to high dimensionality and complex correlation among variables. In this work, we propose an anomaly detection framework for spacecraft multivariate time-series data based on temporal convolution networks (TCNs). First, we employ dynamic graph attention to model the complex correlation among variables and time series. Second, temporal convolution networks with parallel processing ability are used to extract multidimensional features for the downstream prediction task. Finally, many potential anomalies are detected by the best threshold. Experiments on real NASA SMAP/MSL spacecraft datasets show the superiority of our proposed model with respect to state-of-the-art methods. \n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nDeep space of the solar system has numerous satellites in orbit collecting planetary data for exploration  missions such as Tianwen-1's high-resolution multispectral imagery and magnetic monitoring missions around Mars. These satellites have made great contributions to scientific research and resource and environmental exploration. The internal systems of these spacecraft are composed of various sophisticated technologies such as telemetry sensing, navigation control, and many others, which make the system structure complicated <cit.>. Furthermore, spacecraft operate in an extremely complex deep space environments and are confronted with unforeseen anomalies and failures. Therefore, it is vital to effectively and timely detect anomalies in components of spacecraft to ensure its reliable, safe, and continuous operation during exploration missions <cit.>.  \n\nFor on-orbit spacecraft, the most commonly used method is to collect real-time operation data of each component from multi-sensors <cit.> to monitor the status of internal spacecraft. These data are converted into electrical signals and transmitted to the ground telemetry center, where the original variable information of each channel is restored through the signal demodulation technology <cit.>. Then, pattern discovery and anomaly detection analysis can be performed on such telemetry data, which are multidimensional time series <cit.>. In fact, spacecraft telemetry anomaly detection is an intractable problem. There are thousands of telemetry channels that need to be monitored and data have sophisticated patterns. It is impossible for domain experts to observe each channel and manually mark anomalies in a predefined range <cit.>.  \n\n\n\nMany data-driven anomaly detection methods have been proposed for multivariate time series data <cit.>. These approaches build a mathematical model for spacecraft normal pattern from telemetry data to detect anomalies without using any prior knowledge of experts. \nSome representative statistical models are autoregressive moving average (ARMA) <cit.>, gaussian mixture <cit.>,  and autoregressive integrated moving average (ARIMA) <cit.>. However, these models perform poor facing huge, non-linear and high-dimensional time series data. Inspired by the success of deep learning, \nmany anomaly detection methods are built upon deep neural networks <cit.>. Due to the lack of labels, most methods follow an unsupervised learning scheme <cit.>, which learns normal and expected behavior of telemetry channel by predicting <cit.> or reconstructing expected errors <cit.>. They use some popular architectures, including long short-term memory networks (LSTMs) <cit.>, auto-encoders (AE) <cit.>, generative adversarial networks (GANs) <cit.>, and Transformer <cit.>. \nThese deep learning methods have achieved significant performance improvements for time-series anomaly detection. However, there are several downsides in applying them to spacecraft telemetry data. First, most existing methods need to construct a separate model to monitor each telemetry channel, which fails to consider the potential correlations in real spacecraft datasets. Second, they require long training time to support complex computation.\n\nTo this end, we propose an anomaly detection framework for spacecraft multivariate time series data based on temporal convolution networks\n(TCNs). Spacecraft data including the Soil Moisture Active Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover <cit.> are applied to verify the effectiveness of our proposed framework. Specifically, the main contributions are:\n\n    \n  * First, we exploit dynamic graph attention to model the complex correlation among variables and capture the long-term relationship. \n    \n  * Second, the TCNs with parallel processing ability is used to extract multidimensional features. \n    \n  * Third, the static threshold method is applied to detect potential anomalies in real-world spacecraft data. \n\n\n\n\n\u00a7 RELATED WORK\n\n\n\nRecently, deep neural network architectures have achieved leading performance on various time series anomaly detection tasks. \nEspecially, LSTMs and RNNs can effectively process time-series data, capturing valuable historical information for future prediction. Based on LSTMs, NASA Jet Propulsion Laboratory designs an unsupervised nonparametric anomaly thresholding approach for spacecraft anomaly detection <cit.>; Park et al. <cit.> propose variational auto-encoders that fuse signals and reconstruct expected distribution. Most telemetry data are multi-dimensional due to the interrelation of components in the satellite's internal structure. As illustrated in Fig. <ref>, each curve corresponds to a variable (or channel) in \nspacecraft multivariate time series, and an anomaly in one channel of the spacecraft also causes abnormality in other channels.\n\n\nFor online anomaly detection task, they have to create a model for each variable and simultaneously invoke multiple trained models, which are inefficient. Therefore, the above methods cannot detect anomalies due to the complex correlations among multivariate. \n\n\nConsequently, the methods considering multivariable and their potential correlations have received extensive attention. For example, NASA Ames Research Center proposes a clustering-based inductive monitoring system (IMS) to analyze archived system data and characterize normal interactions between parameters <cit.>. \nSu et al. <cit.> utilize stochastic variable connection and planar normalizing flow for multivariate time series anomaly detection, which performs well in datasets of NASA. \nZhao et al. <cit.> utilizes the graph attention method to capture temporal and variable dependency for anomaly detection. Li et al. <cit.> adopts GANs to detect anomalies by considering complex dependencies between multivariate. Zong et al. <cit.> introduce deep auto-encoders with a gaussian mixture model.\n\n\nChen et al. <cit.> directly built a transformer-based architecture that learns the inter-dependencies between sensors for anomaly detection.\n\nAlthough these methods have made a significant improvement in anomaly detection, there are still some shortcomings. For example, RNNs processing the next sequence need to wait for the last output of the previous sequence. Therefore, modeling long-time series data requires a long time, which leads to inefficient detection and does not meet the real-time requirement for spacecraft telemetry anomaly detection. Additionally, most models have high complexity and are not suitable for the practical application of spacecraft anomaly detection. Bai et al. <cit.> firstly propose TCNs that have parallel processing ability and also model historical information with exponential growth receptive field. In recent years, many studies have verified the effectiveness of TCNs for long time series <cit.>. However, anomaly detection based on TCNs has not been investigated. Therefore, this paper develops a multivariate temporal convolution anomaly detection model for complex spacecraft telemetry data.\n\n\n\n\n\n\n\u00a7 METHODOLOGY\n\nThe proposed spacecraft multivariate telemetry data anomaly detection method aims to detect anomalies at entity-level <cit.> instead of channel-level since the overall status is more noteworthy and less expensive to observe. \nLet X\u2208\u211b^w \u00d7 m denotes the multivariate time series, where w is the length of input timestamp and m is the number of feature (or called variable) of input. \nGiven a historical sequence {x_t-w,...,x_t-1}, our goal is to predict its value at the next time step t.\nBased on it, we can calculate the anomaly score  and threshold, and finally output  y_t \u2208{0, 1}, indicating whether it is anomalous or not at timestamp t. Considering the imbalance between anomalous and normal spacecraft telemetry data, we set the model to learn a normal mode by offline training and to monitor the anomalies online.\n\nThe overview of our proposed spacecraft anomaly detection architecture is shown in Fig. <ref>, which consists of three modules:\n(a) Given a multivariate time-series sequence, we apply 1-D convolution to extract high-level features and use dynamic attention to capture temporal and variable relations. (b) Concatenate the outputs of the dynamic attention layer and convolution layer, and perform multi-stack temporal convolution to encode multivariate time-series representation. c) Multi layered perceptron (MLP) is used to map the encoding representation to predict future values. We minimize the residuals between predicted and observed values to update the model until convergence.\n\n\n\n\n \u00a7.\u00a7 Graph Attention Mechanism\n\nAs aforementioned, spacecraft multivariate telemetry time series have complex interdependence. We use graph structure to model the relationships between variables <cit.>. Given an undirected graph \ud835\udca2=(\ud835\udcb1, \u2130), where \ud835\udcb1 denotes the set of vertices (or nodes) and \u2130\u2286\ud835\udcb1\u00d7\ud835\udcb1 is a set of edges.\n\nMultivariate time series X = [x_t-w,...,x_t-1] \u2208\u211b^w \u00d7 m and x_i={x_i^(1),x_i^(2),...,x_i^(m)}\u2208\u211b^m, where i denotes the i-th time step (or node i), which can be considered as w nodes and x_i is feature vector corresponding to each node. It can be used to capture temporal dependencies. \nAt the same time, to sufficiently capture the relationship of variables, the feature  matrix can be transformed into X^ T=[x^(1),...,x^(m)] \u2208\u211b^m \u00d7 w, x^(i) = {x^(i)_t-w, x^(i)_t-w+1,...,x^(i)_t-1}\u2208\u211b^w.\n\n\n\nWe capture temporal and variable dependencies according to its importance in the fully connected graph as shown in Fig. <ref>. Specifically, graph attention block is based on graph attention networks (GATs) <cit.>. Taking temporal attention for example, \nit learns a weighted averaged of the representation of neighbor nodes as follows:\n\n\n    x_i = \u03c3(\u2211_j \u2208\ud835\udca9_i\u03b1_ij x_j )\n\nwhere x_i denotes the output representation of temporal attention on x_i, \u03c3 is a nonlinear activation function, and  the attention score \u03b1_ij is normalized across all  neighbors j \u2208\ud835\udca9_i by softmax.\n\n\n    \u03b1_ij=softmax(e(x_i,x_j))=exp(e(x_i, x_j))/\u2211_k \u2208\ud835\udca9_iexp(e(x_i, x_k))\n\nwhere scoring function e(x_i, x_j) is defined as:\n\n    e_ij=e(x_i,x_j)=LeakyReLU(a^T\u00b7 [Wx_i||Wx_j])\n\nwhich measures the importance of features of neighbor j to node i, || denotes concatenation operation,\na and W are trainable parameters. In fact, GATs are static attention and can deteriorate the model fitting capability <cit.>. This is because the learned layers a and W are applied consecutively, and thus can be collapsed into a single linear layer. We apply dynamic graph attention by changing the order of operations in GATs. Concretely, after concatenating, a linear transformation is applied and then an attention layer is utilized after the activation function. Mathematically, dynamic attention can be defined as below:\n\n\n    e_ij=e(x_i, x_j) = a^TLeakyReLU(W\u00b7 [x_i||x_j])\n\n\n\n\n\n\n \u00a7.\u00a7 Temporal Convolution Encoding\n\nAs aforementioned, existing methods do not consider the model complexity and long training time. TCNs have proved to be superior to LSTMs and RNNs in terms of computational speed and ability to mine historical information for very long time series.\nWe utilize TCNs as a backbone network to learn the representation of time series. TCNs are an improved architecture that overcomes the limitations of RNNs-based models, which are not able to capture the property of long time series and have low computational efficiency. TCNs' parallel structure makes it appealing to boost the efficiency of spacecraft anomaly detection. TCNs use a 1-D fully-convolutional network as architecture and zero padding to guarantee the hidden layer be the same size as the input, and also apply causal convolution. \n\n\n\nSuppose convolution filter F={f_1, f_2, ..., f_K}, where K denotes the size of convolution kernel. \n\n\nThe mathematical of the element x_t-1 by causal convolution can be defined as follow:\n\n    F(x_t-1) = \u2211^K_k=1f_kx_t-1-K+k\n\n\n\n\n\nIt can be observed from the above equation that the ability to process long sequence data is limited unless a large number of layers are stacked, which will make the task inefficient due to limited computing resources. The dilated convolution enlarges the receptive field with limited layers so that each convolution output contains a wide range of information. Dilated convolution reduces the depth of a simple causal convolution network. It also ensures that the output and input size are the same by skipping the input value in a given time step. As the network deepens, its receptive field covering each input in history expands exponentially. The dilated convolution with dilated factor d=1,2,4 is shown in Fig. <ref> and the mathematical expression can be formulated as:\n\n    F_d(x_t-1)=\u2211^K_k=1f_kx_t-1-(K-k)d\n\n\n\n\nFinally, the residual connection is applied, which has been proven to be effective for neural network training.\nIn addition, skipping connection through across-layer manner is also adopted to fully transmit information and avoid vanishing gradient problem in a deep network. The output of residual can be formulated as:\n\n\n    F(x_t-1) = F_d(x_t-1) + x_t-1\n\n\n\n\n \u00a7.\u00a7 Spacecraft Anomaly Detection\n\nThe whole procedure of our proposed Attention Temporal Convolution\nNetwork (ATCN) for spacecraft anomaly detection is shown in Fig. <ref>. We train the model on normal data to predict telemetry. We minimize the Root Mean Square Error (RMSE) loss \u2112=RMSE(x\u0302,x) between predicted output sequence x\u0302 and observed sequence x, to update the online model. When a detection job arrives, the online model computes the anomalous score sequence s by the deviation level \nbetween the input sequence and prediction sequence to find the threshold. Then, the error sequence s is compared with the calculated threshold value. If an error at a certain time step exceeds the threshold, the data at this position is considered as an abnormal value.\n\n\n\u00a7 EXPERIMENTS\n\n\n\n\n \u00a7.\u00a7 Datasets\n\nWe use real-world spacecraft datasets to verify the effectiveness of our model, including MSL and SMAP <cit.>, which are two public datasets of NASA\nspacecraft. The statistics of them are shown in Table <ref>, including the number of variables, size of the training set, size of testing set, the proportion of anomaly in the testing set, and partial variable information.\n\nWe first normalize the training and testing dataset. Taking training set as an example, \n\n    x:=x - min (X_train)/max (X_train) - min (X_train)\n\nwhere max (X_train) and min (X_train) are the maximum value and the minimum value of the training set respectively.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Baseline\n\nWe compared our model performance with state-of-the-art unsupervised anomaly detection methods, including reconstruction model (R-model) and prediction model (P-model):\n\n\t\n  * KitNet <cit.> is the first work to use auto-encoder with or without ensembles for online anomaly detection. \n\t\n  * OmniAnomaly <cit.> proposes a variational auto-encoder with gated recurrent units for multivariate time series anomaly detection. \n\t\n  * GAN-Li <cit.> and MAD-GAN <cit.> are unsupervised multivariate anomaly detection method based on GANs. They adopt LSTM-RNN as the  generator and discriminator model  to capture the temporal correlation of time series distributions.\n    \n  * LSTM-VAE <cit.> aims at fusing signals and reconstructing their expected distribution. \n    \n  * LSTM-NDT <cit.> is a univariate time series detection method based on LSTM with a novel nonparametric anomaly thresholding approach for NASA datasets.\n    \n  * DAGMM <cit.> utilizes a deep auto-encoder to generate error sequence and feeds into  Gaussian Mixture Model (GMM) for anomaly detection. \n    \n  * MTAD-GAT <cit.> captures time relationships and variable dependency with jointly optimizing a forecasting-based model and a reconstruction-based model. \n    \n  * GTA <cit.> develops a new framework for multivariate time series anomaly detection that involves automatically learning a graph structure, graph convolution, and modeling temporal dependency\n\tusing a Transformer-based architecture.\n\nThese methods mainly model temporal dependency or multivariate correlation to detect anomalies by reconstruction or prediction model. We implement our method and all its variants with Pytorch version 1.6.0 with CUDA 10.2. The overall experiments are conducted on Tesla T4 GPU, 32G.\n\n\n\n\n\n\n\n  \n\n\n\n \u00a7.\u00a7 Evaluation Metrics\n\nWe evaluated the performance of various methods by the most frequently used metrics in the anomaly detection community, including Precision, Recall, and F1 score over the testing set: \n\n    Precision   =TP/TP+FP\n     Recall   =TP/TP+FN\n     F1   =2 \u00d7 Precision \u00d7 Recall/Precision + Recall\n\nwhere TP, FP, FN are the numbers of true positives, false positives, and false negatives. \nFollowing the evaluation strategy in <cit.>, we use point-wise scores. In practice, anomalies at one time point in time series usually occur to form contiguous abnormal segments. Anomaly alerts can be triggered in any subset of the actual anomaly window. Therefore, the entire anomalous segment is correctly detected if any one time point is detected as anomaly by the model. The implementation of ATCN is publicly available[ The code is available at < https://github.com/Lliang97/Spacecraft-Anonamly-Detection>].\n\n\n\n\n1) Data preprocessing: We perform a data standardization before training to improve the robustness of our model. Data preprocessing is applied on both training and testing set:\n\n    x=x - min X_train/max X_train - min X_train\n\nwhere max X_train and min X_train are the maximum value and the minimum value of the training set respectively.\n\n\n\n \u00a7.\u00a7 Experimental Setup\n\nWe set the historical sliding window size to 100 and predict the value at the next timestamp. Moreover, the dropout strategy was applied to prevent overfitting and dropout rate is fixed to 0.1. The models are trained using the Adam optimizer with a learning rate initialized as 1e^-3 and batch size as 256 for 100 epochs. Table <ref> summarises the network configuration details. For anomaly detection on each test dataset, we apply a grid search on all possible anomaly thresholds and choose the best threshold to report F1 score. \n\n\n\n\n\n \u00a7.\u00a7 Result and Analysis\n\nThe experimental results of various anomaly detection approaches on two datasets are reported in Table <ref>. It can be seen that our method shows superior performance and achieves the best F1 score 0.9272 for SMAP and 0.9613 for MSL. Specifically, we can draw the following conclusions. \n\n\t\n  * Compared to the newest method GTA published in 2021, our model achieves 2.31% and 5.02% F1 improvement on two datasets respectively. Similarly, the precision is also boosted by 6.28% and 3.15% on SMAP and MSL, respectively. MTAD-GAT has comparable performance as GAT on SMAP.\n\t\n\t\n  * Our method surpasses OmniAnomaly and DAGMM in most cases. Though OmniAnomaly captures temporal dependencies by stochastic RNNs, it ignores the correlations between variables, which is vital for multivariate times-series anomaly detection. The performance of DAGMM is not satisfactory since it does not consider historical temporal information. Therefore, it is important to dig the correlated information in terms of variable and temporal features.\n\t\n  * LSTM-NDT creates a model for each telemetry channel, which leads to high expensive for modeling. It produces poor performance on MSL.\n\t\n  * GAN-based anomaly detection methods GAN-Li and MAD-GAN give inferior performance because they fail to fully consider the correlations between\n\tvariables. \n\t\n  * Most methods use RNNs to capture temporal dependency, which is limited by the need to retain historical information in memory gates, restricting the ability to model long-term sequences and being subject to long computing times. TCNs with multi-stack dilated convolution and residual connection can capture long sequence that  provides more pattern information and be calculated in parallel. Thus, our proposed model has clear advantages compared with existing models, which makes it attractive for spacecraft telemetry anomaly detection.\n\n\nWe give an example of anomaly detection results on MSL in Fig. <ref>. When spacecraft telemetry data arrive, the residuals of predicted data and actual data are calculated to obtain anomaly scores,  based on which threshold is calculated to determine whether it is an anomaly on each timestep. The blue line represents the curve of the anomaly score, the orange line denotes the calculated threshold, and the red line can be recognized as the anomalous segment. It can be seen that the detected outliers are mostly consistent with the true outliers, indicating the accuracy of our proposed anomaly detection algorithm.\n\nIn order to observe the influence of long-term time series on the model, we set different window sizes, i.e., w=[20, 40, 60, 80, 100], to predict the value at the next timestamp. Then, the F1, precision, and recall are shown in Fig. <ref>.  We can observe that F1 reaches the highest value at w=100, so our model can capture the relationships in long time series. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Ablation Study\n\nTo verify the necessity of each component in our method, we exclude variable attention, temporal attention, and the dynamic attention was replaced with original graph attention respectively to see how the model performs after these operations. \nAs shown in Fig. <ref>, our original model always achieves the best F1, which verifies that the dynamic graph attention capturing correlations benefits model performance. On the other hand, the performance will degrade if the variable or temporary relationship information are removed, which validates the importance of relationship modeling in dealing with multivariate time series anomaly detection. \n\n\nSince using different thresholds will reach different results, the anomaly detection model was tested with two other statistical threshold selection methods to verify its robustness. With multivariate time series of N observations, we compute an anomaly score as S={S_1, S_2,..., S_N} for every observation.\nSpecifically, the epsilon method <cit.> and Peak Over Threshold (POT) <cit.> method were adopted to select threshold in offline train period. Epsilon method calculates the threshold \u03f5 based on error sequence S  according to \n\n    \u03f5 = \u03bc(S)+z\u03c3(S),\n\nwhere \u03f5 is determined by:\n\n    \u03f5=argmax(\u03f5)=\u0394\u03bc(S) / \u03bc(S)\n    \t\t+ \u0394\u03c3(S) / \u03c3(S)\n    \t/|S_a|+|P_seq|^2\n\nwhere \u03bc is expectation and \u03c3 is standard deviation.\n\n    \u0394\u03bc(S)    = \u03bc(S) - \u03bc({S_i \u2208 S | S_i < \u03f5}) \n    \u0394\u03c3(S)    = \u03c3(S) - \u03c3({S_i \u2208 S | S_i < \u03f5}) \n    \n    \tS_a    = {S_i \u2208 S | S_i > \u03f5}    P_seq = sequence of S_a\n\n\nPOT is the second theorem in Extreme Value Theory (EVT) and is a statistical theory to find the law\nof extreme values in a sequence. The advantage of EVT is that it does not need to assume the data distribution and learns the threshold by a generalized Pareto distribution (GPD)\nwith parameters. The GPD function is as follows:\n\n    F(s) = P(th - S  > s | S < th ) \u223c(1 + \u03b3 s/\u03b2) ^ - 1/\u03b3\n\nwhere th is the initial threshold, \u03b3 and \u03b2 are\nshape and scale parameters of GPD, and S is any value in {S_1, S_2,...,S_N}. The portion below the threshold th is denoted as th - S and it is empirically set to a low quantile. Then, the values of parameters \u03b3\u0302 and \u03b2\u0302 are obtained by Maximum Likelihood Estimation. The final threshold can be calculated by:\n\n    th_F\u2243 th - \u03b2\u0302/\u03b3\u0302((qN/N_th)^-\u03b3\u0302-1 )\n\nwhere q is the proportion of S < th, N_th denotes the number of S < th. \n\nFrom Table <ref>, it can be concluded that the proposed ATCN model has competitive performance with respect to above two threshold selection approaches. We observe that epsilon method has achieved very close results benefiting from appropriate modeling of outliers. The POT method does not work well in terms of F1 because it has two parameters that need to be empirically fine-tuned. \n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSIONS\n\nThis paper proposes a model for spacecraft anomaly detection task. A temporal convolution networks-based architecture to process multivariate time-series was designed. In particular, the dynamic graph attention module was utilized to learn the correlation between variables and times and perform weighted embedding. After that, a temporal convolution networks module was designed to learn the patterns of the spacecraft data and detect anomalies. Experiments on two real-world NASA spacecraft datasets show that our method outperforms baselines in terms of F1, Precision, and Recall. Thus, it is helpful for operator to localize and understand anomalies. In the future, the researchers plan to investigate online training model toward the employment of proposed method in future spacecraft.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspmpsci      \n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}