{"entry_id": "http://arxiv.org/abs/2303.07189v1", "published": "20230313153028", "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging", "authors": ["Tina Dorosti", "Manuel Schultheiss", "Felix Hofmann", "Luisa Kirchner", "Theresa Urban", "Franz Pfeiffer", "Johannes Thalhammer", "Florian Schaff", "Tobias Lasser", "Daniela Pfeiffer"], "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "text": "\nTransverse single-spin asymmetry of midrapidity \u03c0^0 and \u03b7\nmesons in p+Au and p+Al collisions at \u221a(s__NN)= 200 GeV\n    L.\u00a0Zou\n    March 30, 2023\n=================================================================================================================\n\n\nChronic Obstructive Pulmonary Disease (COPD) is a leading cause of death worldwide, yet early detection and treatment can prevent the progression of the disease. In contrast to the conventional method of detecting COPD with spirometry tests, X-ray Computed Tomography (CT) scans of the chest provide a measure of morphological changes in the lung. It has been shown that automated detection of COPD can be performed with deep learning models. However, the potential of incorporating optimal window setting selection, typically carried out by clinicians during examination of CT scans for COPD, is generally overlooked in deep learning approaches. We aim to optimize the binary classification of COPD with densely connected convolutional neural networks (DenseNets) through implementation of manual and automated Window-Setting Optimization (WSO) steps. Our dataset consisted of 78 CT scans from the Klinikum rechts der Isar research hospital. Repeated inference on the test set showed that without WSO, the plain DenseNet resulted in a mean slice-level AUC of 0.80\u00b10.05. With input images manually adjusted to the emphysema window setting, the plain DenseNet model predicted COPD with a mean AUC of 0.86\u00b10.04. By automating the WSO through addition of a customized layer to the DenseNet, an optimal window setting in the proximity of the emphysema window setting was learned and a mean AUC of 0.82\u00b10.04 was achieved. Detection of COPD with DenseNet models was optimized by WSO of CT data to the emphysema window setting range, demonstrating the importance of implementing optimal window setting selection in the deep learning pipeline.\n\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\nChronic Obstructive Pulmonary Disease (COPD) refers to a group of respiratory diseases that reduce the exchange of oxygen and carbon-dioxide in the lung. COPD chronically impairs the structure of the lung by narrowing the airways and damaging the air sacs. One of the common diseases associated with COPD is emphysema, which is most often observed in smokers <cit.>. Although disease progression can be prevented with early detection, COPD is among the leading causes of death worldwide, with 3.23 million deaths recorded across the globe in 2019 <cit.>. In addition to increased mortality rates in direct correlation with the disease, patients with COPD are likely to develop comorbid diseases, such as cardiovascular diseases, mental disorders, and other respiratory diseases <cit.>. Furthermore, with respect to the recent outbreak of the Severe Acute Respiratory Syndrome Coronavirus type 2 (SARS\u2011CoV\u20112) in 2019 and the associated Coronavirus disease (COVID-19), current research suggests that all-cause mortality risks are higher for individuals with COPD preconditions <cit.>,<cit.>. With early detection and intervention, the prevalence and negative impacts of COPD can be decreased <cit.>.\n\n\nA readily-available procedure for the detection of COPD is the spirometry test, whereby a measure of forced exhalation volume less than a reference value is indicative of COPD. The Global Initiative for Chronic Obstructive Lung Disease (GOLD) committee has defined a four-stage progression scale for the diagnosis of  COPD based on spirometry measurements, staging from mild (I) to very severe (IV) <cit.>. Although spirometry reliably detects advanced stages of COPD, results for patients at an early stage of COPD can still be negative despite the presence of chronic symptoms, such as a persistent cough and shortness of breath <cit.>,<cit.>. Moreover, patients categorized in the same GOLD stage have shown drastic morphological differences in the lung structure <cit.>. \n\nX-ray Computed Tomography (CT) scanning of the chest is an alternative method for the detection of COPD. Chest CT scans provide detailed three-dimensional morphological information about the lung structure. Each volume element is characterized by its Hounsfield Unit (HU) value, a measure of the local attenuation coefficient for X-rays. \n\nThe three-dimensional information obtained about phenotypic abnormalities and pattern of morphological changes reflecting emphysema allows for detection and control of disease progression even in early stages. In 2015, the Fleischner Society introduced a disease progression scale based on pattern of abnormalities present in CT data that correspond to COPD and emphysema sub-types <cit.>.\n\n\n\n\n\n\n\n\n\n\n\nIn recent years, large scale studies with publicly-available datasets, such as the Evaluation of COPD Longitudinally to Identify Predictive Surrogate End-points (ECLIPSE) and the COPDGene study, have been carried out to investigate the association of COPD with biomarkers, genetic risk factors, and epidemiologic indicators  <cit.>,<cit.>. In parallel, improvements in computation power and machine learning algorithms have made Convolutional Neural Networks (CNN) a popular tool for automated classification and detection tasks in medical imaging. CNNs are a specialized case of machine learning algorithms that can extract features from image data and are often applied to computer vision tasks <cit.>. Consequently, with rising prevalence of COPD, large imaging datasets, and technological advancements in the field of machine learning, CNNs have been applied to automate binary classification of COPD and have shown promising results <cit.>,<cit.>,<cit.>,<cit.>. However, model outcomes are still not ready for integration into a computer-aided clinical workflow for efficient and cost-effective COPD diagnosis. CNN research in other areas of medical data analysis, such as e.g. intracranial hemorrhage classification, has shown that the incorporation of clinically-relevant steps in the model workflow can improve the output. In particular, it was found that optimizing clinical window-setting parameters of input CT images greatly affects the output quality. <cit.>,<cit.>,<cit.>. \n\n\n\n\nSince the extant literature on COPD detection using CNNs predominantly focuses on fine-tuning deep learning algorithms, the potential of implementing preprocessing steps to more closely adapt clinical workflow processes has thus far not been explored in detail. Furthermore, relevant literature mainly benefits from the ECLIPSE and COPDGene study datasets, where ground truth labels for the scans are given on the GOLD standard progression scale, instead of the phenotypic-relevant scale introduced by the Fleischner Society <cit.>,<cit.>,<cit.>,<cit.>.\n\nIn this work, we aim to optimize the detection of COPD based on emphysema presence in the lung with densely connected CNNs (DenseNets). We adapted a routine clinical-workflow procedure for a total of 78 chest CT scans obtained from the Klinikum rechts der Isar research hospital of the Technical University of Munich. In doing so, the effects of manually-adjusted versus automated window-setting optimization on the binary classification task for differentiation between healthy and COPD patient slices were explored in detail. Our findings demonstrate that diligent preprocessing based on existing radiological knowledge, as well as selecting phenotypically representative ground truth labels positively impact the outcome of COPD detection with CNN models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 METHODS\n\n\n\n\n \u00a7.\u00a7 Dataset\n\nA total of 78 patients with contrast enhanced chest CTs were retrospectively selected from our picture archiving and communication system at the Klinikum rechts der Isar research hospital between October, 2018 and December, 2019. CT scans included those of patients suffering from different COPD stages (n = 43) and healthy controls (n = 35). Scans that presented conditions or pathologies that did not correspond to COPD, yet could influence lung parenchyma, such as pulmonary congestion or lung cancer, were excluded in the selection process.\n\nImaging was carried out with an IQon Spectral CT scanner (Royal Philips, Netherlands).\n\nThe CT scans were first anonymized and then graded by three expert radiologists with four to 12 years of experience. Patient-level grading was based on the six Fleischner Score (FS) categories of absent (FS = 0), trace (FS = 1), mild (FS = 2), moderate (FS = 3), confluent (FS = 4), and advanced destructive (FS = 5) emphysema, as per Fleischner society's statement <cit.>. \n\nScans with FS > 2 were considered as the COPD class for our binary classification task. Patients at a moderate COPD stage exhibit many defined areas of low attenuation in the CT scan covering over 5% of the lung region <cit.>. Therefore, to distinguish slices presenting COPD from other slices, CT scans with an FS = 3 were further annotated on slice-level basis by a radiologist not involved in the initial FS grading process. Datasets were selected on slice-level basis as such: Training and validation sets each included 3,392 and 1,114 slices, respectively. A total of 2,688 slices were reserved for the test set. All sets contained equal number of slices from the COPD and the no COPD class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n \u00a7.\u00a7 Data preprocessing\n\nAs an initial preprocessing step, each slice was multiplied by its corresponding lung segmentation mask, generated with a commercially available software (IntelliSpace, Royal Philips, Netherlands). The 256x256 pixel images were clipped to the respective window setting and normalized to values between zero and one. A window setting is given by the window width and the window level (WW, WL) in HU as standardized by radiologists. Note that the WL defines the mid-point value of a window setting. Here, the emphysema window (124, -962) HU was used to clip the CT images for classification of COPD. Furthermore, a \u2019full-range\u2019 windowing (2048, 0) HU was applied to introduce a base-line intensity range for all slices. The (WWfull-range, WLfull-range) values were set based on the minimum, -1024 HU, and the maximum, 966 HU, intensity values recorded over all slices. <ref> shows an example slice from the no COPD class in (a, b), and a slice from the COPD class in (c\u2013f). The slices were preprocessed to the full-range window setting in <ref>(a, c, e) and to the emphysema window setting in (b, d, f). The nonhomogeneous patches of low attenuation corresponding to emphysema are emphasized with a stronger contrast in <ref>(d) compared to the full-range window setting in <ref>(c).\n\n\n\n \u00a7.\u00a7 Implementation of DenseNets\n \nThree DenseNets with minor differences in their architectures and training process were compared to examine the effects of window setting on COPD detection. The models were implemented with the TensorFlow platform (version 2.4.0) <cit.>.\n\n\n  \u00a7.\u00a7.\u00a7 Plain DenseNet\n\nThe DenseNet with 121 layers (plain DenseNet) was chosen as it has been shown to outperform other CNNs such as VGGNet, AlexNet, ResNet, and DenseNet201 for COPD classification <cit.>. <ref> depicts the architecture of the DenseNet model used in this work as introduced by <cit.> with a  growth rate  of 32.  All models were compiled with a binary cross entropy loss and the Adam optimizer <cit.>. Early stopping and reduced learning rate were scheduled for the training process over 50 and 15 epochs respectively. A learning rate of 0.01 was initially set and reduced by a factor of 10 after 15 epochs if the validation loss did not reduce. The aforementioned parameters were set empirically. To analyze the influence of preprocessed input slices to different window settings on classification of COPD, the plain DenseNet model was trained and tested on images linearly clipped to the full-range and the emphysema window settings.\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 DenseNet with Added Window-Setting Optimization Layer (DenseNetWSO)\n\nA window-setting optimization (WSO) layer was added to the aforementioned DenseNet as suggested by <cit.>. Both a Rectified Linear Unit (ReLU) function and a sigmoid function were initially considered for the WSO layer. The ReLU variant consistently outperformed the sigmoid variant for the validation set. Therefore, only DenseNetWSO models with a ReLU activation function in the WSO layer are considered here. As depicted in <ref>, the WSO layer consisted of a 1x1 convolution layer followed by a ReLU activation function. The ReLU hereby acts as a windowing function, trained to find an optimal window setting for the classification task. The  WW  and  WL values were related to the learnable weight (w) and bias (b) parameters of the ReLU function, taken from <cit.> with correction,\n\n\n    f_ReLU(x) = max(min(wx+b, U), 0),   wherew=U/WW,   b=U/WW(WW/2 - WL).\n\n\n\n\n\nThe parameter U sets the upper bound for the ReLU windowing function. Therefore, to achieve learned window settings that range between zero and one, the upper limit was set to U = 1. The DenseNetWSO model was trained to converge to an optimal window setting after being initialized to the full-range and the emphysema window settings, while simultaneously adjusting learnable parameters of the DenseNet block for  classification  of COPD.  Initialization  of the WSO layer was  carried  out  by  defining  the learnable parameters for each window setting respectively. To do so, all input slices  for DenseNetWSO were  given in  the  full-range  window setting  and  normalized. The optimal window settings learned by the model were calculated using (<ref>). All other architectural elements and training processes were identical to that of the plain DenseNet.\n\n\n\n\n  \u00a7.\u00a7.\u00a7 DenseNetWSO with Sequentially Trained WSO Parameters (DenseNetFNF)\n\n\nThe learned window setting by the DenseNetWSO model after initialization to the full-range window setting exhibited large standard deviations over seven runs, as described in <ref>. In an attempt to stabilize the learned window setting over all runs, the DenseNetWSO model was first trained with the learnable parameters from the WSO layer, w and b, frozen. In doing so, the clipping parameters from the WSO layer were fixed to the initialized settings. Then, the model was further trained with the WSO layer unfrozen, which allowed its parameters to adjust for the  optimal window setting. Additionally, the  same  model  was  trained continuously for  a  third  round,  again with  the  learnable parameters of the WSO  layer frozen. We refer to this sequence of training with frozen, not-frozen, and frozen (FNF) WSO layer learnable parameters as DenseNetFNF. Similar to DenseNetWSO, all input slices for DenseNetFNF were clipped to  the  full-range  windowing  and  normalized. All other architectural elements and training processes were identical to that of the plain DenseNet.\n\n\n\n \u00a7.\u00a7 Evaluation Metrics\n\n\nTraining was repeated seven times and each run was inferred on once with the test data. The Receiver Operating Characteristics (ROC) curve, and area under the ROC curve (AUC) were  used to assess the performance of DenseNet models with different window settings on the binary classification task. As the AUC utilizes different threshold choices, this metric was considered over the conventional accuracy metric. Additionally, for smaller sample sizes, the choice of maximizing for sensitivity or (1-specificity) becomes ambiguous since there is an inherent trade-off between the two parameters. Therefore, the AUC value was taken as the evaluation metric to resolve any ambiguities based on the choice of threshold by providing the highest value for the best observer while independent of the choice of a threshold <cit.>. The Scikit-learn library (version 1.2.0) was used to generate the ROC curves, choose optimal thresholds for each curve, and calculate the respective AUC values <cit.>.\n\n\n\n\n\u00a7 RESULTS\n\nThis section presents the classification results of the three DenseNet variants. \n\n\n\n \u00a7.\u00a7 Manually-adjusted WSO\n\n\nUsing the plain DenseNet model, slice-level ROC plots with corresponding AUC values were compared between full-range and emphysema window settings in <ref>. Since the test set had balanced slices from both classes of no COPD and COPD, the chance diagonal was used as a visual guide to mark the AUC value of 0.5. We see in <ref> that clipping data to emphysema window setting allows the model to consistently achieve better results (mean AUC = 0.86\u00b10.04) in comparison to the full-range window setting (mean AUC = 0.80\u00b10.05). The single highest AUC value of 0.91 corresponded to the plain DenseNet model with the input slices preprocessed to the emphysema window setting.\n\n\n\n\n\n\n \u00a7.\u00a7 Automatically-adjusted WSO\n\n\nThe window-setting values in <ref> correspond to the mean and standard deviation values for WW and WL over the seven runs of each arrangement. The information in <ref> is independent  of the inference  data  set,  as  the  learned  window-setting  values are fixed model-specific parameters after a completed training run. The learned WW and WL parameters were calculated from the weights and bias values of the WSO layer using (<ref>). <ref> shows the learned and the corresponding initialization window setting for each WSO model. Note that the window settings used for initialization of WSO models were the same as the parameters used for clipping the inputs to the plain DenseNet.\n\n\n\n\n\n\n\n    < g r a p h i c s >\n\nfigureROC plots and AUC values show inference on slice-level test data for each run of the plain DenseNet for input data clipped to full-range and emphysema window settings.\n\n\n\n\n\n\n\n\n\n    < g r a p h i c s >\n\nfigureThe full-range and the emphysema window settings (green) plotted against the mean learned window setting with standard deviation over seven runs for DenseNetWSO (blue) and DenseNetFNF (orange). Note, the standard window settings were used to clip the inputs to the plain DenseNet model, and also to initialize the DenseNetWSO and DenseNetFNF models. Exact values for window settings are provided in <ref>.\n\n\n\n\n\n\n\n\ntableFull-range and emphysema window setting parameters in comparison to windowing parameters optimized by the DenseNetWSO and DenseNetFNF models. The learned window setting values are given as the mean and standard deviation values over seven runs for each model.\n\n\n\n  \n    Window setting (model)      Full-range (WW, WL) HU     Emphysema (WW, WL) HU\n\n    Standard (Plain DenseNet)            (2048, 0)     (124, -962) \n\n    Learned (DenseNetWSO)            (1301 \u00b1 676, -373 \u00b1 338)           (90 \u00b1 13, -979 \u00b1 6)\n\n    Learned (DenseNetFNF)            (993 \u00b1 337, -528 \u00b1 169)          (114 \u00b1 37, -967 \u00b1 19)\n\n    \n\n\n\n\n\n\nWe notice a shift towards the lower end of the HU range in all learned window settings, as given by <ref> and <ref>. The mean learned WL decreased more drastically for models initialized to the full-range window setting. The observed trends suggest a convergence towards the standard emphysema window setting for the learned WW and WL parameters by both DenseNetWSO and DenseNetFNF when initialized to the full-range window setting. Between the two models, DenseNetFNF learned a window setting closer to the emphysema window setting regardless of initialization window setting. However, when initialized to the full-range window, the DenseNetFNF arrived at the mean WW and WL parameters over seven runs with less deviation in comparison to when the model was initialized to the emphysema window. Overall, we see that when the learned window setting is closer to the standard emphysema window, the better mean AUC values are achieved.\n\n\n\n<ref> and <ref> depict the ROC curves for DenseNetWSO and DenseNetFNF models respectively. We observe that initialization to emphysema windowing  results in more consistent AUC values over seven runs compared to the full-range window setting for the DenseNetWSO model. Conversely, for the DenseNetFNF model, initialization to the full-range window generates more consistent AUC values over seven runs compared to the emphysema window setting. These results are in agreement with the standard deviation values given in <ref>. The highest AUC value achieved between the DenseNetWSO and the DenseNetFNF models was 0.91. This corresponded to the emphysema window setting initialization for the DenseNetFNF model. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Optimal Window Setting for COPD Detection\n\n\nThe mean AUC values for all model and window setting combinations for inference on the same test set are provided in <ref>. Overall, the plain DenseNet with input slices initialized to the emphysema window setting resulted in the best mean AUC value at 0.86\u00b10.04 over all runs. Implementation of the WSO layer in DenseNetWSO and DenseNetFNF models did not drastically enhance the AUC compared to the results obtained with the plain DenseNet. Taking the plain DenseNet model with full-range input images as baseline, the DenseNetFNF model generated slightly better AUC values when initialized to either window setting. However, The most optimal window setting for the COPD detection task was the standard emphysema window setting of (124, -962) HU and not a window setting learned by either of the automated WSO models.\n\n\n\n\n\n\n\n\n\n\u00a7 DISCUSSION\n\n\nResults in <ref> indicate that adjusting input slices to different window settings directly impacts the binary classification of COPD. Looking closer at the plain DenseNet model, clipping the input data to different window settings influenced the AUC values: with AUC values for the plain DenseNet model for full-range input data as baseline, when the input was clipped to the emphysema window, the AUC values increased from 0.80 to 0.86.\n\nThe AUC values for the  DenseNetWSO model in <ref> suggest the shortcoming of the model in simultaneously detecting COPD and converging to optimal windowing parameters when initialized to the full-range window setting. Furthermore, the windowing parameters learned with this setup suffered from large standard deviations between the seven runs, as seen in <ref>. Lower standard deviations in learned window settings were observed when the WSO layer was trained with periodically frozen learnable parameters, as implemented in DenseNetFNF initialized to the full-range window setting. \n\n\nThrough automatic WSO, only minimal improvement in AUC value was observed with the DenseNetWSO and the DenseNetFNF models initialized to emphysema window setting, in comparison to the baseline. The window settings learned by these two models were in the vicinity of the standard emphysema window at the lower ranges of the HU scale. However, neither DenseNetWSO nor DenseNetFNF outperformed the mean AUC values obtained with the plain DenseNet model with images clipped to the standard emphysema window setting. A possible explanation is that although the single WSO layer was effective in converging to the optimal emphysema window setting, it was not sufficiently complex for the task of optimal window setting selection.\n\n\n\nThe standard emphysema windowing is tailored to present high contrast between healthy and emphysematous tissue in the lung. Therefore, as the ground truth labels for our dataset were graded based on the severity of emphysema, the results were in line with the hypothesis that slices clipped directly to the standard emphysema windowing, or automatically clipped with the WSO layer to learned window-setting parameters in the proximity of standard emphysema window, would improve classification of COPD with DenseNets. Optimizing for window setting as a means of increasing contrast in slices was effective for the detection task because the Fleischner Score (FS) ground-truth labels were directly based on disease-relevant morphological changes in the lung. Therefore, for models trained with spirometry-based GOLD standard COPD stages as ground truth label for lung CTs, adjusting input data based on window setting could potentially not be as effective. Utilizing FS as ground-truth labels also enabled us to achieve comparable results to related works in the literature, despite our use of a considerably smaller dataset <cit.>,<cit.>,<cit.>.\n\nThe main limitation of this work was its small dataset, giving rise to intra-slice correlation for slice-level evaluations. Additionally, all patients were examined at the same hospital. Extendability of our findings to a larger, more diverse dataset should be further explored. In the context of COPD, future works could further explore categorical classification of the disease based on the progression scale introduced by the Fleischner society.\n\nWe showed that optimizing for a task-specific window-setting improved CNN outcome by enhancing disease-relevant information from the input data. Our findings can be extended to a range of computer vision tasks in medicine focusing on X-ray and CT data. Specifically, when disease relevant window settings are commonly used by radiologists, that information can be extended to the deep learning pipeline.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\n\nOur results demonstrate the importance of incorporating the common clinical workflow process of window setting selection for CT scans in the CNN pipeline for binary classification of COPD. Specifically, preprocessing CT images to emphysema window setting improved the plain DenseNet model's performance. Furthermore, we showed that when information regarding the optimal window setting for classification of COPD is unknown, learning an optimal windowing through the addition of a WSO layer with the DenseNetFNF model would result in higher AUC values in comparison to training a plain DenseNet model with full-range normalized slices. \n\n\n\n\n\n\n00\n\nVogelmeier2017 C. F. Vogelmeier\u00a0et al., \u201cGlobal Strategy for the Diagnosis, Management, and Prevention of Chronic Obstructive Lung Disease 2017 Report. GOLD Executive Summary,\u201d Am. J. Resp. Crit. Care. Med.., vol. 195, no. 5, pp. 557\u2013582, Mar. 2017. Accessed on: Aug. 17, 2022, DOI: 10.1164/RCCM.201701-0218PP, [Online].\n\n\n\n\n\nWHO2022 World Health Organization. (2022, May. 20). Fact sheets: Chronic Obstructive Pulmonary Disease (COPD). Geneva, Switzerland. May 20, 2022. [Online]. Available: https://www.who.int/en/news-room/fact-sheets/detail/chronic-obstructive-pulmonary-disease-(copd). Accessed on: Aug. 18, 2022.\n\n\nMannino2007 D. M. Mannino and S. Braman, \u201cThe epidemiology and economics of chronic obstructive pulmonary disease,\u201d in  Proc. Am. Thorac. Soc.., vol. 4, no. 7, pp. 502\u2013506, Oct. 2007, Accessed on: Aug. 17, 2022, DOI: 10.1513/pats.200701-001FM, [Online].\n\nZhao2020 Q. Zhao\u00a0et al., \u201cThe impact of COPD and smoking history on the severity of COVID-19: A systemic review and meta-analysis,\u201d J. Med. Virol.., vol. 92, no. 10, pp. 1915\u20131921, Oct. 2020. Accessed on: Aug. 17, 2022, DOI: 10.1002/JMV.25889, [Online].\n\nHalpin2021 D. M. G. Halpin\u00a0et al., \u201cGlobal Initiative for the Diagnosis, Management, and Prevention of Chronic Obstructive Lung Disease. The 2020 GOLD Science Committee Report on COVID-19 and Chronic Obstructive Pulmonary Disease ,\u201d Am. J. Resp. Crit. Care. Med.., vol. 203, no. 1, pp. 24\u201336, Jan. 2021. Accessed on: Aug. 18, 2022, DOI: 10.1164/RCCM.202009-3533SO, [Online].\n\nGrenier2020 P. A. Grenier. \u201cEmphysema at CT in Smokers with Normal Spirometry: Why It Is Clinically Significant,\u201d \u00a0Radiology., vol. 296, no. 3, pp. 650\u2013651, Jul. 2020. Accessed on: Aug. 18, 2022, DOI: 10.1148/RADIOL.2020202576, [Online].\n\nLynch2015 D. A. Lynch\u00a0et al., \u201cCT-Definable Subtypes of Chronic Obstructive Pulmonary Disease: A Statement of the Fleischner Society,\u201d \u00a0Radiology., vol. 277, no. 1, pp. 192\u2013205, Oct. 2015. Accessed on: Aug. 18, 2022, DOI: 10.1148/radiol.2015141579, [Online].\n\ncopdGeneStudy E. A. Regan\u00a0et al., \u201cGenetic epidemiology of COPD (COPDGene) study design,\u201d COPD., vol. 7, no. 1, pp. 32\u201343, Feb. 2010. Accessed on: Aug. 18, 2022, DOI: 10.3109/15412550903499522, [Online].\n\nVestbo2008 J. Vestbo\u00a0et al., \u201dEvaluation of COPD Longitudinally to Identify Predictive Surrogate End-points (ECLIPSE),\u201d \u00a0Eur. Respir. J.., vol. 31, no. 4, pp. 869\u2013873, Apr. 2008. Accessed on: Aug. 18, 2022, DOI: 10.1183/09031936.00111707, [Online].\n\nLecun2015 Y. Lecun, Y. Bengio, and G. Hinton, \u201dDeep learning,\u201d Nature., vol. 521, no. 7553, pp. 436\u2013444, May 2015. Accessed on: Aug. 18, 2022, DOI: 10.1038/nature14539, [Online].\n\n\nHo2021 T. T. Ho\u00a0et al., \u201cA 3D-CNN model with CT-based parametric response mapping for classifying COPD subjects,\u201d \u00a0Sci. Rep.., vol. 11, no. 1, pp. 1\u201312, Jan. 2021. Accessed on: Aug. 18, 2022, DOI: 10.1038/s41598-020-79336-5, [Online].\n\nGonzalez2018 G. Gonzalez\u00a0et al., \u201cDisease Staging and Prognosis in Smokers Using Deep\nLearning in Chest Computed Tomography,\u201d  Am. J. Resp. Crit. Care. Med.., vol. 197, no. 2, pp. 193\u2013203, Jan. 2018. Accessed on: Aug. 18, 2022, DOI: 10.1164/RCCM.201705-0860OC., [Online].\n\nTang2020 L. Y. W. Tang, H. O. Coxson,  S. Lam, J. Leipsic, R. C. Tam, and D. D. Sin, \u201dTowards large-scale case-finding: training and validation of residual networks for detection of chronic obstructive pulmonary disease using low-dose CT,\u201d Lancet Digit. Health., vol. 2, no. 5, pp. e259\u2013e267, May 2020. Accessed on: Aug. 18, 2022, DOI: 10.1016/S2589-7500(20)30064-9, [Online].\n\nZhang2022 L. Zhang, B. Jiang, H. J. Wisselink, R. Vliegenthart, and X. Xie, \u201dCOPD identification and grading based on deep learning of lung parenchyma and bronchial wall in chest CT images,\u201d Br. J. Radiol.., vol. 95, no. 1133, May 2022. Accessed on: Feb. 03, 2023, DOI: 10.1259/bjr.20210637, [Online].\n\n\nKloenne2020 M. Kloenne\u00a0et al., \u201dDomain-specific cues improve robustness of deep learning-based segmentation of CT volumes,\u201d  \u00a0Sci. Rep.., vol. 10, no. 1, pp. 1\u20139, Jul. 2020. Accessed on: Aug. 18, 2022, DOI: 10.1038/s41598-020-67544-y, [Online].\n\nLee2018 H. Lee, M. Kim, and S. Do. (Dec. 2018). \u201dPractical window setting optimization for medical image deep learning.\u201d Presented at \u00a0NIPS. [Online]. Available: https://arxiv.org/abs/1812.00572.\n\n\nWang2021 X. Wang\u00a0et al., \u201dA deep learning algorithm for automatic detection and classification of acute intracranial hemorrhages in head CT scans,\u201d \u00a0Neuroimage. Clin.., vol. 32, pp. 1\u201310, Jan. 2021, Accessed on: Aug. 18, 2022, DOI: 10.1016/J.NICL.2021.102785, [Online].\n\n\nTensorFlow M. Abadi\u00a0et al., \u201cTensorFlow: Large-Scale Machine Learning on Heterogeneous Systems,\u201d 2015. Accessed on: Aug. 29, 2022, Available:  https://www.tensorflow.org/, [Online].\n\n\n\n\nHegel2021 M. Hegel, \u201dClassification of Chronic Obstructive Pulmonary Disease in\nClinical X-Ray Compute Tomography using Deep Learning Techniques,\u201d M.S. thesis, Info., Tech. Uni. Munich, Munich, Germany, 2021.\n\n\nHuang2018 G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, \u201dDensely Connected Convolutional Networks,\u201d in \u00a0Proc. IEEE CVPR, Honolulu, HI, USA, 2017, pp. 2261\u20132269.\n\nKingma2014 D. P. Kingma and J. L. Ba. (Dec. 2015). \u201dAdam: A Method for Stochastic Optimization.\u201d Presented at \u00a0ICLR. [Online]. Available: https://arxiv.org/abs/1412.6980.\n\nRuiz2018 Medium: Towards data science. (2018, Oct. 10). Understanding and visualizing DenseNets. [Online]. Available: https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a. Accessed on: Jan. 02, 2022.\n\n\n\nChakrabotry2018\nD. P. Chakraborty, \u201cModeling the binary task,\u201d in Observer Performance Methods for Diagnostic Imaging. Boca Raton, FL, USA: CRC Press, 2021, ch. 3, sec. 9-12, pp. 47\u201357.\n\nScikit-learn F. Pedregosa\u00a0et al., \u201cScikit-learn: Machine Learning in Python,\u201d JMLR., vol. 12, pp. 2825\u20132830, 2011. Accessed on: Aug. 29, 2022, Available:  https://scikit-learn.org/, [Online].\n\n\n\n\n\n\n\n\n\n\n"}