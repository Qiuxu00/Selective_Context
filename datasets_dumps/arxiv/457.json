{"entry_id": "http://arxiv.org/abs/2303.06679v1", "published": "20230312145048", "title": "RotoGBML: Towards Out-of-Distribution Generalization for Gradient-Based Meta-Learning", "authors": ["Min Zhang", "Zifeng Zhuang", "Zhitao Wang", "Donglin Wang", "Wenbin Li"], "primary_category": "cs.CV", "categories": ["cs.CV"], "text": "\n\n\n\n\n\n\n\nJournal of  Class Files,\u00a0Vol.\u00a014, No.\u00a08, August\u00a02021\nShell et al.: A Sample Article Using IEEEtran.cls for IEEE Journals\n\n\n\n\n\nRotoGBML: Towards Out-of-Distribution Generalization for Gradient-Based Meta-Learning\n    Min Zhang^1, 2, Zifeng Zhuang^2, Zhitao Wang^2, Donglin Wang^2, \u2020, Wenbin Li^3\n^\u2020 Corresponding author, ^1 Zhejiang University, ^2 Westlake University\n^3 Nanjing University, liwenbin@nju.edu.cn\n{zhangmin, zhuangzifeng, wangzhitao, wangdonglin}@westlake.edu.cn\n\n\n\n    March 30, 2023\n==========================================================================================================================================================================================================================================================================\n\n\n\n\n    Gradient-based meta-learning (GBML) algorithms are able to fast adapt to new tasks by transferring the learned meta-knowledge, while assuming that all tasks come from the same distribution (in-distribution, ID). However, in the real world, they often suffer from an out-of-distribution (OOD) generalization problem, where tasks come from different distributions. OOD exacerbates inconsistencies in magnitudes and directions of task gradients, which brings challenges for GBML to optimize the meta-knowledge by minimizing the sum of task gradients in each minibatch. To address this problem, we propose RotoGBML, a novel approach to homogenize OOD task gradients. RotoGBML uses reweighted vectors to dynamically balance diverse magnitudes to a common scale and uses rotation matrixes to rotate conflicting directions close to each other. To reduce overhead, we homogenize gradients with the features rather than the network parameters. On this basis, to avoid the intervention of non-causal features (e.g., backgrounds), we also propose an invariant self-information (ISI) module to extract invariant causal features (e.g., the outlines of objects). Finally, task gradients are homogenized based on these invariant causal features. Experiments show that RotoGBML outperforms other state-of-the-art methods on various few-shot image classification benchmarks.\n\n\n\n    Out-of-distribution, Few-shot learning, Gradient-based meta-learning, Multi-task learning\n\n\n\n\u00a7 INTRODUCTION\n\nDeep learning has achieved great success in many real-world applications such as visual recognition\u00a0<cit.> and natural language processing\u00a0<cit.>.\nHowever, deep learning relies heavily on large-scale training data, showing the limitation of not being able to effectively generalize to small data regimes.\nTo overcome this limitation, researchers have explored and developed a variety of meta-learning algorithms\u00a0<cit.>, whose goal is to extract the meta-knowledge over the distribution of tasks rather than instances, and hence compensate for the lack of training data. Among the two dominant strands of meta-learning algorithms, we prefer gradient-based\u00a0<cit.> over metric-based\u00a0<cit.> for their flexibility and effectiveness. Unfortunately, most of these researches have a restrictive assumption that each task comes from the same distribution (in-distribution, ID). However, distribution shifts among tasks are usually inevitable in real-world scenarios\u00a0<cit.>.\n \nIn this paper, we consider a realistic scenario, where each minibatch is constructed of tasks from different distributions or datasets (out-of-distribution, OOD). Surprisingly, through repeated experiments, we found that the OOD tasks seriously affect the performance of GBML, e.g., the performance of MAML drops from 75.75% to 54.29% with CUB dataset under the 5-way 5-shot setting. \nIntuitively, we explain the possible reason from the optimization objective of the meta-knowledge.\nSpecifically, GBML algorithms learn the meta-knowledge by minimizing the sum of gradients for each minibatch of tasks (see equation\u00a0(<ref>)).\nIf task gradients have a significant inconsistency, it may cause the learned meta-knowledge to be dominated by certain tasks with large gradient values and fail to generalize to new tasks, affecting the performance of GBML algorithms.\nThe OOD generalization problem exacerbates the phenomenon, where task gradients are inconsistent. \nTo demonstrate the impact of the OOD problem on task gradients in each minibatch, we next give an illustrative example.\n\n\n \nWe take two different distributions to evaluate the impact in Figure\u00a0<ref>.\nThe optimization process of meta-knowledge in GBML has two loops: an inner-loop at task space (Figure\u00a0<ref> (a) and (c)) and an outer loop at meta space (Figure\u00a0<ref> (b) and (d)). \nWe randomly sample two OOD tasks (task1 and task2) from the two different distributions and represent them using green and gray contour lines, respectively.  \nFirst, in the task space, each task learns a task-specific parameter \u03c8_1^\u03c4 or \u03c8_2^\u03c4 using the same meta-knowledge \u03c8. \nThen, in the meta space, the losses of two OOD tasks are calculated using \u03c8_1^\u03c4 and \u03c8_2^\u03c4 and are summed in turn to optimize the meta-knowledge from \u03c8 to \u03c8^*.\nFrom Figure\u00a0<ref> (a), it clearly shows that in the whole optimization process, task2 has a large gradient value (the length of g_2 > g_1) and the large gradient dominates the learning process, i.e., the updated meta-knowledge \u03c8^* is close to task2 in Figure\u00a0<ref> (b).\nThis causes the learning of meta-knowledge to be dominated by task2 and ignore the existence of task1, and eventually GBML cannot fast adapt to new tasks using the learning meta-knowledge.\nWhen the gradient directions of OOD tasks are conflicting, the meta-knowledge optimized by summing and averaging the two task gradients may counteract each other.    \n\nIn this paper, to solve inconsistencies in task-gradient magnitudes and directions, we propose a simple yet effective framework, RotoGBML, to simultaneously homogenize magnitudes and directions and boost the learning of meta-knowledge in GBML.\nSpecifically, (1) RotoGBML solves the gradient magnitudes by dynamically reweighting task gradients at each step of the learning process, while encouraging the learning of ignored tasks. (2) Instead of directly modifying gradient directions, RotoGBML smoothly rotates each task space, seamlessly aligning gradient directions in the long run (see Figure\u00a0<ref> (c)). \n(3) To reduce overhead, we use the features instead of network parameters to homogenize task gradients and more details can be found in Section\u00a0<ref>. \n(4) We also propose an invariant self-information (ISI) module to extract invariant causal features (e.g., object outline), which are used for homogenization.\nThe introduction of ISI is mainly because of the fact that the features learned by neural networks are inevitably interfered with by some non-causal features (e.g., image backgrounds), which in turn affects the homogeneity of task gradients.\nWe theoretically and experimentally demonstrate that the OOD tasks affect meta-knowledge learning process. The main contributions could be briefly summarized as follows:\n\n\n  * We consider a real-world OOD scenario and propose a general RotoGBML algorithm to solve the OOD generalization problem. RotoGBML helps GBML algorithms learn good meta-knowledge by homogenizing task-gradient magnitudes and directions.\n\n  * To reduce memory, we homogenize task gradients at a feature level. Also, we design an invariant self-information (ISI) module to extract the invariant causal features. Homogenizing gradients using these features provides further guarantees for learning robust meta-knowledge. \n\n  * We theoretically evaluate our motivation and experimentally demonstrate the effectiveness of RotoGBML algorithm in various few-shot image classification benchmarks.\n\n\n\n\u00a7 PRELIMINARIES\n\n\n\n\n\n \u00a7.\u00a7 Task formulation in GBML.\n\nIn this paper, a supervised learning setting is considered, where each data point is denoted by (x,y) with x\u2208 X being the input and y\u2208 Y being its corresponding label.\nGBML assumes N training tasks {\ud835\udcaf_i}_i=1^N\u223c\ud835\udcaf_tr in each minibatch to be sampled, and an arbitrary testing task \ud835\udcaf_i\u223c\ud835\udcaf_te is picked.\nFormally, each n-way k-shot task \ud835\udcaf_i consists of a support set \ud835\udcae_i=(x_i^s, y_i^s) and a query set \ud835\udcac_i=(x_i^q, y_i^q).\nx_i^s\u2208\u211d^n_s\u00d7 d, x_i^q\u2208\u211d^n_q\u00d7 d, y_i^s\u2208\u211d^n_s\u00d7 n and y_i^q\u2208\u211d^n_q\u00d7 n, where d=c\u00d7 h\u00d7 w indicates the image size, n_s and n_q denote the number of support and query examples, respectively.\nThe label spaces of training, validation and testing tasks are different, i.e., Y_tr\u2229 Y_val\u2229 Y_te =\u2205.\nMost gradient-based meta-learning (GBML) algorithms have a strict assumption for tasks as:\n\n   In-distribution (ID): each task is randomly sampled from the same distribution \u2119(\ud835\udcaf), i.e., \n   \ud835\udcaf_i\u223c\u2119(\ud835\udcaf) comes from the task set {\ud835\udcaf_tr, \ud835\udcaf_val, \ud835\udcaf_te} with \u2200 i.  \n \n\n\nThe assumption indicates a highly restrictive setting due to the following reasons: \n(1) It is contradictory that tasks with disjoint classes come from the same distribution.\n(2) The data collection process is susceptible to some unobservable variables, which can cause distribution shifts even from the same dataset.\nImproving the generalization of gradient-based meta-learning (GBML) algorithms in the real world is very important.\n\n\n\n \u00a7.\u00a7 Task optimization in GBML.\n\n\nGBML aims to learn a good meta-knowledge and fast adapts to new tasks using two optimization loops (inner loop and outer loop).\nGenerally, the network architectures of GBML contain a feature encoder f_\u03b8 parameterized by \u03b8, which is used to extracted features f_\u03b8: \u211d^d\u2192\u211d^m, and a classifier c_\u03d5 parameterized by \u03d5, which is used to output predict labels c_\u03d5: \u211d^m\u2192\u211d^n. \nIn the inner loop, the model is grounded to an initialization (or meta-knowledge), i.e., (\u03d5, \u03b8), which is adapted to the i-th task in a few gradient steps \u03c4 (typically 1 \u223c 10 steps) by using its support set \ud835\udcae_i.\nIn the outer loop, the performance of the adapted model, i.e.  (\u03d5_i^\u03c4, \u03b8_i^\u03c4), is measured on the query set \ud835\udcac_i, and in turn used to optimize the initialization from (\u03d5, \u03b8) to (\u03d5^*, \u03b8^*).\nLet \u2112 denotes the loss function and the above interleaved process is formulated as a bi-level optimization,\n\n\n    (\u03d5^*, \u03b8^*) := min_(\u03d5, \u03b8)1/N\u2211_i=1^N\ud835\udd3c_(x_i^q, y_i^q)\u223c\ud835\udcac_i\u2112_i(\u03d5_i^\u03c4(\u03b8_i^\u03c4(x_i^q)), y_i^q), \n       s.t. (\u03d5_i^\u03c4, \u03b8_i^\u03c4) \u2190min_(\u03d5_i^0, \u03b8_i^0)\ud835\udd3c_(x_i^s, y_i^s)\u223c\ud835\udcae_i\u2112_i(\u03d5_i^0(\u03b8_i^0(x_i^s)), y_i^s),\n\n\nwhere equations\u00a0(<ref>) and\u00a0(<ref>) are the outer-loop and inner-loop, respectively.\n(\u03d5_i^0, \u03b8_i^0) = (\u03d5, \u03b8) is the initial parameters for the i-th task.\nThe learning of meta-knowledge uses the summed and averaged gradients over all tasks in current batch.\n\n\n\n\n\n\n\n\n\u00a7 METHODOLOGY\n\n\nTo improve the generalization ability of GBML algorithms in real-world scenarios, in this paper, we consider an  out-of-distribution (OOD) setting, i.e., all tasks randomly sampled from a distribution set {\u2119_i(\ud835\udcaf)}_i=1^N. A new assumption on the OOD task distributions is proposed as follows:\n\n   Out-of-distribution (OOD): each task comes from the different distributions {\u2119_i(\ud835\udcaf)}_i=1^N, i.e., \ud835\udcaf_i\u223c\u2119_i(\ud835\udcaf) and \ud835\udcaf_j\u223c\u2119_j(\ud835\udcaf) with \u2200 i, j, i \u2260 j and \u2119_i(\ud835\udcaf) \u2260\u2119_j(\ud835\udcaf).    \n   \n\n\nTo solve the problem that OOD exacerbates the inconsistencies of task-gradient magnitudes and directions, we introduce RotoGBML, a novel algorithm that consists of two building blocks:\n(1) Reweighting OOD task-gradient magnitudes. \nA reweighted vector set \ud835\udc30_\u03c9={\u03c9_i}_i=1^N parameterized by \u03c9 is used to normalize the magnitudes to a common scale (see Section\u00a0<ref>);\n(2) Rotating OOD task-gradient directions. \nA rotation matrix set R_\u03b3={\u03b3_i}_i=1^N parameterized by \u03b3 is used to rotate the directions close to each other (see Section\u00a0<ref>).\nThe two blocks complement each other and facilitate meta-knowledge to learn common information of all tasks in each minibatch, thereby fast adapting to new tasks with only a few samples. The optimization of RotoGBML is re-defined as:\n\n\n    (\u03d5^*, \u03b8^*) := min_(\u03d5,\u03b8)1/N\u2211_i=1^N\ud835\udd3c_(x_i^q, y_i^q)\u223c\ud835\udcac_i\u03c9_i\u2112_i(\u03d5_i^\u03c4(\u03b3_i\u03b8_i^\u03c4(x_i^q)), y_i^q), \n       s.t. (\u03d5_i^\u03c4, \u03b8_i^\u03c4) \u2190min_(\u03d5_i^0, \u03b8_i^0)\ud835\udd3c_(x_i^s, y_i^s)\u223c\ud835\udcae_i\u2112_i(\u03d5_i^0(\u03b8_i^0(x_i^s)), y_i^s).\n\n\nWe use red to annotate the differences between the generic GBML and RotoGBML.\nIt clearly shows that a set of corresponding \u03c9_i and \u03b3_i for each task at each batch is used to homogenize gradients in the outer loop optimization process.\nAnd, if task-gradient magnitudes and directions are consistent,  the equation\u00a0(<ref>) degenerates into the equation\u00a0(<ref>). \nIt is worth mentioning that our proposed RotoGBML algorithm is a model-agnostic method that can be equipped with arbitrary GBML algorithms (More details is given in Section\u00a0<ref>).\n\n\n\n \u00a7.\u00a7 Reweighting OOD Task-Gradient Magnitudes\n\n\nHow to determine the value of \ud835\udc30_\u03c9? \nThis is a key challenge for reweighting OOD task-gradient magnitudes.\nMost previous works on multi-task learning use static approaches, such as hyperparameters or prior assignment\u00a0<cit.>. However, these methods are difficult to adapt to the learning process due to the use of fixed values \ud835\udc30_\u03c9={\u03c9_i}_i=1^N for each task. \nIn Table\u00a0<ref>, the experiments of static reweighted vector evaluate the phenomenon. \nInstead, we dynamically adjust \u03c9_i to adapt task distribution shifts by using an optimization strategy over the training iterative process. \n  \nSpecifically, we initialize {\u03c9_i=1|i\u2208 N} for each task in each batch \ud835\udcaf_b={\ud835\udcaf_i|i\u2208 N}, which aims to treat each task equally at the beginning.\nThen, the reweighted vector set is dynamically adjusted by using average gradient norms for the current batch during training.\nThe optimization objective is as: \n\n    \u03c9^* := min_\u03c9\u2211_i=1^N\ud835\udd3c_(x_i^q, y_i^q)\u223c\ud835\udcac_i\u2112_\u03c9_i(\u03b8_i^\u03c4, x_i^q, y_i^q), \n       s.t. \u2112_\u03c9_i = g_wi - g\u0305_wb\u00d7 [I_i]^\u03b2_1,\n\nwhere \u00b7_1 is the \u2113_1-norm.\ng_wi=\u2207_\u03b8\u03c9_i\u2112_i(\u03b8_i^\u03c4(x_i^q), y_i^q)_2 is the \u2113_2-norm of the gradients for each reweighted task loss \u03c9_i\u2112_i in outer loop.\ng\u0305_wb=1/N\u2211_i=1^N g_wi is the average gradient for \ud835\udcaf_b.\nIn our experimental settings, we only use the gradients of feature encoder \u03b8 to optimize the reweighted vector set \ud835\udc30_\u03c9. \nThis operation not only saves compute times but also is reasonable because the feature knowledge is more helpfule for the generalization of GBML algorithms\u00a0<cit.>.\nI_i aims to balance each task gradient and the formulation is\nas follows:\n\n    I_i = \u2112\u0302_i/\u2211_i=1^N\u2112\u0302_i, \n               s.t. \u2112\u0302_i = \u2112_i/\u2112_i^0,\n\nwhere \u2112_i is the cross-entropy loss for query set in outer loop and \u2112_i^0 is the initial loss to be determineed as log(n) and n is classes.\n\nSpecifically, the vaule of I_i is used to adjust the tasks of learning too fast or too slow, i.e., the lower value of I_i encourages the task to train more slowly, and vice versa. \n\nIn equation\u00a0(<ref>), a novel hyperparameter \u03b2 is introduced to control the learning rate of each task.\nWhen the distributions of tasks very different, a higher \u03b2 should be used to produce the large learning rate.\nConversely, a lower \u03b2 is appropriate for similar tasks.\nNote that \u03b2=0 means the learning rate is equal for all tasks.\nThe dynamically optimized \u03c9_i can be integrated into the learning process to homogenize task-gradient magnitudes. \nIn the next section, we describe how to resolve conflicts of task directions in each batch. \n\n\n\n \u00a7.\u00a7 Rotating OOD Task-Gradient Directions\n\n\nHow to define and learn the matrix of R_\u03b3?\nThis is a key challege for rotating OOD task-gradient directions.\n(1) Definition.\nMotivated by previous work\u00a0<cit.>, we initialize R_\u03b3\u2208 SO(M), where SO(M) is special orthogonal group to denote the set of all rotation matrix \u03b3_i with size M (the network parameters).\nDue to the large size of M, to reduce overhead, we focus on feature-level task gradients \u2207_\u1e91_i^q\u2112_i (rather than \u2207_\u03b8\u2112_i).\nThis is reasonable due to chain rule \u2207_\u03b8\u2112_i = \u2207_\u03b8\u1e91_i^q\u00b7\u2207_\u1e91_i^q\u2112_i, where \u1e91_i^q = \u03b3_iz_i^q, z_i^q = \u03b8_i^\u03c4(x_i^q).\nFinally, R_\u03b3\u2208 SO(m) is used, where m is the size of feature dimensions.\n(2) Learning.\nR_\u03b3 aims to reduce the direction conflict of the task gradients in each batch by rotating the feature space.\nWe optimize \u03b3_i to make task spaces closer to each other and the objective is to maximize the cosine similarity or to minimize\n\n\n    \u03b3^* := min_\u03b3\u2211_i=1^N\ud835\udd3c_(x_i^q, y_i^q)\u223c\ud835\udcac_i\u2112_\u03b3_i(\u03b8_i^\u03c4, x_i^q, y_i^q),  \n       s.t. \u2112_\u03b3_i = - <\u03b3_ig_i, g\u0305_rb>,\n\nwhere g_i=\u2207_\u03b8\u2112_i(\u03b8_i^\u03c4(x_i^q), y_i^q), g_ri=\u03b3_ig_i=\u2207_\u1e91_i^q\u2112_i(\u03b3_i\u03b8_i^\u03c4(x_i^q), y_i^q) and g\u0305_rb=1/N\u2211_i\u2208 Ng_ri is the average gradient for \ud835\udcaf_b.\nThe optimization of the reweighted vector set in equation\u00a0(<ref>), the rotation matrix set in equation\u00a0(<ref>) and the neural network in equation\u00a0(<ref>) can be interpreted as a Stackelberg game: a two player-game in which the leader and follower alternately move to minimize their respective losses, and the leader knows how the followers will react to their moves. \nSuch an interpretation allows us to derive simple guidelines to guarantee training convergence, i.e., the network loss does not oscillate as a result of optimizing the two different objectives. We introduce more details in Appendix.\n\n\n\n \u00a7.\u00a7 Invariant Self-Information\n\n\nAs mentioned above, we homogenize the task gradients from feature level. However, these features learned by neural network are susceptible to some biases, e.g., image backgrounds or textures\u00a0<cit.>.\nFor example, in an image of a coat shape with a dog skin texture, the CNN tends to classify it as a dog rather than a coat. This is because the neural network trained with empirical risk minimization (ERM) are more prone to inrobust texture features and ignore robust shape features\u00a0<cit.>. \nIn this section, we further introduce the invariant self-information (ISI) module to extract the robust shape features as invariant causal features.\nWe homogenize OOD task gradients based on these invariant causal features, which helps the reweighted vector set and the rotation matrix set avoid being affected by these biases (e.g., texture features).\n\nHow to extract the robust shape features? \nSince there are no existing corresponding shape labels, this is a challenging problem.\nGiven an image, we observe that the shape regions tend to be more pronounced and carry a high information compared with neighboring regions.\nTherefore, at each layer of the neural network, we learn shape features by saving neurons that extract high-informative regions and zeroing out neurons in low-informative regions.\nSpecifically, we first extract features z_i^l\u2208\u211d^c^l\u00d7 k\u00d7 k from input data x_i\u2208\u211d^c\u00d7 h\u00d7 w in i-th task \ud835\udcaf_i, where l is the l-th layer of the neural network. Then a drop coefficient d is proposed to drop these less-information regions:\n\n    d(z_i,c^l) \u221d e^-\u2110(p_i,k^l-1)/T, \n       s.t. \u2110(p_i,k^l-1) = -log q_i,k^l-1(p_i,k^l-1),\n\nwhere p_i,k^l-1 is the k-th region for c-th channel's in z_i^l-1 and p_i,k^l-1\u2208\u211d^c_l-1\u00d7 k\u00d7 k. p_i,k^l-1 is sampled from the defined distribution q_i,k^l-1. \u2110 denotes self-information and T is temperature. When the amount of information of p_i,k^l-1 is low, that is, the value of this part of the self-information \u2110 is low, the corresponding neuron is not optimized. \n\nTo evaluate q_i,k^l-1, we use Manhattan radius C to obtain (2C+1)^2 regions as the neighbourhood of p_i,k^l-1. And, we also assume that p_i,k^l-1 and its neighbourhood regions \ud835\udca9_i,k^l-1 come from the same distribution.\nWe approximate q_i,k^l-1(\u00b7) with its kernel desity estimator and these neighbouring regions, the approximate  representation q\u0302_i,k^l-1 is shown as follows:\n\n    q\u0302_i,k^l-1(p) = 1/(2C+1)^2\u2211_p^'\u2208\ud835\udca9_i,k^l-1K(p, p^'),\n\nwhere K(\u00b7, \u00b7) is kernel function. \nA Gaussian kernel is used, i.e., K(p, p^')=1/\u221a(2\u03c0)hexp(-1/2h^2p-p^'^2), where h is the bandwidth.\nThen the information of p_i,k^l-1 is estimated by\n\n    \u2110\u0302(p_i,k^l-1) = -log {\u2211_p^'\u2208\ud835\udca9_i,k^l-1e^-1/2h^2p_i,k^l-1-p^'^2}.\n\n\nIf the more information is included, it can be observed that the larger the difference between p_i,k^l-1 and its neighbourhood regions \ud835\udca9_i,k^l-1. In other words, shapes are more unique in their surroundings and thus more informative.\n\n\n\n \u00a7.\u00a7 Implementation\n\n\nWe summarize the overall proposed approach in Algorithm\u00a0<ref>.\nIn this paper, we consider a more challenging and real-world setting, i.e., tasks are randomly sampled from different distributions during training and testing phases.\nIn the training phase, we first use the invariant self-information (ISI) module to extract the invariant causal features.\nThen, based on these invariant features, we use the reweighted vector set \ud835\udc30_\u03c9 to reweight task-gradient magnitudes and the rotating matrix R_\u03b3 to rotate task-gradient directions.\nFinally, these homogenized task gradients are used to optimize the meta-knowledge in equation\u00a0<ref>.\nIn the testing phase, invariant self-information (ISI) module is removed to examine whether our network has truly learned invariant features.\nWe also remove \ud835\udc30_\u03c9 and R_\u03b3 to evaluate the performance of meta-knowledge learned by gradient-based meta-learning (GBML) algorithms.\n\n\n\n\n\u00a7 THEORETICAL ANALYSIS\n\n\nIn this section, we first theoretically investigate why OOD acerbates inconsistencies in task magnitudes and directions.\nWe sample two tasks from different distributions, where \ud835\udcaf_i=(\ud835\udcae_i, \ud835\udcac_i)\u223c\u2119_i(\ud835\udcaf) and \ud835\udcaf_j=(\ud835\udcae_j, \ud835\udcac_j)\u223c\u2119_j(\ud835\udcaf) with i \u2260 j. In outer loop, the gradient difference is calculated as:\n\n    d_ij =    \u2207_(\u03d5,\u03b8)\u2112_i(\u03d5_i^\u03c4(\u03b8_i^\u03c4(x_i^q)), y_i^q) \n       - \u2207_(\u03d5,\u03b8)\u2112_j(\u03d5_j^\u03c4(\u03b8_j^\u03c4(x_j^q)), y_j^q),\n\nwhere g_i=\u2207_(\u03d5,\u03b8)\u2112_i(\u03d5_i^\u03c4(\u03b8_i^\u03c4(x_i^q)), y_i^q) and g_j=\u2207_(\u03d5,\u03b8)\u2112_j(\u03d5_j^\u03c4(\u03b8_j^\u03c4(x_j^q)), y_j^q) are gradients of task \ud835\udcaf_i and \ud835\udcaf_j, respectively.\nTo bridge the connections of task distributions and task gradients, we introduce Total Variation Distance (TVD) to re-estimate d_ij on the task distribution.\nThe definition of Total Variation Distance (TVD) is shown as follows:\n\n    (Total Variation Distance (TVD)) For two distributions P and Q, defined over the sample space \u03a9 and \u03c3-field \u2131, the TVD is defined as P-Q_T V:=sup _A \u2208\u2131|P(A)-Q(A)|.\n    \n\nIt is well-known that the total variation distance (TVD) admits the following characterization\n\n    P-Q_T V=sup _f: 0 \u2264 f \u2264 1\ud835\udd3c_x \u223c P[f(x)]-\ud835\udd3c_x \u223c Q[f(x)].\n\n\n    The difference of task gradients d_ij=g_i-g_j can be bounded by the TVD as: \n    \n    d_ij\u2264 4 \u03b7_base GL \u2119_i(\ud835\udcaf)-\u2119_j(\ud835\udcaf)_TV,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhere \u03b7_base is the learning rate of the inner loop. The G, L and more proofs are introduced in Appendix. \nWhen \u2119_i(\ud835\udcaf) \u2260\u2119_j(\ud835\udcaf), there is a gradient difference between \ud835\udcaf_i and \ud835\udcaf_j.\nThen, we analyze that RotoGBML can narrow the difference between task gradients from Cosine Theorem\u00a0<cit.>.\nWhen viewing gradients as a vector, the value of d_ij is simplified to calculate the length of the third edge d_ij=g_i-g_j using Cosine Theorem in Figure\u00a0<ref> (left). Based on Cosine Theorem, equation\u00a0(<ref>) can be re-expressed as \u221a(g_i^2+g_j^2-2g_ig_jcos<g_i, g_j>), where \u00b7 means the length of the vector and cos<\u00b7, \u00b7> is the consine angle between two vectors. \nRotoGBML homogenize task gradients by reweighting task-gradient magnitudes from g_i, g_j to g_i^*, g_j^*, respectively and rotating task-gradient directions from cos<g_i, g_j> to cos<g_i^*, g_j^*> to narrow the task gradients difference from d_ij to d_ij^* in Figure\u00a0<ref> (right).\n\n\n\u00a7 RELATED WORK\n \n\n\nGBML for few-shot image classification.\nA plethora of GBMLs have been proposed to solve the few-shot image classification problem. \nThe goal of these algorithms is to fast adapt to new tasks with only a few samples by transferring the meta-knowledge acquired from training tasks\u00a0<cit.>.\nHowever, these works have a strict assumption that training and testing tasks come from the same distribution, which seriously violates the real world.\n\nRecently, some works\u00a0<cit.> have been proposed to study the OOD problem of GBML. However, they mainly focus on the shifts caused by training and testing data (e.g., training from miniImageNet, testing from CUB). \nThis setting follows the definition of distribution shifts in traditional machine learning\u00a0<cit.>.\nThey do not consider the problem from the GBML optimization itself and proposed appropriate algorithms for GBML frameworks.\nWe consider the distribution shifts at the task level due to GBML uses task information of each minibatch to optimize the meta-knowledge.\n\n\n\n\n\n\n\n\nTask gradients homogenization in other fields.\nHomogenization of task-gradient magnitudes and directions is also found in multi-task learning\u00a0<cit.>. \n\nTheir goal is to simultaneously learn K different tasks, that is, finding K mappings from a common input dataset to a task-specific set of labels (generally K=2).\nMotivated by\u00a0<cit.>, we regard GBML meta-knowledge learning as a multi-task optimization process and homogenize task gradients from a multi-task perspective.\nOur work differ from these works in: (1) the input data is different for different tasks in GBML, but the input data of different tasks in multi-task learning is the same. (2) In multi-task learning, existing works on alleviating gradient conflicts usually assume that tasks come from the same distribution. However, we address the problem of conflicting gradients in different distributions. (3) We propose a new invariant self-information module to extract causal features.\n\n \n\n\n\n\u00a7 EXPERIMENTS\n\n\n\nIn this section, we conduct comprehensive experiments to evaluate the effectiveness of RotoGBML and compare it with state-of-the-art algorithms.\nSpecifically, we consider two OOD generalization problems in few-shot image classification: The weak OOD generalization problem is training and testing tasks from the same dataset but with disjoint classes\u00a0<cit.>.\nThe strong OOD generalization problem is training and testing tasks from different datasets and has multiple datasets in training data\u00a0<cit.>. Unlike these works, we use a more difficult setting, i.e., each minibatch of tasks from different datasets. \n\nWe aim to answer the following questions:\nQ1: How does the proposed RotoGBML framework perform for the few-shot image classification task on the weak OOD generalization problem (see Section\u00a0<ref>)?\nQ2: Can RotoGBML fast generalize to new tasks from new distributions when faced with the strong OOD generalization problem (see Section\u00a0<ref>)? \nQ3: How well each module (\ud835\udc30_\u03c9, R_\u03b3 and ISI) in our proposed framework performs in learning the meta-knowledge (see Section\u00a0<ref>)?\n\nDatasets.\nFor the weak OOD generalization problem, we adopt two popular benchmarks for image classification, i.e., miniImageNet and CUB-200-2011 (abbr: CUB). \nFor the strong OOD generalization problem, we adopt nine benchmarks, including miniImageNet, CUB, Cars, Places, Plantae, CropDiseases, EuroSAT, ISIC and ChestX following prior works\u00a0<cit.>.\nIn the strong OOD generalization, miniImageNet is used only as training data because of its diversity, and evaluate the trained model on the other eight datasets using a leave-out-of method, i.e., randomly sampled one dataset as testing data and other datasets as training data.\n\n\n\nBackbone of GBML.\nSince our RotoGBML is model-agnostic and can be equipped with arbitrary GBML algorithms, we use five representative and generic GBML algorithms as our GBML backbone including MAML\u00a0<cit.>, MAML++\u00a0<cit.>, ANIL\u00a0<cit.>, Reptile\u00a0<cit.>, iMAML\u00a0<cit.>.\n\nIn all experimental results, iMAML is used as our GBML backbone due to its good performance, unless otherwise stated. \n\nFeature encoders.\nWe follow previous works\u00a0<cit.> using three general networks as our feature encoder including,\ni.e. conv4 (filter:64), resnet10 and resnet18.\nHowever, it is well known that GBML algorithms (e.g, MAML) under-perform when applied to large networks\u00a0<cit.>, so we use conv4 to show the main experimental results for the weak OOD generalization.\nFor a fair comparison with some cross-domain methods\u00a0<cit.>, we follow their setting using resnet10 for the strong OOD generalization. We also show the performance of the three feature encoders in Figure\u00a0<ref>. \n   \nExperimental setting.\nWe use the Adam optimizer with the learning rate of inner loop \u03b7_base=0.01, outer loop \u03b7_meta=0.001 and rotation matrix \u03b7_\u03b3=5e-4. We set \u03b2=0.1 for weak and \u03b2=1.5 for strong OOD. We optimize all models from scratch and process datasets using data augmentation following previous work\u00a0<cit.>. We evaluate the performance under two generic settings, i.e., 5-way 1-shot and 5-shot and report the average accuracy as well as 95% confidence interval.\n\n\n\n\n \u00a7.\u00a7 Weak OOD Generalization Problem\n\n\nWe conduct experiments on two representative few-shot image classification datasets: miniImageNet and CUB. Table\u00a0<ref> reports the experimental results. From Table\u00a0<ref>, we have some findings as follows:\n(1) Compared to Vanilla GBML algorithms (2-nd block), the proposed RotoGBML framework consistently and significantly improves all performances by homogenizing task-gradient magnitudes and directions.\nMoreover, compared to the 95% confidence interval, it is clear that RotoGBML reduces the uncertainty of model predictions and further reduces the high variances of model learning, thereby improving the robustness and generalization.   \n(2) Compared to some state-of-the-art few-shot image classification methods (1-st block), RotoGBML outperforms all methods, including metric-based model (ProtoNet), fine-tuning model (Linear), pretrain-based model (MTL) and  knowledge-distillation-based model (SKD-GEN1).\nThis further demonstrates the effectiveness of our proposed RotoGBML algorithm, while also providing a new solution for existing gradient-based meta-learning (GBML) algorithms to outperform metric-based meta-learning methods. \n\nWe also compare the performance of the model with different feature encoders (conv4, resnet10 and resnet18) in Figure\u00a0<ref>.\nWe can find that (1) our proposed RotoGBML algorithm outperforms all existing gradient-based meta-learning (GBML) algorithms in all experimental settings with different network sizes.\n(2) It's worth noting that RotoGBML can alleviate the performance degradation problem of large networks.\nThis is mainly because our proposed ISI module can extract invariant causal features, i.e., the shapes or outlines of objects, which avoid some non-causal features (e.g., the backgrounds, colors or textures of objects) to affect the generalization of large networks on some new tasks from new distributions.\n\n\n\n \n\n\n\n\n\n \u00a7.\u00a7 Strong OOD Generalization Problem\n\n\nIn this section, we consider a more challenging OOD setting, i.e., each task of each minibatch (typically the number of tasks N=4) comes from different datasets.\nWe compare our method and some state-of-the-art methods with the strong OOD generalization problem in Table\u00a0<ref>.\nFrom Table\u00a0<ref>, we have some significant findings as follows:\n(1) Compared to Vanilla GBML algorithms (2-nd block), RotoGBML outperforms all algorithms on eight datasets with different performance gains.\nThese results again prove that our RotoGBML can learn robust meta-knowledge, which in turn generalizes quickly to new tasks from new distributions.\n(2) Compared to some cross-domain methods (1-st block), RotoGBML has a good performance in most settings, which demonstrates that we can help GBML algorithms to achieve state of the art by homogenizing task-gradient magnitudes and directions.\n(3) The improvement of the strong OOD setting is usually larger than that of the weak OOD setting (Table\u00a0<ref>).\nThe phenomenon justifies our conclusion that the larger the distribution difference, the more obvious inconsistencies in magnitudes and directions of task gradients.\n\nIn Figure\u00a0<ref>, the performances of the strong OOD problem are shown with different network sizes.\nWe show the results on Cars and EuroSAT as we\nhave similar observations on other datasets.\nCompared to Vanilla GBML algorithms, iMAML has the best performance on the weak OOD problem, but significantly degrades on the strong OOD problem.\nBecause it uses a regularization to encourage task parameters to close to meta parameters, large distribution shifts affect the learning of meta parameters.\nOur RotoGBML can learn good meta parameters by homogenizing task gradients.\n\n\n\n \u00a7.\u00a7 Ablation Study\n\n\n\n\n  \nThe performance of our proposed three modules\nWe use a hierarchical ablation study to evaluate the performance of each module for RotoGBML under the weak and strong OOD problems in Table\u00a0<ref>.\nThe 1-st row represents the results of Vanilla iMAML.\nThe plus sign means performance increase and the minus sign means performance decrease, where violet is the weak OOD and blue is the strong OOD experiments. \nTo evaluate the performances of a fixed reweighted vector set, e.g., [0.1,0.5,0.3,0.4] is used for the four tasks in each minibatch in our experiments, the results are shown in the 2-nd row.\nFrom Table\u00a0<ref>, the following findings:\n(1) compared to Vanilla iMAML, the performances of hyperparameters have a significant drop in most settings, but our dynamic adjustment strategy (3-rd row) has a clear improvement.\nThis further evaluates the effectiveness of our learning method to dynamically optimize the reweighted vectors.\n(2) Each module has different performance gains (3\u223c5-th rows). Compared to the strong OOD problem, the performances of ISI on the weak OOD problem have a large improvement, because even if invariant features are learned, the strong inconsistencies of task gradients affect the learning of meta-knowledge.\n(3) Arbitrary combination of two modules has good performance in 6\u223c8-th rows, especially with ISI. This is because adjusting the gradients based on invariant robust information from different distributions can learn better. We also give some visualization experiments of ISI learning invariant features in Figure\u00a0<ref>.\nAnd all modules are used to have the best performance.\n\n\n\n  \nThe hyperparameter of \u03b2\nThe hyperparameter \u03b2 is introduced in equation\u00a0(<ref>) in Section\u00a0<ref>. The \u03b2 aims to adjust the tasks learning rate and \u03b2=0.1 is used for the weak OOD generalization problem and \u03b2=1.5 is used for the strong OOD generalization problem.\nIt is because a lower \u03b2 is appropriate for similar tasks and a higher \u03b2 should be used for dissimilar tasks.\nMore experimental results for \u03b2 are shown in Figures\u00a0<ref> and\u00a0<ref>, where \u201cNone\u201d means the performance of iMAML and the bars with \u201cred\u201d represents the performance of our method (iMAML-).\n\nFrom Figures\u00a0<ref> and\u00a0<ref>, \u03b2=0 damages the performance of vanilla iMAML in the strong OOD generalization problem. \nThe main reason is that \u03b2 = 0 tries to pin the backpropagated gradients of each task to be equal at network parameters. \nFor the strong OOD generalization problem, this is unreasonable since each task comes from a different distribution, which varies widely from each other.\nMoreover, we have two hyperparameters and experiment with a control variable strategy.\n\n\n\n  \nThe hyperparameter of temperature T\nThe hyperparameter of temperature T is used as a \u201csoft threshold\" of information in equation\u00a0(<ref>) in Section\u00a0<ref>. When T is small, this means more conservative filtering, i.e., only patches with the least information will be dropped and most shape and texture are preserved. When T goes to infinity, all neurons will be dropped with equal probability, and the whole algorithm becomes regular Dropout\u00a0<cit.>. As mentioned above, we have two hyperparameters, so we adopt a strategy of fixing one to experiment with the other. The experimental results are shown in Figure\u00a0<ref> under the 5-way 1-shot and Figure\u00a0<ref> under the 5-way 5-shot setting, where \u201cNone\u201d means the performance of iMAML, \u201cINF\u201d means that it degrades to regular Dropout and the bars with \u201cred\u201d represents the performance of our method (iMAML-). \n\nFrom Figures\u00a0<ref> and \u00a0<ref>, we find that the strong OOD generalization problem uses a larger temperature than the weak OOD generalization problem.\nThis phenomenon is consistent with our analysis, because the strong OOD generalization problem has greater distribution differences than the weak OOD generalization problem, and more useless information needs to be dropped.\n\n\n\n  \nVisualization of the invariant self-information module\nWe propose the invariant self-information (ISI) module to avoid some non-causal features to affect the generalization of the neural network on some new tasks from new distributions in Section\u00a0<ref>.\nMotivated by\u00a0<cit.>, we extract the robust shape features as invariant causal features.\nTo verify the learning of shape features with the ISI module, we visualize gradients of model output using the saliency map.\nSpecifically, we use SmoothGrad\u00a0<cit.> to calculate the saliency map S(x):\n\n\n    S(x) = 1/n\u2211_i=1^n\u2202 f(x_i)/\u2202 x_i,\n \n\nwhere x_i = x + \u03b4_i is original image x with i.i.d. Gaussian noise \u03b4_i and f(\u00b7) is the network. \nThe experiments are shown in Figure\u00a0<ref>, where these original images are randomly sampled from the nine datasets used in our experiments.\nWe can see that ISI is more human-aligned and sensitive to the shapes of objects. While the Saliency map of the baseline (iMAML) algorithm is filled with noise, which indicates the baseline method is less shape-biased and lacks interpretability.\nAlthough on some difficult examples (the 3-rd, 4-th and 5-th columns), our ISI module also has impressive performance. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\n\nIn this paper, we address the challenging problem of learning a good meta-knowledge of gradient-based meta-learning (GBML) algorithms under the OOD setting. We show that OOD generalization exacerbates the inconsistencies in task-gradient magnitudes and directions. Therefore, we propose RotoGBML, a general framework to dynamically reweight diverse magnitudes to a common scale and rotate conflicting directions close to each other. Moreover, we also design an invariant self-information (ISI) module to extract the invariant causal features. Homogenizing gradients using these causal features provide further guarantees for learning robust meta-knowledge. Finally, we analyze the feasibility of our method from the theoretical and experimental levels. We believe that our work makes a meaningful step toward adjusting task gradients under the OOD problem for GBML.\n\n\n\n\n\nIEEEtran\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 THEORETICAL ANALYSIS\n\n\n\n\n\n\n\n \u00a7.\u00a7 RotoGBML as Stackelberg games\n\n\nThe optimization objective of learning the meta-knowledge in GBML algorithms has two loops: an inner loop and an outer loop. In the outer loop, we simultaneously optimize the network parameters (\u03d5, \u03b8) and the module parameters of (\u03c9, \u03b3).\nThe two optimization objectives can be interpreted as a Stackelberg game\u00a0<cit.>, which is an asymmetric game with players playing alternately. The neural networks (\u03d5, \u03b8) are called as the follower to minimize their loss function. The reweighted vector set and rotation matrix set (\u03c9, \u03b3) are named as the leader. Compared to the follower, the leader attempts to minimize their own loss function, but it does so with the advantage of knowing which will be the best response to their movement by the follower. The problem can be written as:\n\n    Leader:  min_(\u03c9, \u03b3){\u2112_(\u03c9, \u03b3)(\u03c9, \u03b3, \u03d5, \u03b8)| (\u03d5, \u03b8)\u2208min_(\u03d5, \u03b8)\u2211_i=1^N\u2112_i(\u03d5, \u03b8, \u03c9, \u03b3) },  \n        Follower:  min_(\u03d5, \u03b8)\u2211_i=1^N\u2112_i(\u03d5, \u03b8, \u03c9, \u03b3) .\n\nThe leader knows the global objective while the follower only has access to their own local loss function. In gradient-play Stackelberg game, all players perform gradient updates at s-th step:\n\n    (\u03c9^s, \u03b3^s)    = (\u03c9^s-1, \u03b3^s-1) - \u03b7_(\u03c9, \u03b3)\u2207_(\u03c9, \u03b3)\u2112_(\u03c9^s-1, \u03b3^s-1)(\u03c9^s-1, \u03b3^s-1, \u03d5^s-1, \u03b8^s-1),   \n    \n        (\u03d5^s, \u03b8^s)    = (\u03d5^s-1, \u03b8^s-1) - \u03b7_(\u03d5, \u03b8)\u2211_i=1^N\u2207_(\u03d5^s-1, \u03b8^s-1)\u2112_i(\u03d5^s-1, \u03b8^s-1, \u03c9^s-1, \u03b3^s-1),\n\nwhere \u03b7_(\u03c9, \u03b3) and \u03b7_(\u03d5, \u03b8) are the learning rates of the RotoGBML and neural network, respectively. \n\nEquilibrium is an important concept in game theory, the point at which both players are satisfied with their situation, meaning that there is no action available that can immediately improve any player's score.\nIf the two players can converge to an equilibrium point, this also guarantees the convergence of the training phase.\nWe introduce the definition of Stackelberg equilibrium\u00a0<cit.>:\n\n\n    (Differential Stackelberg equilibrium).  If \u2207_(\u03c9, \u03b3)\u2112_(\u03c9, \u03b3)(\u03c9, \u03b3, r(\u03c9, \u03b3))=0 and \u2207_(\u03c9, \u03b3)^2\u2112_(\u03c9, \u03b3)(\u03c9, \u03b3, r(\u03c9, \u03b3)) is positive definite, the pair of points (\u03d5, \u03b8), (\u03c9, \u03b3) is a differential Stackelberg equilibrium point and (\u03d5, \u03b8)=r(\u03c9, \u03b3) is implicitly defined by \u2207_(\u03d5, \u03b8)\u2112_i(\u03d5, \u03b8, \u03c9, \u03b3)=0.\n\n\n\n\n\nWhen the players manage to reach such an equilibrium point, both of them are at a local optimum. Therefore, here we also provide theoretical convergence guarantees for an equilibrium point.\n\n    In the given setting, if the leader's learning rate \u03b7_(\u03c9, \u03b3) goes to zero at a faster rate than the follower's \u03b7_(\u03d5, \u03b8), that is, they will asymptotically converge to a differential Stackelberg equilibrium point almost surely.\n    \n\nAs long as the follower learns faster than the leader, they will end up in a situation where both are satisfied. In our experiments, the learning rate of the follower is 1e-3 and that of the leader is 5e-4.\n\n\n\n \u00a7.\u00a7 Proof of Theorem 4.1\n\n\nIn our main paper, we propose the Theorem 4.1 to bound the difference of task gradients d_ij=g_i-g_j\u2264 4 \u03b7_base GL \u2119_i(\ud835\udcaf)-\u2119_j(\ud835\udcaf)_TV by using the total variation distance (TVD) based on an assumption of G and L. Motivated by previous work\u00a0<cit.>, the assumption is defined as follows:\n\n\n   For any x\u2208 X, the loss function \u2112(\u00b7, x) is twice continuously differentiable. Furthermore, we assume it satisfies the following properties for any \u03c8=(\u03d5,\u03b8), \u03c8\u0305=(\u03d5\u0305, \u03b8\u0305):\n   \n       \n  * The gradient norm is uniformly bounded by G over \u03c8, i.e., \u2207\u2112(\u03c8, x)\u2264 G.\n       \n  * The loss is L-smooth, i.e., \u2207\u2112(\u03c8, x) - \u2207\u2112 (\u03c8\u0305, x) \u2264 L \u03c8- \u03c8\u0305.\n   \n   \n\n\n\n\n\n\ud835\udcaf_i=(\ud835\udcae_i, \ud835\udcac_i)\u223c\u2119_i(\ud835\udcaf) and \ud835\udcaf_j=(\ud835\udcae_j, \ud835\udcac_j)\u223c\u2119_j(\ud835\udcaf) with i \u2260 j are randomly sampled from the different distributions. The difference of task gradients is definited as follows:\n\n    d_ij   = \u2207_\u03c8\u2112_i(\u03c8_i^\u03c4(x_i^q), y_i^q) - \u2207_\u03c8\u2112_j(\u03c8_j^\u03c4(x_j^q), y_j^q) ,  \n       = \u2207_\u03c8\u2112_i(\u03c8- in_i, x_i^q, y_i^q) - \u2207_\u03c8\u2112_j(\u03c8 - in_j, x_j^q, y_j^q),    \n        = \ud835\udd3c_{(x_i^k, y_i^k)\u223c\ud835\udcac_i\u223c\u2119_i(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_i(\u03c8- in_i, x_i^k, y_i^k)  \n               - \ud835\udd3c_{(x_j^k, y_j^k)\u223c\ud835\udcac_j\u223c\u2119_j(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_j(\u03c8- in_j, x_j^k, y_j^k) ,   \n       where in_i = \u03b7_base\ud835\udd3c_{(x_i^k, y_i^k)\u223c\ud835\udcae_i\u223c\u2119_i(\ud835\udcaf)}_k=1^n_s\u2207_\u03c8_i^\u03c4\u2112_i(\u03c8_i^\u03c4-1(x_i^k), y_i^k),  \n                          in_j = \u03b7_base\ud835\udd3c_{(x_j^k, y_j^k)\u223c\ud835\udcae_j\u223c\u2119_j(\ud835\udcaf)}_k=1^n_s\u2207_\u03c8_j^\u03c4\u2112_j(\u03c8_j^\u03c4-1(x_j^k), y_j^k),\n\nwhere n_s and n_q are the number of the support set and query set examples, respectively.\ng_i = \u2207_\u03c8\u2112_i(\u03c8_i^\u03c4(x_i^q), y_i^q) and g_j = \u2207_\u03c8\u2112_j(\u03c8_j^\u03c4(x_j^q), y_j^q) are the task gradients for \ud835\udcaf_i and \ud835\udcaf_j using query set in the outer loop, respectively.\nHence, with probability n_qt (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^t (1-\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^n_q-t, we have x_i^k\u2260 x_j^k for t choices of k (out of 1,...,n_q). In addition, based on the Assumption\u00a0<ref>, the equation\u00a0(<ref>) is bounded as follows:\n\n\n    d_ij   = \ud835\udd3c_{(x_i^k, y_i^k)\u223c\ud835\udcac_i\u223c\u2119_i(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_i(\u03c8- in_i, x_i^k, y_i^k) - \ud835\udd3c_{(x_j^k, y_j^k)\u223c\ud835\udcac_j\u223c\u2119_j(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_j(\u03c8- in_j, x_j^k, y_j^k) ,   \n       \u2264 2 \u03b7_base L \ud835\udd3c_{(x_i^k, y_i^k)\u223c\ud835\udcac_i\u223c\u2119_i(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_i(\u03c8_i^\u03c4(x_i^k), y_i^k) - \ud835\udd3c_{(x_j^k, y_j^k)\u223c\ud835\udcac_j\u223c\u2119_j(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_j(\u03c8_j^\u03c4(x_j^k), y_j^k) , \n       \u2264 4 \u03b7_base GL t/K.\n\n\nAs a result, we have\n\n\n    d_ij    = \ud835\udd3c_{(x_i^k, y_i^k)\u223c\ud835\udcac_i\u223c\u2119_i(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_i(\u03c8- in_i, x_i^k, y_i^k) - \ud835\udd3c_{(x_j^k, y_j^k)\u223c\ud835\udcac_j\u223c\u2119_j(\ud835\udcaf)}_k=1^n_q\u2207_\u03c8\u2112_j(\u03c8- in_j, x_j^k, y_j^k) ,  \n       \u2264\u2211_t=0^K Kt (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^t (1-\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^K-t\u00b7 4 \u03b7_base GL t/K, \n        = 4 \u03b7_base GL (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV) \u2211_t=0^K t/KKt (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^t-1 (1-\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^K-t,  \n        = 4 \u03b7_base GL (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV),\n\n\nwhere the last equality follows from the fact that\n\n\n    t/KKt (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^t-1 (1-\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^K-t\n          = K-1t-1 (\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^t-1 (1-\u2119_i(\ud835\udcaf) - \u2119_j(\ud835\udcaf) _TV)^K-1-(t-1).\n\n\n\n\nTherefore, we can prove the conclusion of d_ij=g_i-g_j\u2264 4 \u03b7_base GL \u2119_i(\ud835\udcaf)-\u2119_j(\ud835\udcaf)_TV.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}