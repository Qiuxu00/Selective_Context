{"entry_id": "http://arxiv.org/abs/2303.06783v1", "published": "20230312235151", "title": "Asynchronous Decentralized Federated Lifelong Learning for Landmark Localization in Medical Imaging", "authors": ["Guangyao Zheng", "Michael A. Jacobs", "Vladimir Braverman", "Vishwa S. Parekh"], "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV", "eess.IV"], "text": "\n\n\n\nAsynchronous Decentralized Federated lifelong Learning\n\n\n\n\n\nZheng et al.\n\n\n\nDepartment of Computer Science, Rice University, Houston, TX, USA Department Of Diagnostic And Interventional Imaging, McGovern Medical School, UTHealth Houston, Houston, TX The Russell H. Morgan Department of Radiology and Radiological Science, The Johns Hopkins University School of Medicine, Baltimore, MD the University of Maryland Medical Intelligent Imaging (UM2ii) Center\n \nDepartment of Diagnostic Radiology and Nuclear Medicine \n\n    University of Maryland School of Medicine \n\n    Baltimore, MD\n\ntz30@rice.edu\n\nAsynchronous Decentralized Federated Lifelong Learning for Landmark Localization in Medical Imaging\n    Guangyao Zheng1 Michael A. Jacobs2,3 Vladimir Braverman1 Vishwa S. Parekh3,4\n    March 30, 2023\n===================================================================================================\n\n\n\n\nFederated learning is a recent development in the machine learning area that allows a system of devices to train on one or more tasks without sharing their data to a single location or device. However, this framework still requires a centralized global model to consolidate individual models into one, and the devices train synchronously, which both can be potential bottlenecks for using federated learning. In this paper, we propose a novel method of asynchronous decentralized federated lifelong learning (ADFLL) method that inherits the merits of federated learning and can train on multiple tasks simultaneously without the need for a central node or synchronous training. Thus, overcoming the potential drawbacks of conventional federated learning.  We demonstrate excellent performance on the brain tumor segmentation (BRATS) dataset for localizing the left ventricle on multiple image sequences and image orientation. Our framework allows agents to achieve the best performance with a mean distance error of 7.81, better than the conventional all-knowing agent's mean distance error of 11.78, and significantly (p=0.01) better than a conventional lifelong learning agent with a distance error of 15.17 after eight rounds of training. In addition, all ADFLL agents have comparable or better performance than a conventional LL agent. In conclusion, we developed an ADFLL framework with excellent performance and speed-up compared to conventional RL agents.\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\nMedical imaging, MRI (Magnetic Resonance Imaging), PET (Positron Emission Tomography), CT (Computerized Tomography), X-ray, and Ultrasound, play a critical role in the diagnosis, prognosis, and preventative care of patients. The use of machine learning methods in medical imaging, such as classification, segmentation, noise reduction, and landmark localization, has been used in different completing complicated environments and settings <cit.>. However, these methods are usually done on single tasks, without the ability to generalize to other tasks. They often require a full dataset on a device for training, which may cause privacy concerns about patient data and computational constraints for the device specifications <cit.>.\n\nTo address these challenges, Federated Learning (FL) has emerged as a promising approach that enables multiple agents to collaboratively train a model without sharing their data <cit.>. A federated learning system aims to protect data privacy and reduce computational costs by distributing the computation to multiple agents to train the model on their local data and sharing only the model updates with a central server. Federated learning implementations have shown promising results in various medical applications <cit.>. However, federated learning frameworks often rely on synchronized learning schedules, meaning all participating agents start training at the same time. They also require agents to have the same architecture in order for the central server to aggregate the model weights. Data and agent heterogeneity influence the training speed which greatly reduces the efficiency and challenges the robustness of these approaches <cit.>. Additionally, Federated learning approaches cannot perform Lifelong Learning (LL), which is an important aspect of machine learning applied to medical imaging.  Works have shown the ability to improve accuracy, have excellent performance on multiple tasks, and generalize <cit.>. With medical imaging tasks involving constant and rapid altering in imaging environments, such as new imaging sequences or abnormal patient conditions, a federated learning framework that is trained in an older environment may not perform well when evaluated in an unseen environment. One way to address this issue is to train the model again on the new dataset. However, new environment data can potentially be scarce, and this approach may lead to catastrophic forgetting, where the model loses its ability to operate effectively in the older environment. Federated lifelong learning implementation such as Liu et. al. exist <cit.>, but it is limited applied to robotics, and the synchronous and centralized nature still remains an issue.\n\nTo address all the limitations mentioned above, we propose an asynchronous decentralized federated lifelong learning (ADFLL) approach to landmark localization in medical imaging. This framework leverages Federated learning's ability to protect data privacy and reduce computational constraints, while also permitting data and agent heterogeneity to be in the system. This framework does not require a central node, and can together lifelong learn multiple tasks without catastrophic forgetting. We provide a flexible, efficient, and robust framework that can be deployed in real-world applications. This paper presents experimental results demonstrating the efficacy of our framework on the 2017 brain tumor segmentation (BraTS) dataset consisting of 8 different image environments and imaging sequences, highlighting its potential to revolutionize landmark localization in the medical imaging field while also maintaining data privacy and reducing computational costs.\n\n\n\n\n\u00a7 METHOD\n\n\n\n \u00a7.\u00a7 Deep Reinforcement Learning\n\nWe created a deep reinforcement learning framework that utilizes the deep Q-network (DQN) algorithm, which is depicted in Figure <ref>. The 3D DQN model we used in this paper was adapted from existing works <cit.>. The environment was represented by a 3D imaging volume with x, y, and z dimensions. The agent was represented by a 3-dimensional bounding box with six possible actions: moving in the positive or negative in the x, y, or z axis. The state was defined by the current location (or a chain of locations) of the agent, each represented by a 3-dimensional bounding box. The reward was calculated by the change in distance to the target landmark location before and after the agent takes an action. The agent's exploration within the environment generated state-action-reward-resulting state [s,a,r,s'] tuples, which were recorded in the experience replay buffer (ERB) over multiple  episodes.\n\n\n\n\n \u00a7.\u00a7 Lifelong Learning\n\nWe implemented lifelong learning using selective experience replay <cit.>. The goal of selective experience replay is to avoid catastrophic forgetting by focusing on selected experiences from previous tasks. Additionally, this technique is agnostic to the model being used and enables the sharing of experiences across different models. To achieve lifelong learning, we utilized a selective experience replay buffer that collects a sequence of experience samples throughout the model's training process. In order to learn a generalized representation of both current and past tasks, the model selects a batch of experiences from both the ERB of its current task and from the replay buffers of previous tasks during training.\n\n\n\n \u00a7.\u00a7 Asynchronous Decentralized Federated Lifelong Learning\n\nWe developed the Asynchronous Decentralized Federated lifelong Learning (ADFLL) by constructing a network of lifelong deep reinforcement learning agents. Each agent shares their database of personal experiences with each other to facilitate learning from each other experiences. More specifically, once an agent finishes training with a dataset and an ERB, the resulting experience from the training is shared with the network. Furthermore, we modified the training setup for each agent to sample experiences from the current dataset ERB, the agent's personal experiences and the incoming experiences from other agents, as shown in Fig.\u00a0<ref>. As a result, every agent in the network can learn from each other's experiences, thereby integrating federated lifelong learning capability. \n\nIn a naive setup, every agent would communicate their experiences with every other agent in the network. However, such an all-to-all communication setup is highly inefficient and not scalable as it would require a large amount of communication bandwidth. To address this issue, we implemented a homogeneous distributed database system as illustrated in Fig.\u00a0<ref>. As shown in Fig.\u00a0<ref>, our network consists of a predefined set of hub nodes that act as communication hubs for spatially adjacent nodes in the network. Subsequently, every agent in the network exclusively communicates with their nearest hub node at the end of each personal training round. The experience sharing between an agent and a hub node is bidirectional. Finally, every hub node maintains a shared experience database on the network as shown in Fig.\u00a0<ref>. The hub nodes periodically communicate with each other to synchronize their databases. The agents in the system are not required to have standardized training speed or start training at the same time. The hub will regulate and preserve the experiences in the system and agents in the system can train on different tasks. An example of this system is demonstrated in Fig.\u00a0<ref>.\n\n\n\nThe advantage of our system setup is that it is robust against node or hub failures. When a node fails, the only loss is the training information from that node, and when a hub fails, the loss is the ERBs it contains but other hubs do not. Moreover, the communication complexity is linear with respect to the number of nodes, each node only needs to communicate with its respective hub, and hubs sync periodically. Compared to other federated learning systems, centralized or not, they either are prone to system-wide failure caused by a node failure, or sacrifice communication complexity to prevent system-wide failures.\n\n\n\n\n\n\n\n\u00a7 EXPERIMENT AND RESULT\n\n\n\n \u00a7.\u00a7 Dataset and Experimental Setup\n\n\n\n  \u00a7.\u00a7.\u00a7 Clinical Data\n\nFor evaluation of our ADFLL  framework, we utilized the 2017 brain tumor segmentation (BraTS) dataset <cit.>. This dataset consisted of 285 patients and included pre-contrast T1-weight, post-contrast T1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR) sequences in the axial orientation. From this dataset, we randomly sampled a subset of 100 patients to use as our experiment dataset. 60 patients have high-grade glioma (HGG) and 40 patients have low-grade glioma (LGG). We split the 100 patients into two parts 80:20, 80 were used for training and 20 for evaluation, with the training set consisting of 48 HGG and 32 LGG tumors, and the test set consisting of 12 HGG and 8 LGG tumors. We reconstructed the dataset to include all three imaging orientations (coronal, sagittal, and axial). As a result, we obtained a total of twenty-four imaging environments with combinations of two pathologies, 4 imaging sequences, and 3 image orientations. The top left ventricle was chosen as the task for this experiment, and 8 task-environment pairs were sampled as shown in Fig.\u00a0<ref>.\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Experimental Setup\n\n\nEvery agent implements a multi-task lifelong reinforcement learning algorithm for localizing landmarks across the human anatomy. The federated lifelong learning component is implemented by integrating experience replay buffers from previous experiences shared by agents across the network for training. There are four agents in this experimental system: we implemented two on an NVIDIA DGX-1 each with an NVIDIA V100 and two on Google Cloud each with an NVIDIA T4. The topology of the system is shown in Fig.\u00a0<ref>. The two agents A1, and A2 on Google Cloud have their individual hubs H1 and H2. The two agents A3, and A4 on the DGX-1 are connected to the third hub H3 with a total of three hubs for 4 agents. Since the GPUs on DGX-1 are much more powerful than the GPUs on Google Cloud, A3 and A4 will run significantly faster than A1 and A2. We also implemented asynchronous learning, meaning when the agent finishes training on a task, as long as there are new ERBs that they have not learned from, they will start a new round and learn from those ERBs. Each agent will also get a different image training dataset each round. This process is continued until all four agents complete three rounds of training, guaranteeing all 8 sampled tasks for this experiment will be learned by the system.\n\n\n\n\nAll-knowing agent and partially-knowing agent: To better compare our framework with non-lifelong learning ones, we ran two different deep reinforcement learning agents. Agent X is the all-knowing agent, with all 8 datasets available to it at the start of training, then it trained on them for one round. Agent Y is the partially-knowing agent, which only has access to one dataset and can therefore only train for one round.\n\nTraditional lifelong deep reinforcement learning agent:\nTo better compare our framework with the traditional lifelong learning framework, we ran an Agent M that has access to the dataset sequentially and is therefore trained for eight rounds to account for learning eight different environments.\n\nExperimental Metric:\nThe performance metric was set as the terminal Euclidean distance between the agent's prediction and the target landmark. We performed paired t-tests to compare the performance of the decentralized federated lifelong learning framework with the traditional lifelong learning framework and all-knowing deep reinforcement learning agent and partial-knowing deep reinforcement learning agent. The p-value for statistical significance was set to p \u2264 0.05. \n\n\n\n\n\n \u00a7.\u00a7 Results\n\nWe conducted an experiment based on 8 sub-task-environment pairs: Axial HGG t1ce, Sagittal HGG t1ce, Coronal HGG t1ce, Axial HGG flair, Sagittal LGG flair, Coronal LGG flair, Coronal LGG t2, Sagittal LGG t1. We sampled one image from each task to test the performance of our model and baseline models. Each round the four federated lifelong learning will receive a new task. They will begin the next round when there is also ERB to train from. Since the agents' training speeds are very different, A1 and A2 will finish their tasks slower, allowing them to learn from more ERBs at once. As shown in <ref>, after three rounds of training, A2 was able to achieve a mean distance error of 7.81 on all 8 tasks, compared to the all-knowing agent's 11.78 (p=0.22), but significantly lower compared to partially-knowing agent's 54.58 (p<0.001), and the traditional lifelong learning agent's 15.17 (p=0.01) after eight rounds of training. Note that the all-knowing agent and the partially-knowing agent only train for 1 round for this experiment because they have no lifelong learning capability. \n\nCompared to the All-knowing agent shown in <ref>, our framework is able to achieve an excellent performance boost. Compared to the traditional lifelong learning agent, our framework is able to achieve a significant performance boost and an outstanding speedup.\n\n\n\n\n\n\u00a7 CONCLUSION\n\nPrevious works have explored the application of federated learning to the medical field <cit.>. They have shown decentralized federated learning system setups, each demonstrating good performance in their experiment tasks. But because of their system topology implementation, one node failure can potentially collapse the entire system. Moreover, the learning tasks examined were limited, binary classifications or MNIST dataset classification, resulting in limited potential applications. Additionally, their implementation offers a synchronous training procedure, which means in a real application scenario, users of their framework will have to coordinate the training process.\n\nAsynchronous federated learning has also been explored in other areas <cit.>. They offer the ability to deal with nodes with different computational power but lack the decentralization that allows the system to be more flexible.\n\nAsynchronous decentralized federated learning has also been explored in other areas <cit.>. However, they are still limited in their system implementation. The cost of removing a central node is a quadratic complexity communication scheme in that every node communicates with every node.\n\nWe have demonstrated a privacy-aware, asynchronous decentralized federated learning system with robust and efficient system topology. We have demonstrated excellent performance on landmark localization tasks on the BraTS image dataset. Our framework also performs better than all-knowing deep reinforcement learning agents and traditional lifelong learning agents. In the future, we will optimize our approach, expand the system, and conduct more experiments.\n \n\n\n\n\n  \u00a7.\u00a7.\u00a7 Acknowledgements\n ***\n\n\n\n\n\n\n\n\n\n\nsplncs04\n\n\n\n"}