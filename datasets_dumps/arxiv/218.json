{"entry_id": "http://arxiv.org/abs/2303.07056v1", "published": "20230313122531", "title": "Harnessing the instability mechanisms in airfoil flow for the data-driven forecasting of extreme events", "authors": ["Benedikt Barthel", "Themistoklis Sapsis"], "primary_category": "physics.flu-dyn", "categories": ["physics.flu-dyn", "math.DS"], "text": "\n\nTracing chirality from molecular organization to triply-periodic network assemblies: \n \nThreading biaxial twist through block copolymer gyroids\n\n    Gregory M. Grason\n    Accepted xxxx xxxxxx xx. Received xxxx xxxxxx xx; in original form xxxx xxx xx\n================================================================================================================================================\n\n \n\nThis work addresses the data-driven forecasting of extreme events in the flow over a static airfoil. For certain Reynolds numbers and flow configurations, airfoils are subject to sporadic high amplitude fluctuations in the aerodynamic forces. These extreme excursions may be seen as prototypical examples of the kind of unsteady and intermittent dynamics relevant to the flow around airfoils and wings in a variety of laboratory and real-world applications. Here we investigate the instability mechanisms at the heart of these extreme events, and how knowledge thereof may be harnessed for efficient data driven forecasting. Through a wavelet and spectral analysis of the flow we find that the extreme events arise due to the instability of a specific frequency component distinct from the vortex shedding mode. During these events this extreme event manifold draws energy from the energetically dominant vortex shedding flow and undergoes an abrupt inverse cascade of energy transfer from small to large scales. We also investigate the spatial dependence of the temporal correlation and mutual information between the surface pressure and the aerodynamic forces, with the aim of identifying regions of the airfoil amenable to sparse sensing and the efficient forecasting of extremes. Building on previous work on predictive machine learning models, we show that relying solely on the mutual information for optimal sensor placement fails to improve model prediction over uniform or random sensor placement. However, we show that by isolating the extreme event frequency component offline through a wavelet transform we are able to circumvent the requirement for a recursive long-short term memory (LSTM) network \u2013 resulting in a significant reduction in computational complexity over the previous state of the art. Using the wavelet pre-processed data in conjunction with an extreme event-tailored loss function we find that our model is capable of forecasting extreme events using only three pressure sensors. Furthermore, we find our model to be robust to sensor location \u2013 showing promise for the use of our model in dynamically varying applications. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\nMany engineering systems are subject to rare high-amplitude fluctuations commonly referred to as extreme events <cit.>. While here we focus primarily on fluid-structure interactions, such events occur in a wide variety of systems ranging from climate systems to stock markets. Although rare, events like gusts or rogue waves have a disproportionate affect on the fatigue life of aircraft, naval vessels, or marine infrastructure. Due to their rare nature, the prediction of these events is inherently challenging, especially as they often occur in complex systems were the physical mechanisms are unknown <cit.>. Various authors have ventured to address this problem through strategies such as optimal sampling <cit.> or training strategies which preferentially amplify rare events <cit.>. \n\nTwo dimensional airfoil flow is one of the canonical test cases for the dynamics of fluid-structure interaction and has been the subject of extensive study for decades <cit.>. However, the advent of machine learning and data driven techniques has unlocked new lenses to study this and other classical problems in the field of fluid dynamics <cit.>. In particular, several authors including <cit.> have proposed neural network models for the reconstruction of the flow from sparse measurements. Data driven prediction's based the airfoil surface pressure have been of particular interest due to it's practical measurability. Most aerospace applications will require predictions made from sparse arrays of sensors, and thus effective strategies for the optimal distribution of pressure sensors is of critical importance. <cit.> used both data assimilation and convolutional and recursive neural networks for the context of prediction of the leading edge suction parameter (LESP), while <cit.> investigated a range of neural network models for the prediction of the drag coefficient. \n\nOscillator flows such as airfoil flows are generally insensitive to noise and exhibit multiple characteristic time scales <cit.>. This makes them an ideal candidate for the study of multi-scale slow-fast type extreme events \u2013 as classified by <cit.>.\nFrom this perspective, the Reynolds number regime \ud835\udcaa\u223c(10^4) is of particular interest. This regime lies between steady laminar and fully turbulent regimes, and is especially susceptible to highly nontrivial dynamics which depend significantly on angle of attack and Reynolds number <cit.>. One tool for the study of such systems is the continuous wavelet transform, which in a manner analogous to the short time Fourier transform, quantifies the time varying strength of a signal's frequency components  <cit.>. Wavelet analysis has previously been used in the context of extreme events by <cit.> and <cit.> for the detection of rogue waves and turbulent bursts in pipe flow respectively. The majority of these studies have focused on spatial wavelet transforms, while here we perform a temporal analysis. Additionally, the combination of wavelet analysis with machine learning models using the type of output weighted strategies discussed above remains largely unexplored. \n\nThis work conducts an investigation of the physical mechanisms driving the extreme bursting events observed in the flow over a two-dimensional airfoil at R = 17,500 at constant angle of attack.  We build on previous work by <cit.> who studied the data driven reconstruction of this flow using a range of neural network architectures. We exploit the findings of our analysis to design extreme event tailored \u2013 also referred to as output-weighted <cit.> \u2013 data processing and training strategies for the efficient data-driven prediction of extreme events from optimal sparse sampling of the surface pressure. For a broad discussion of output-weighted strategies for neural networks applied to this and other systems see <cit.>.\n\nThe rest of the paper is organized as follows. In <ref> we describe the problem under investigation. In <ref> we perform a statistical analysis of the data and describe the physical mechanisms driving the extreme events, and how these manifest in the observed data. In <ref> we discuss the limitations of offline optimal sensing algorithms. The main results of this work are then presented in <ref>, and we provide some discussion of our findings in <ref>. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 PROBLEM DESCRIPTION\n\nWe consider a 2D direct numerical simulation of an incompressible flow around a NACA 4412 airfoil at an angle of attack \u03b1 = 5^\u2218 and a cord length based Reynolds number R = 17,500. The flow is governed by the Navier-Stokes and continuity equations,\n\n    \u2202\ud835\udc2e/\u2202 t +\ud835\udc2e\u00b7\u2207\ud835\udc2e-1/R\u2207^2\ud835\udc2e + \u2207 p =0,\n\n\n    \u2207\u00b7\ud835\udc2e =0,\n\nwhere \ud835\udc2e\u2261 [u(x,y,t),v(x,y,t)] is the velocity, p(x,y,t) is the pressure field, t is time, and x,y are the spatial dimensions parallel and perpendicular to the free stream respectively. The simulation is carried out using the open source spectral element code Nek5000 developed by <cit.> with 4368 elements at spectral order 7 and a convective outflow boundary condition <cit.>. We use the same data set as <cit.> who report that further refinement of the numerical grid did not meaningfully alter the results. At this Reynolds number the flow is susceptible to intermittent, yet non-periodic turbulent bursts which manifest as high amplitude fluctuations in the drag coefficient. Therefore we focus on two observables: the surface pressure and the drag coefficient. The former is a practically measurable quantity and will serve as the input to our model, while the latter encodes the extreme events and will serve as the model output. \n\n\n\nThroughout this work we define s as a generalized measure of arc length measured clockwise from the leading edge (as shown in figure <ref>). For example,  s\u2208[0,0.5) refers to the upper surface of the airfoil and s\u2208[0.5,1) refers to under side. The surface pressure is saved at 100 equally spaced locations around the airfoil surface. A visualization of the airfoil flow, the simulation grid and the arc length measure are summarized in figure <ref>, and we refer the interested reader to <cit.> for a more detailed discussion of the numerical method.\n\n\nThe aerodynamic forces are computed using skin friction and surface pressure according to\n\n    \ud835\udc05(t) = \u222e_s (\u03c4(s,t) + \ud835\udc27P(s,t)) ds = L(t)\ud835\udc1e\u0302_x + D(t)\ud835\udc1e\u0302_y.\n\nHere t is time, and x and y represent the directions parallel and normal to the free stream respectively. The lift and drag coefficients are then defined as \n\n    C_L(t) \u2261L(t)/\u03c1 U_\u221e^2c,  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 C_D(t) \u2261D(t)/\u03c1 U_\u221e^2c.\n\nTo distinguish the extreme events from the background vortex shedding we apply a Gaussian smoothing operation to the time series of the drag coefficient to extract the non-periodic behaviour,\n\n    q(t) \u2261(K*C_D )(t).\n\nwhere K(t') \u221d exp(-(t'/2 f_v)^2 ) is a Gaussian smoothing kernel. f_v = 1.44 is the most energetic frequency and corresponds to periodic vortex shedding. Moving forward we simply refer to q(t) as the drag. In addition to the raw pressure signal, we also consider a version of the pressure with the same Gaussian filter applied,\n\n    P(s,t) \u2261(K*P(s,t) )(s,t).\n\nWe refer to P(s,t) and P\u0303(s,t) as the raw and filtered pressures respectively. In general we will consider the pressure measured at subset of discrete sensor locations, and thus treat the surface pressure as a vector valued quantity \ud835\udc0f(t) \u2208\u211d^n, where n is the number of sensors. An illustrative example of the drag as well as the raw and filtered pressures is shown in figure <ref>.\n\n\n\nThis flow was previously investigated by <cit.> using a deep long-short term memory (LSTM) network. Those authors considered a variety of input observables, and found that the extreme events could be predicted from a range of different observables including full and reduced order descriptions of the flow field as well as surface pressure. This suggest that the extreme events are a result of an underlying physical instability inherent in the governing equations. The primary focus of this work is to identify and exploit this mechanism for optimal sensing and forecasting. Practically, we aim to predict future extreme events observed in the drag from sparse measurements of the surface pressure as efficiently as possible. In other words we seek a data driven map\n\n    \ud835\udc0f(t) \u2192 q(t+\u03c4)\n\nfor maximum lead time \u03c4, with minimal dim(\ud835\udc0f), and at minimal computational cost.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 STATISTICAL ANALYSIS AND PHYSICAL MECHANISMS OF EXTREMES\n\nIn order to gain a deeper insight into the dynamics of the flow and mechanisms driving the extreme events, we first perform a detailed statistical analysis of the data. We first analyze the surface pressure, as this will serve as the basis of our modeling efforts, then in <ref> we analyze the vorticity field \u2013 both globally and locally along the airfoil surface \u2013 to further probe the extreme event dynamics.\n\nBefore presenting our results, we first review some definitions we use throughout the following sections. \nFor a signal x(t) with discrete values x_i and distribution X, we define the mean \u03bc_x, variance \u03c3^2_x, and the probability density function f_X(x). For two signals x(t) and y(t) the covariance is defined as\n\n    \u03c3_xy\u2261cov(X,Y) = 1/n-1\u2211_i=1^n (x_i - \u03bc_x) (y_i - \u03bc_y).\n\nTo further quantify the connection between two signals we also make use the mutual information (MI) defined as\n\n    I(X,Y) \u2261\u222b_y \u222b_x f_X,Y(x,y)log(f_X,Y(x,y)/f_X(x)f_Y(y)) dx dy,\n\nwhere f_X,Y is the joint probability density function of X and Y. The MI is the Kullback\u2013Leibler (KL) divergence between the joint probability distribution and the product of the marginal probability distributions \u2013 it quantifies the error in the assumption that two distributions X, and Y are uncorrelated.\nWe also propose the \u201cextreme event conditioned mutual information\u201d, defined as the mutual information integrated only over values of the output greater than two standard deviations from the mean: y>2\u03c3_y \u2013 all values of the input X are included \u2013\n\n    I_EE(X,Y) \u2261\u222b_x \u222b_y>2\u03c3_y f_X,Y(x,y)log(f_X,Y(x,y)/f_X(x)p_Y(y)) dx dy.\n\nWe choose a cut-off of two standard deviations, however we found that the results were not sensitive to changes of \u00b1\u03c3. For the results presented in this section the probability density functions in (<ref>) and (<ref>) are approximated using Monte Carlo estimation using 50,000 samples and the relevant integrals are then carried out using trapezoidal integration.\n\n\n\n\n\n \u00a7.\u00a7 Mutual Information Structure\n\nTo investigate the spatial dynamics of the surface pressure we compute the covariance and mutual information matrices: cov(P(s,t),P(s',t)) and I(P(s,t),P(s',t)) for both the raw pressure P and the filtered pressure P\u0303. These quantify the information shared between different locations along the airfoil.  The covariance matrices and mutual information matrices are shown in figures <ref> and <ref> respectively. The left plot shows the raw pressure signal and the right shows the filtered pressure. We notice that the results for the raw and filtered pressure are qualitatively similar, and thus the following discussion applies to both. \n\n\nThese results reveal three distinct regions. First, the underside of the airfoil, 0.5<s<1.0. This region displays a high degree of mutual information and strong correlation.\nSecond, the front section of the upper surface, 0<s<0.3. This region exhibits similar features as the underside: strong mutual information and correlation, however, in this region the mutual information drops off much more quickly with separation between the sensor locations. These results imply that these regions are amenable to sparse sensor distribution, since any additional sensor is unlikely to contribute new information.  Note also that due to the airfoil having a non-zero angle of attack we see strong negative correlation between the upper and lower surface pressures. However, there is little mutual information between the upper and lower surfaces. This implies that measurements on one surface do not necessarily provide information about the other. The exception to this is the rear part of the upper surface, 0.3<s<0.5. In this region there is little to no mutual information and significant variation in the correlation. As a result, this region likely requires relatively higher sensor density. We note that the transition point between the first two regions, s=0.3, coincides with the point of flow separation (see figure <ref>). Therefore the increased disorder observed in section 3 is likely due to to the complexity and increased unsteadiness of the flow in this region.\n\n\nWe also compute the standard and extreme event mutual information between the surface pressure and the drag coefficient: I(P(s,t),q(t+\u03c4)) and I_EE(P(s,t),q(t+\u03c4)). These are plotted in figure <ref> for the raw and filtered pressure signals for a range of \u03c4. As we are interested in the spatial variation of these quantities, to ease comparison we normalize each by its maximum value. In all cases we do not observe strong dependence on the lead time \u03c4.  As with the intra-pressure mutual information we see strong spatial dependence in the region 0.3<s<0.5. For both the raw and filtered pressure signal, the extreme event mutual information is (locally) peaked in this region. On the other hand, for the standard mutual information this region lies in the trough of the spatial distribution. This suggests that the mechanisms driving the extreme events are strongest in the separation region. However, due to their rarity, this connection is not reflected in the standard mutual information profile. Next, we analyze this extreme event mechanism, and its connection to the extreme event mutual information in more detail.\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Extreme Event Mechanisms\n\nExtreme events occurring in dynamical systems are known to arise due to a variety of factors \u2013 not all of which are fully understood. One class of dynamical system known to give rise to extreme events are slow-fast multi-scale systems <cit.>. In such cases, the system evolves on two or more manifolds which have significant separation of characteristic time scales. At most times, the system evolves along the slower manifold. Occasionally, the trajectory may encounter an instability of this slow manifold, resulting in the trajectory rapidly approaching the fast manifold. Once the unstable region has passed the system relaxes back to the slow manifold. Such phenomena are often observed as sporadic high amplitude bursts <cit.>. \n\nAirfoil flow is an example of such a multi-scale system. Such systems have multi-peaked spectral content \u2013 or in other words they have multiple characteristic frequencies. At this Reynolds number there are two high frequencies (fast manifolds), the vortex shedding frequency, f_v = 1.44 corresponding to the energetically dominant oscillatory flow, and a second frequency corresponding to the extreme event manifold, f_e = 0.4. Figure <ref> shows the standard and pre-multiplied temporal Fourier power spectrum of the filtered surface pressure defined as\n\n    \ud835\udcab(s,f) \u2261\u222b P(s,t) e^-iftdt,\n\nand\n\n    \ud835\udcab_pm(s,f) \u2261  f\ud835\udcab(s,f),\n\nrespectively. \nThe latter is useful for visualizing higher frequency content as it de-emphasizes the slow dynamics (f\u21920).\nIn the standard power spectrum there is a clear maximum close to f=0, corresponding to the slow dynamics. The extreme event frequency (manifold) is also evident in the plain spectrum, but is best seen in pre-multiplied spectrum, which exhibits a clear peak around f = 0.4. We show the spectrum of the filtered pressure as the vortex shedding frequency at f = 1.44 is much stronger than either the slow or extreme event dynamics and obscures these when included in the spectrum. Note also the increased magnitude in the region 0.3<s<0.5 consistent with the results of <ref>.\n\n\nThe connection between this frequency and the extreme events is best interpreted through the wavelet transform. The wavelet transform allows for the visualization of the time varying strength of a signal's frequency content. The wavelet transform has been used in the past to identify extreme events by for example <cit.> to detect bursts in pipe flow and <cit.> for the early detection of rogue waves. The continuous wavelet transform (CWT) of a signal x(t) is defined as\n\n    X\u0302(f,t) \u2261\ud835\udcb2(x(t))= \u221a(f/f_c)\u222b^\u221e_-\u221e x(s) \u03c8(f s-t/f_c) ds.\n\nHere \u03c8(t), is the wavelet function, and f_c is the wavelet specific center frequency. The wavelet function is not unique, but must satisfy several conditions including finite energy and localized support <cit.>. Here we use the Morlet wavelet,\n\n    \u03c8(t) = e^-t^2/2cos(5t).\n\nMoving forward we refer to the wavelet transform of the pressure signal as P\u0302(s,f,t) where f is the frequency. The wavelet transform of the pressure signal at s = 0.34 is shown in the upper panel of figure <ref>. This location corresponds to the peak in the spatial power spectrum in figure <ref>. Figure <ref> clearly shows the bursts of energy at f = f_e = 0.4.\n\nWe define the extreme event indicator \u03b3 as the wavelet coefficient which maximizes the spectrogram of the filtered pressure signal, i.e. for f=f_e\n\n    \u03b3(s,t) \u2261|P\u0302(s,f_e,t)|.\n\nIn the lower panel of figure <ref> we show the clear correlation between \u03b3 and the extreme drag events. This connection is even further highlighted in figure <ref> where we compare the spatial dependence of the norm \n\n    \u03b3(s) =\u221a(\u222b |\u03b3(s,t)|^2 dt),\n\nto the standard and extreme mutual information profiles (also shown in figure <ref>). As we previously found that these mutual information profiles do not depend significantly on \u03c4, we show only the distribution for \u03c4 = 0. Notice that the norm of the wavelet coefficient peaks in the same region of the airfoil, 0.3<s<0.5, as the extreme event mutual information between the pressure signal and the drag. This suggests that the extreme events observed in this flow are indeed of the multi-scale system type, and that the connection (as quantified by the extreme event mutual information) is a reflection of the strength of the extreme event frequency. In <ref> we show that preprocessing the pressure signal to extract this extreme event manifold allows for a drastic reduction in the model complexity and data required for accurate forecasting.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Flowfield Analysis\n\nIn <ref> and <ref> we identified the unstable extreme event manifold and its connection to the separation region of the airfoil. Here we zoom out and analyze the full boundary layer to better understand the mechanisms at the heart of the instability and the subsequent extreme drag events. To this end we follow the time evolution of the vorticity field, \n\n    \u03c9(x,y,t) \u2261\u2202 v/\u2202 x -\u2202 u/\u2202 y\n\nover the course of a single extreme event from t=911-931, with a peak at t = 921. Figure <ref> shows 8 snapshots of the vorticity field over this time interval \u2013 for clarity we focus on the region near the boundary layer. The corresponding values of the instantaneous drag coefficient are shown in the top left panel of the same figure. The red markers in the latter represent the time instances of the 8 vorticity snapshots.  We see clear evidence of boundary layer separation/disorder during the time instance corresponding to the peak in drag coefficient. Although we show only a single extreme event here, this disordered behaviour of the boundary layer was observed during the peak of all extreme events. \n\n\nThe transient dynamics observed in the full vorticity field are subtle, and thus to better understand these transient dynamics we compute the wavelet transform of the entire vorticity field,\n\n    \u03a9\u0302(x,y,t,f) = \ud835\udcb2( \u03c9(x,y,t) ).\n\nThis allows us to investigate the component of the vorticity evolving with the extreme event frequency identified in <ref> \u2013 which is not the dominant energetic contributor to the full field, and is thus liable to be obscured in the snapshots in figure <ref>. \n\n\n\n  \u00a7.\u00a7.\u00a7 Global Dynamics\n\nTo analyze the dynamics of the boundary layer we first consider the wavelet transform of the full flowfield \u2013 focusing on the the extreme event frequency, \n\n    \u03a9\u0302_e(x,y,t) \u2261\u03a9\u0302(x,y,t,f)|_f=f_e=0.4,\n\nand the vortex shedding frequency,\n\n    \u03a9\u0302_v(x,y,t) \u2261\u03a9\u0302(x,y,t,f)|_f=f_v=1.44.\n\nThe wavelet component associated with the extreme event frequency (<ref>) and the vortex shedding frequency (<ref>) are plotted in figures <ref> and <ref> respectively for the same time instances as in figure <ref>. In the former, we see clear evidence of a coherent structure with relatively small characteristic spatial length scale which undergoes a transient instability resulting in a temporary loss of coherence during the extreme event before recovering as the drag coefficient returns to its nominal state. The vortex shedding mode has a much larger characteristic length scale \u2013 on the order of the vortical structures seen in figure <ref> \u2013 and does not appear to undergo any significant changes during the extreme event. \n\n\n\n\n\n\n\nTo further illustrate the dynamics of these two frequency components we compute the temporal correlation function\n\n    r_\u03b1(t_0,t) \u2261|\u222b\u222b\u03a9\u0302^*_\u03b1(x,y,t_0) \u03a9\u0302_\u03b1(x,y,t) dx dy|,\n\nwhere ^* denotes the complex conjugate and \u03b1 = e,v and the integration is performed over the entire domain. For the special case where t_0=t this is equivalent to the L_2 norm of the wavelet mode\n\n    \u03a9\u0302_\u03b1^2(t) \u2261\u222b\u222b |\u03a9\u0302_\u03b1(x,y,t)|^2 dx dy.\n\nThese metrics respectively quantify the temporal evolution of the shape (length scale) and magnitude of the vorticity at a specific temporal frequency.\n\n\nThe correlation (<ref>) is plotted in the upper panel of figure <ref> for both \u03a9\u0302_e (blue circles) and \u03a9\u0302_v (red triangles). We fix t_0 = 911 as a representative snapshot corresponding to the vorticity structure during the quiescent periods \u2013 however, any quiescent time instance could be used. We clearly observe a systematic and drastic loss of coherence in the extreme event mode during the spikes in the drag coefficient. Inspection of figure <ref> suggests that this is at least in part due to an increase in the dominant spatial length scale. The coherence of the vortex shedding mode actually fluctuates \u2013 with what further analysis reveals to be at close to the extreme event frequency \u2013 with an amplitude that slightly increases during the extreme events, however no drastic loss of coherence is observed. The significance of this fluctuation is not immediately clear, but it suggests some interaction between the two frequency components \u2013 the investigation of which is the focus of ongoing research.\n\n\nThe central and lower panel of figure <ref> show the time evolution of the norm (<ref>) of the extreme event mode (blue circles) and vortex shedding mode (red triangles). The central panel shows the large difference in magnitude between these two frequency components \u2013 the vortex shedding mode generally contains an order of magnitude more energy than the extreme event mode. The lower panel compares these norms (normalized by their value at t_0) to the drag coefficient (black). For reference, in the lower panel we also plot the normalized surface pressure extreme event wavelet coefficient, \u03b3(s,t)_s=0.34 (<ref>) (green squares). As in the previous sections, the location s = 0.34 is chosen as it is located within the separation region. While as previously noted, the magnitude of \u03b3 peaks in sync with the extreme drag events, the global norm of the extreme event component of the vorticity, \u03a9\u0302_e, drops in magnitude during the same time intervals. In contrast to both of these, the dominant vortex shedding mode, (<ref>), is significantly more stable and exhibits a much smaller relative drop in magnitude during the extreme events.\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Dynamics on the Airfoil Surface\n\nTo better understand the instability of the extreme event mode and the associated transfer of energy we also compute the spatial Fourier transform of the temporally wavelet transformed vorticity evaluated at the airfoil surface. In other words we compute \n\n    \u03a9\u0303_s(t,f,k_s) \u2261| \u2131( \u03a9\u0302(x(s),y(s),t,f)  )| = |\u222b\u03a9\u0302(x(s),y(s),t,f) e^-ik_s sds|\n\nwhere k_s is the spatial wavenumber with respect to the arclength s along the airfoil surface defined in <ref>  and x(s) and y(s) are the coordinates of that surface. This reduces the spatial dimensions from two to one, and thus allows us to visualize the transfer of energy between various spatial and temporal scales as a function of time. The isocontours of this quantity are plotted in figure <ref> over a time horizon covering two extreme events \u2013 the drag coefficient is also plotted for reference. This plot succinctly summarizes the observations discussed above. First we see that during the quiescent periods, the energy of the extreme event mode, which actually seems to meander slightly about f=0.4, is concentrated at a wavenumber k_s \u2248 20. Then during the extreme events, energy is drawn from the higher frequency vortex shedding mode, which serves as an energy reservoir, leading to the instability of the extreme event mode which abruptly transfer its energy to a lower wave number k_s \u2248 10. This appears in figure <ref> as the \u201cpinching off\u201d of the isocontours during the spikes in the drag. This is the manifestation of loss of coherence and increase in spatial scale of the extreme event mode observed in figure <ref> and quantified in the upper panel of <ref>. We note in closing that this phenomenon of the extreme events evolving on a manifold distinct from the energetically dominant one has been observed in other systems such as for example Kolmogorov flow <cit.>. In that case the energy of the flow is dominated by a specific triad of spatial wavenumbers, however projecting the flow onto this triad fails to predict the extreme energy dissipation events observed in that flow. Similarly, in the case of the airfoil flow considered here, extracting only the dominant vortex shedding dynamics would miss the extreme event dynamics entirely. However, our findings are contrary to the far more common phenomenon of instabilities transferring energy from large to small scales.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 OFFLINE SPARSE SENSOR PLACEMENT\n\nThe analysis of mutual information structure described in <ref> indicates that certain sections of the airfoil are statistically more informative of the drag coefficient. To test the practical implications of this discovery we first propose an offline strategy to optimally select sensor locations. Such an algorithm does not require actually training the neural network. Therefore, it can be thought of as a prepossessing step which allows us to optimally design the network architecture prior to training. At each iteration, the sampling algorithm, which is outlined in algorithm <ref>, selects the next best sensor location by maximizing a cost function referred to as an acquisition function. Throughout this work we use the term \u201cacquisition function\u201d strictly in connection with such a sampling strategy, and the term \u201ccost function\u201d to refer to the cost function used to train a given model.\n\nFor a given application, the choice of acquisition function is not obvious, see for example <cit.>. In this framework sensor locations are selected sequentially, and therefore we seek locations which are maximally informative of the drag coefficient and minimally redundant with respect to the previously placed sensors. Thus, we propose the following two acquisition functions based on the previously defined standard and extreme event mutual information\n\n    a^1_j+1(s,s^*_j) = I(P(s),q)/1/j\u2211_k=1^jI(P(s),P(s_k^*)),\n\n\n    a^2_j+1(s,s^*_j) = I_EE(P(s),q)/1/j\u2211_k=1^jI(P(s),P(s_k^*)).\n\nThe numerator \u2013 the mutual information between the pressure signal with the drag coefficient \u2013 rewards predictive capability. The denominator \u2013 the average of the intra-pressure sensor mutual information \u2013 penalizes redundancy. This second condition ensures that sensors are not placed in locations which do not contribute information not already encoded in previously placed sensors. \n\nThere is no unique way to quantify the connection between a prospective sensor location and the previously placed sensors, and the average used here is only one option. Therefore, we also considered a second acquisition function where the arithmetic mean in the denominator of (<ref>) and (<ref>) is replaced with a geometric mean, but we did not observe significantly different results. A more exhaustive study of candidate functions is beyond the scope of this work, and so for the sake of brevity we restrict ourselves to (<ref>) and (<ref>). Going forward we refer to any results obtained using this algorithm as offline-mutual-information (OMI_N) where N is the number of sensors.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Results: Sensor Placement\n\nWe apply algorithm <ref> with acquisition functions (<ref>) and (<ref>) to our data set to compute the first six optimal sensor locations. Because the results of figure <ref> indicate that the general behaviour of the mutual information is not dependent on the lead time \u03c4, we fix \u03c4 = 0. Additionally, in order to facilitate comparison with <cit.>, we consider only the raw pressure signal. The acquisition function landscape for at each iteration is plotted in figure <ref>.  The optimal senor locations after each iteration are then summarized in figure <ref>. \n\n\nThe globally optimal sensor locations are simply the points of maximum standard and extreme event mutual information \u2013 these are located at approximately s = 0.15 for (<ref>) and s= 0.3 for (<ref>) respectively. However, inspection of figure <ref> indicates that in the latter case the acquisition function landscape does not display any significant variation along the airfoil, calling into question the viability of (<ref>) as a practical metric for optimal sensor placement. For the standard mutual information case, (<ref>), at iteration 2-4 the acquisition function exhibits multiple local maxima of roughly equal value in the region 0.3<s<0.5. These multiple peaks are sequentially \u201cpicked off\u201d throughout the iterations 2-4. This phenomenon is also observed, but to a slightly lesser extent, in the extreme event mutual information case (<ref>). The similarity of these local maxima mean that these 4 sensor locations should be thought of as an \u201coptimal grouping\u201d rather than a strict ranking, since measurement noise or numerical errors could affect their ordering. However, we note that adding small amounts of noise did not significantly impact the qualitative features of the results. Figure <ref> highlights that while the ordering of the sensors varies between the standard and extreme event versions of the model, the final distribution of the optimal sensors is qualitatively very similar.\n\n\nThe under side of the airfoil (0.5<s<1) is completely ignored by the algorithm until iteration 5 for the standard case and iteration 6 for the extreme event case, where a strong maximum is observed just downstream of the leading edge. This solitary underside sensor near the leading edge is consistent with the mean pressure profile observed in the flow over an inclined airfoil. The mean pressure gradient (w.r.t. arc length) is generally significant along the upper surface but relatively weak along the lower surface. Therefore, a single sensor can capture a significant amount of the information of the pressure field along the lower surface, since once the jump in pressure across the leading edge is established there is not much more to be gained from further probing the pressure along the underside of the airfoil. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Results: Evaluation\n\nTo test the efficacy of the proposed offline sensor placement algorithm we train the same LSTM network described in <cit.> using the first 5 optimal sensor locations predicted using algorithm <ref> with acquisition function (<ref>). Due to the similarities of the sensor locations predicted by (<ref>) and (<ref>) and the high computational cost of training the network we omit the predictions of (<ref>) from this analysis. We compare those results to those in <cit.> using 50 sensors spaced equally around the airfoil. The network architecture is \n\n    \u2192 FC32 \u2192 LSTM32 \u2192 LSTM32 \u2192 FC32 \u2192 FC16 \u2192 FC8 \u2192 FC4 \u2192 FC1 \u2192\n\nwhere FC and LSTM stand for `fully-connected' and `long-short term memory' respectively, and the swish activation function is applied between each layer <cit.>. In order to isolate the effects of the sensor placement, we make no changes to the architecture or other than the input dimension and utilize the same training strategies as <cit.>. Training is conducted using 70% of the data, with the remaining 30 % split evenly between validation and testing. The model was trained over 3 restarts using 140 history points and a mean square error loss function until the validation error failed to decrease for 10 epochs \u2013 no regularization was used. The interested reader is referred to <cit.> for a more detailed description of the network architecture and training strategy. \n\nWe compare three different models: the reference case from <cit.> using 50 sensor locations, the OMI_5 model, as well as a second reference case using 5 uniformly spaced sensors \u2013 all three use the raw pressure data as an input. The last case is included to verify that any potential benefit of our algorithm is actually due to the algorithmic placement of the sensors and not simply a reflection of oversampling by <cit.>. The three models are summarized in table <ref>. \n\n\nTo compare the predictive capabilities of the models we compute both the mean square error (MSE) of the model prediction as well as the maximum adjusted area under the precision-recall curve \u2013 a metric introduced  by <cit.> which quantifies the accuracy of extreme event prediction. The area under the precision-recall curve is then defined as\n\n    \u03b1(\u03c7)=\u222b_0^1 S(R,\u03c7) dR,\n\nwhere the event rate \u03c7 is defined as the probability that the output exceeds some threshold, the precision, S, the ratio of correct event predictions to total event predictions, and the recall, R, is the ratio of correct event predictions to the actual number of events. The maximum adjusted value is then defined as\n\n    \u03b1^* = max_\u03c7(\u03b1(\u03c7)-\u03c7).\n\nWhen the value of \u03b1^* is large (approaches unity) the model is very good at predicting rare events, alternatively, when the value approaches zero a model does no better than a guess based on the aggregate frequency of extreme events. \n\nFigure <ref> compares the mean absolute error, MAE, and  \u03b1^* of the various models for a range of lead times \u03c4. As expected, for all cases MAE increases and \u03b1^* decreases with \u03c4 \u2013 it is more difficult to predict the far future. Comparing the models, we first observe that there is no significant difference between the two reference cases with 5 and 50 sensors, suggesting that the NN model developed by <cit.>, is amenable to far more sparse sensor distributions than is suggested by those authors. Additionally,  we see no clear distinction between the results of the model trained using our predicted optimal sensor locations and the uniformly sampled reference cases. This highlights the limitations of the mutual information as a practical tool for engineering design. To further highlight this limitation and exclude the possibility of our conclusions being influenced by oversampling we train the model using the 5 optimal sensor locations individually. In other words we train 5 models, each with a single sensor (the n^th optimal OMI prediction) as its input. The same error metrics for this experiment are plotted in figure <ref>. Again we see that the optimal sensor location s=0.14 performs no better, and in many cases worse, than the suboptimal locations \u2013 see for example the value of \u03b1^* at \u03c4 = 0 and 7. These results strongly suggest that optimal sensing based purely on mutual information does not adequately capture the extreme event mechanism identified in <ref> and thus fails as a practical tool for optimal sensing.\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 WAVELET PREPROCESSING FOR EXTREME EVENT PREDICTION\n\nDespite its robustness to sensor location, the LSTM network considered in <ref> is expensive to train, so here we explore a different avenue of model reduction: preprocessing the data through offline identification of the extreme event dynamics. In <ref> we find that the extreme event dynamics are directly related to the dynamics of a single frequency component.  Here we show that exploiting this observation through the event indicator (<ref>) allows for the forecasting of the extreme events using very simple network models. \n\n\n\n \u00a7.\u00a7 Methods\n\nThe extreme event indicator \u03b3 defined in (<ref>) is not only highly correlated with the bursting events, as it represents an isolated frequency component, but is also free of noise. This makes it amenable to accurate numerical differentiation. We therefore define the following transformation\n\n    D_n(\u03b3): \u00a0 \u03b3\u2192[ \u03b3,\u03b3\u0307, ... , \u03b3^(n)],\n\nwhich allows us to track not only the value of \u03b3, but also its growth rate. This is crucial as we seek to forecast bursting for nonzero lead times \u03c4, and therefore it is imperative for the model to observe growth and not just magnitude. The differentiation operation in (<ref>) is essentially a phase shift of the signal and thus aids the forecasting capabilities of the model, i.e. the predictions for \u03c4 >0. We find that for this flow, a single derivative (n=1) is sufficient, and including a second derivative did not meaningfully improve results. Note that this differentiation is applied offline, and thus does not affect the computational cost of training the model. We propose a preprocessing procedure described in algorithm <ref>, in which we replace (<ref>) with\n\n    \u0393(t) \u2192 q(t+\u03c4).\n\nHere the input data is defined as\n\n    \u0393\u2261 D_1(\u03b3) = [\u03b3,\u03b3\u0307],\n\nand \u03b3 is defined in (<ref>). We utilize a fully connected neural network f: R^n \u2192R^1 with layers\n\n    \u2192 FC8 \u2192 FC16 \u2192 FC16 \u2192 FC8 \u2192 FC1 \u2192,\n\nwith the swish activation function <cit.> applied between each layer. A regularization constant of 0.01 was applied to the activation layers \u2013 no regularization was applied to the kernels. Note that unlike the LSTM network (<ref>) utilized by <cit.>, this network does not map sequences to sequences, it simply maps values of \u0393 at time t, to values of q at time t+\u03c4. To train the model we use both a standard and output-weighted mean absolute error loss function,\n\n    MAE = \u2211_j|q\u0302_j - q_j| ,\n\n\n    MAE_OW = \u2211_j|q\u0302_j - q_j| /f_q(q_j).\n\nHere q\u0302_j is the model prediction, q_j is the training data, and f_q(q_j) is the probability density function of the training data evaluated at q_j.  <cit.>  found that output-weighted loss functions significantly improve prediction of outlier events in a variety of flows including airfoil and Kolmogorov flow. While those authors use the mean square error, we find that in our case the mean absolute error consistently performed slightly better. Our model is summarized graphically in figure <ref>.\n\nIn order to quantify the uncertainty of our model, we perform an ensemble analysis resulting in a mean prediction q\u0302(t) and variance \u03c3_q(t). We set aside 80% of the data set for training, and for each iteration of the ensemble we randomly select 75% of that training data (60% of the total) to use for training. The remaining 20% of the data is used for testing. All results presented here are computed exclusively using this test data. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Results: Basis Comparison\n\nTo illustrate the advantages of the wavelet basis and the output-weighted loss function we compare the model predictions using the three basis types: P, P, and [\u03b3,\u03b3\u0307 ] and the two loss functions MAE and MAE_OW.  In all cases we use four evenly spread sensor locations at s = 0.05, 0.35, 0.65, 0.95. The first two sensor location represent areas identified in <ref> and <ref> as predictive of the drag. The latter two locations are chosen as to not neglect the underside of the airfoil. In all cases train an ensemble of 10 models for 200 epochs.\n\n\n\nFigures <ref>  and <ref> compare the model prediction of the drag coefficient to the true value for \u03c4 = 0 and \u03c4 = 7. At \u03c4 =0, the filtered pressured model and the wavelet model, shown in blue and red respectively, perform well, with only the raw pressure model, shown in green, suffering from significant noise corruption. In fact, in this case the smooth pressure model slightly outperforms the wavelet basis \u2013 best seen by comparing the predicted probability density functions in figure <ref>. This is because there exists an accurate linear mapping from the smooth pressure \ud835\udc0f(t) to the drag q(t), and in taking the wavelet transform of the filtered pressure some information is lost \u2013 limiting the potential accuracy of the wavelet model. See appendix <ref> for a brief discussion on this linear mapping. Furthermore, we observe that for zero lead time, the models trained using the MAE_OW loss function perform slightly better than those trained using the MAE loss \u2013 The benefit is most pronounced for the raw pressure data.\n\n\n\nThe benefits of the wavelet basis and the output weighted loss functions do not become apparent until considering non-zero lead times \u2013 a reflection of the nonlinearity of the time shift operation q(t) \u2192 q(t+\u03c4). In this case, when using the standard MAE loss, all three models entirely fail to capture the extreme events. However, using the output-weighted loss the wavelet basis retains much of the accuracy observed for \u03c4 = 0, while the performance of the raw and filtered pressure models deteriorate significantly. The filtered pressure model still traces the occurrence of the extreme events, but suffers from significant noise corruption leading to number of false positive predictions. This phenomenon is even more pronounced for the raw pressure model, which, as expected, suffers from even greater noise corruption. The distinction between the three basis types is less evident in the predicted probability density functions shown in <ref>. Here we  see again that the models trained using the standard MAE loss fail to capture the tails of the distribution entirely, however with the MAE_OW loss both the filtered pressure and wavelet models capture the general shape of the distribution. The wavelet model does however capture the small peaks around q=-1.5 and q=3 slightly better than the others.\n\n\n\nTo quantify the forecasting capabilities of each model we track the number of extreme events predicted as a function of time. For this purpose we define an extreme event as a local maximum, whose value is more than 2 standard deviations greater than the mean. Thus, a time instant t_j is considered to represent an extreme event t_EE if it satisfies the following conditions,\n\n    t_EE: \u00a0 t_j   \u00a0  s.t. \u00a0 .[\u2202 q/\u2202 t|_t_j = 0 \u00a0 &\u00a0 q(t_j) > 2\u03c3_q ].\n\nWe then define the number of extreme events N_EE(t_1,t_2) as the number of extreme events in the interval, t_1 to t_2, or more explicitly,\n\n    N(t_n,t_0) = \u2211_j=j_0^j_n\u03b4_t_j,t_EE,\n\nwhere t_j is treated as a discrete series and j_0 and j_n are the indices of t_n and t_0 respectively. In order to avoid over-penalizing noise, we enforce a minimum separation of the identified extreme events equal to the characteristic period of the extreme event frequency: T_EE=1/f_EE. While it relies on two user defined parameters: the extreme event threshold and the minimum peak separation, this metric provides a useful quantification of the forecasting capabilities of each model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis metric is plotted in figure <ref> for the filtered pressure and wavelet models for \u03c4 = [0,3,7,10] \u2013 we omit the raw pressure model due to its poor performance. Since the models trained using the MAE loss and perform so poorly for \u03c4 >0 we plot only the results obtained using the MAE_OW loss. Again we see that for \u03c4 = 0 both models perform similarly, with the filtered pressure model slightly outperforming the wavelet model. However, as the lead time \u03c4 increases, the wavelet model retains much of it's accuracy, while the filtered pressure model on the other hand dramatically overestimates the number of extreme events. This is due to the significant noise in the filtered pressure model, the magnitude of which is often comparable to the underlying signal. \n\nWe also compute the MAE, MSE, \u03b1^*, defined in (<ref>), as well as the error in the total number of extreme events predicted. These are plotted in figure <ref>. Again, both pressure models overestimate the number of extreme events defined by (<ref>), however for the aggregate error metrics (MAE and MSE) as well as the \u03b1^* the differences are less pronounced. Both the filtered pressure and wavelet model significantly outperform the raw pressure model, but the difference between them is minimal. \n\nThe discrepancy in performance between the three basis types can be understood through the simple nature of the model architecture. The large amplitude of the high frequency fluctuations in the raw pressure is comparable and sometimes even larger than the bursting amplitude \u2013 see figure <ref> \u2013 therefore a one-to-one map is destined to fail. This phenomenon is mitigated by filtering the vortex shedding frequency out of the pressure data \u2013 in this case there is indeed a linear map for zero lead time. However, for non-zero lead times the amplitude of the fluctuations at the extreme event frequency are significant enough to introduce significant ambiguity in a one-to-one map. Conversely, the wavelet basis is free of noise and fluctuates on a time scale associated with the mean time between extreme events, thereby greatly improving the feasibility of such a simple mapping. Moving forward we exclusively use the wavelet pre-processed input data \u0393.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Results: Optimal Sensing\n\nWe now assess how to best exploit the wavelet preprocessing algorithm through optimal sensor selection. Here we focus exclusively on \u03c4 = 7. As in <ref> we use algorithm <ref>, however in this case the acquisition function requires training the network (and is minimized, not maximized). In particular we consider the following two acquisition functions which penalize uncertainty in the model prediction,\n\n    a_iu = 1/T\u222b^T_0 \u03c3_q(t) dt = 1/N\u2211^N_j=1\u03c3_q,j,\n\n\n\n    a_pw = 1/T\u222b^T_0 \u03c3_q(t)/p_q(q(t)) dt = 1/N\u2211^N_j=1\u03c3_q,j/p_q(q_j).\n\nWe refer to these as \u201cintegrated uncertainty\u201d (iu) and \u201cprobability weighted\u201d (pw) respectively. To distinguish the effects of the loss and acquisition functions, we perform three iterations of algorithm <ref> with each acquisition function with both the MAE and MAE_OW loss functions. As the acquisition functions need to be evaluated at every sensor location, we use a slightly reduced ensemble of 7 models and train over only 70 epochs during the active search. The resulting optimal sensor locations are summarized in table <ref>. Once the optimal sensor locations are found, we retrain an ensemble of 10 models using those optimal sensors locations for 200 epochs.\n\n\n\nFigure <ref> compares the  output pdf and time series of the mean predictions  of the model trained with each loss function and each acquisition function \u2013 each using their respective optimal sensor locations.  As a comparison we also include the predictions of a reference model with three evenly spaced sensors. For both the time series and the pdf, we observe that regardless of the acquisition function the models trained using the standard MAE loss fail, while the models trained with the output-weighted MAE_OW predict the bursting events relatively accurately. To further compare the models we plot the time series of the uncertainty bound, q\u0302(t) \u00b1\u03c3_q in figure <ref>. Consistent with the results of <ref>, we observe the model to be robust to specific sensor locations, with little distinction between the three sensor distributions.\n\n\nInterestingly, inspection of figures <ref> and <ref> indicates that the output-weighted acquisition function (<ref>) performs slightly worse than the others \u2013 exhibiting some false positive fluctuations between t=920 and t=960. Furthermore, the results using the non output-weighted acquisition function (<ref>) do not exhibit any meaningful improvement over the reference case. These findings indicate that the specific locations of the sensors are of secondary importance when compared to the effects of the output-weighted loss function and the wavelet preprocessing. The latter of which extracts the bursting events from the input data a priori. These results indicate that further emphasizing extreme events through strategies such as output-weighted optimal sensing is not only unnecessary, but could result in a loss of accuracy during the quiescent periods. \n\n\nFrom a practical point of view, the similarity of these results is significant. The active regions of the flow, and thus the optimal sensor locations predicted here and in <ref>, are likely to vary with Reynolds number and angle of attack. However, aircraft experience a wide range of flow speeds and orientations, making the robustness to sensor location a valuable asset. These results support the possibility of a sparse sensing strategy which is applicable for a wide range of airfoil designs and is robust to dynamic changes in angle of attack. A parameter study over Reynolds number and flow geometry to confirm this hypothesis is beyond the scope of the present work, but is the topic of ongoing research. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 DISCUSSION\n\nWe have investigated the mechanisms driving the non-periodic bursting phenomena observed in the two-dimensional flow over a NACA 4412 airfoil at finite angle of attack. We have conducted a detailed analysis of the spatiotemporal statistics of the airfoil surface pressure and its connection to the extreme events observed in the drag force. Through a wavelet analysis we found that the surface pressure exhibits multi-scale behaviour with three distinct time scales. In addition to the dominant vortex shedding frequency, the flow exhibits a slowly varying quiescent time scale and a second energetic frequency component \u2013 at approximately one third the vortex shedding frequency. We established that the extreme excursions of the drag first observed by <cit.>, correspond to instabilities of this latter frequency component in the surface pressure.\n\nThese findings were corroborated by an analysis of the wavelet transformed vorticity field. This analysis revealed that during quiescent times the extreme event manifold evolves independently of the vortex shedding manifold, however occasionally the extreme event manifold undergoes a transient instability which links the fortunes of these two generally disparate time scales. This instability is comprised of two steps, first the extreme event manifold draws energy from the higher frequency vortex shedding flow, then at the extreme event frequency, there is an abrupt nonlinear energy transfer from smaller to larger spatial length scales. Interestingly these findings are contrary to the far more common situation where linear instabilities transfer energy from a slowly evolving (or stationary) mean flow to faster time scales and smaller length scales. Therefore, while we have identified the slow-fast system at the heart of the bursting events, the exact mechanism by which the instabilities in the pressure and vorticity are translated to the aerodynamic forces is not yet clear, and remains the topic of ongoing research.\nFor example, it is still unclear what causes the global (integrated over the full domain) magnitude of the extreme event mode to decrease during the extreme events \u2013 see the lower panel of figure <ref> \u2013 or why the temporal correlation of the vortex shedding mode exhibits fluctuations resembling the extreme event frequency \u2013 see the upper panel of the same figure. Furthermore, here we have considered only a single angle of attack, and further study is required to establish how the orientation of the flow impacts both the active regions of the airfoil and the extreme event frequency.\n\n\nFrom a modeling perspective, we pursued two separate strategies. First, in <ref> we investigated the implications of these results for the existing LSTM architecture developed by <cit.> \u2013 which takes raw pressure as its input. We considered an optimal sensing strategy based purely on the statistics of the data, and therefore did not require the computationally costly step of training model. Using the LSTM model this mutual information based algorithm failed to predict sensor locations which performed better than a simple uniform sensor distribution. This failure of the purely mutual information based sensor placement demonstrated the limitations of a purely statistical offline sampling strategy and highlighted the limitations of mutual information as a practical tool. Additionally, the model complexity incurred by the LSTM layers needed to process rapidly varying time series such as the fluctuating surface pressure remains cumbersome regardless of the sparsity of the sensor array.\n\n\n\nSecond, we also developed a preprocessing algorithm (see figure <ref>) to extract the time varying magnitude of the extreme event frequency component from the raw pressure signal. By isolating the wavelet coefficient associate with the extreme event frequency we eliminate the high frequency fluctuations resulting in a signal which slowly fluctuates on a time scale associated with the mean time between extreme events \u2013 which are by definition rare. This enables the (approximate) one-to-one mapping of the wavelet coefficient, which is free of rapid high amplitude noise, to the drag for lead times \u03c4 >0. This then eliminates the need for a costly LSTM architecture and allows for accurate prediction using a simply connected feed forward neural network. These results are consistent with findings of <cit.> who used a spacial wavelet transform wavelet transform to extract unstable spatial length scales to efficiently predict rogue waves in variety of dynamical systems including the Majda\u2013McLaughlin\u2013Tabak model and the modified nonlinear Schrodinger equation.\n\n\nWhile this preprocessing drastically reduces the noise in the signal, it can, and in our case does, eliminate some potentially useful information as well. As noted in <ref> and in appendix <ref> for \u03c4 = 0 there exists an accurate linear map from the surface pressure to the drag coefficient. By isolating a single wavelet coefficient, some of the information in the pressure signal is lost leading to the wavelet model performing slightly worse than the filtered pressure model for \u03c4 =0. However, the predictions from the wavelet model are far more robust to increasing values of \u03c4. At \u03c4 = 7 the predictions of the wavelet model have degraded only slightly, while the raw and filtered pressure models exhibit significant noise corruption. The higher the frequency of oscillation, the more nonlinear the transformation q(t) \u2192 q(t+\u03c4) \u2013 resulting in the degradation of the filtered and raw pressure models for \u03c4 >0.\n\n\n\nThis preprocessing alleviates the need for recursive or convolutional network architectures as used by authors such as <cit.>. However, even with this highly extreme event targeted algorithm we found that training the model using an output-weighted loss function is necessary for accurate predictions. Most interestingly, we find that with these training interventions the specific locations of the sensors is of secondary importance. This is incredibly advantageous as it suggests that the predictive capabilities of our approach are robust to dynamic changes in angle of attack or free stream velocity \u2013 however this requires further study. Our findings suggest that improving the prediction of rare events does not necessarily require more complex models, but can be achieved by identifying observables which reflect the underlying physical mechanisms and through tailored training strategies \u2013 as also discussed by various authors including <cit.>. We believe the herein proposed wavelet based analysis is applicable to a wide range of slow-fast systems and remains the topic of ongoing research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 APPENDIX\n\n\n\n\n \u00a7.\u00a7 Linear Mapping\n\nHere we illustrate the linear map from the vector valued filtered pressure signal \ud835\udc0f(t) to the scalar drag coefficient q(t). Let \ud835\udc0f\u2208\u211d^N\u00d7 100 and \ud835\udc2a\u2208\u211d^N\u00d7 1 be their discrete representations \u2013 N is the number of data points (time steps). We then seek a linear representation \ud835\udc2a\u0302 = \ud835\udc0f\ud835\udc1a that minimizes the L_2 norm \ud835\udc2a-\ud835\udc2a\u0302^2. The optimal coefficient vector is given by\n\n    \ud835\udc1a^* = \ud835\udc0f_train^+\ud835\udc2a_train,\n\nwhere ^+ denotes the pseudo inverse, and the subscript _train refers to the subset of data used for training. Here we use the first 10% of the data to fit the regression (<ref>) and the last 20% for testing. Figure <ref> compares the predictions of the linear regression to the truth for \u03c4 =0 and \u03c4 = 7. For \u03c4 = 0 the linear prediction is indistinguishable from the truth, while for \u03c4 = 7 the linear model completely fails. This is a reflection of the highly nonlinear nature of the time shift operation q(t) \u2192 q(t+\u03c4).\n\n\n\n\n\u00a7 FUNDING SOURCES\n\n\n\n\n\n\u00a7 ACKNOWLEDGMENTS\n\nWe thank Samuel Rudy and Tanner Harms for their constructive feedback. We also acknowledge support from the Army Research Office (grant no. W911NF-17-1-0306) and the Air Force Office of Scientific Research (grant no. MURI FA9550-21-1-0058)\n\n\nabbrvnat\n\n\n\n\n"}