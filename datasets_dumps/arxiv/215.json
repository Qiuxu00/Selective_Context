{"entry_id": "http://arxiv.org/abs/2303.07060v1", "published": "20230313122819", "title": "Parametric Estimation of Tempered Stable Laws", "authors": ["Till Massing"], "primary_category": "math.ST", "categories": ["math.ST", "math.PR", "stat.TH", "60E07, 60G51, 62F12, 62P20"], "text": "\n\n\n\n\n\n\n\n\n\n\n\n \na]Till MassingFaculty of Economics, University of\nDuisburg-Essen, Universit\u00e4tsstr.\u00a012, 45117 Essen, Germany.\nE-Mail:\ntill.massing@uni-due.de\n\n\n\n\nParametric Estimation of Tempered Stable Laws\n    [\n    March 30, 2023\n=============================================\n\n\n\n\nTempered stable distributions are frequently used in financial applications (e.g., for option pricing) in which the tails of stable distributions would be too heavy. Given the non-explicit form of the probability density function, estimation relies on numerical algorithms as the fast Fourier transform which typically are time-consuming. We compare several parametric estimation methods such as the maximum likelihood method and different generalized method of moment approaches. We study large sample properties and derive consistency, asymptotic normality, and asymptotic efficiency results for our estimators. Additionally, we conduct simulation studies to analyze finite sample properties measured by the empirical bias and precision and compare computational costs. We cover relevant subclasses of tempered stable distributions such as the classical tempered stable distribution and the tempered stable subordinator. Moreover, we discuss the normal tempered stable distribution which arises by subordinating a Brownian motion with a tempered stable subordinator. Our financial applications to log returns of asset indices and to energy spot prices illustrate the benefits of tempered stable models.\n\n\n\n\n60E07;60G51;62F12;62P20\nactivate=true\n\n\n\n\u00a7 INTRODUCTION\n\n\nWe discuss parametric estimation methods for some well-known subclasses of tempered stable distributions. Estimation relies heavily on numerical methods as the probability density function is not given in closed form. This paper aims to compare available estimation methods both from an analytical as well as from a practical point of view. \n\nTempered stable distribution are relevant from both a theoretical perspective and in the context of financial applications. Since tempered stable distributions are infinitely divisible, they can be used as the underlying marginal distribution for tempered stable processes. They arise by tempering the measure of stable distributions with a suitable tempering function. Tempered stable distributions were introduced in <cit.>, where the associated process was called smoothly truncated flight, which itself is a generalization of Tweedie distributions <cit.>. Since then, tempered stable distributions have been generalized in several directions by mainly generalizing the class of tempering functions. <cit.> presents a general framework for tempered stable distributions which contain the parametric subclasses to be considered in this paper. Further developments are surveyed in <cit.>.\n\nThe three subclasses we consider in this paper are the tempered stable subordinator (a one-sided distribution with finite variation), the classical tempered stable distribution (with the classical exponential tempering), and the normal tempered stable distribution (which is a normal-variance mixture with a tempered stable subordinator). The CGMY distribution <cit.> is a well-known special case of the classical tempered stable distribution which was introduced to model log-returns of stock prices. Tempered stable distributions have frequently been used for financial applications <cit.>. Furthermore, <cit.> and <cit.> propose tempered stable distributions because the tails of tempered stable distributions are not too heavy for option pricing (contrary to stable distributions).\n\n Estimation methods for generalized tempered stable distributions are still an active area of research. We compare various well-established estimation methods in the literature. The first is the traditional maximum likelihood (ML) method, which works by numerical optimization and Fourier inversion, see <cit.>. <cit.> proves strong consistency of the maximum likelihood estimator (MLE). <cit.> propose moment methods which are easier and faster than the ML method. We also use the generalized method of moments estimator by <cit.> that is based on empirical characteristic functions and the generalized method of moments on a continuum of moment conditions by <cit.>. The latter method already turned out to be useful to estimate stable distributions, see <cit.>. Further available methods include the method of simulated quantiles <cit.>, and non- or semiparametric methods <cit.>.\n\nThis paper contributes to the literature in three ways. First, we derive asymptotic theory for the ML method and the generalized method of moments for the three classes of tempered stable distributions. More precisely, we prove asymptotic efficiency and asymptotic normality of the estimators by verifying the set of sufficient conditions. Second, we compare finite sample properties of the estimators in a Monte Carlo study. Third, we illustrate that tempered stable distributions are more suitable in financial applications than stable distributions because the tails of the latter are too heavy. For this, we study log-returns of three financial time series namely the S&P 500, the German DAX, and the German EEX electricity spot prices.\n\nThe remainder of this paper is organized as follows. Section <ref> presents formal definitions and properties of tempered stable distributions and their important subclasses. Section <ref> discusses the estimation strategies and states their general asymptotic results. Section <ref> contains our theoretical results. All proofs are relegated to the appendix. In Section <ref> we conduct a simulation study to analyze finite sample properties. We discuss financial applications in Section <ref>. Section <ref> concludes.\n\n\n\n\u00a7 TEMPERED STABLE DISTRIBUTIONS\n\n\nTo establish notation, we describe some general properties of tempered stable distributions and the considered special cases in this paper. Recall that by the L\u00e9vy-Khintchine formula every process can uniquely be described by its characteristic triple (a,B,\u03a0), where a denotes the trend, B the diffusion matrix and \u03a0 the measure. Important special cases are so called stable (or \u03b1-stable) processes (see <cit.> or <cit.>). Stable processes in d dimensions are characterized by the measure\n\n    M( r,  u) = r^-1-\u03b1 r \u03c3( u),\n\nwhere \u03b1\u2208(0,2) and \u03c3 is a finite, non-zero measure on the (d-1)-dimensional unit sphere S^d-1. In one dimension the measure takes the form\n\n    M( r) = (\u03b4_+/r^1+\u03b11_(0,\u221e)(r)+\u03b4_-/|r|^1+\u03b11_(-\u221e,0)(r)) r,\n\nwith \u03b4_+,\u03b4_-\u22650 s.t.\u00a0(\u03b4_+,\u03b4_-)\u2260(0,0).\n\nTempered stable distributions arise by tempering the measure of a stable distribution by a tempering function. The measure of d-dimensional tempered stable measure with a general tempering function is\n\n    Q( r,  u) = r^-1-\u03b1 q(r,u) r \u03c3( u),\n\nwhere q:(0,\u221e)\u00d7 S^d-1\u2192 (0,\u221e) is a Borel function s.t.\u00a0q(\u00b7,u) is completely monotone with lim_r\u2192\u221eq(r,u)=0 for each u\u2208 S^d-1, i.e., (-1)^n\u2202^n/\u2202 r^nq(r,u)>0 for all r>0,u\u2208 S^d-1, n\u2208\u2115_0. It is called a proper tempered stable distribution if, in addition, lim_r\u21930q(r,u)=1 for each u\u2208 S^d-1. <cit.> generalize tempered stable distributions by allowing q to only fulfill lim_r\u21920||q(r,\u00b7)-g(\u00b7)||_L^1(S^d-1,\u03c3)=0 for some non-negative function g\u2208 L^1(S^d-1,\u03c3). There are various ways of choosing q (see <cit.> for some examples). In this paper, we mainly focus on the exponential (or classical) tempering function where we apply an exponentially decreasing function. See the next subsections for details. For both stable and tempered stable distributions the diffusion matrix B is zero.\n\n\n\n \u00a7.\u00a7 Tempered stable subordinator\n\n\nThe first special case we discuss is the tempered stable subordinator (TSS). It is constructed from the stable subordinator which is a non-negative, increasing process with \u03b1-stable marginals. In this case, the stability parameter \u03b1 needs to be in (0,1). Its measure is \n\n    \u03b4/r^1+\u03b11_(0,\u221e)(r) r,\n\nwhere \u03b4>0 is a scale parameter. For exponential tempering, the measure of the TSS distribution is given by\n\n    Q_TSS( r)=e^-\u03bb r\u03b4/r^1+\u03b11_(0,\u221e)(r) r,\n\nwhere \u03bb>0 is the tempering parameter.\n\nLet Y\u223c TSS(\u03b1,\u03b4,\u03bb) be a TSS distributed random variable. Using (<ref>) it is possible to derive the characteristic function of the TSS distribution, see <cit.> for a proof of\n\n    \u03c6_TSS(t;\u03b8):=\ud835\udd3c_\u03b8[e^itY]= exp(\u03b4\u0393(-\u03b1)((\u03bb-it)^\u03b1-\u03bb^\u03b1)),\n\nwith parameter vector \u03b8=(\u03b1,\u03b4,\u03bb).\n\nThe probability density function of tempered stable distributions is generally not available in closed form. For the TSS distribution we can make use of the identity\n\n    f_TSS(y;\u03b8)=e^-\u03bb y-\u03bb^\u03b1\u03b4\u0393(-\u03b1)f_S(\u03b1,\u03b4)(y),\n\nwhere f_TSS(y;\u03b8) denotes the density function of the TSS distribution, see <cit.>. S(\u03b1,\u03b4) denotes the distribution of the \u03b1-stable subordinator with scale parameter \u03b4 and f_S(\u03b1,\u03b4)(y) denotes its density, which is (except of a few special cases) not available in closed form. However, many software packages (like the stabledist or Tweedie packages in R) have fast computation routines based on series or integral representations. Combining such series representation with (<ref>) we obtain a series representation for the TSS distribution\n\n    f_TSS(y;\u03b8)=e^-\u03bb y-\u03bb^\u03b1\u03b4\u0393(-\u03b1)-1/\u03c0\u2211_k=1^\u221e(-1)^k/k!\u0393(1+\u03b1 k)\u0393(1-\u03b1)^k(\u03b4/\u03b1)^ky^-(1+\u03b1 k)sin(\u03b1\u03c0 k),\n\nsee <cit.>.\n\nThe estimation method in Section <ref> makes use of matching theoretical with empirical cumulants. Therefore, we state the cumulant generating function of the TSS distribution \n\n    \u03c8_TTS(t;\u03b8)= \u03b4\u0393(-\u03b1)((\u03bb-t)^\u03b1-\u03bb^\u03b1),\n\nfor t\u2264\u03bb, derived in <cit.>. Thus, the m-th order cumulants \u03ba_m=.^n/ t^n\u03c8(t)|_t=0 are given by\n\n    \u03ba_m=\u0393(m-\u03b1)\u03b4/\u03bb^m-\u03b1,   m\u2208\u2115.\n\n\nSimulation, which we need in the Monte Carlo study, of TSS distributed random variates is straightforward by an acceptance-rejection algorithm, i.e., we first generate U\u223c\ud835\udcb0(0,1) and V\u223c S(\u03b1,\u03b4). If U\u2264e^-\u03bb V we set Y:=V, otherwise we repeat the first step, see <cit.>. For the generation of stable random numbers see, e.g., <cit.>. See <cit.> for the more efficient double rejection method.\n\n\n\n\n \u00a7.\u00a7 Classical tempered stable distribution\n\n\nSecond, we discuss one dimensional classical tempered stable (CTS) distributions. They are defined by their measure \n\n    Q_CTS( r)=(e^-\u03bb_+r\u03b4_+/r^1+\u03b11_(0,\u221e)(r)+e^-\u03bb_-|r|\u03b4_-/|r|^1+\u03b11_(-\u221e,0)(r)) r.\n\n\u03b1\u2208(0,2) is the stability parameter, \u03b4_+,\u03b4_->0 are scaling parameters, \u03bb_+,\u03bb_->0 are tempering parameters and \u03bc is a location parameter. The indices + and - refer to the positive and negative parts of the distribution (centered around \u03bc). We collect all parameters in the vector \u03b8=(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc). Note that for the CTS distribution the parameter vector \u03b8 is different than for the TSS distribution.\n\nLet X\u223c CTS(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc). The characteristic function is given by <cit.>\n\n    \u03c6_CTS(t;\u03b8):=\ud835\udd3c_\u03b8[e^itX]   =exp(it\u03bc+\u03b4_+\u0393(-\u03b1)((\u03bb_+-it)^\u03b1-\u03bb_+^\u03b1+it\u03b1\u03bb_+^\u03b1-1).\n        . +\u03b4_-\u0393(-\u03b1)((\u03bb_-+it)^\u03b1-\u03bb_-^\u03b1-it\u03b1\u03bb_-^\u03b1-1)),\n\nfor all \u03b8\u2208(0,2)\u00d7(0,\u221e)^4\u00d7\u211d such that \u03b1\u22601. For \u03b8_1=(1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc) the characteristic function of the CTS distribution instead has the form\n\n    \u03c6_CTS(t;\u03b8)   =exp(it\u03bc+\u03b4_+((\u03bb_+-it)log(1-it/\u03bb_+)+it).\n        . +\u03b4_-((\u03bb_-+it)log(1+it/\u03bb_-)-it)).\n\nNote that the characteristic function (and hence the density function) is discontinuous at \u03b1=1, which affects the compact domain for which asymptotic analysis is possible <cit.>.\n\nAs for the TSS distribution, the density function of the CTS distribution does not exist in closed form. Crucially, even a simple relationship with a stable density as for the TSS distribution in (<ref>) is not available. For numerical evaluations it is therefore necessary to rely on algorithms like the fast Fourier transform <cit.> applied to the characteristic function (<ref>).\n\nAs for the TSS distribution, we specify the cumulant generating function\n\n    \u03c8_CTS(t;\u03b8)   = t\u03bc+\u03b4_+\u0393(-\u03b1)((\u03bb_+-t)^\u03b1-\u03bb_+^\u03b1+t\u03b1\u03bb_+^\u03b1-1)\n         +\u03b4_-\u0393(-\u03b1)((\u03bb_-+t)^\u03b1-\u03bb_-^\u03b1-t\u03b1\u03bb_-^\u03b1-1),\n\nfor t\u2208[-\u03bb_-,\u03bb_+]. We use theoretical cumulants for cumulant matching below. The m-th order cumulants can be derived from (<ref>) and take the form\n\n    \u03ba_m=\u0393(m-\u03b1)\u03b4_+/\u03bb_+^m-\u03b1+(-1)^m\u0393(m-\u03b1)\u03b4_-/\u03bb_-^m-\u03b1,\n\nfor m\u2265 2 and \u03ba_1=\u03bc.\n\nTo explain a feasible simulation algorithm we first discuss the relationship between the CTS distribution and the TSS distribution of the previous subsection by introducing a related distribution. The relation to the CTS distribution will become apparent in the following.\nClosely related to the TSS distribution is the centered and totally positively skewed tempered stable distribution TS^'(\u03b1,\u03b4,\u03bb) which is defined by its characteristic function\n\n    exp(\u03b4\u0393(-\u03b1)((\u03bb-it)^\u03b1-\u03bb^\u03b1+it\u03b1\u03bb^\u03b1-1)),\n\nfor \u03b1\u2208(0,1)\u222a(1,2). For \u03b1\u2208(0,1), we have the relation that if Y\u223c TSS(\u03b1,\u03b4,\u03bb), then Y-\u03b4\u0393(1-\u03b1)\u03bb^\u03b1-1\u223c TS^'(\u03b1,\u03b4,\u03bb). In particular, \n\n    f_TS^'(y;\u03b1,\u03b4,\u03bb)=f_TSS(y-\u03b4\u0393(1-\u03b1)\u03bb^\u03b1-1;\u03b1,\u03b4,\u03bb).\n\nFor \u03b1\u2208(0,1)\u222a(1,2), we additionally have\n\n    f_TS^'(y;\u03b1,\u03b4,\u03bb)=e^-\u03bb y-\u03bb^\u03b1\u03b4(\u03b1+1)\u0393(-\u03b1)f_S(\u03b1,\u03b4)(y-\u0393(1-\u03b1)\u03b4\u03bb^\u03b1-1),\n\nwhere S(\u03b1,\u03b4) is the totally positively skewed stable distribution with measure \u03b4 r^-\u03b1-11_(0,\u221e)(r) r.\n\nUsing this, CTS distributed random variables can be constructed from totally positively skewed tempered stable random variables in the following way. Let Y_+\u223c TS^'(\u03b1,\u03b4_+,\u03bb_+) and Y_-\u223c TS^'(\u03b1,\u03b4_-,\u03bb_-) and \u03bc\u2208\u211d. Then\n\n    X:= Y_+ - Y_- +\u03bc\u223c CTS(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc).\n\n\nSimulation of classical tempered stable variables therefore reduces to simulation of totally positively skewed tempered stable random variables. However, this is more involved than for the subordinator as the simple acceptance-rejection does not work for \u03b1\u2208(1,2). <cit.> present several remedies, e.g., a truncated series representation by <cit.>. We opt for the simulation approach of <cit.>, i.e., using an approximate acceptance-rejection algorithm which works as follows: first fix a number c>0. Second, simulate U\u223c\ud835\udcb0(0,1) and V\u223c S(\u03b1,\u03b4). If U\u2264e^-\u03bb (V+c) we set Y:=V -\u0393(1-\u03b1) \u03b4\u03bb^\u03b1-1, otherwise we return to the second step. The algorithm is not exact, i.e., Y TS^'(\u03b1,\u03b4,\u03bb). The number c controls the degree of approximation and also the acceptance rate. For c too small the approximation might not be sufficient. For large c the approximation improves; yet, the acceptance probability decreases and therefore the runtime elongates.\n\n\n\n\n \u00a7.\u00a7 Normal tempered stable distribution\n\nA further model for financial applications is the normal tempered stable (NTS) distribution. It is constructed as a classical normal variance mixture, see <cit.>. For this, let Y\u223c TSS(\u03b1,\u03b4,\u03bb), with (\u03b1,\u03b4,\u03bb)\u2208(0,1)\u00d7(0,\u221e)^2. Let W\u223c N(0,1) independent of Y and \u03b2,\u03bc\u2208\u211d.\nSet\n\n    Z=\u221a(Y)W+\u03b2 Y+\u03bc.\n\nThen, Z is NTS(\u03b8) distributed, where for this case \u03b8=(\u03b1,\u03b2,\u03b4,\u03bb,\u03bc).\nWe can also obtain the NTS distribution by tempering a stable distribution. The corresponding tempering function can be found in <cit.>. Note that the tempering function is not completely monotone but is in the class of generalized tempered stable distributions of <cit.>.\n\nFor our parametrization, the characteristic function now takes the form\n\n    \u03c6_NTS(t;\u03b8)=E[e^itZ]= exp(it\u03bc+\u03b4\u0393(-\u03b1)((\u03bb-it\u03b2+t^2/2)^\u03b1-\u03bb^\u03b1)).\n\nAs for the CTS distribution, the density function is not available in closed form and numerical computation relies on the FFT. \n\nAs cumulants do not have an easy pattern as for the other examples we omit them. We also do not propose a cumulant matching estimation method here.\n\nSimulation of NTS distributed random variables is easy given the TSS distribution and Brownian motion realizations by invoking (<ref>).\n\n\n\n\u00a7 ESTIMATION METHODS\n\nThis section discusses some parametric estimation strategies available in the literature. We apply these to the tempered stable distributions considered above and derive asymptotic efficiency and normality in the next section. In this section, we briefly present the methods and some known general asymptotic results. We state maintained assumptions in Appendix <ref>. Throughout this section let X be a random variable following one of the tempered stable distributions of Section <ref> and let f(x;\u03b8) denote its density function, depending on the parameter vector \u03b8. Also denote by\n\u03c6_\u03b8(t):=\ud835\udd3c_\u03b8[e^itX]\nits characteristic function, where \ud835\udd3c_\u03b8 is the expectation operator w.r.t.\u00a0the data generating process indexed by \u03b8. Let \u03b8_0 be the unknown true parameter vector. In this paper, we only consider the case of an i.i.d.\u00a0sample X_1,\u2026,X_n with density function f(x;\u03b8).\n\n\n\n \u00a7.\u00a7 Maximum likelihood estimation\n\n\nMaximum likelihood estimation is standard in the literature and frequently used, for example in <cit.>. We numerically maximize the log-likelihood function\n\n    \u2113(\u03b8)=\u2211_j=1^nlog f(X_j;\u03b8)\n\nw.r.t.\u00a0\u03b8.\n\nAs described in the preceding section, the density functions of our distributions are not available in closed form but either via a series representation (TSS) or via the Fourier inversion (CTS and NTS)\n\n    f(x;\u03b8)=1/2\u03c0\u222b_\u211de^-itx\u03c6_\u03b8(t) t\n\nbased on the characteristic function \u03c6_\u03b8(t). In practice, we use the FFT algorithm to approximate (<ref>).\n\nAmong others <cit.> (which we here follow) proved the limiting behavior of the maximum likelihood estimator as given in the following proposition.\n\nUnder Assumption <ref> in Appendix <ref>, the ML estimator\n\n    \u03b8\u0302_n,ML=_\u03b8\u2208\u0398\u2113(\u03b8)\n\nis consistent and\n\n    n^1/2(\u03b8\u0302_n,ML-\u03b8_0)\u2112\u2192N(0,I_\u03b8_0^-1),\n\nas n\u2192\u221e, where I_\u03b8_0^-1 denotes the inverse of the Fisher information matrix.\n\n\n\n\n \u00a7.\u00a7 Generalized Method of Moments\n\n\nThe generalized method of moments (GMM) by <cit.> is suitable for estimating tempered stable laws. One approach to define moment conditions is to use the theoretical characteristic function \u03c6_\u03b8(t) of X.\nThe sample analogue for the realizations {X_j}_j=1,\u2026,n is\n\n    \u03c6\u0302_n(t)=1/n\u2211_j=1^n e^itX_j.\n\nWe form moment conditions\n\n    \ud835\udd3c_\u03b8_0[h(t,X_j;\u03b8)]=0\n\nfor all t\u2208\u211d^d, where\n\n    h(t,X_j;\u03b8)=e^itX_j-\u03c6_\u03b8(t).\n\nThe sample analogue is denoted by\n\n    \u0125_n(t;\u03b8)=1/n\u2211_j=1^n h(t,X_j;\u03b8)=\u03c6\u0302_n(t)-\u03c6_\u03b8(t).\n\n\nWe now review some approaches on how to choose a set of t's to obtain appropriate moment conditions. One way is to to choose a finite grid {t_1,\u2026,t_R}\u2282\u211d. <cit.> show that the asymptotic variance of the estimator can be made arbitrarily close to the Cram\u00e9r-Rao bound by selecting the grid sufficiently fine. However, as argued by <cit.>, the grid size must not be larger than the sample size. Otherwise, the problem becomes ill-posed since the asymptotic variance matrix of the moment conditions becomes singular. <cit.> generalize the empirical characteristic function GMM approach by introducing an estimator based on a continuum of moment conditions (CGMM). They derive that the asymptotic variance attains the Cram\u00e9r-Rao bound. They solve the singularity issue of the asymptotic variance matrix by applying a suitable regularization. We discuss this approach in more detail below. For the case of the GMM estimator based on a discrete set of moment conditions, we follow <cit.> in the numerical computations and also use a regularization to make the scheme numerically stable. We use an equally spaced grid. Other suggestions can be found in <cit.>.\n\nNext, we describe the CGMM estimation method of <cit.> based on <cit.> and <cit.>. We start by introducing some notation. Let \u03c0 be a probability density on \u211d and L^2(\u03c0) be the Hilbert space of complex valued functions such that\n\n    L^2(\u03c0)={f: \u211d\u2192\u2102 :  \u222b|f(t)|^2\u03c0(t) t<\u221e}.\n\nThe inner product on L^2(\u03c0) is defined as\n\n    \u27e8 f,g\u27e9_L^2(\u03c0)=\u222b f(t) g(t)\u03c0(t) t\n\nand the norm on L^2(\u03c0) as\n\n    ||g||_L^2(\u03c0)^2=\u222b |g(t)|^2\u03c0(t) t.\n\nLet K be the asymptotic variance-covariance operator associated with the moment functions h(t,X;\u03b8). K is an integral operator that satisfies\n\n    K: L^2(\u03c0)   \u2192 L^2(\u03c0)\n     f   \u21a6 g, where g(s)=\u222b k(s,t)f(t)\u03c0(t) t,\n\nwhere k(s,t) is a kernel given by\n\n    k(s,t)=\ud835\udd3c_\u03b8[h(s,X;\u03b8)h(t,X;\u03b8)].\n\nThen the efficient CGMM estimator is given by\n\n    \u03b8\u0302=_\u03b8\u27e8 K^-1\u0125_n(\u00b7;\u03b8),\u0125_n(\u00b7;\u03b8)\u27e9_L^2(\u03c0).\n\n\nThe above CGMM is non-feasible because we need an estimate K\u0302_n for K. It is possible to estimate (<ref>) with\n\n    k\u0302_n(s,t)=1/n\u2211_j=1^n(e^is^'X_j-\u03c6\u0302_n(s))(e^it^'X_j-\u03c6\u0302_n(t)).\n\nHowever, an empirical operator K\u0302_n with kernel function k\u0302_n(s,t) is non-invertible. Therefore, <cit.> estimate K^-1 by\n\n    K\u0302_n,\u03b3_n^-1=(K\u0302_n^2+\u03b3_n I)^-1K\u0302_n.\n\n\u03b3_n is (depending on the sample size) a sequence of hyperparameters which allow K\u0302_n,\u03b3_n^-1f to exist for all f\u2208 L^2(\u03c0) and to dampen the sensitivity of K\u0302_n,\u03b3_n^-1f to variation in the input f.\nThen, the feasible CGMM estimator is given by\n\n    \u03b8\u0302_n,CGMM(\u03b3_n)=_\u03b8\u27e8K\u0302_n,\u03b3_n^-1\u0125_n(\u00b7;\u03b8),\u0125_n(\u00b7;\u03b8)\u27e9_L^2(\u03c0).\n\n\n<cit.> show that the CGMM estimator is consistent, asymptotically efficient and asymptotically normal (for stationary Markov processes) given a set of assumptions. An earlier version <cit.> proves the statement for i.i.d.\u00a0data with a simpler set of assumptions. We use their assumptions and prove that the tempered stable distributions fulfill them. More precisely, in general the CGMM estimator satisfies the following asymptotic result.\n\nUnder the Assumptions <ref> in the Appendix, the CGMM estimator is consistent and\n\n    n^1/2(\u03b8\u0302_n,CGMM(\u03b3_n)-\u03b8_0)\u2112\u2192N(0,I_\u03b8_0^-1),\n\nas n, \u03b3_nn^1/2\u2192\u221e and \u03b3_n\u21920, where I_\u03b8_0^-1 denotes the inverse of the Fisher information matrix. \n\n\nIn practice, we require a reasonable choice of the regularization parameter \u03b3_n. <cit.> derived the optimal estimator for \u03b3_n. However, we choose for simplicity an ad-hoc method for selecting the regularization parameter as <cit.> found that the specific choice of the regularization parameter does not have a striking impact on the estimation precision in their simulations for the stable distribution.\n\n\n\n \u00a7.\u00a7 Cumulant matching\n\nWe also discuss a method of cumulants approach which follows <cit.>. They match empirical cumulants with their theoretical counterparts. We extend this by using 's () GMM framework. We call the approach generalized method of cumulants (GMC) to distinguish it from the GMM method using characteristic function moment conditions. However, it fits well into 's () framework allowing for standard asymptotic theory. It works as follows. Let\n\n    \ud835\udd3c_\u03b8_0[g(X;\u03b8)]=0\n\ndenote the theoretical moment conditions and\n\n    1/n\u2211_j=1^ng(X_j;\u03b8)=0\n\nthe empirical moment conditions. We build the function g by the relation between moments and cumulants given by\n\n    E(X)   =\u03ba_1,\n    \n    E(X^2)   =\u03ba_2+\u03ba_1^2,\n    \n    E(X^3)   =\u03ba_3+3\u03ba_2\u03ba_1+\u03ba_1^3,\n    \n    E(X^4)   =\u03ba_4+4\u03ba_3\u03ba_1+3\u03ba_2^2+6\u03ba_2\u03ba_1^2+\u03ba_1^4,\n       \u22ee\n    \n    E(X^p)   =\u2211_m=1^p B_p,m(\u03ba_1,\u2026,\u03ba_p-m+1),\n\nwhere B_p,m denote incomplete Bell polynomials. In particular for p moment conditions, we choose g(X;\u03b8)=(g_1,\u2026,g_p)^' to be\n\n    g_1   =X-\u03ba_1,\n    \n    g_2   =X^2-\u03ba_2-\u03ba_1^2,\n       \u22ee\n    \n    g_p   =X^p-\u2211_m=1^p B_p,m(\u03ba_1,\u2026,\u03ba_p-m+1).\n\nHere, the theoretical cumulants \u03ba_m for the TSS distribution are given in (<ref>) and, for the CTS distribution, given in (<ref>). For the NTS distribution cumulants do not have an easy-to-use pattern which is why we do not use this method for the NTS distribution. The asymptotic result then is the following proposition. The proof can be found in <cit.>.\n\n\nUnder the assumptions of <cit.> in Theorems 2.6 and 3.4, the GMC estimator\n\n    \u03b8\u0302_n,GMC=_\u03b8\u2208\u0398(1/n\u2211_j=1^ng(X_j;\u03b8))^'\u03a9\u0302^-1(1/n\u2211_j=1^ng(X_j;\u03b8)),\n\nis a consistent for \u03b8_0 and, moreover,\n\n    n^1/2(\u03b8\u0302_n,GMC-\u03b8_0)\u2112\u2192N(0,(G^'\u03a9^-1G)^-1),\n\nwith G=.\ud835\udd3c_\u03b8[\u2202 g(X;\u03b8)/\u2202\u03b8]|_\u03b8=\u03b8_0, \u03a9=\ud835\udd3c_\u03b8_0[g(X;\u03b8)g(X;\u03b8)^'] and \u03a9\u0302^-1 is a consistent estimator of \u03a9^-1.\n\n\n\n\n\n\n\n\u00a7 ASYMPTOTIC RESULTS\n\n\nWe present our asymptotic results for the ML, the CGMM and the GMC estimation method. The GMM method of <cit.> has already been discussed to have problems with the singularity of the asymptotic covariance matrix. All proofs can be found in Appendix <ref>. We start with a theorem for the ML estimator. \n\nThe ML estimator \u03b8\u0302_n,ML for \u03b8_0\u2208int(\u0398) of\n\n\n  (a) the TSS(\u03b1,\u03b4,\u03bb) distribution with \u03b8=(\u03b1,\u03b4,\u03bb)\u2208\u0398=[\u03b5,1-\u03b5]\u00d7[\u03b5,M]^2,\n\n  (b) the TS'(\u03b1,\u03b4,\u03bb) distribution with \u03b8=(\u03b1,\u03b4,\u03bb)\u2208\u0398=([\u03b5,1-\u03b5]\u222a[1+\u03b5,2-\u03b5])\u00d7[\u03b5,M]^2\n\n  (c) the CTS(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc) distribution with \u03b8=(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc)\u2208\u0398=([\u03b5,1-\u03b5]\u222a[1+\u03b5,2-\u03b5])\u00d7[\u03b5,M]^4\u00d7[-M,M],\n\n  (d) the NTS(\u03b1,\u03b2,\u03b4,\u03bb,\u03bc) distribution with \u03b8=(\u03b1,\u03b2,\u03b4,\u03bb,\u03bc)\u2208\u0398=[\u03b5,1-\u03b5]\u00d7[-M,M]\u00d7[\u03b5,M]^2\u00d7[-M,M],\n\nis consistent, asymptotically normal and asymptotically efficient as n\u2192\u221e.\n\n<cit.> has already established strong consistency. Therefore, it only remains to show asymptotic normality and efficiency.\n\nWe next show that the CGMM also possesses the desired asymptotic properties for our tempered stable distributions.\n\nThe CGMM estimator \u03b8\u0302_n,CGMM(\u03b3_n) for \u03b8_0\u2208int(\u0398) of\n\n\n  (a) the TSS(\u03b1,\u03b4,\u03bb) distribution with \u03b8=(\u03b1,\u03b4,\u03bb)\u2208\u0398=[\u03b5,1-\u03b5]\u00d7[\u03b5,M]^2,\n\n  (b) the TS'(\u03b1,\u03b4,\u03bb) distribution with \u03b8=(\u03b1,\u03b4,\u03bb)\u2208\u0398=([\u03b5,1-\u03b5]\u222a[1+\u03b5,2-\u03b5])\u00d7[\u03b5,M]^2\n\n  (c) the CTS(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc) distribution with \u03b8=(\u03b1,\u03b4_+,\u03b4_-,\u03bb_+,\u03bb_-,\u03bc)\u2208\u0398=([\u03b5,1-\u03b5]\u222a[1+\u03b5,2-\u03b5])\u00d7[\u03b5,M]^4\u00d7[-M,M],\n\n  (d) the NTS(\u03b1,\u03b2,\u03b4,\u03bb,\u03bc) distribution with \u03b8=(\u03b1,\u03b2,\u03b4,\u03bb,\u03bc)\u2208\u0398=[\u03b5,1-\u03b5]\u00d7[-M,M]\u00d7[\u03b5,M]^2\u00d7[-M,M],\n\nis consistent, asymptotically normal and asymptotically efficient as n\u2192\u221e and \u03b3_nn^1/2\u2192\u221e and \u03b3_n\u21920.\n\n\n<cit.> showed that the method of cumulant matching is locally consistent, i.e., the equations of the moment conditions do have a root which is unique in an open neighborhood by the implicit function theorem. However, the assumptions of Proposition <ref> require that the root is unique for the whole domain. We show that this does not hold by constructing counterexamples for a global inverse function theorem.\n\nThe GMC estimator \u03b8\u0302_n,GMC is locally but not globally consistent (i.e., there may be multiple roots).\n\n\n\n\n\u00a7 MONTE CARLO STUDY\n\n\nIn this section, we compare empirical properties of the proposed estimators in a simulation study. In order to do so, we simulate n=100 and n=1000 random numbers distributed according to the distributions TSS(0.5, 1,1), CTS(1.5, 1,1,1,1,0), and NTS(0.5,0,1,1,0). We estimate the parameters using the ML, the GMM method according to <cit.>, the CGMM method according to <cit.>. For the TSS and CTS distributions we additionally compute the GMC estimator using three different numbers of moment conditions, i.e., the just-identified case (3 moment conditions for TSS, 6 moment conditions for CTS) and two overidentified cases (4 and 5 moment conditions for TSS, 7 and 8 moment conditions for CTS). We choose a regularization parameter 0.01 and a cut-off regularization <cit.> for GMM and a Tikhonov regularization for CGMM. Further details on computational settings are available upon request. The implemented routines will be published in an R package. We repeat the experiments in 10,000 independent Monte Carlo replications.\n\nTable <ref> shows empirical bias and empirical root mean squared errors (RMSE) (in parenthesis) for the TSS distribution for each of the parameters. In the last column, we display the average runtime for estimation in seconds. The striking difference is that while the GMM and the GMC estimation performs in less than a  second ML and CGMM need considerably more time to compute. As expected, the estimates are more precise for a larger sample. Importantly, all methods (except the MLE) suffer from a small sample size which implies that the algorithms run into boundary solutions (i.e., finding stability parameters close to zero). This implies a negative empirical bias for \u03b1. The ML estimator outperforms the other methods followed by CGMM. The GMC with 4 moment conditions also works fairly well, adding further moment conditions has no additional value.\n\n\n\nTable <ref> shows similar experimental results for the CTS distribution. Again, we report the empirical bias and the RMSE for each of the parameters. As expected, estimating 6 parameters is more demanding than estimating 3 as above. We see that for the GMC and GMM methods extremely high values of bias and RMSEs occur, which is due to rare extremely high parameter estimates. Therefore, we also compute the median absolute deviation from the true parameters, printed in square brackets. Generally, we observe that all methods fail to provide good estimates for 100 observations. In this case, the optimization algorithms find boundary solutions for many of the randomly drawn sets. Thus, the CTS distribution should only be used as a model if the sample size is not too small. The GMC and GMM methods also fail for 1000 observations for most of the Monte Carlo replications. For 1000 observations, the ML estimator performs better than the latter methods. However, it still has difficulties to estimate the stability index correctly in some instances. The CGMM method has the longest runtime but works fairly well especially compared with the other estimators. Boundary estimates rarely occur.\n\n\n\n\nTable <ref> presents the results for the NTS distribution. For this distribution, we only use the CGMM, the GMM and the ML methods. As before a larger sample is beneficial since small samples lead to boundary estimates. For example, the bias and RMSE for \u03b2 are very large for the GMM method because of large outliers. As for the CTS above, the CGMM method seems to perform better than ML and much better than the GMM method, which performs poorly even for a larger sample.\n\n\n\nTo conclude, the CGMM works good for all three examples and is the only reliable estimator for the CTS distribution. Unfortunately, the runtime is quite lengthy as well as for the ML estimator, which finds boundary solutions more frequently. The GMM and GMC estimators only work for the TSS subordinator. Therefore, we recommend to use the CGMM estimator for the CTS and NTS distribution.\n\n\n\n\u00a7 APPLICATIONS\n\n\nWe discuss financial applications to motivate the use of tempered stable distributions. Tempered stable distributions have already been proposed to model log-returns of financial assets, see e.g., <cit.>. In the case of electricity markets, e.g., <cit.> models the evolution of electricity spot prices by a tempered stable driven Ornstein-Uhlenbeck process.  \n\nWe here analyze log-returns of three financial assets. We consider the S&P 500 index (2012-06-01 to 2022-05-31), the German DAX index (2012-06-01 to 2022-05-31), and base-load spot prices from the German power exchange EEX (2018-09-30 to 2022-05-31). We obtain daily data from Refinitiv's Eikon. Before modeling tempered stable distributions we perform some simple manipulations and fit preliminary models to clean the data. In this order, we first deseasonalize the data of the EEX regarding its weekly profile by applying a moving average filter, see <cit.>. Second, we exclude the rare cases of negative prices of the EEX. Next, we compute log-returns for the three indices (for the EEX we also omit all log-returns next to days with negative prices). Last, we fit GARCH(1,1) models (with normal errors) to each of the log-return series to remove stochastic volatility from the data which can mistakenly interpreted as evidence for heavy tailed distributions <cit.>. With this approach, we follow <cit.> who found that this quasi-MLE performs nearly identically as to a correctly specified MLE of a GARCH model with CTS or NTS distributed errors as in <cit.>.\n\nFigures <ref> to <ref> show the original time series (a), the (deseaonalized) log-returns (b), and the GARCH residuals (c). We observe in panels (b) that for each of the series of log-returns stochastic volatility is apparent. The GARCH residuals do not exhibit volatility clustering anymore. However, the residuals reveal skewness and heavy tails which is why we next fit tempered stable distributions to them.\n\n\n\n\n\n\n\n\nWe compare the CTS and the NTS distributions with a univariate stable distribution as a baseline model. Needless to say, there are plenty of other models for log-returns in the literature, e.g., generalized hyperbolic models (and their subclasses) by <cit.>, or finite mixture models <cit.>. For conciseness, we do not present them here but refer to the aforementioned references and <cit.> for a comparison. \n\nTo compare the goodness-of-fit we use the Kolmogorov-Smirnov (KS) and the Anderson-Darling (AD) statistics. Lower statistics indicate a better fit. It is known that the KS distance better reflects the fit around the center of the distribution while the AD statistics concentrates on the tails of the distributions <cit.>. Of course, the CTS and the NTS distributions have a larger number of parameters hence a better fit is to be expected. Therefore, we also compute the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) to penalize large models to avoid overfitting. The penalization of larger models is higher for the BIC.\n\nFor brevity, we decide to only present estimates and plots obtained with the CGMM estimator. The reason for this choice is that it performed best in the simulation study in Section <ref>. Table <ref> shows parameter estimates for the three time series and the three distributions. Table <ref> presents KS, AD, AIC, and BIC statistics.\n\n\n\n\n\n\nFor the KS and AD statistics we observe a mixed pattern. For the S&P 500 the stable distribution is favored while for the DAX and EEX the CTS or NTS distributions have lower values. While in each case the NTS distribution has the lowest AIC, the stable distribution always has the lowest BIC. To visualize goodness-of-fit we moreover depict QQ-plots.\nFigures <ref>\u2013<ref> plot sample quantiles versus theoretical quantiles for the different scenarios. The solid line is the reference line. We observe that, although in some cases the stable distribution has lower KS or AD statistics, the QQ-plots suggest that the tails of the stable distribution are too heavy. CTS and NTS distributions seem to provide a better fit.\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION AND FUTURE WORK\n\nThis paper derived asymptotic efficiency results for parametric estimation methods of the tempered stable subordinator, the classical exponentially tempered stable distribution and the normal tempered stable distribution. We conducted a Monte Carlo study to establish finite sample properties. It turned out that the GMM estimator with a continuum of moment conditions outperformed other methods. We discussed why tempered stable distributions are relevant in financial applications.\nAsymptotic results for other tempering functions or the derivation of a set of conditions to ensure asymptotic efficiency for general tempering function are subject of future work. \n\n\n\n\u00a7 ACKNOWLEDGEMENTS\n\nFinancial support of the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) via the project 455257011 is gratefully acknowledged.\n\nThe author is grateful to Christoph Hanck for valuable comments which helped to substantially improve this paper. Full responsibility is taken for\nall remaining errors.\n\n\nagsm\n\n\n\n\n\n\u00a7 APPENDIX: ASSUMPTIONS\n\n\n\n\n  (i) \u03b8\u0302_n,ML is consistent for \u03b8_0.\n\n  (ii) \u03b8_0 is an interior point of \u0398 which is compact.\n\n  (iii) f(x;\u03b8) is twice continuously differentiable and f(x;\u03b8)>0 in a neighborhood \ud835\udca9 of \u03b8_0.\n\n  (iv) \u222bsup_\u03b8\u2208\ud835\udca9||\u2202 f(x;\u03b8)/\u2202\u03b8|| x<\u221e, \u222bsup_\u03b8\u2208\ud835\udca9||\u2202^2 f(x;\u03b8)/\u2202\u03b8\u2202\u03b8^'|| x<\u221e.\n\n  (v) I_\u03b8_0=.\ud835\udd3c_\u03b8[(\u2202log f(X;\u03b8)/\u2202\u03b8)(\u2202log f(X;\u03b8)/\u2202\u03b8)^']|_\u03b8=\u03b8_0 is positive definite.\n\n  (vi) \ud835\udd3c_\u03b8[sup_\u03b8\u2208\ud835\udca9||\u2202^2 log f(X;\u03b8)/\u2202\u03b8\u2202\u03b8^'||]<\u221e.\n\n\n\n\n\n  (i) The observed data {x_1,\u2026,x_n} are i.i.d.\u00a0realizations of X which has values in \u211d^dand has p.d.f.\u00a0f(x;\u03b8) with \u03b8\u2208\u0398\u2282\u211d^q and \u0398 is compact.\n\n  (ii) \u03c0 is the p.d.f.\u00a0of a distribution that is absolutely continuous with respect to the Lebesgue measure and strictly positive for all x\u2208\u211d^d\n\n  (iii) The equation\n\n    E_\u03b8_0[e^it^'X]-\u03c6_\u03b8(t)=0 for all t\u2208\u211d^p, \u03c0-a.s.\n\nhas a unique solution \u03b8_0 which is an interior point of \u0398.\n\n  (iv) f(x;\u03b8) is continuously differentiable with respect to \u03b8 on \u0398.\n\n  (v) \u222bsup_\u03b8\u2208\u0398||\u2202 f(x;\u03b8)/\u2202\u03b8|| x<\u221e.\n\n  (vi) I_\u03b8_0=.\ud835\udd3c_\u03b8[(\u2202log f(X;\u03b8)/\u2202\u03b8)(\u2202log f(X;\u03b8)/\u2202\u03b8)^']|_\u03b8=\u03b8_0 is positive definite.\n\n\n\n\n\n\n\n\u00a7 APPENDIX: PROOFS\n\n\n\n\n\n  (a) We will follow <cit.> who proved asymptotic normality for stable distributions. Although he did not consider stable subordinators explicitly it is a corollary of his theorem. This is because (in his notation) the skewness parameter \u03b2 is fixed at \u03b1 and does not need to be estimated. Thus the proof for stable subordinators follows along his lines. We check the conditions of Assumption <ref>. We also call these regularity conditions throughout. <cit.> proved condition (i). (ii) \u0398 is compact by construction. The density function (<ref>) for the TSS distribution is twice continuously differentiable with respect to the parameters by the twice continuous differentiability of the density of the stable subordinator <cit.> which implies (iii). To show (iv), we make use of (<ref>) and bound the partial derivatives\n\n    |\u2202 f_TSS(y;\u03b8)/\u2202\u03d1|\u2264 C_\u03b8\u00b7 f_TSS(y;\u03b8)+|\u2202 f_S(\u03b1,\u03b4)(y)/\u2202\u03b1|,   \u03d1=\u03b1,\n     f_TSS(y;\u03b8)+|\u2202 f_S(\u03b1,\u03b4)(y)/\u2202\u03b4|,   \u03d1=\u03b4,\n     f_TSS(y;\u03b8) +yf_TSS(y;\u03b8),    \u03d1=\u03bb,\n\nwhere C_\u03b8 is a positive, finite constant which depends on \u03b8 but not on y. Because \u03b8\u2208\u0398 which is compact and because C_\u03b8 can be taken to be continuous in \u03b8 which follows from (iii), C_\u03b8 can be bounded by a constant C. The result now follows by the regularity of the stable subordinator <cit.> and because the expected value of a TSS distribution exists. The second part of (iv) follows analogously. In order to show (v), we follow <cit.> and show the equivalent condition that for every \u03b8\u2208\u0398 and for every a=(a_1,a_2,a_3)\u2208\u211d^3 the function\n\n    g(a,y)=a_1\u2202 f_TSS(y;\u03b8)/\u2202\u03b1+a_2\u2202 f_TSS(y;\u03b8)/\u2202\u03b4+a_3\u2202 f_TSS(y;\u03b8)/\u2202\u03bb\n\nis identically 0 for all y if and only if a_1=a_2=a_3=0. g(a,y) is of the form \u222be^-iyt\u03d5(a,t) t, where \u03d5 is a linear combination of derivatives of the TSS characteristic function given in (<ref>) and g(a,y)\u22610 iff \u03d5(a,y)\u22610. The partials are\n\n    \u03d5_1=\u2202\u03c6_TSS(t;\u03b8)/\u2202\u03b1   =\u03c6_TSS(t;\u03b8)\u03b4\u0393(-\u03b1)(((\u03bb-it)^\u03b1log(\u03bb-it)-\u03bb^\u03b1log(\u03bb))-((\u03bb-it)^\u03b1-\u03bb^\u03b1)\u03c8(-\u03b1)),\n    \u03d5_2=\u2202\u03c6_TSS(t;\u03b8)/\u2202\u03b4   =\u03c6_TSS(t;\u03b8)\u0393(-\u03b1)((\u03bb-it)^\u03b1-\u03bb^\u03b1),\n    \u03d5_3=\u2202\u03c6_TSS(t;\u03b8)/\u2202\u03bb   =\u03c6_TSS(t;\u03b8)\u03b4\u0393(-\u03b1)(\u03b1(\u03bb-it)^\u03b1-1-\u03b1\u03bb^\u03b1-1),\n\nwhere \u03c8(x)=\u0393^'(x)/\u0393(x) denotes the digamma function. The characteristic function given in (<ref>) is non-zero for each t which implies that it is sufficient to study the latter terms of \u03d5_1,\u03d5_2,\u03d5_3. \u03d5_1 is a linear combination of ((\u03bb-it)^\u03b1log(\u03bb-it)-\u03bb^\u03b1log(\u03bb)) and ((\u03bb-it)^\u03b1-\u03bb^\u03b1), \u03d5_2 is a multiple of ((\u03bb-it)^\u03b1-\u03bb^\u03b1), and \u03d5_3 is a multiple of (\u03b1(\u03bb-it)^\u03b1-1-\u03b1\u03bb^\u03b1-1). \nSince \u03d5_1 is the only linear combination with term (\u03bb-it)^\u03b1log(\u03bb-it) it follows a_1=0. Therefore, it is necessary for \u03c8(x)=0 for all t that also a_2=a_3=0.\n\nTo show (vi), we recall that <cit.> proved the statement for the stable distribution. By (<ref>),\n\n    \u2202^2/\u2202\u03b8\u2202\u03b8^'log f_TSS(y;\u03b8)=\u2202^2/\u2202\u03b8\u2202\u03b8^'(-\u03bb y-\u03bb^\u03b1\u03b4\u0393(-\u03b1))+\u2202^2/\u2202\u03b8\u2202\u03b8^'log f_S(\u03b1,\u03b4)(y),\n\nwhich elements can be bounded in absolute value by a function C(y), independent of \u03b8, which is bounded in any closed y-interval. Following <cit.>, it is therefore only necessary to study the behavior of C(y) at its limit points. <cit.> showed that for y\u2192\u221e the corresponding C(y) for the stable distribution is of the order O(log^2|y|). For y\u21920, we can follow his lines with the same arguments (deriving an absolutely continuous series). Hence, C(y) for the tempered stable subordinator is of order O(|y|).  \n\nThis implies that \u222b_0^\u221e C(y)f_TSS(y;\u03b8) y<\u221e for each \u03b8\u2208\u0398. \n\n\n  (b) The proof is analogously to (a) but replacing relation (<ref>) with (<ref>).\n\n\n  (c) Conditions (i) and (ii) work just as in (a). For (iii) and (iv), we use that by (<ref>)\n\n    f_CTS(x+\u03bc;\u03b8)=\u222b_-\u221e^\u221ef_+(x+y)f_-(y) y,\n\nwhere f_+ is the density of Y_+\u223c TS^'(\u03b1,\u03b4_+,\u03bb_+) and Y_-\u223c TS^'(\u03b1,\u03b4_-,\u03bb_-). This ensures (iii). In order to show (iv),\n\n    \u2202 f_CTS(x;\u03b8)/\u2202\u03b8   =\u2202/\u2202\u03b8\u222b_-\u221e^\u221ef_+(x+y-\u03bc)f_-(y) y\n       =\u222b_-\u221e^\u221e\u2202/\u2202\u03b8(f_+(x+y-\u03bc)f_-(y)) y\n       =\u222b_-\u221e^\u221e(\u2202 f_+(x+y-\u03bc)/\u2202\u03b8f_-(y)+\u2202 f_-(y)/\u2202\u03b8f_+(x+y-\u03bc)) y.\n\nIn the second line we used the regularity of the TS' density derived in part (b) and the easy relation (<ref>). Hence,\n\n    \u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_CTS(x;\u03b8)/\u2202\u03b8|| x\n    \u2264    \u222b_-\u221e^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_+(x+y-\u03bc)/\u2202\u03b8f_-(y)|| y x\n    + \u222b_-\u221e^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_-(y)/\u2202\u03b8f_+(x+y-\u03bc)|| y x\n    \n    =    \u222b_-\u221e^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_+(x+y-\u03bc)/\u2202\u03b8f_-(y)|| x y\n    + \u222b_-\u221e^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_-(y)/\u2202\u03b8f_+(x+y-\u03bc)|| x y\n    \u2264    \u222b_-\u221e^\u221esup_\u03b8\u2208\u0398|f_-(y)|\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_+(x+y-\u03bc)/\u2202\u03b8|| x y + \u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_-(y)/\u2202\u03b8||\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398|f_+(x+y-\u03bc)| x y\n    \n    <    \u221e,\n\nwhere we used Fubini's Theorem. The left inner integral in (<ref>) is finite by part (b) and of order O(log(x)x^-1-\u03b1). The right inner integral isof order O(x^-1-\u03b1). Therefore, both double integrals are finite. The second part of (iv) follows analogously. (v) follows analogously to part (a), in particular, if we again denote (\u03d5_1,\u2026,\u03d5_6)^'=\u2202\u03c6_CTS(t;\u03b8)/\u2202\u03b8 we observe that \u03d5_1 is the only linear combination with terms (\u03bb_+-it)^\u03b1log(\u03bb_+-it) and (\u03bb_-+it)^\u03b1log(\u03bb_-+it), which implies a_1=0. \u03d5_2 is a linear combination of t and (\u03bb_+-it)^\u03b1, \u03d5_3 is a linear combination of t and (\u03bb_-+it)^\u03b1, \u03d5_4 is a linear combination of t and (\u03bb_+-it)^\u03b1-1, \u03d5_5 is a linear combination of t and (\u03bb_-+it)^\u03b1-1, and \u03d5_6 is a multiple of t. This implies a_2=a_3=a_4=a_5=0 and hence a_6=0. As in (a), we have to consider the limiting behavior of C(x) which is the function which bounds the elements of \u2202^2/\u2202\u03b8\u2202\u03b8^'log f_CTS(x;\u03b8) in absolute value. Because of the convolution property (<ref>), the tails behave as O(|x|) for x\u2192\u00b1\u221e, which proves (vi).\n\n\n  (d) (i) and (ii) as above. For the remainder we use the subordination property of the NTS distribution, i.e.,\n\n    f_NTS(z;\u03b8)=\u222b_0^\u221ef_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb) y,\n\nwhere f_N(z;m,s^2) denotes the density of the normal distribution with mean m and variance s^2. Similarly to <cit.>, we can show that |\u2202 f_N(z;\u03bc+\u03b2 y,y)/\u2202\u03bc|\u2264C/y and |\u2202 f_N(z;\u03bc+\u03b2 y,y)/\u2202\u03b2|\u2264 C for all \u03b8\u2208\u0398. Additionally, because |f_N(z;\u03bc+\u03b2 y,y)|\u2264C/y, we have for \u03d1\u2208(\u03b1,\u03b4,\u03bb) that |\u2202 f_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb)/\u2202\u03d1|\u2264C/y|\u2202 f_TSS(y;\u03b1,\u03b4,\u03bb)/\u2202\u03d1| such that\n\n    \u2202 f_NTS(z;\u03b8)/\u2202\u03b8=\u222b_0^\u221e\u2202/\u2202\u03b8(f_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb)) y\n\nholds by property (iv) for the TSS distribution. (iv) follows analogously as in (c) because\n\n    \u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202 f_NTS(z;\u03b8)/\u2202\u03b8|| z\n    \u2264    \u222b_-\u221e^\u221e\u222b_0^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03b8(f_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb))|| y z\n    \n    =    \u222b_0^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03b8(f_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb))|| z y.\n\nIn order to bound (<ref>), we discuss the partial derivatives separately. For \u2202/\u2202\u03d1, \u03d1\u2208(\u03b1,\u03b4,\u03bb),\n\n    \u222b_0^\u221e\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03d1(f_N(z;\u03bc+\u03b2 y,y)f_TSS(y;\u03b1,\u03b4,\u03bb))|| z y\n    \u2264    \u222b_0^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03d1f_TSS(y;\u03b1,\u03b4,\u03bb)||\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398|f_N(z;\u03bc+\u03b2 y,y)| z y\n    \u2264    C\u222b_0^\u221e1/\u221a(y)sup_\u03b8\u2208\u0398||\u2202/\u2202\u03d1f_TSS(y;\u03b1,\u03b4,\u03bb)|| y\n    \n    <    \u221e,\n\nby (<ref>) and by the regularity of the stable distribution. For \u2202/\u2202\u03bc, (<ref>) is bounded by\n\n    \u222b_0^\u221esup_\u03b8\u2208\u0398||f_TSS(y;\u03b1,\u03b4,\u03bb)||\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03bcf_N(z;\u03bc+\u03b2 y,y)|| z y\n    \u2264    C\u222b_0^\u221e1/ysup_\u03b8\u2208\u0398||f_TSS(y;\u03b1,\u03b4,\u03bb)|| y\n    \n    <    \u221e,\n\nby the regularity of the normal distribution. For \u2202/\u2202\u03b2,\n\n    \u222b_0^\u221esup_\u03b8\u2208\u0398||f_TSS(y;\u03b1,\u03b4,\u03bb)|\u222b_-\u221e^\u221esup_\u03b8\u2208\u0398||\u2202/\u2202\u03b2f_N(z;\u03bc+\u03b2 y,y)|| z y\n    \u2264    C\u222b_0^\u221esup_\u03b8\u2208\u0398||f_TSS(y;\u03b1,\u03b4,\u03bb)|| y\n    \n    <    \u221e.\n\nThe second part of (iv) follows analogously. (v) follows in a similar fashion as in (a) and (c).\n\n\n\n\n\n\n\n\n\n\nAs in (a)\u2013(c), it is for (vi) enough to consider the behavior of C(z) for z\u2192\u00b1\u221e, where C(z) is the function which bounds the elements of \u2202^2/\u2202\u03b8\u2202\u03b8^'log f_NTS(z;\u03b8) in absolute value. With the same arguments as above it holds that\n\n    \u2202^2 f_NTS(z;\u03b8)/\u2202\u03b8\u2202\u03b8'=\u222b_0^\u221e\u2202^2/\u2202\u03b8\u2202\u03b8'(f_N(z;\u03bc+\u03b2 y,y)e^-\u03bb y-\u03bb^\u03b1\u03b4\u0393(-\u03b1)f_S(y;\u03b1,\u03b4)) y.\n\nWe use that by the series representation for the parameter derivatives of <cit.> the second derivatives of the stable distribution are of order O(y^-\u03b1-1log(y)^2). Tedious computations thus yield that C(z)=O(z^2log(|z|)^2), which implies (iv).\n\n\n\n\nWe check the conditions of Assumption <ref> for the tempered stable subordinator. The other two cases follow analogously. (i) \u0398 is compact by construction and \u03c0 is chosen in such a way that it fulfills (ii). (iii) holds because \n\n    exp(\u03b4\u0393(-\u03b1)((\u03bb-it)^\u03b1-\u03bb^\u03b1))=exp(\u03b4_0\u0393(-\u03b1_0)((\u03bb_0-it)^\u03b1_0-\u03bb_0^\u03b1_0))\n\nhas to hold for each t which uniquely determines \u03b1=\u03b1_0,\u03bb=\u03bb_0 and thus also \u03b4=\u03b4_0. (iv)\u2013(vi) have been shown in the proof of Theorem <ref>.\n\n\n\nThe crucial assumption for consistency of a GMC estimator is that W\ud835\udd3c_\u03b8_0[g(X_j;\u03b8)]=0 only if \u03b8=\u03b8_0, where W is a positive definite matrix. (For the efficient GMC estimator we would choose W=\u03a9^-1.) <cit.> showed that cumulant matching for the CTS distribution this holds locally by the local inverse function theorem. A generalization to GMC is straightforward. However, we argue now why this only holds locally.\n\nConsider for simplicity the TSS distribution and three moment conditions. The argument carries over to the other cases. <cit.> proved the following version of the Hadamard-Caccioppoli global inverse function theorem: Let f:X\u2192 Y be a local homeomorphism with X,Y path-connected Hausdorff spaces and Y is simply connected. Then f is a homeomorphism onto Y if and only if it is a proper function, i.e., the preimage f^-1(K) of any compact set K\u2282 Y is compact. We will use the equivalent statement that whenever a sequence {x_n}\u2286 X satisfies x_n\u2192 x for some x\u2208\u2202 X then f(x_n)\u2192 y for  y\u2208\u2202 Y, where \u2202 X denotes the boundary of X.\n\nLet \n\n    f:(0,1)\u00d7 (0,\u221e)\u00d7(0,\u221e)   \u2192 (0,\u221e)^3\n    \u03b8   \u21a6 (\u0393(1-\u03b1)\u03b4/\u03bb^1-\u03b1,\u0393(2-\u03b1)\u03b4/\u03bb^2-\u03b1,\u0393(3-\u03b1)\u03b4/\u03bb^3-\u03b1).\n\n<cit.> showed that f is a local homeomorphism. Obviously, X and Y are path-connected Hausdorff spaces and Y is simply connected. Take a sequence \u03b8_n such that \u03b1_n\u21920 and \u03b4_n\u2261\u03b4,\u03bb_n\u2261\u03bb. This fulfills that \u03b8_n\u2192(-\u221e,1,\u221e)\u2208\u2202 X. However, f(\u03b8_n)\u2192(\u0393(1)\u03b4/\u03bb,\u0393(2)\u03b4/\u03bb^2,\u0393(3)\u03b4/\u03bb^3)\u2209\u2202 Y. Therefore the local homeomorphism is not global.\n\n\n\nThe issue of global invertibility is not solved if we extend the possible parameter space of the index \u03b1 to (-\u221e,1), which is technically possible to define distribution on this space <cit.>. In this case, we can construct a sequence such that \u03b1_n\u2192-\u221e, \u03b4_n\u22611 and \u03bb_n=\u0393(1-\u03b1_n)^1/1-\u03b1_n. Thus, \u03b8_n\u2192\u2202 X, but, f(\u03b8_n)\u2192 (1,e,e^2)\u2209\u2202 Y.\n\n\n"}