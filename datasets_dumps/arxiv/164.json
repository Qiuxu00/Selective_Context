{"entry_id": "http://arxiv.org/abs/2303.07130v3", "published": "20230313135947", "title": "Enhancing COVID-19 Severity Analysis through Ensemble Methods", "authors": ["Anand Thyagachandran", "Hema A Murthy"], "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "text": "\nActive target TPC for study of photonuclear reactions at astrophysical energies\nPresented at Zakopane Conference on Nuclear Physics 2022\n\n\n    M.\u00a0Kuich^1e-mail: mkuich@fuw.edu.pl, M.\u00a0\u0106wiok^1, W.\u00a0Dominik^1, A.\u00a0Fija\u0142kowska^1, M.\u00a0Fila^1, A.\u00a0Giska^1, Z.\u00a0Janas^1, A.\u00a0Kalinowski^1, K.\u00a0Kierzkowski^1, C.\u00a0Mazzocchi^1, W.\u00a0Okli\u0144ski^1, M.\u00a0Zaremba^1, D.\u00a0Grz\u0105dziel^2, J.\u00a0Lekki^2, W.\u00a0Kr\u00f3las^2, A.\u00a0Kuli\u0144ska^2, A.\u00a0Kurowski^2, W.\u00a0Janik^2, T.\u00a0Pieprzyca^2, Z.\u00a0Szklarz^2, M.\u00a0Scholz^2, M.\u00a0Turza\u0144ski^2, U.\u00a0Wi\u0105cek^2, U.\u00a0Wo\u017anicka^2, A.\u00a0Caciolli^3, M.\u00a0Campostrini^4, V.\u00a0Rigato^4, M.\u00a0Gai^5, H.\u00a0O.\u00a0U.\u00a0Fynbo^6\n^1Faculty of Physics, University of Warsaw, Warsaw, Poland\n\n^2Institute of Nuclear Physics Polish Academy of Sciences, Cracow, Poland\n\n^3University of Padova and INFN-PD, Padova, Italy\n\n^4Laboratori Nazionali di Legnaro, Legnaro, Italy\n^5University of Connecticut, CT, USA \n ^6Department of Physics and Astronomy, Aarhus University, Aarhus, Denmark\n\n\n    March 30, 2023\n=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n\n\n\n\nComputed Tomography (CT) scans provide a detailed image of the lungs, allowing clinicians to observe the extent of damage caused by COVID-19. The CT severity score (CTSS) based scoring method is used to identify the extent of lung involvement observed on a CT scan. This paper presents a domain knowledge-based pipeline for extracting regions of infection in COVID-19 patients using a combination of image-processing algorithms and a pre-trained UNET model. Then, an infection rate-based feature vector is proposed for each CT scan. The severity of the infection is then classified into different categories using an ensemble of three machine-learning models: Extreme Gradient Boosting, Extremely Randomized Trees, and Support Vector Machine. The proposed system was evaluated on a validation dataset in the AI-Enabled Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (AI-MIA-COV19D) and achieved a macro F1 score of 64%. These results demonstrate the potential of combining domain knowledge with machine learning techniques for accurate COVID-19 diagnosis using CT scans. The implementation of the proposed system for severity analysis is available at https://github.com/aanandt/Enhancing-COVID-19-Severity-Analysis-through-Ensemble-Methods.git \n\n\n\n\nCOVID-19, CT-Scans, Infection Segmentation, Machine Learning Methods, Severity Analysis\n\n\n\n\n\u00a7 INTRODUCTION\n\n\nThe outbreak of COVID-19 has resulted in a substantial need for prompt and precise diagnostic testing to detect individuals who may have contracted the SARS-CoV-2 virus. Laboratory tests such as Reverse Transcription Polymerase Chain Reaction (RT-PCR) <cit.> and antigen tests are commonly used for diagnosing COVID-19. While these tests detect the virus's presence from the respiratory samples <cit.>, but fail to provide an accurate analysis of the disease severity. Additional diagnostic tools are needed to assess the extent of lung damage. Radiological imaging of the chest, including chest radiography and CT scans, is essential to determine the severity of COVID-19 infections <cit.>. At the same time, chest X-rays do not furnish sufficient resolution to evaluate the extent of lung damage. CT scans provide a more detailed view of the lungs and can identify the distribution and area of infection. Clinicians can comprehend critical information to gauge the severity of the disease and deliver timely and effective treatment to the patients.\n\n\nRadiologists typically observe ground-glass opacities (GGO)  <cit.>, which indicate lung inflammation but that do not obstruct the underlying pulmonary vessels. Consolidations are the advanced stage of GGO and hide the underlying vessels  <cit.>. Pleural effusion occurs when fluid accumulates excessively in the pleural space surrounding the lungs and is a highly severe case of COVID-19 <cit.>. These clinical features are critical in identifying and diagnosing COVID-19 in patients <cit.>. In addition to GGO and consolidations, radiologists observe features such as the halo sign (central consolidations surrounded by GGO), the reverse halo sign (central ground-glass lucent area with peripheral consolidation), and crazy paving patterns. These features and their distribution provide crucial information to diagnose and manage COVID-19 patients <cit.>.\n\nMachine learning and deep learning methods have been extensively encountered to classify and segment the infection regions from the CT scans. The classification task between COVID-19 and non-COVID-19 is proposed in various studies such as <cit.>. Additionally, some studies have extended the classification task to include three categories - COVID-19, Community-acquired Pneumonia (CAP), and Normal, such as <cit.>. COVID-19 and CAP diseases share similar features; distinguishing between these two categories is crucial to monitor the progression of COVID-19, which tends to be much faster than that of CAP. These methods are performed well enough in classification but need to identify the severity of patients. Further, many research works have been focused on the infection region segmentation from CT scans that can be used for severity analysis. Generating large medical image datasets for infection segmentation is time-consuming and requires highly qualified domain experts to annotate the data. Different strategies are proposed to address the unavailability of the large corpus, such as semi-supervised method (small dataset is used for supervised training along with a large amount of unlabelled data) <cit.>, weakly supervised way (ground truth data used partially in training process) <cit.>, and unsupervised methods (without any ground truth data) <cit.>. A criterion on the volume of infection has been used as an indicator of the severity of infection <cit.> and classified the CT scans into different classes such as healthy, mild, moderate, severe, and critical.\n\n\nRadiologists commonly use the CT severity score (CTSS) to determine the extent of severity in COVID-19 patients <cit.>. The score ranges from 0 to 25 and is calculated based on the distribution and magnitude of abnormalities (lung involvement) seen on chest CT scans. A higher CTSS score indicates more severe lung damage, and this information is essential in making appropriate treatment decisions <cit.>. In line with this approach, we have developed an automatic method that categorizes CT severity into four classes: mild, moderate, severe, and critical. The proposed method employs various image processing algorithms and a pre-trained UNET model <cit.> to extract infected regions from CT scans. Then, an infection rate-based feature vector is proposed for each CT scan. Various classical machine-learning models and ensemble-based models learn these representative feature vectors to predict the severity classes for chest CT scans. A fully automatic severity analysis model can significantly reduce clinicians' time to assess a patient's condition.\n\n\n\n\nThe paper is organized as follows: Section <ref> explains the dataset used in the study. Section <ref> presents the proposed method for segmenting relevant clinical features and classifying COVID-19 patients into different severity classes. Section <ref> discusses results and inferences. Finally, Section <ref> summarizes the present study.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 DATASET\n\n\n\nThe COVID-19-CT-Database (COVID-19-CT-DB) is provided as part of the \"AI-enabled Medical Image Analysis Workshop, and COVID-19 Diagnosis Competition (AI-MIA-COV19D)\" <cit.>. The CT scans were collected from September 1, 2020, to March 31, 2021. Four highly experienced medical experts annotated these CT scans (two radiologists and two pulmonologists). \n\nGenerally, CT scans are volumetric data (3D scans) and are usually available in Digital Imaging and Communications in Medicine (DICOM) and Neuroimaging Informatics Technology Initiative (NIfTI) formats. These two image formats represent the CT scan image in higher resolution, also known as  Hounsfield Units (HU). Radiologists use a mapping table based on the HU values to identify the different parts of the CT scan images and lung abnormalities. The COVID-19-CT-DB dataset transforms the HU scale image into an 8-bit gray-scale (JPG) image. This down-sampling process introduces an information loss and reduction in the resolution of the CT scan images. \n\nThe severity assessment challenge consists of 462 CT scans for training (456 patients' CT scans are used for training models) and 101 CT scans for validating the robustness of the trained model. The number of slices in each patient varies from a minimum of 27 to a maximum of 702 slices. The summary of the severity analysis dataset is shown in Table <ref>, and the description of severity categories are given in Table <ref>. The test data set consists of 231 CT scans. Five patients' data in the test dataset consists of coronal slices of the CT scan. The patient's ids for those CT scans are 'test_ct_scan_138', 'test_ct_scan_139', 'test_ct_scan_140', 'test_ct_scan_141', and 'test_ct_scan_197'. The training and validation dataset did not contain coronal slices of CT scans.\n\n\n\n\n\n\n\u00a7 PROPOSED METHOD\n\n\n\nThe proposed pipeline consists of two parts, lesion segmentation from the CT scan and quantifying the severity based on the infection rate. The proposed method uses various image processing algorithms, machine learning, and deep learning models to predict the severity score for COVID-19 patients.\n\n  \n\n\n\n\n \u00a7.\u00a7 Infection Segmentation\n\nThe infection segmentation pipeline uses domain knowledge to extract the lesion areas. Initially, the lung region is extracted from the chest CT image by a pre-trained UNET model. Then, the resultant image's contrast is enhanced by histogram hyperbolization <cit.>. Next,  the pulmonary blood vessels are enhanced using the top-hat morphological operation <cit.>. Finally, the resultant image combines morphological operations to fine-tune the infection regions. The complete overview of the pipeline is shown in  Algorithm <ref>.\n \n\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Lung Mask Generation\n\nThe chest CT scan contains the lung region and organs like the trachea, diaphragm, heart, stomach, and tissues. This module aims to extract the lung region from the chest CT scan and remove the unnecessary areas from further analysis. A pre-trained UNET <cit.> model is used to extract the lung region from the CT scan images. This model is trained on the HU scale CT images, and the images in the given dataset are in JPG format. A linear transformation is applied to the JPG images to make them compatible with the input format for the UNET model.\n\n\n\n\n\n\nThe UNET model is an end-to-end fully convolution neural network comprising a contraction and expansion path. The contracting path consists of 2D convolution layers, a nonlinear activation function, and average pooling layers. A high-dimensional feature map is finally generated. This feature map is up-sampled (by using transposed convolution) and concatenated with the feature map generated from the contracting path through skip connections. These concatenated feature maps are passed through 2D convolution layers and nonlinear activation functions in the expanding path to produce a segmentation mask from the feature map. This is primarily an encoder-decoder model. \n\n\n\nThe lung mask involvement accounts for variations in the number of CT image slices across patients. An empirical threshold on the lung mask's involvement and a threshold on the number of slices from the middle region (slice number which lies between one-third to two-thirds of the total number of slices) are used to select the CT scan images for further analysis. The region of interest is extracted using the lung mask from the chest CT scan images. The segmented CT scan images are applied with a  Gaussian filter to smooth the image without significantly reducing the sharpness of the edges. Further, this image is fed to the image enhancement module. The lung masks and extracted regions of interest from different categories of COVID-19 severity are shown in Fig. <ref>.\n\n \n\n\n\n  \u00a7.\u00a7.\u00a7 Image Enhancement using Histogram Hyberbolization\n\nHistogram hyperbolization, introduced in <cit.>, is a non-linear image enhancement method that improves the contrast of an image by adjusting its perceived brightness levels. The primary objective of this approach is that it mimics the process of vision and could correspond to the radiologist's view of the image.\n\n\n\n\n\n\n\n\n\n\n    \n    .7!J(I) = c (exp[ log (1 + 1/c) * normcm[I]] - 1)\n\n\nwhere J(I) is the space-invariant hyperbolization transformation of the image I. c is an empirical threshold. normcm is the normalized cumulative distribution of the intensity histogram. The contrast-enhanced image contains infection regions and the pulmonary vessels. The contrast-enhanced lung region of the CT scan images using histogram hyperbolization is shown in Fig. <ref>.\n\n\n\n\n\n\n\n\n\n\n            \n\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Morphological operations\n\nThe present work mainly uses three commonly-used morphological operations: dilation, opening, and top-hat <cit.>. A kernel matrix (a rectangular kernel (3 x 3)) is used to convolve with the input image. The dilation operation chooses the maximum pixel value from each (3 x 3) neighborhood and replaces the center pixel. The erosion operation finds the minimum pixel value from the kernel neighborhood. The open morphological procedure removes any small foreground objects from the binary image by employing the erosion operation followed by the dilation operation. The top-hat transformation enhances blood vessel-like structures by subtracting the image from its open morphological image. Foreground-connected components are computed from the resultant image. A criterion on the size or area of involvement is used to retain the connected components.\n\n\nThe OTSU adaptive binarization method  <cit.> is applied to the contrast-enhanced image from the previous module. Morphological operation top-hat transform is applied to enhance and remove the blood vessels. The resultant image is then fed to morphological operations open and area-based foreground filter to remove the small connected components in the resultant image. The dilation operation is employed to fine-tune the boundary of the extracted infection region. The enhanced blood vessels and infection masks generated from the different severity classes are shown in  Fig. <ref>.\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Lesion To Severity Score\n\n \nThis section describes the various methods explored to identify the correlation between the infection regions in the CT images and their severity class. Inspired by the CTSS method, a weighted average on the percentage of infection in the left and right lungs is estimated. Further, various machine learning algorithms are experimented with to classify the CT scan into different severity classes. \n\n\n\n  \u00a7.\u00a7.\u00a7 Weighted Average Method (WAM)\n\nThe infection rate in the left and right lungs are estimated separately for each slice in the CT scan with the help of the infection mask and the UNET lung mask. In CTSS estimation, the right lung is divided into three lobes and the left into two lobes, and the radiologist visually determines each lobe's degree of involvement. The lobe scores are calculated by the percentage of infection involvement in each lobe <cit.>. An average score lobe across the CT scan slices and sum up to the final CTSS. In the WAM, a score ranging from one to four is assigned based on the rate of infection,  one (0- 25% ), two (25 - 50% ), three (50 - 75% ), and four (75 - 100 % ). We employed a similar approach to the CTSS, a proportional weighted average method, to find the severity score for each CT scan slice. The right lung region is multiplied by a weight of three and the left lung region by two. The severity score is estimated by averaging the scores across the CT scan images.\n\n\n\n  \u00a7.\u00a7.\u00a7 Non-linear Methods\n\nThis study utilizes a feature vector with a dimension of 80 to represent a CT scan. Two features are extracted from each image, such as the left and right lung infection rates. Two methods are employed for a fixed-length representation of the CT scans. If the CT scan contains more than 40 slices, the slices are uniformly divided into forty regions, choosing the median slice features from each region. On the other hand, the feature vector is enhanced by computing the average percentage of infection from the available slices and appending it to generate an 80-dimensional vector. Machine learning models, including logistic regression (LR), gradient boost (Gboost), Ada boost, k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), extreme gradient boosting (XGboost) <cit.>,  extremely randomized tree (ERT) <cit.>, support vector machine (SVM), and voting based ensemble models, are employed to learn from these feature representations to predict the severity classes. The machine learning models are implemented with the help of the sklearn library in Python.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 RESULTS AND DISCUSSIONS\n\n\n\nThe proposed pipeline aims to identify the correlation between the severity class and the lung infection rate. The weighted average method finds a linear mapping between the infection rate and the severity classes, which yielded a macro F1 score of 0.43. This result led to the realization of the non-linear relationship between the infection rate and severity analysis, prompting the exploration of various machine-learning methods. The results of various classifiers are shown in Fig. <ref> and tabulated in Table <ref>.\n\nThe machine learning models achieve better results (regarding macro F1 score) than the WAM except for logistic regression. The XGboost, ERT, and SVM serve top-3 performing models for the severity analysis. An ensemble of these models achieves the best-performing system in the experiments. The ensemble model can improve the accuracy and robustness of predictions, reduce over-fitting, and improve the model's generalization. The confusion matrices show that the mild class achieves higher classification accuracy and less misclassification with other classes. In the case of the moderate class, the trained models need clarification with the severe classes; the SVM, Ensemble, and RF models provide more misclassifications to the severe category than the mild category. Similarly, the severe class CT scans are misclassified into the mild and moderate classes. While the proposed pipeline works well, it has some class misclassification issues.   While we have observed that the boundary detector has issues in some extreme cases, appropriate domain information is required to improve lung segmentation accuracy. \n\n\n\nThe standard evaluation metrics, such as precision, recall, and macro F1 score, are used to evaluate the models. Precision refers to the proportion of true positives among all predicted positive instances. Recall measures the proportion of true positives among all actual positive instances. The Macro F1 score is a harmonic mean of precision and recall, providing an overall measure of model performance across all classes. It considers false positives and negatives and is a valuable metric for imbalanced classes. The performance of linear and non-linear classifiers is shown in Table <ref>.  The baseline model is based on a convolutional neural network (CNN)- recurrent neural network (RNN) where the CNN is used as a feature extractor and RNN is used to model the sequence of features extracted from the CT scan images. The baseline model achieved a macro F1 score of 38%. It is observed from the Table <ref> that all non-linear models, except logistic regression, outperformed the baseline model. A voting-based ensemble of XGboost, ERT, and SVM  models achieves the best result on the validation data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 CONCLUSION\n\n\n\nIn this paper, we proposed a domain knowledge-based preprocessing pipeline to extract the relevant lesion regions. Infection rate-based features are proposed. Linear and non-linear models are used to predict the CT scan severity class. A voting-based XGboost, ERT, and SVM ensemble model achieves a macro F1 score of 64%.\n\n\n\nIEEEbib\n\n\n\n\n\n"}