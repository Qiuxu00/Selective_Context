{"entry_id": "http://arxiv.org/abs/2303.07131v1", "published": "20230313140137", "title": "Evolutionary quantum feature selection", "authors": ["Anton S. Albino", "Otto M. Pires", "Mauro Q. Nooblath", "Erick G. S. Nascimento"], "primary_category": "quant-ph", "categories": ["quant-ph", "cs.LG", "math.CO"], "text": "\n\n\n\n\nanton.simen@kipu-quantum.com\nKipu Quantum, Berlin, Germany.\nLatin American Quantum Computing Center, SENAI CIMATEC, Salvador, Brazil.\n\n\notto.pires@fbter.org.br\nLatin American Quantum Computing Center, SENAI CIMATEC, Salvador, Brazil.\n\n\nmauro.neto@fbter.org.br\nLatin American Quantum Computing Center, SENAI CIMATEC, Salvador, Brazil.\n\n\nerick.sperandio@surrey.ac.uk\nSurrey Institute for People-Centred Artificial Intelligence, University of Surrey, Guildford, United Kingdom\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffective feature selection is essential for enhancing the performance of artificial intelligence models. It involves identifying feature combinations that optimize a given metric, but this is a challenging task due to the problem's exponential time complexity. In this study, we present an innovative heuristic called Evolutionary Quantum Feature Selection (EQFS) that employs the Quantum Circuit Evolution (QCE) algorithm. Our approach harnesses the unique capabilities of QCE, which utilizes shallow depth circuits to generate sparse probability distributions. Our computational experiments demonstrate that EQFS can identify good feature combinations with quadratic scaling in the number of features. To evaluate EQFS's performance, we counted the number of times a given classical model assesses the cost function for a specific metric, as a function of the number of generations.\n\n\n\n\n\n\n\n\n\n\nEvolutionary quantum feature selection\n    Erick Giovani Sperandio Nascimento\n    March 30, 2023\n======================================\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\nQuantum Feature Selection (QFS) is a novel approach to Feature Selection (FS) in Machine Learning (ML) that leverages principles of Quantum Computing (QC) to enhance the efficiency and effectiveness of traditional FS methods. The most informative features are typically selected in traditional FS methods based on their correlation with the target variable or their predictive power. However, these methods can struggle with high-dimensional datasets, a phenomenon known as the curse of dimensionality <cit.>. On the other hand, Evolutionary Algorithms (EAs) are a family of optimization algorithms that are inspired by the process of natural selection and evolution. These algorithms use a population of candidate solutions and iteratively improve them over generations through selection, recombination, and mutation operations. <cit.><cit.>. \n\nThe rapid increase in the amount of data has made it challenging to keep up with the computational demands of traditional FS methods <cit.>. As a result,  researchers have explored alternative perspectives such as quantum computing and evolutionary algorithms. A procedure was described for a novel FS algorithm based on a Quadratic Unconstrained Binary Optimization (QUBO) problem for reducing model complexity in Machine Learning <cit.>. The algorithms selects a specific number of features based on their importance and redundancy, and the direct approach used in the algorithm yields higher quality solutions compared to iterative or greddy methods. The QUBO problems are particularly interesting because they can be solved on Quantum Hardware, which is why the proposed algorithm was evaluated using a classical computer, a quantum gate computer, and a quantum annealer. The proposed FS algorithm based on QUBO is a promising approach to address the challenges posed by the growing amount of data in Machine Learning.\n\n Other study was realized by <cit.> that describes a variational quantum algorithm designed to solve unscontrained black box binary optimization problems, where the objective function is given as a black box. Unlike typical algorithms for optimization where a classical objetive function is provided as a Quandratic Uncontrained Binary Optimization problem and mapped toa sum of Pauli operators, this algorithm directly handles the black box objective function. The algorithm\u00b4s theorical justification is based on convergence guarantees of quantum imaginary time evolution. The authors demonstrated that the quantum method produced competitive, and in certain aspects, even better perfomance compared to traditional FS techniques used in today\u00b4s industry. This suggests that quantum algorithms could potentially offer significant advantages over classical methods in FS and other optimization problems. However, further research is necessary to explore the full capabilities of this approach and it\u00b4s potential applications in real-world scenarios. \n\nThis paper focuses on the challenge of effective FS for artificial intelligence models due to exponential time complexity. To address this challenge, we propose an innovative heuristic called Evolutionary Quantum Feature Selection (EQFS) that uses the Quantum Circuit Evolution (QCE) algorithm. The QCE uses shalllow depth circuits to sparse probability distributions, because of this they can be useful to be applied in Noisy Intermediate-Scale Quantum(NISQ) devices, which EQFS harnesses to identify good feature combinations with quadratic scaling in the number of features. We evaluated EQFS\u00b4s perfomance by counting the number of times a given classical model assesses the cost function for a specific metric as a function  of the number of generations. This work was organized as follows: In part <ref>, a brief description of the model used was made. In part <ref>, the results were discussed and finally in part <ref> the conclusions of this work.\n\n  \n\n\n\n\n\n\n\n\n\u00a7 QUANTUM FEATURE SELECTION\n \n\nThe procedure that will be described to perform QFS uses a hybrid approach, where a quantum evolutionary algorithm plays the role of feature combination optimizer and works together with a classical algorithm that evaluates feature combinations in a supervised learning model. Let X be a dataset of dimensionality dim(X) = n. Each sample of X can be represented as an n-dimensional vector, \ud835\udc2f with its associated vector of binary values, \ud835\udc31 = (x_0, x_1, x_2, . .., x_n), which plays the role of indicating whether a variable will feed (x_i = 1) or not (x_i=0) the classical model. Let a metric function f(\ud835\udc31) evaluate the model quality given the \ud835\udc31 combination of features. Let an initial quantum state be given by |\u03c8\u27e9 = |0\u27e9 ^\u2297 n and the unit transformation, U|\u03c8\u27e9 = |\u03d5\u27e9 being U generated by a quantum circuit that can be subjected to mutations over the generations (see Fig. <ref>).  The QFS objective function can be writen as \n\n\n    F(U) = \u2211_\ud835\udc31|\u27e8\ud835\udc31|\u03d5\u27e9|^2 f(\ud835\udc31).\n\n\nIt is important to note that here we are considering that |\u03d5\u27e9 is not a proper quantum state, but rather a vector of quasi-probabilities after a polynomial set of measurements on U|\u03c8\u27e9. Since we have \ud835\udcaa(2^n) possible solutions to the problem, a number of measures m = \ud835\udcaa(poly(n)) ensures that the approximate solution is found with a time complexity that scales polynomially with the number of variables.\n\n\n\nIn this work, the algorithm used to evolve U is Quantum Circuit Evolution, proposed by <cit.>. At each generation, \u03bb copies of U are created and a mutation operation with a respective probability is applied to each generation. Possible mutations are insert a new gate; modify a rotation angle of a single or two-qubit gate on the current circuit; delete one of the current gates and swap a two-qubit gate (flip target and control). Each of these mutations has its respective probability of occurring on each of the \u03bb copies of U and the \u03bc best individuals are carried over to the next generation, characterizing an elitist procedure known in the literature as (\u03bc + \u03bb)EA.\n\nIn order to estimate the number of times the objective function is evaluated, consider \u03a9 to be the set of probability amplitudes derived from |\u03d5\u27e9. If we take m as the number of measurements performed on the quantum circuit, we have dim \u03a9\u2265 m. However, because it is a heuristic whose initial and final generations have sparse states - since the quantum circuit starts with a small depth - we can consider that very possibly dim \u03a9\u226b m. Given a number K of generations and \u03bb copies, we empirically observe that, for a small k, the total number of model evaluations in each generation, \u2211_i=0^\u03bbdim\u03a9_i, can be approximated by a linear function with dependence on k and with a fixed constant defined for m as\n\n    \u2211_i=0^\u03bbdim\u03a9_i = m/K k.\n\nTherefore, we can approximate the number t of times that the objective function, f(x), is evaluated by calculation the Area Under the Curve (AUC), given by\n\n\n    t \u2248\u222b_0^Km/K k  dk.\n\n\nNote that to approximate the solution in reasonable time, we can choose m and K appropriately. The experiments showed that for m and K being \ud835\udcaa(linear(n)), the heuristic can already find better solutions than for \ud835\udc31 containing all features. \n\n\n\n\u00a7 RESULTS AND DISCUSSION\n\n\nThe results of the proposed feature selection procedure using quantum computing are presented and analyzed in this section. This method aims to address the challenges faced by classical feature selection algorithms in handling high dimensional datasets. The procedure is designed to improve the accuracy and efficiency of feature selection. Experimental results are presented to demonstrate the effectiveness of the proposed method and its comparison to classical methods.\n\nTo carry out the experiments, a labeled data set of dimension n=13 (number of qubits) which uses chemical features to determine the origin of wines <cit.> was used. We adopted the elitist scheme (6+1)EA with the following mutation probabilities: 50 % to insert; 30 % to modify; 10 % delete and 10 % swap. The total number of measurements performed on the quantum circuit was m=64, that is, m \u2248 5n. Note that for n=13, dim(|\u03c8\u27e9) = 2^n = 8192, so m/2^n \u2248 7.8e-3. The metric used for f(\ud835\udc31) is the test accuracy of the Support Vector Classifier (SVC) model with a linear kernel function. The unseen labeled data used for testing is 20 % of the total data. Fig. <ref> shows the behavior of the quality of the solutions over the course of K=12 generations. The same experiment was performed 10 times for statiscal analysis purposes.\n\n\n\n\n\n\n\nIn view of this, it was found that even for a small number, m, of measures and few generations of evolution of the circuit, the EQFS can find several combinations of features whose metric, f(\ud835\udc31), exceeds the case where the data set is used entirely. The best final distribution of the best individual among the 10 experiments can be seen in Fig. <ref>. From this distribution, we obtained several different combinations of features with test accuracy superior to the case where all features are used (88.8%).\n\n\n\n\n \u00a7.\u00a7 Model Evaluations\n\n\nThe experimental evaluation of the model's performance was based on the total number of times that f(\ud835\udc31) is evaluated, since this is a critical point of the algorithm. In Fig. <ref> it can be seen that for a small number of generations, K, the total number of evaluations - for all \u03bb individuals - from f(\ud835\udc31) grows linearly as a function of the number of generations (with m=64).\n\nThe Area Under Curve (AUC) for the mean value of evaluations was AUC=434. This value shows that for a small constant c  n, the number of evaluations needed to find values equal to the quality of the presented experiments is \ud835\udcaa(c n^2).\n\n\n\n \u00a7.\u00a7 Quantum circuit depth\n\n\nThe depth of the quantum circuit for the number of generations K obviously cannot exceed this value. Our experiments showed that the circuit depth - considering the base B = {RX, RY, RZ, RXX, RYY, RZZ} - reached the average value of p=3, over all executions. The first run generated the circuit of Fig. <ref>.\n\n\nThe Quantum Circuit Evolution heuristic has shown promise for solving combinatorial optimization problems in quantum computers, mainly due to the production of shallow quantum circuits. Fig. <ref> showed that for the feature selection task this heuristic also produced circuits with low depth and a reduced level of entanglement (only 3 operations that generate entanglement between qubits), which further corroborates the suitability of this algorithm for NISQ computers, since two-qubit quantum gates have a lower fidelity than single-qubit gates.\n\nGiven the mutation probabilities chosen for the experiment, which are 30%, 10%, 10% and 10% for insert, delete, swap and modify, respectively, we can see that the sum of the success rates of the delete, swap and modify operations - which do not contribute to increasing the loop depth - is greater than that of the insert operation, since p =3 is 1/4 of k=12. The worst case for loop depth would be p=K, for a scenario where insert would have a 100% success rate.\n\n\n\n\u00a7 CONCLUSIONS\n \n\nIn this study, we introduced a novel approach for feature selection based on Quantum Circuit Evolution (QCE) algorithm. Our results demonstrate that our procedure, Evolutionary Quantum Feature Selection (EQFS), can identify good feature combinations with a quadratic number of model evaluations. Additionally, we observed that the depth of the quantum circuits generated by EQFS was shallow and produced circuits with a small entanglement degree compared to their variational counterparts.\n\nThe effectiveness of our method highlights its potential to pave the way for the practical application of quantum computers in feature selection. With our findings, we hope to encourage further research in this area, as the potential impact of quantum computing on feature selection and other machine learning tasks could be significant. Our work contributes to the growing body of knowledge on quantum algorithms for machine learning and provides a promising new avenue for future research.\n\n\n\n\u00a7 ACKNOWLEDGEMENTS\n\nThe authors would like to thank Banco Votorantim (BV) for providing resources for the project from which this article is derived, as well as for contributions and discussions throughout the work. Acknowledgements also to the Supercomputing Center for Industrial Innovation (CS2i), the Reference Center for Artificial Intelligence (CRIA), and the Latin American Quantum Computing Center (LAQCC), all from SENAI CIMATEC.\n\n\n\n"}