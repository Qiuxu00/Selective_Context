{"entry_id": "http://arxiv.org/abs/2303.06686v1", "published": "20230312151305", "title": "MizAR 60 for Mizar 50", "authors": ["Jan Jakub\u016fv", "Karel Chvalovsk\u00fd", "Zarathustra Goertzel", "Cezary Kaliszyk", "Mirek Ol\u0161\u00e1k", "Bartosz Piotrowski", "Stephan Schulz", "Martin Suda", "Josef Urban"], "primary_category": "cs.AI", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SC"], "text": "\nQuantifying the Effects of Magnetic Field Line Curvature Scattering on Radiation Belt and Ring Current Particles \n    [\n    March 30, 2023\n=================================================================================================================\n\n\n\n\n\n\nAs a present to Mizar on its 50th anniversary, we develop an AI/TP system that\nautomatically proves about 60 of the Mizar theorems in the hammer setting. We also\nautomatically prove 75 of the Mizar theorems when the automated provers are\nhelped by using only the premises used in the human-written Mizar proofs.  We\ndescribe the methods and large-scale experiments leading to these results. This\nincludes in particular the E and Vampire provers, their ENIGMA and Deepire\nlearning modifications, a number of\nlearning-based premise selection methods,\nand the incremental loop that interleaves growing a corpus of\nmillions of ATP proofs with \ntraining increasingly strong AI/TP systems on them. We also present a selection of Mizar problems that were proved automatically. \n\n\n\n\n\n\n\u00a7 INTRODUCTION: MIZAR, MML, HAMMERS AND AITP\n\n\n\nIn recent years, methods that combine machine learning (ML),\nartificial intelligence (AI) and automated theorem proving\n(ATP)\u00a0<cit.> have been considerably\ndeveloped, primarily targeting large libraries of formal mathematics\ndeveloped by the ITP community. This ranges from premise\n  selection methods\u00a0<cit.> and hammer\u00a0<cit.> systems to\ndeveloping and training learning-based internal guidance of ATP\nsystems such as E\u00a0<cit.> and Vampire\u00a0<cit.> on the thousands to\nmillions of problems extracted from the ITP libraries. Such large ITP\ncorpora have further enabled research topics such as automated\n  strategy invention\u00a0<cit.> and tactical guidance\u00a0<cit.>,\nlearning-based conjecturing\u00a0<cit.>, autoformalization\u00a0<cit.>,\nand development of metasystems that combine learning and reasoning in\nvarious feedback loops\u00a0<cit.>.\n\nStarting with the March 2003 release<http://mizar.uwb.edu.pl/forum/archive/0303/msg00004.html> of the MPTP\nsystem\u00a0<cit.> and the first ML/TP and\nhammer experiments over it\u00a0<cit.>, the Mizar\nMathematical\nLibrary\u00a0<cit.>\n() and its subsets have as of 2023 been used for twenty years for this research,\nmaking it perhaps the oldest and most researched AI/TP resource in the last two decades.\n\n\n\n \u00a7.\u00a7 Contributions\n\n\nThe last large Mizar40 evaluation\u00a0<cit.> of the AI/TP methods over\nMML was done almost ten years ago, on the occasion of 40 years of\nMizar. Since then, a number of strong methods have been developed in\nareas such as premise selection and internal guidance of ATPs. In this\nwork, we therefore evaluate these methods in a way that can be\ncompared to the Mizar40 evaluation, providing an overall picture\nof how far the field has moved. Our main results are: \n\n\n  * Over 75 of\n  the Mizar toplevel lemmas can today be proved by AI/TP systems\n when the premises for the proof can be selected from the library either by a human or a machine.\n\n This should be compared to 56 in Mizar40 achieved on the same version of the MML.\n Over 200 examples of the automatically obtained proofs are analyzed on our web\n page.<https://github.com/ai4reason/ATP_Proofs>\n\n  * 58.4 of the Mizar toplevel lemmas can be proved today\n  without any help from the users, i.e., in the large-theory\n  (hammering) mode. This should be compared to about 40.6 achieved on\n  the same version of the MML in Mizar40. In both cases, this is done by a\n  large portfolio of AI/TP methods which is limited to 420 of CPU time.\n\n  * Our strongest single AI/TP method alone now proves in 30 40\n  of the \n  lemmas in the hammering mode, i.e., reaching the\n  same strength as the full 420 portfolio in Mizar40.\n\n  * Our strongest single AI/TP method now proves in 120 60\n  of the toplevel lemmas in the human-premises (bushy) mode (Section\u00a0<ref>), i.e., outperforming the union of all methods developed in Mizar40 (56).\n\n  * We show that our strongest method transfers to a significantly newer\n  version of the MML which contains a lot of new terminology and\n  lemmas. In particular, on the new 13370 theorems coming from the new\n  242 articles in MML version 1382, our strongest method outperforms\n  standard E prover by 58.2, while this is only 56.1 on the\n  Mizar40 version of the library where we do the training and\n  experiments. This is thanks to our development and use of\n  anonymous\u00a0<cit.> logic-aware ML methods that learn only from\n  the structure of mathematical problems.  This is unusual in\n  today's machine learning which is dominated by large language models that\n  typically struggle on new\n  terminology.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Overview of the Methods and Experiments\n\n\nThe central methods in this evaluation are internal guidance provided by\nthe ENIGMA (and later also Deepire) system, and premise\nselection methods. We have also used several additional approaches such as\nmany previously invented strategies and new methods for constructing\ntheir portfolios, efficient methods for large-scale training on\nmillions of ATP proofs, methods that interleave multiple runs of ATPs\nwith restarts on ML-based selection of the best inferred clauses\n(leapfrogging), and methods for minimizing the premises needed for the\nproblems by decomposition into many ATP subproblems. These methods are\ndescribed in Sections\u00a0<ref>, <ref>, and <ref>, after introducing the MML in Section\u00a0<ref>.\nSection\u00a0<ref> describes the large-scale evaluation and its final results,\nand Section\u00a0<ref> showcases the obtained proofs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 THE MIZAR MATHEMATICAL LIBRARY AND THE MIZAR40 CORPUS\n\n\n\nProof assistant systems are usually developed together with their respective proof libraries. This allows evaluating\nand showcasing the available functionality. In the case of Mizar <cit.>,\nthe developers have very early decided to focus on its library, the MML (Mizar Mathematical\nLibrary) <cit.>. This was done by establishing a dedicated library committee\nresponsible for the evaluation of potential Mizar articles to be included, as well as for maintaining\nthe library. As a result, the MML became one of the largest libraries of formalized mathematics today.\nIt includes many results absent from those derived in other systems, such as\nlattices\u00a0<cit.> and random-access Turing machines\u00a0<cit.>.\n\nAll the data gathered and evaluations performed in the paper (with the\nexception of version-transfer in Section <ref>) use the same\nMizar library version as the previous large evaluation\n<cit.> and all subsequent evaluation papers. This allows\nus to rigorously compare the methods and evaluate the\nimprovement. That version of the library, MML 1147, when exported to\nfirst-order logic using the MPTP export <cit.> corresponds to\n57897 theorems including the unnamed toplevel lemmas. For a rigorous evaluation in the hammering scenario, we will\nfurther split this dataset into several training and testing parts in\nSection\u00a0<ref>.\n\n\n\n\n\n\n\n\u00a7 ENIGMA: ATP GUIDANCE AND RELATED TECHNOLOGIES\n\n\n\nENIGMA\u00a0<cit.>\nstands for \u201cEfficient Learning Based\n  Inference Guiding Machine\u201d. It is the first learning-guided ATP that\nin 2019 achieved large improvements over state-of-the-art saturation ATPs\u00a0<cit.>, and the main ingredient of the work reported here.\n\n\n\nThis section summarizes previously published research on ENIGMA and also the related\nmethods that were used to undertake the large-scale experiments done \n\nhere (Section\u00a0<ref>).\n\n\n\n \u00a7.\u00a7 Saturation Theorem Proving Meets Machine Learning\n\n\n\nSaturation Provers: State-of-the-art automated theorem provers, like E Prover\u00a0<cit.>\nand Vampire\u00a0<cit.>, perform the search for a contradiction, first\ntranslating the input first-order logic problem into a refutationally\nequivalent set of clauses.\n\n\nThen the prover operates the proof search using the given clause algorithm.\nIn this algorithm, the proof state is split into two subsets, the set P of\nprocessed clauses, and the set U of unprocessed clauses. Clauses in\nU are ordered by a heuristic evaluation function. In each iteration of the\nmain loop, the (heuristically) best clause in U is picked. This given\nclause g is then simplified with respect to all clauses in P. If it is not\nredundant, it is used in turn to simplify all clauses in P. After that, all\ngenerating inferences between g and the remaining clauses in P are\nperformed. Both the newly generated clauses and the simplified clauses from P\nare then completely simplified with respect to P, heuristically evaluated,\nand added to U. This process continues until the empty clause emerges (or\nuntil the system runs out of resources).\n\n\n\n\nTraining Data: As of E\u00a01.8\u00a0<cit.>, E maintains an internal proof\nobject\u00a0<cit.> which allows it to\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninspect all proof clauses and \n\ndesignate all clauses that have been selected\nfor processing and are part of the proof, as positive training\nexamples. All clauses that have been selected for processing, but not\ncontributed to the proof, are designated as negative training\nexamples. Clauses that have not been processed at all are neither\npositive nor negative, reducing the total number of training examples\nto typically thousands of processed clauses, as opposed to millions of\nclauses generated.\n\nE allows the user to request the actual proof object, or to provide\nany combination of positive and negative training examples. Examples\nare provided in separate batches and are also annotated as positive\nor negative for easy processing.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nML-Based Selection: Selection of the right given clause is critical in E, and an\nobvious point for the use of machine learning (ML). The positive and negative examples\nare extracted from previous successful proof searches,\n\nand a machine learning model is trained to \n\nscore the generated clauses or to classify them as useful (\u229e) or useless\n(\u229f). \nE Prover selects the given clause from a priority queue, where the unprocessed\nclauses are sorted by various heuristics.\nENIGMA extends E Prover with an additional queue where clauses positively\nclassified by the ML model are prioritized.\nThe ENIGMA queue is used together with the standard E selection mechanisms,\ntypically in a cooperative way where roughly half of the clauses are selected by\nENIGMA.\nThis approach proved to be the most efficient in practice.\n\n\n\n\n\n\nParental Guidance: Later ENIGMA\u00a0<cit.> introduced\nlearning-based parental guidance, which addresses the quadratic\nfactor when doing all possible inferences among the processed\nclauses in classical saturation-based provers. Instead, an ML model is trained to prevent inferences\nbetween the parent clauses that are unlikely to meaningfully interact.\n\n\nWhen such an inference is \nrecognized by the model as useless with a\nhigh degree of confidence, the child clause is not inserted into the set of\nunprocessed clauses U but its processing is postponed.\nTo maintain completeness, the clause can not be directly discarded\nsince the ML model might be mistaken.\nInstead, the clause is put into a \u201cfreezer\u201d from which it can be retrieved in\nthe case the prover runs out of unprocessed clauses.\nAs opposed to the above clause selection models, this method affects the\nstandard E selection mechanism because the clause is not inserted into any\nqueue.\nENIGMA clause selection models and parental (generation) models can be successfully\ncombined.\nThis is schematically illustrated in Figure\u00a0<ref> (left).\n\n\n\nMulti-Phase ENIGMA: ML-based multi-phase clause selection was introduced in\u00a0<cit.>\nto deal with computationally expensive (slow) ML models, like graph neural networks (GNNs).\nIn a two-phase selection model, a faster model is used for\npreliminary clause filtering, and only the clauses that pass \n\nare evaluated by the\nslower model.\nThe fast model is expected to over-approximate on positive classes so that\nonly clauses classified with high confidence as negatives are rejected. When parental guidance is added to the mix,\nthis leads to a three-phase ENIGMA.\nThis is schematically illustrated in Figure\u00a0<ref> (middle).\nAggressive forward subsumption is an additional logic-complete pruning method\nbased on efficient subsumption indexing in E\u00a0<cit.>.\nWe use it to eliminate many redundant generated clauses\nbefore calling more expensive ML methods (GNN) for clause evaluation. For the effect of such methods, see some of the 3-phase ENIGMA examples in Section\u00a0<ref>.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining: Strong ENIGMAs are typically developed in many prove-learn feedback loops\u00a0<cit.> that proceed as follows.\n(1) The training data T are curated from (previous) successful proof searches.\n(2) A model M is trained on data\n  T to distinguish positive from negative clauses.\n(3) The model M is run with the ATP (E), usually in cooperation\nwith the strategy used to obtain the training data.\nThen we go to step (1) with the new data obtained in step (3).\nThe loop, illustrated in Figure\u00a0<ref> (right),\n\ncan be repeated as long as new problems are proved. We run this loop for several months in this work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Gradient Boosted Decision Tree Classifiers and Features\n\n\n\n\nENIGMA supports classifiers based on Gradient Boosted Decision Trees (GBDTs).\nIn particular, we experiment with XGBoost\u00a0<cit.>\nand LightGBM\u00a0<cit.>. \nBoth frameworks are\n\nefficient and can handle large data well both in training and evaluation.\n\nFor learning, we represent first-order clauses by numeric feature vectors.\nA decision tree is a binary tree with nodes labeled by conditions on the values of the feature vectors.\nGiven a clause, the tree is navigated to the leaf where the clause evaluation is stored.\nBoth frameworks work with a sequence (ensemble) of several trees, constructed in a\nprogressive way (boosting).\n\n\nThe frameworks differ in the underlying algorithm for the construction of\ndecision trees.\nXGBoost constructs trees level-wise, while LightGBM leaf-wise.\nThis implies that XGBoost trees are well-balanced.\nOn the other hand, LightGBM can produce much deeper trees, and the tree depth\nlimit is indeed an important learning meta-parameter that can be optimized.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nENIGMA extracts various syntactic information from a first-order clause and\nstores them in the feature vector of the clause.\n\nGiven a finite set of features, each feature is assigned an index in the feature\nvector, and the corresponding feature value is stored at this index.\nFor example, a typical clause feature is the clause length.\n\nENIGMA supports the following.\n\n\n\nVertical Features\nare constructed by traversing the clause syntax tree and collecting\nall top-down oriented symbol paths of length 3.\n\n\n\n\n\n\nAdditionally, to abstract from variable names and to deal with possible\ncollisions of Skolem symbols, all variables are replaced by a special\nname \u2299 and all Skolem symbols by .\n\n\n\nHorizontal Features introduce for every term\n  f(t_1,\u2026,t_n), a new feature f(s_1,\u2026,s_n), where s_i is the top-level symbol of t_i.\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\nCount Features include the clause length, literal counts, and similar statistics.\n   \n   \n   \n   \n   \n   \n   \n   \n\nConjecture Features embed the conjecture to be proved in the feature\n   vector.\n   \n   \n   \n   \n   Thusly, ENIGMA is able to provide goal specific predictions.\n   \n\nParent Features represent a clause by features (concatenated or summed) of its parents.\n   \n\nFeature Hashing\n   is an important step towards large data in ENIGMA\u00a0<cit.>.\nIt significantly reduces the feature vector size and thusly allows handling of\nlarger data.\n\n\n\n\n\nEach feature is represented by a unique string identifier. \n\n\nThis string is passed through the hashing function \n\nand the hash modulo the selected hash base is used as the feature\nindex.\n\n\n\n\n\n\nSymbol Anonymization allows to abstract from specific symbol\n   names\u00a0<cit.>.\n\n\n\n\n\n\n\n\n\n\n\n\nDuring the extraction of clause features, all symbol names are replaced by\nsymbol arities, keeping only the information whether the symbol\nis a function or a predicate.\n\n\n\nIn this way, a decision tree classifier does not depend on symbol names, at\nthe price of\n\nsymbol collisions, which are however empirically mitigated by collecting longer paths as features.\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Graph Neural Network (GNN) Classifiers\n\n\n\nAnonymizing graph neural networks provide an alternative approach for abstracting from specific terminology.\nENIGMA uses\u00a0<cit.> a symbol-independent GNN\narchitecture initially developed for guiding tableaux search\u00a0<cit.> implemented in TensorFlow\u00a0<cit.>.\nA set of\n\nclauses is directly represented by a hypergraph with three\nkinds of nodes for clauses, subterms/literals, and symbols.\n\n\nRelationships among the objects are represented by various graph edges, which\nallow the network to distinguish different symbols while abstracting from their\nnames.\n\n\n\n\n\n\n\nThe GNN layers perform\nmessage passing across the edges, so the information at every node can get to its neighbors.\n\n\n\n\nThis allows the network to see how\nthe symbols are used without knowing their names. We always classify\nthe new clauses together with the initial clauses which provide\n\nthe context \nfor the meaning of the anonymized symbols.\nDuring the ATP evaluation, predictions of hundreds of generated clauses are computed at once in larger batches, with the context given both by the initial and the processed clauses.\n\n\n\nThe context can be either fixed, containing an initial segment of the initial and processed clauses, or\n\nit can be a shifting context using a window of clauses with the best GNN\nevaluation. \n\n\n\n\n \u00a7.\u00a7 Additional Related Techniques\n\n\nGPU Server Mode allows using GPUs for real-time\n   evaluation\u00a0<cit.>.\n\n\n\n\nTo reduce the GPU overhead of model loading, we developed a Python GPU server,\nwith preloaded models that can distribute the evaluation over several GPUs.\nE Prover clients communicate with the server via a network socket.\n\n\n\n\n\n\n\nWe\nfully utilize our physical server\n36 hyperthreading Intel(R) Xeon(R) Gold 6140 CPU @ 2.30\ncores, 755 of memory, and 4 NVIDIA GeForce GTX 1080 Ti GPUs.\nwhen we run 160 instances of E prover in parallel.\n\n\n\n\n\nRunning both the server and clients on the same machine reduces the network\ncommunication overhead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeapfrogging addresses the problem of evolving context when new given\n   clauses are selected\u00a0<cit.>.\n\n\n\n\nWe run ENIGMA with a given abstract limit and generate a larger set of clauses. Then we run\na premise selection on these generated clauses (e.g., only\nprocessed clauses), take the good clauses, and use them as input for a\nnew ENIGMA run.\n\n\n\n\nA related split/merge method involves repeatedly\n\nsplitting the generated clauses  into\ncomponents that are run separately and then merged with premise selection. This is inspired by the idea that harder problems consist of components\nthat benefit from such divide-and-conquer approaches.\n\n\nDeepire\nis an extension\u00a0<cit.>\nof Vampire <cit.> by machine-learned clause selection guidance,\ngenerally following the ENIGMA-style methodology. It is distinguished\nby its use of recursive neural networks for classifying the generated clauses based solely on their derivation history.\nThus Deepire does not attempt to read \u201cwhat a clause says\u201d, but only bases its decisions\non \u201cwhere a clause is coming from\u201d. This allows the clause evaluation to\nbe particularly fast, while still being able to recognize and promote useful clauses,\nespecially in domains with distinguished axioms which reappear in many problems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 LEARNING PREMISE SELECTION FROM THE \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen an ATP is used\nover a large ITP library, typically only a small fraction of the \nfacts are relevant for proving a new conjecture.\nSince giving too many redundant\npremises to the ATP significantly decreases the chances of proving the\nconjecture, premise selection is a critical task.\nThe most efficient premise selection methods use data-driven or\nmachine-learning approaches. If T is a set of theorems with their\nproofs and C is a set of conjectures without proofs, the task is to learn a\n(statistical) model from T, which for each conjecture c \u2208 C will rank (or\nselect a subset of) its available premises according to their relevance for\nproducing an ATP proof of c. Two \nmain machine learning settings can be\nused. \n\n\nIn Multilabel classification, premises used in the\n\t\tproofs are treated as opaque labels and a machine learning model is trained to label conjectures based on their features.\n    Binary classification aims to recognize\n    pairwise-relevance of the (conjecture,\n        premise) pairs, i.e. to estimate the chance of a\n\t\tpremise being relevant for proving the conjecture based on the\n\t\tfeatures of both the conjecture and the premise.\n\n\nThe first setting is suitable for simpler, fast ML methods, like\nk-NN or Naive Bayes \u2013 these are described in Section <ref>. The\nsecond setting (Section\u00a0<ref>) allows using more powerful ML architectures, like GBDTs and GNNs  \n(Sections\u00a0<ref> and <ref>). However, this setting\nalso requires selecting negative examples for training\u00a0<cit.>, which increases its complexity.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Multilabel Premise Selection (, , )\n\n\n\n\nNaive Bayes and k-nearest neighbors\n\nwere the strongest selection\nmethods in the \nMizar40 evaluation\u00a0<cit.>.\nIn this work, we improve them and apply them together with newer methods.\n\n\nk-NN (): The k-nearest neighbours algorithm, when applied to premise selection,\nchooses k facts closest to the conjecture in the feature space and selects their dependencies.\n\nAlready known modifications of the standard k-NN \ninclude considering the number of dependencies of facts (proofs with more dependencies\nare longer and thus less important) as well as TF-IDF (rare features are more important) <cit.>.\nAdditionally, we realize that we do not need to fix the k. Instead,\nwe consider a small k and if the number of scored dependencies \nis too low,\nwe increase the k and update the dependencies. \nThis is\nrepeated until the requested number of predictions is obtained. The\n\nk-NN-based predictions with fixed k will be denoted, e.g., by 512, while\nwith variable k this will be feavar, where fea specifies the features used.\n\n\nNaive Bayes (): The sparse Naive Bayes algorithm estimates the relevance of a fact F\n\nby the conditional probability of F being useful (estimated from past proof statistics)\nunder the condition of the features being present in the conjecture (again estimated from\nstatistics). We \nalso consider extended\nfeatures of F, i.e.,  features of F and features of facts proved using F.\nTogether with premise selection-specific weights this improves on the basic Naive Bayes\nand has already been used in HolyHammer and later Sledgehammer. A complete derivation\nof the algorithm is discussed in \n<cit.>.\nThe Naive Bayes predictions will be denoted by fea.\n\n\nThese \nalgorithms can \nbe parametrized by\nmore complex \nfeatures. We considered:\n for constants and paths (Section\u00a0<ref>) in the term graph,\n for subterms,\n for anti-unification \nfeatures <cit.>,\n for online ENIGMA features discussed in Section\u00a0<ref>\nand  for the union of all above.\nFinally, these algorithms also support the chronological mode, which in the learning\nphase discards proofs that use facts introduced after the current conjecture in the Mizar\ncanonical order (). This slightly weakens the algorithms, but is compatible\nwith the previous Mizar40 premise selection evaluation <cit.>. These will be marked by ^chrono.\n\nDependent Selection with RNNs ():\nPremise selection methods were originally mainly based on \nranking the facts  independently\nwith respect to the conjecture. \nThe highest ranked facts\nare then used as axioms and given to the ATP systems together with the\nconjecture. Such approaches (used also with GBDTs), although useful and successful, do not take into\naccount\n\nthat the premises are\nnot independent of each other. \nSome premises complement each other better when proving a\nparticular conjecture, while some highly-ranked premises might be just minor\nvariants of one another. \nRecurrent neural network (RNN) encoder-decoder\nmodels\u00a0<cit.>\nand transformers\u00a0<cit.> (language models) turn out to be suitable ML \narchitectures for modeling such implicit dependencies. \nSuch models have been traditionally developed for natural language processing,\nhowever, recently they are also increasingly used in symbolic\nreasoning tasks <cit.>, including premise selection\n<cit.>.\n\n\n\n\n\n \u00a7.\u00a7 Premise Selection as Binary Classification (, )\n\n\n\n\nGradient Boosted Decision Trees (): We use GBDTs (LightGBM) also for premise selection in the binary mode.\n\n\n\n\nThey are faster to train than the deep\nlearning methods, perform well with unbalanced training sets, and handle well sparse features.\n\n\n\nWe fix the LightGBM hyperparameters here based on \nour previous experiments with  applying GBDTs to premise selection\u00a0<cit.>.\nIn the binary setting, the GBDT scores the pairwise\nrelevance of the conjecture and a candidate premise. Because the number of\npossible candidates is large (all preceding facts in the large ITP library), we first use the cheaper k-nearest neighbors\nalgorithm to pre-filter the available premises.\nThe predictions from LightGBM will be denoted as  below.\n\n\n\n\n\nDependent Selection with GNNs ():\nThe message-passing GNN architecture\ndescribed in Section\u00a0<ref>\n\ncan also be applied to premise selection.\nLike RNNs, it can also take into account the dependencies between premises.\nAs the GNN is relatively slow, we\nwill use it in combination with a simpler premise selection method, such as k-NN, preselecting 512 facts. \n\n\nWe will denote GNN predictions by  below.\nBoth  and , can be indexed with the threshold on the\nscore (like 0.1 or -1), used to\ndifferentiate useful and useless clauses.\n\n\n\n \u00a7.\u00a7 Ensemble Methods for Premise Selection ()\n\n\nThere are several ways how we can combine the premise selection methods discussed in previous subsections.\nNaturally, using different methods for different strategies works well, however, we also found that\n\ncombining the predictions obtained from several \nmethods and using them\nfor a single prover run gives good and complementary results.\nSince prediction scores resulting from different algorithms are often incomparable <cit.>, we only\nuse the rankings produced by the various methods and based on this we create a combined ranking. We have\ncompared several ways to combine rankings in previous work <cit.> and found that several averages\n\nwork well: arithmetic mean, minimum, and geometric mean, with the harmonic mean giving experimentally\nthe best results. Additionally, we add weights to the different combined methods. The weights give more priority to\na stronger prediction method, but allow it to benefit from the simpler ones overall (by picking up some lost facts).\nGiven \npredictions from n different methods and method weights w_1,\u2026,w_n, assume\nthat a fact has been ranked as r_1-th by the first method until and r_n-th by the last one. Then, the\nensemble method would give that fact a score of\n\n1/\u2211_i=1^nw_i/r_i.\nThe scores\nof the facts obtained in this way are sorted, to get a ranking of all facts.\nThe ensemble predictions will be denoted by , with methods and their weights in the super and subscript,\nfor example ,,0.25,0.25,0.5.\n\n\n\n\n \u00a7.\u00a7 Subproblem Based Premise Minimization ()\n\n\n\nThe proof dependencies obtained by successful ATP runs typically\nperform better as data for premise selection than the dependencies\nfrom the human-written ITP\nproofs\u00a0<cit.>. However, some Mizar proofs are\nhundreds of lines long and it is so far unrealistic to raise the 75\nATP performance obtained here in the bushy setting to a number close\nto 100. This means that if we used only ATP-based premise data, we\nwould currently miss in the premise selection training 25 of the\nproof dependency information available in the MML.\n\nTo remedy that, we\nnewly use here subproblem based premises.\n\nThe idea behind this is that a theorem with a longer Mizar proof consists of a series of natural deduction steps that typically have to be justified.\nOnce ATP proofs of all such steps (we call them subproblems) for a\ngiven toplevel theorem are available, they can be used to prune the\n(overapproximated) set of human-written premises of the theorem. Such minimization also increases the chance of proving the theorem directly.\n\n\n\n\n\n\n\nIn more detail, we consider  the following approaches: \n\n  (1) Use the premises from only ATP-proved subproblems, ignoring unproved subproblems. \n(2) Add to (1) all explicit Mizar premises of the theorem (possibly ignoring some background facts).\n(3) Add to (2) also the (semi-explicit) definitional expansions detected by the natural deduction module.\n(4) Add to (3) also some of the background premises, typically those ranked high by the trained premise selectors.\n\nWhen using (1) and (3), we were able to prove more than 1000 hard theorems (see Table\u00a0<ref> in Section\u00a0<ref>).\nWe also use (3) as additional proof dependencies for ATP-unproved theorems when training premise selectors (Section\u00a0<ref>).\n\n\n\n\u00a7 STRATEGIES AND PORTFOLIOS\n\n\nStrategies: E, ENIGMA, Vampire and Deepire are parameterized by\n  ATP strategies and their combinations.  While ENIGMA-style guidance\n  typically involves the application of a larger (neural, tree-based,\n  etc.) and possibly slower statistical model to the clauses, standard\n  ATP strategies typically consist of much faster clause evaluation\n  functions and programs written in a DSL provided by the prover. Such\n  programs can again be invented and learned in various ways for\n  particular classes of problems.\n  For the experiments here we have used many ATP strategies invented automatically\n  by the BliStr/Tune \n  systems\u00a0<cit.>.\n\n   They implement feedback loops that interleave targeted parameter search on problem clusters\n   using engines like ParamILS\u00a0<cit.>, with a large-scale evaluation of the invented strategies used for evolving the problem clustering.\n   Starting from few strategies, BliStr/Tune typically evolve \n   each strategy on the\n   problems where the strategy performs best.\n   During our experiments with the systems we have developed several thousand E\n   Prover strategies, many of them targeted to Mizar problems.\n   Some of these are mentioned in the experiments in Section\u00a0<ref>.\n\n\n\n\n\n\n\n\n\n\n\n\nRobust Portfolios: Larger AI/TP systems and metasystems\nrely on portfolios\u00a0<cit.> of complementary strategies that\nattack the problems serially or in parallel using a global time\nlimit. In the presence of premise selection and multiple ATPs, such\nportfolios may consist of tens to hundreds of different methods. The\nlarger the space of methods, the larger is the risk of overfitting the\nportfolio during its construction on a particular set of problems.\nFor example, naive construction of \u201coptimal\u201d portfolios by using SAT\nsolvers for the set-cover problem (where each strategy covers some\npart of the solution space) often leads to portfolios that are highly\nspecialized to the particular set of problems. This is mitigated in\nmore robust \nmethods such as the greedy\n  cover, however, the overfitting there can still be significant. E.g.,\na 14-strategy greedy cover built in the Mizar40\nexperiments\u00a0<cit.> solved 44.1 of the random subset used for its\nconstruction, while it solved only 40.6 of the whole MML,\ni.e., 8 less.\n\n\nTo improve on this, we propose a more robust way of portfolio\nconstruction here, based again on the machine-learning ideas of\ncontrolling overfitting. Instead of simply constructing one greedy\ncover C (with a certain time budget) on the whole development set\nD and evaluating it in the holdout set H, we first split D\nrandomly into two equal size halves D_1 and D_2. Then we construct a\ngreedy cover C_1 only on D_1, and evaluate its performance also on\nD_2 and the full set D. This is repeated n times (we use\nn=1000), which for large enough n typically guarantees that the\ngreedy cover C_1^i will for some of the random splits D_1^i, D_2^i\noverfit very little (or even underfit). This can be further improved\nby evaluating the best (strongest and least overfitting) covers on\nmany other random splits and selecting the most robust ones. We use\nthis in Section\u00a0<ref> to build a portfolio that performs only\n3.5 worse on the (unseen) holdout set than on the development set used for its construction.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 EXPERIMENTS AND RESULTS\n\n\n\n\n\n \u00a7.\u00a7 Bushy Experiments and Timeline\n\n\n\nThe final list of all 43717 Mizar problems proved by ATPs in our evaluation is available on our web\npage.<http://grid01.ciirc.cvut.cz/\u00a0mptp/00proved_20210902>\nThe approximate timeline of the methods and the added solutions is shown in Table\u00a0<ref>.\nThis was\ncontinuously recorded on our web page,<https://github.com/ai4reason/ATP_Proofs>\nwhich also gives an idea of how the experiments progressed and how increasingly hard problems were proved.\n\nThe large evaluation started in April 2020, as a follow-up to our work\non ENIGMA Anonymous\u00a0<cit.>. By combining the methods\ndeveloped there and running with higher time limits, the number of\nproblems proved by ENIGMA in the bushy setting reached\n65.65 in June 2020. This was continued by iterating\nthe learning and proving in a large Malarea-style feedback loop. The\ngrowing body of proofs was continuously used for training the graph\nneural networks and gradient boosted guidance, which were used for\nfurther proof attempts, combined with different search parameters and\n\nlater used also for training premise selection.\n\nThis included\nmany grid searches on a small random subset of the problems over the\nthousands of differently trained GNNs and GBDTs corresponding to the\ntraining epochs, and then evaluating the strongest and most\ncomplementary ENIGMAs using the differently trained GNNs and GBDTs on\nall, or just hard (the so far ATP-unproved), problems.  The\ntotal number of the saved snapshots of the GNNs corresponding to the\ntraining epochs and usable for the grid searches and full evaluations\nreached 15920 by the end of the experiments in September\n2021.For the grid searches, this was compounded by further\n  parameters of the ENIGMA and E strategies.  The longest GNN\ntraining we did involved 964 epochs and 12 days on a high-end NVIDIA\n\n\n\nV100 GPU card.We generally use the same GNN hyper-parameters\n  as in\u00a0<cit.>\n  with the exception of the number of layers that varied here\n  between 5 and 12, providing tradeoffs between the GNN's speed and precision.\nThe GNN training occasionally (but rarely) diverged after hundreds of epochs, which we handled by restarts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe total number of proofs that we trained the ENIGMA guidance on\neventually reached more than three million, which in a pickled and\ncompressed form take over 200. Since the full data\ndo not fit into the main memory of even large servers equipped for\nefficient GPU-based neural training, we have programmed custom\npipelines that continuously load, mix and unload smaller chunks of\ndata used for the ENIGMA training. For many problems, we obtained\nhundreds of different proofs, while for some problems we may have only\na single proof. This motivated further experiments on how and with\nwhat frequency the different proofs should be represented in the\ntraining data. This was a part of the larger task of training data\n  normalization, which included, e.g., removing or pruning very large\nproof searches in the training data that would cause memory-based GPU\ncrashes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe 75 milestone was reached on July 26\n2021<https://github.com/ai4reason/ATP_Proofs/blob/master/75percent_announce.md>\nby using the freshly developed \n2 and 3-phase ENIGMAs,\ntogether with differently parameterized leapfrogging (Section\u00a0<ref>) runs.  The\nstrongest single 3-phase ENIGMA strategy has reached 56.4\nperformance in 30 on the bushy problems when trained and evaluated\nin a rigorous train/dev/holdout setting\u00a0<cit.>. This\nbest ENIGMA uses a parental threshold of 0.01, 2-phase threshold of\n0.1, and context and query sizes of 768 and 256. Its\n(server-based) GNN has 10 layers trained on at most three proofs for\neach problem in the training set. See also Section\u00a0<ref> for\nits evaluation on a set of completely new 13 370 problems in 242 new articles of a\nlater version of MML.\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Training Data for Premise Selection\n\n\n\nAfter several months of running the learning/proving loop in various\nways on the problems, we used the collected data for training premise\nselection methods. In particular, at that point, there were 41504\nATP-proved problems for which we typically had many alternative proofs\nand sets of premises, yielding 621642 unique ATP proof dependencies.\nSince in the hammering scenarios we can also analyze\nthe human-written proofs and learn from them, we have added for each ATP-unproved problem\nP its premises obtained by taking the union of the ATP dependencies\nof all subproblems of P. In other words, we use subproblem-based\npremise minimization (Section\u00a0<ref>) for the remaining hard problems. This adds 16651 examples to\nthe premise selection dataset. This dataset of 638293 unique proof\ndependencies is then used in various ways for training and evaluating\nthe premise selection methods on MML. In comparison with the Mizar40\nexperiments this is about six times more proof data.\nAs usual in machine learning experiments, we also split the whole set of Mizar problems into the training, development, and holdout subsets, using a 90 : 5 : 5 ratio.\nThis yields 52125 problems in the training set, 2896 in devel, and 2896 in the holdout set.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Training the Premise Selectors\n \n\nWe first train kNN and naive Bayes in multiple ways on the training subset using the\ndifferent features (Section\u00a0<ref>) and their combinations.\nFor training the GNN and LightGBM, we first use kNN-based\npre-selection to choose 512 most relevant premises for each\nproblem. When training, we add for each example its positives (the\nreal dependencies) and subtract them from the 512 premises\npre-selected by kNN, thus forming the set of the negatives for the\nexample. The GNN and LightGBM are thus trained to correct the mistakes\ndone by kNN (a form of boosting). When predicting, this is done\nin the same way, i.e., first we use the trained kNN to preselect 512\npremises which are then ranked by the GNN/LightGBM. We use both score\nthresholds (e.g., including all premises with score better than 0,\n-1 or -3), and fixed-sized slices as in other premise selection\nmethods. With the same best version of ENIGMA, the strongest GNN-based\npredictor (-1) solves 1089 problems compared to 870 solved when using the baseline kNN,\nwhich is a large (25.2) improvement. The GNN also\noutperforms LightGBM, which seems to overfit more easily on the\ntraining data. Table\u00a0<ref> shows the detailed performance\non the devel and holdout sets\nof the main methods used in the evaluation.\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 ENIGMA Experiments on the Premise Selection Data\n\n\n\n\n\n\nFirst, to train ENIGMA on the premise selection problems, we perform several prove/learn iterations with\nENIGMA/GBDT  on our premise slices.\n\n\n\n\n\n\n\n\n\n\nIn loop (1), we start with three selected slices -1, 0.1, and 64, which were found experimentally to be complementary.\nWe evaluate strategy 1 () on the three slices obtaining\n20604 proved training problems.\nWe train several decision tree (GBDT) models with various learning\nhyperparameters (tree leaves count, tree depth, ENIGMA features used).\nWe use all the training proofs\navailable.\n\n\n\nIn loop (2), we evaluate several ENIGMA\nmodels trained on \u00a0(bushy problems) to obtain additional\ntraining data.\nAfter few training/evaluation iterations, the training data might start\naccumulating many proofs for some (easier) problems solved by many strategies.\nFrom loop (2) on, we, therefore, use only a limited number of proofs per problem.\nWe either select randomly up to 6 proofs for each problem, or we select\nonly specific proofs (e.g., the shortest, longest, and one medium-length proof).\n\nIn loop (3), additional training data are added by ENIGMA/GNN runs on the premise\n\nslices, with GNN trained on the GBDT runs.\n\n\n\nIn loop (4), we consider training data from 7 additional slices (variants of\n, , ), obtained by running ENIGMA\nmodels trained of bushy problems.\nIn loop (5), we extend the training data with bushy proofs of unsolved\ntraining problems obtained by our various previous efforts.\n\n\n\n\n\n\n\n\n\n\n\n\nStarting from 1215 solved development problems, we ended up with \n1735 problems solved after the fifth iteration.\nWhile we train GBDT models only on few selected slices, we evaluate the models\non many more, up to 56, development slices covering all families\n, , , , and\n.\nWe report the increasing number of training problems (trains) and the\ntotal of number of solved development problems by all the evaluated\nstrategy/slice pairs (devel union).\nSince every strategy/slice pair is evaluated in 10 seconds, we construct the\ngreedy cover of best 42 strategy/slice pairs, to approximate the best possible\nresult obtainable in 420 (see columns devel cover).\nSince the development set has not been used in any way to train the GBDT\nmodels, we can see this as an approximation of the best possible result on the\nholdout set.\n\nWe reach 55.59 of problems solvable in 420, only with\nENIGMA/GBDT models.\nTo compare this result to other methods, we construct compatible greedy covers\nfor E Prover in auto-schedule mode, and for Vampire in CASC mode,\nthat is, in their respective strongest default settings.\nWe evaluate both provers on all 56 development slices, with 30 limit\nper problem.\nFor each prover, we construct a greedy cover of best 14 slices, again\napproximating the best possible result obtainable in 420.\n\nBliStr/Tune is our previously invented portfolio of 15 E strategies for Mizar\nbushy problems.\nWe evaluate all 15 strategies on all 56 slices with 2 seconds per problem.\nSimilarly, the greedy cover of length 210 is constructed.\nThe column pairs specifies the greedy cover length considered in\neach case.\nThe time limit for each strategy/slice pair is 420/\ud835\udc5d\ud835\udc4e\ud835\udc56\ud835\udc5f\ud835\udc60.\n\nThe training data obtained in five loops were finally used to train new\nENIGMA/GNN models for premise selection slices.\nVarious GNN models were trained (various numbers of layers, networks from various epochs) and evaluated with the limit of 5.\nAs before, we construct the greedy cover of length 84 to simulate the best\npossible run in 420.\nENIGMA/GNN performs even better then ENIGMA/GBDT, solving 57.66 problems.\nThe two ENIGMA/* portfolios cover together 1701 development problems (in 840),\nsuggesting a decent complementarity of the methods.\nNote that only the ENIGMA/GBDT strategies can cover up to 1735 (see column\ndevel on the left), which is 59,9 of the development set.\n\nMost of our ENIGMA models are combined with the baseline strategy\n.\nThis together with  are two strategies invented by\nBliStr/Tune\u00a0<cit.> which perform well on premise selection\ndata.\nWe additionally use another two older BliStr\u00a0<cit.> strategies\n and  which perform well on bushy problems.\nWe usually combine training data only from strategies with compatible term\nordering and literal selection setting.\nHowever, data from strategies with incompatible orderings, were found useful\nwhen used in a reasonably small amounts.\n\n\n\n\nFew other BliStr and Vampire strategies, together with E in the auto mode, are used to gather additional solved development problems.\nWith all our methods (ENIGMA & BliStr/Tune) and with additional Vampire runs of\nselected strategies, we have solved more than\n\n\n\n\n\n\n\n\n\n62.7\n\n\ndevelopment problems.\nThese results provide training data for the construction of the final holdout portfolio, as described in the next section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Final Hammer Portfolio\n\n\nWith the large database of the development results of the systems run\non the premise slices, we finally construct our ultimate hammering\nportfolio. For that, we use the robust portfolio construction method described in Section\u00a0<ref>.\nIn particular, we randomly split the development set into two equal-sized parts, and compute the 420 greedy cover\nusing our whole database of results on the first part.\nThis greedy cover is evaluated on the second part, thus measuring the overfitting.\nThis randomized procedure is repeated one thousand times. Then we (manually) select the 20 strongest and least overfitting portfolios and evaluate each of them on 80 more random splits, thus measuring how balanced they are on average. Typically, they reach up to 60.5 performance on the whole devel set, so we choose a threshold of 59.5 on the 160 random halves to measure the imbalance. The most balanced portfolio wins with 135 of the 160\nrandom halves passing the threshold.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis final 420-second portfolio has 95 slices that solve 1749 (60.4) of the devel problems\nand\n1690 (58.36) of the holdout problems.\n\nTable\u00a0<ref> shows the initial segment of 13 slices of this portfolio with the numbers of problems solved.\nThe full portfolio is presented in Table\u00a0<ref>. The\nfirst number t is the number of seconds to run the slice.  The\nbase column specifies the ATP strategy used, and ENIGMA\ndescribes what kinds of ENIGMA models are used (if any).  We can see\nthat GNN models dominate the schedule with fast runs.  The schedule is\nclosed by longer runs, notably also GBDT models, which while evaluated\nin a single-CPU setting, need several seconds to load the model.  This\nmeans that we are favoring the GNN ENIGMAs thanks to the use of the\npreloaded GNN server, and a further improvement is likely if we also\npreload the GBDT models.\n\n\nOur single strongest GNN-based strategy solves 1178 of the holdout problems in 30 using the  -1 predictions.\nThis is 39.5, which is only 1.1 less than the 40.6 solved by the full\n420 portfolio constructed in the Mizar40 experiments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 Transfer to MML 1382\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the final experiment, we run for 120 the best trained ENIGMA (3-phase, see Section\u00a0<ref>)\non the bushy problems from a new version of Mizar (1382) that has 242 new\narticles and 13370 theorems in them. ENIGMA not only never trained on any of these articles, but also never saw the new terminology introduced there.\nWe also run the standard E auto-schedule for 120 on the new version. ENIGMA proves 37094 (52.7) of the 70396 problems in the new library, while the E auto-schedule proves 24158 (34.32) of them. ENIGMA thus improves over E by 53.55 on the new library.\n\nWe compare this with the old MML, where the trained ENIGMA solves 34528 (59.65) of the 57880 problems, and E solves 22119 (38.22), i.e.,\nthe relative improvement there is 56.10.\n\nSurprisingly, just on the new 13370 theorems \u2013 more than half of which contain new terminology \u2013\nthe ratio of ENIGMA-proved to E-proved problems is 5934 to 3751, i.e., ENIGMA is here better than E by 58.20.\nThese numbers show that the performance of our\n  anonymous\u00a0<cit.> logic-aware ML methods, which learn only from\n  the structure of mathematical problems, is practically untouched by the transfer to the new setting with many new concepts and lemmas.\n  This is quite unusual in\n  today's machine learning which seems dominated by large language models that\n  typically struggle on new\n  terminology.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 PROOFS\n\n\nAs the main experiments progressed from spring 2020 to summer 2021,\nwe have collected interesting examples of automatically found\nproofs and published their summary descriptions on our web\npage.\n\n\nAs of September 2021 there were over 200 of such\nexample proofs, initially with ATP length in tens of clause\nsteps, and gradually reaching hundreds of clause\nsteps. Initially these were proofs found in the bushy setting,\nwith proofs done in the chainy (premise-selection) setting added\nlater, typically to show the effect of alternative\npremises.\n\nOne of the earliest proofs that we put on the web\npage<https://bit.ly/3Spmf26>\n\nis\n\u00feNEWTON:72<https://bit.ly/3ILEkEp>\n\nproving that for every natural number there exists a larger prime:\n\n\n\n\n\nThe\nENIGMA\nproof<https://bit.ly/3Z2iXo3>\n\nstarts from 328 preselected Mizar facts which translate to 549 initial\nclauses. The search is guided by a particular version of the GNN\nrunning at that time (April 2020) on the CPU. Since this is\nrelatively costly, the proof search generated only 2856 nontrivial\nclauses in 6, doing 734 nontrivial given clause loops. The final\nproof takes 83 clausal steps, and uses 38 of the 328 initially\nprovided steps. Many of them replay the arithmetical arguments done in\nMizar. An interesting point is that the guided prover is here capable\nof synthesizing a nontrivial witness (n! + 1) by using the supplied\nfacts, after which the proof likely becomes reasonably\nstraightforward  given the knowledge in the library (see the Appendix for a more detailed discussion of this example).\nIn general, using\nthe supplied facts together with the trained learner for guided\nsynthesis of nontrivial witnesses seems to be one of the main\nimprovements brought by the ENIGMA guidance that contributed to the\nnew proofs in comparison with the Mizar40 evaluation. This led us to\nstart research of neural synthesis\nof witnesses and conjectures for AI/TP settings\u00a0<cit.>.\n\nArithmetical reasoning, and other kinds of \u201croutine computation\u201d\nin general, have turned out to be areas where ENIGMA often gradually\nimproved by solving increasingly hard Mizar\nproblems and learning from them.  Such problems include reasoning about trigonometric\nfunctions, integrals, derivatives, matrix manipulation, etc. From the\nmore advanced results done by 3-phase ENIGMA, this is, e.g., a 619-long proof of\n\u00feSINCOS10:86<https://bit.ly/3StOHzV>\n\nfound in 60, doing a lot of computation about the domain and range of\narcsec,<https://bit.ly/2YZ0OgX>\nand a 326-long proof of\n\u00feFDIFF_8:14,<https://bit.ly/3IuYHV0>\n\nfound in 31, about the derivative of\ntan (ln\nx).<https://bit.ly/3SdZjTq>\n\n\n\n\n\n\nThe first proof uses 83 Mizar facts,\nstarting with 1025 preselected ones. Its proof search took 5344 nontrivial\ngiven clauses and generated over 100k nontrivial clauses in total,\nmaking the 3-phase filtering and the use of the GPU server essential\nfor finding the proof efficiently.\nThe second proof uses 55 Mizar facts, 3136 given clause loops and it generated 26.6k\nnontrivial clauses.  The reader can see on our web page that there are\nmany solved problems of such \u201cmostly computational\u201d kind,\nsuggesting that such learning approaches may be suitable for\nautomatically gaining competence in routine computational tasks, without the need to manually program them as done, e.g., in SMT solvers.\nThis has motivated our research in learning reasoning\ncomponents\u00a0<cit.>.\nTwo less \u201ccomputational\u201d but still very long ATP proofs found by 3-phase ENIGMA are\n\u00feBORSUK_5:31<https://bit.ly/3KzuPJY>\n\nsaying that the closure of rationals on (a,b) is\n[a,b],<https://bit.ly/3C0Lwa8>\nand\n\u00feIDEAL_1:22<https://bit.ly/3Z7UPQC>\n\nsaying that commutative rings are fields iff ideals are\ntrivial:<https://bit.ly/3BWqR6K>\n\n\n\n\n\nThe Mizar proof of \u00feBORSUK_5:31 takes 80 lines. ENIGMA finds a\nproof from 38 Mizar facts that uses 359 clausal steps in 4883 given\nclause loops. On the 400k generated clauses, the multi-phase ENIGMA mechanisms work as follows. 133869 clauses are\nfrozen by parental guidance, 83871 are then filtered by aggressive subsumption, and 64364 by the first-stage LightGBM model.\n125489 remaining \u201cgood\u201d clauses are gradually\nevaluated (in 176 batched calls) by the GNN server, using a context of 1536 processed clauses.\nThe ENIGMA proof of \u00feIDEAL_1:22 uses 48 Mizar facts and takes 493 clausal steps in 4481 given clause loops.\n\n\nOne example of an ATP proof made possible thanks to the premise\nselector noticing alternative lemmas in the library is\n\u00feFIB_NUM2:69.<https://bit.ly/3YWIfE6>\n\nThis theorem, called in the MML \u201cCarmichael's Theorem on Prime Divisors\u201d, states that\nif m divides the n-th Fibonacci number (Fib n), then m does\nnot divide any smaller Fibonacci number, provided m, n are prime\nnumbers.<https://bit.ly/3oGBdRz>\nThe Mizar proof has 122 lines, uses induction and we cannot so far\nreplay it with ATPs. The premise selector, however, finds a prior library\nlemma \u00feFIB_NUM:5<https://bit.ly/3ExtvmS>\n\nsaying that , from which\nthe proof follows, using 159 clausal steps, 4214\ngiven clause loops and 32 Mizar facts.\nFinally, an example of a long Deepire proof<https://bit.ly/3klDrJr>\n\nusing a high time limit is\n\u00feORDINAL5:36,<https://bit.ly/3SrPyRN>\n\ni.e.,\nthe \u03f5_0= \u03c9^\u03c9^\u03c9^...\nformula for the zeroth epsilon ordinal:<https://bit.ly/3SozGPM>\n\n\n\n\n\n\n\nThe search took 38065 given clause loops and 504. The proof has 1193 clausal steps, using 49 Mizar facts. Deepire's very efficient neural guidance took only 18 of the total time here.\n\n\n\n\n\n\u00a7 CONCLUSION:  AI/TP BET COMPLETED\n \n\n\n\nIn 2014, after the 40 numbers were obtained by Kaliszyk and Urban\nboth on the Flyspeck and Mizar corpora, the last author publicly\nannounced three AI/TP\nbets<http://ai4reason.org/aichallenges.html> in a talk\nat Institut Henri Poincare and offered to bet up to 10000 EUR on\nthem. Part of the second bet said that by 2024, 60 of the MML and\nFlyspeck toplevel theorems will be provable automatically when using\nthe same setting as in 2014. In the HOL setting, this was done as\nearly as 2017/18 by the TacticToe system, which achieved 66.4 on the\nHOL library in 60 and 69 in 120\u00a0<cit.>. One could however argue\nthat TacticToe introduced a new kind of ML-guided tactical prover that\nconsiderably benefits from targeted, expert-written procedures\ntailored to the corpora. This in particular showed in the\nlarge boost on HOL problems that required induction, on which standard\nhigher-order ATPs traditionally struggled.\n\nIn this work, we largely\ncompleted this part of the second AI/TP bet also for the Mizar library. The main caveat is\nour use of more modern hardware, in particular many ENIGMAs using the\nGPU server for clause evaluation. It is however clear (both from\nthe LightGBM experiments and from the very efficient and CPU-based\nDeepire experiments) that this is not a major issue. While it is today\ntypically easier to use dedicated \nhardware in ML-based\nexperiments, there is also growing research in the extraction of faster\npredictors from those trained on GPUs that can run more efficiently on\nstandard hardware.\n\n\n\n\n\u00a7 ACKNOWLEDGMENTS\n\nThe development of ENIGMA, premise selection and other methods used\nhere, as well as the large-scale experiments, benefited from many\ninformal discussions which involved (at least) Lasse Blaauwbroek, Chad\nBrown, Thibault Gauthier, Mikolas Janota, Jelle Piepenbrock, Stanislaw\nPurgal, Bob Veroff, and Jiri Vyskocil.  The funding for the multi-year\ndevelopment of the methods and for the experiments was partially\nprovided by the ERC Consolidator grant AI4REASON no.\u00a0649043\n(ZG, JJ, BP, MS and JU), the European Regional Development Fund under\nthe Czech project AI&Reasoning no. CZ.02.1.01/0.0/0.0/15_003/0000466\n(KC, ZG, JJ, MO, JU), the ERC Starting Grant SMART no.\u00a0714034 (JJ,\nCK, MO), the Czech Science Foundation project 20-06390Y and project\nRICAIP no. 857306 under the EU-H2020 programme (MS), ERC-CZ project\nPOSTMAN no. LL1902 (JJ, BP), Amazon Research Awards (JU) and the EU ICT-48\n2020 project TAILOR no. 952215 (JU).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 FURTHER PROOF DETAILS AND DISCUSSION\n\n\n\n \u00a7.\u00a7 Further proof details of NEWTON:72\n\nWe show the full proof of \u00feNEWTON:72 \u2013 For every natural number there is a larger prime \u2013\nwithout the clausification steps in Figure\u00a0<ref>.\n[ht]\n\n\n  \n    < g r a p h i c s >\n\n\n\nENIGMA's proof of NEWTON:72.\n\n\n\nThe verbatim ENIGMA proof is available online.<https://bit.ly/3Z2iXo3>\nThe original conjecture is as follows. Note that stating twice the primality is an artifact of the Mizar encoding.\n\n  \n\nThen the conjecture is negated. It is not the case that for every (natural number) X1 there is a prime\n(natural number) X2 with X2 > X1.\n\n  \n\nAfter that the X1 (the number a bigger prime exists for) gets\nskolemized into esk1_0. Since this is now negated, instead of \u201cthere\nis a X6\u201d we get a \u201cfor all X6\u201d with  X6 is not prime, or X6 is \u2264\nthat number.\n\n  \n\n\nIn the following inference, the prover synthesizes the term x1!+1\n\u201cplus(fact1(X1),n1)\u201d (called witness from now on) for the first time.\n\n  \n\nThis then goes into the conjecture here:\n\n  \n\nwhich essentially says:\n\n  \n\nOnce this is established, the four cases are handled in relatively straightforward way in the proof.\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u00a7.\u00a7 NEWTON:72 as an example of ML-guided deductive synthesis\n\n\n\n\n\n\nA simplified core behind the above-explained synthesis of the nontrivial witness X1!+1 in the proof \nis the combination of the following two Mizar theorems \u00feNEWTON:39 and  \u00feNEWTON:41:\n\n  \n\n  When resolved, the unification leads to essentially substituting\n   for n in \u00feNEWTON:39, and thus synthesizing the\n  instance  which is the required witness (j divides l!, hence it indeed cannot divide l!+1).\n\nThis \n  demonstrates how (A) (learning-guided) resolution-based synthesis\n  differs from (B) pure learning-guided synthesis or enumeration.\n  In\n  (A), the learner recommends the clauses that should be resolved\n  (parental guidance) or the single (given) clause that is relevant\n  wrt. a set of already selected clauses (standard GBDT/GNN\n  guidance). This recommendation may or may not fully understand what\n  will be the result of the resolution. It is quite likely just a\n  \u201chunch\u201d that combining the two facts may be interesting enough,\n  and the actual deductively synthesized witness comes as a surprise that\n  is here \u201ccomputed\u201d by the logical calculus.\n\n  Whereas in (B), we require\n  the learner (e.g. a language model\u00a0<cit.>, GNN2RNN\u00a0<cit.>, or an\n  MCTS-guided synthesis framework\u00a0<cit.>) to \u201ccome up with the term\n  on its own, based on looking at the situation\u201d. This is plausible in situations where the\n  mathematician has already seen and recognizes the pattern/trick, or\n  analogizes, transferring the terminology as in GNN2RNN. The\n  better and larger the pattern recognition and analogizing database\n  and capability, the surer the mathematician will be in directly\n  coming up with the witness.\n\n  Approach (A) thus seems more exploratory and applicable to new\n  problem-solving situations, reinforcing weaker hunches by deduction/computation\n  leading to possibly novel and surprising discoveries and values. While approach (B)\n  seems useful in known situations, relying more on direct and\n  sufficiently confident recall and memorization of the likely values.\n  Approach (A) is more a hunch about the method or direction that\n  should be used. E.g., we may feel we should somehow combine results X, Y,\n  and Z, compute a particular derivative/integral, solve a set of\n  equations/constraints, look for an inductive hypothesis,\n  etc., without knowing the result. While approach (B) is more a\n  direct hunch/recall of the solution rather than of the process\n  leading to it.\n\n  There is likely again a feedback loop between Type-A and Type-B\n  ML-guided problem-solving approaches. Type-A is more indirect and works by pointing to and\n  invoking further uncertain procedures and searching with them. If\n  reasonably successful in a particular kind of situation, the\n  confidences rise and may lead all the way to more direct Type-B\n  guesses. Which when successful may shorten parts of the Type-A\n  searches, making those more successful too, etc.\n\n\n\n\n \u00a7.\u00a7 Further Sample Proof Graphs\n\n\nTo give the readers a sample of the complexity of the more advanced\nENIGMA proofs described in Section\u00a0<ref>, we include the\ngraphical representation of three of them here (Figure\u00a0<ref>, <ref>, <ref>). We again omit the\nclausification part from them. Since these are large graphs with\nhundreds of nodes (which may further consist of quite complex\nclauses), we refer interested readers also to our web page where the\ngraphs can be viewed interactively as SVG images.[<http://grid01.ciirc.cvut.cz/\u00a0mptp/enigma_prf_graph/t72_newton_nice.proof1.svg>][<http://grid01.ciirc.cvut.cz/\u00a0mptp/enigma_prf_graph/t31_borsuk_5.proof1.svg>][<http://grid01.ciirc.cvut.cz/\u00a0mptp/enigma_prf_graph/t14_fdiff_8.proof1.svg>][<http://grid01.ciirc.cvut.cz/\u00a0mptp/enigma_prf_graph/t86_sincos10.proof1.svg>][<http://grid01.ciirc.cvut.cz/\u00a0mptp/enigma_prf_graph/t22_ideal_1.proof1.svg>]\n\n\n\n[ht]\n\n\n  \n    < g r a p h i c s >\n\n\n\nENIGMA's proof of \u00feFDIFF_8:14.\n\n\n\n[ht]\n\n\n  \n    < g r a p h i c s >\n\n\n\nENIGMA's proof of \u00feSINCOS10:86.\n\n\n\n[ht]\n\n\n  \n    < g r a p h i c s >\n\n\n\nENIGMA's proof of \u00feBORSUK_5:31.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}