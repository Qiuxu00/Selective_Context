{"entry_id": "http://arxiv.org/abs/2303.06851v1", "published": "20230313044608", "title": "On the Regret of Online Edge Service Hosting", "authors": ["R Sri Prakash", "Nikhil Karamchandani", "Sharayu Moharir"], "primary_category": "cs.DC", "categories": ["cs.DC", "cs.LG", "cs.PF"], "text": "\n\n\n\n\n\n\n\nprakash.14191@gmail.com;sriprakash@ee.iitb.ac.in\n\n\nnikhilk@ee.iitb.ac.in\n\n \nsharayum@ee.iitb.ac.in\n\n\norganization=Indian Institute of Technology Bombay,\n\taddressline=Powai,\n\tpostcode=400076,\n\tcity=Mumbai,\n\tcountry=India\n\n\n\tWe consider the problem of service hosting where a service provider can dynamically rent edge resources via short term contracts to ensure better quality of service to its customers. The service can also be partially hosted at the edge, in which case,  customers' requests can be partially served at the edge. \n\tThe total cost incurred by the system is modeled as a combination of the rent cost, the service cost incurred due to latency in serving customers, and the fetch cost incurred as a result of the bandwidth used to fetch the code/databases of the service from the cloud servers to host the service at the edge. In this paper, we compare multiple hosting policies with regret as a metric, defined as the difference in the cost incurred by the policy and the optimal policy over some time horizon T. In particular we consider the Retro Renting (RR) and Follow The Perturbed Leader (FTPL) policies proposed in the literature and provide performance guarantees on the regret of these policies. We show that under i.i.d stochastic arrivals, RR policy has linear regret while FTPL policy has constant regret. Next, we propose a variant of FTPL, namely Wait then FTPL (W-FTPL), which also has constant regret while demonstrating much better dependence on the fetch cost. We also show that under adversarial arrivals, RR policy has linear regret while both FTPL and  W-FTPL have regret O(\u221a(T)) which is order-optimal.\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\nSoftware as a Service (SaaS) instances like online navigation platforms, Video-on-Demand services, etc., have stringent latency constraints in order to provide a good quality of experience to their customers. While most SaaSs use cloud resources, low latency necessitates the use of storage/computational resources at the edge, i.e., close to the end-user. A service is said to be hosted at the edge if the code and databases needed to serve user queries are stored on the edge servers and requests can be served at the edge. In this work, the service can also be partially hosted at the edge, in which case,  customers' requests can be partially served at the edge <cit.>. For instance, consider a SaaS application which provides access to news articles on demand. A typical news article includes some text, some images and possibly some embedded videos. One way to partially host such a service is to store the text corresponding to the news articles at the edge and store the images/videos in the cloud. Each user request will then be served partially by the edge. \n\n\n\nWe consider the setting where third-party resources can be rented via short-term contracts to host the service, and the edge hosting status of the SaaS can be dynamically changed over time. If the service is not hosted at the edge, it can be fetched from the cloud servers  by incurring a fetch cost. The performance of a hosting policy is a function of the rent cost, the fetch cost, and the quality of experience of the users.  We refer to the algorithmic challenge of determining what fraction of the service to host at the edge over time as the service hosting problem. Note that we study the service hosting problem from the perspective of a specific SaaS provider which can rent third-party edge resources to improve their customers' quality of experience by reducing the latency of their service.  \n\n\n\n\n\n\nNovel online service hosting policies with provable performance guarantees have been proposed in <cit.>.\n\nThe metric of interest in <cit.> is the competitive ratio, defined as the ratio of the cost incurred by an online policy to the cost incurred by an optimal offline policy for the same request arrival sequence. Since the competitive ratio is multiplicative by definition, the absolute value of the difference in the cost incurred by an online policy and the optimal policy can be large even though the competitive ratio of the online policy is close to one. This motivates studying the performance of candidate policies in terms of regret, defined as the difference in the cost incurred by the policy and the optimal policy. Regret is a widely used metric in online learning <cit.>, including recently for the caching problem <cit.>, which is closely related to the service hosting problem. In this work, one of our goals is to design hosting policies with provable guarantees in terms of the regret. Another key dimension in the performance guarantees of online policies is the assumption made on the request arrival process. Commonly studied settings include the stochastic setting and the adversarial setting, and\n\n we provide performance guarantees for both settings.\n\n\n\n\n\n \u00a7.\u00a7 Our Contributions\n\nWe propose a variant of the FTPL policy called Wait then Follow the Perturbed Leader (W-FTPL). W-FTPL is a randomized policy that takes into account the fetch cost in its decision-making. More specifically, W-FTPL does not fetch the service for an initial wait period which depends on the request arrivals and is an increasing function of the fetch cost. Following the wait period, W-FTPL mimics the FTPL policy.\n\nFor i.i.d. stochastic request arrivals and the regret metric, we show that RR is sub-optimal while FTPL and W-FTPL are both order-optimal with respect to the time horizon. While the regret of FTPL can increase linearly with the fetch cost, the regret of W-FTPL increases at most polylogarithmically. The improved performance of W-FTPL over FTPL is a consequence of the fact that W-FTPL avoids most of the fetches made by FTPL in the initial time-slots and by the end of the wait period, its estimate of the arrival rate is accurate enough to avoid multiple fetches. \nFurther, we characterize the competitive ratio of FTPL and W-FTPL for the setting where a finite number of partial hosting levels are allowed. We compare these results with the competitive ratio of RR when a single partial hosting level is allowed <cit.> to conclude that  FTPL and W-FTPL outperform RR with respect to the competitive ratio.\n\nFor the adversarial setting, we first characterize a fundamental lower bound on the regret of any online hosting policy. In terms of regret, we then show that RR is strictly suboptimal, while FTPL and W-FTPL have order-optimal performance with respect to time. We show that the competitive ratios of FTPL and W-FTPL are upper bounded by a constant (with respect to time) for any finite number of partial hosting levels. This is a more general setting than the one considered in <cit.>, where the competitive ratio of a variant of RR is characterized when only one partial hosting level is permitted. \n\n\n\n\n\n\n\n \u00a7.\u00a7 Related work\n\n\nSeveral emerging applications such as Augmented / Virtual Reality (AR/VR), online gaming, the Internet of Things (IoT), and autonomous driving have very stringent latency requirements. In addition, many of these applications are also compute-and-storage heavy. This necessitates the migration of some of the storage and computation requirements of these services from remote cloud servers to the edge. To enable such offloading, several edge computing architectures have been proposed in the literature and their performance has been analyzed extensively, see for example <cit.> and references therein. \n     \nThe service hosting problem has received a lot of attention recently, and various settings have been studied. One approach has been to pose the design problem of where to host which service as a one-shot large-scale optimization problem, see for example <cit.>. Our work differs from this line of work in that we consider an online setting where we adaptively decide when (and what fraction of) service to host at any time, depending on the varying number of requests seen thus far. \n\nThere have been recent works <cit.> which consider the online service hosting problem, and design adaptive schemes whose performance is characterized in terms of the competitive ratio with respect to an oracle which known the entire request sequence apriori. Our work differs from these in a couple of ways. Firstly, the above mentioned works study the problem from the perspective of an edge resource provider who has to decide which amongst a collection of services to host at each time on a storage-constrained edge server. On the other hand, similar to some other works <cit.>, we study the problem from the perspective of a service provider which needs to decide when to host its application at the edge so as to minimize the overall cost. Secondly, most of the works mentioned above do not consider partial hosting of the service, which is allowed in our framework. While <cit.> does study partial hosting and proposed the Retro-Renting (RR) policy which is shown to have a constant competitive ratio, it only allows one level of partial hosting of the service. On the other hand, we consider a much more general setting where multiple partial service hosting levels are allowed and are able to show that both the FTPL and its variant W-FTPL are able to achieve a constant competitive ratio.  \n\nWhile the works mentioned above study competitive ratio as a performance metric, another popular measure of performance for online algorithms is the regret which considers the difference in the cost incurred by an online policy and the optimal (static) policy. In particular, for the closely related caching problem, several policies inspired by the recent advances in online convex optimization have been proposed, including Online Gradient Ascent <cit.>, Online Mirror Descent <cit.>, and Follow the Perturbed Leader (FTPL) <cit.>. In particular, FTPL has been shown to have order-optimal regret for the caching problem in the adversarial setting  <cit.>.  In this work, we study regret for the RR and FTPL policies for the service hosting problem under both the stochastic and adversarial settings. \nSince RR is a deterministic policy, its regret performance in the adversarial setting is poor. While FTPL does achieve order-optimal regret (with respect to time), one limitation is that it makes hosting decisions agnostic of the fetch cost. As a result, in some cases, FTPL is prone to fetching and evicting the service multiple times in the initial time-slots when its estimate of the request arrival rate is noisy, thus leading to poor performance. This motivated our design and regret analysis of W-FTPL, a variant of FTPL which takes into account the fetch cost. One recent work which also considers regret as a performance metric is <cit.>, which studied the problem of joint online service hosting and routing and proposed a two time-scale algorithm based on online gradient descent with provably order-optimal regret under adversarial requests. \n\nFinally, there are several other approaches which have been used to address the online service hosting problem, including Markov Decision Processes <cit.>, Reinforcement Learning <cit.>, and Multi-Armed Bandits <cit.>. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 SYSTEM SETUP\n\n\n\n\nWe consider a system consisting of a back-end server and an edge-server to serve customers of a service. The back-end server always hosts the service and can serve any requests that are routed to it.\n\nIn this work, we allow the service to be partially hosted at the edge-server.  When the service is partially hosted at the edge, requests are partially served at the edge and partially at the back-end server. \n\nFurther, the fraction of service hosted at the edge can be changed over time. \n\nIf the service is not hosted or partially hosted at the edge, parts of the service can be fetched from the back-end server to host at the edge.  \n\nSequence of events in each time-slot: We consider a time-slotted system. In each time-slot, we first make the service hosting decision for that time-slot. Following this, requests may arrive and are served at the edge and/or the back-end server.  \n\n\nRequest arrivals: We consider two types of arrival processes in this paper. \n\n\t\n  - Stochastic arrivals: In this case, request arrivals are i.i.d.  across time-slots with mean \u03bc. \n\t\n  - Adversarial arrivals: In this case, the request arrival sequence is generated by an oblivious adversary[ The entire request sequence is assumed to be fixed apriori.].\n\nLet r_t denote the number of request arrivals in time-slot t. We consider bounded requests, specifically, 0\u2264 r_t\u2264\u03ba, and let R_t=\u2211_i=1^tr_i denote the cumulative requests observed by the end of time-slot t. In both cases, we assume that there are at most \u03ba arrivals per slot.\n\n\nCosts: We model three types of costs.\n\n\t\n  - Rent cost (\ud835\udc9e^\ud835\udcab_R,t): The system incurs a cost of c units per time-slot to host the entire service at the edge. For hosting f fraction of service, the system incurs a cost of cf units per time-slot. \n\t\n\t\n  - Service cost (\ud835\udc9e^\ud835\udcab_S,t): This is the cost incurred to use the back-end server to serve (parts of) requests. \n\t\n\tIf f fraction of service is hosted at the edge, the system incurs a service cost of g(f) units per request, where g(f) is a decreasing function of f. We fix g(0)=1, i.e., service cost is one unit when the service is not hosted at the edge.\n\t\n\t\n  - Fetch cost (\ud835\udc9e^\ud835\udcab_F,t): The system incurs a cost of M> 1 units for each fetch of the entire service from the back-end server to host on the edge-server. For fetching f fraction of service, the system incurs a cost of Mf units.\n\n\nLet \u03c1_t^\ud835\udcab denote the edge hosting status of the service in time slot t under policy \ud835\udcab. We consider the setting where \u03c1_t^\ud835\udcab\u2208{\u03b1_1,\u03b1_2, \u22ef , \u03b1_K-1,\u03b1_K} and \u03c1_t^\ud835\udcab=\u03b1_i implies that \u03b1_i fraction of the service is hosted at the edge-server in time-slot t. Note that \u03b1_i\u2208 [0,1] and in particular we consider \u03b1_1=0, \u03b1_K=1 and \u03b1_i<\u03b1_j for i<j. It follows that \u03c1_t^\ud835\udcab=1 implies that the entire service is hosted at the edge in time-slot t, and \u03c1_t^\ud835\udcab=0 implies that the service is not hosted at the edge in time-slot t. \n\n\nWe make some assumptions about the various system parameters. \n\t\n\tc\u2264\u03ba.\n\nThis assumption is motivated by the fact that if \u03ba < c, it is strictly sub-optimal to host the entire service at the edge, irrespective of the number of arrivals in a time-slot.\n\n\n\tFor a fraction of service \u03b1_i, 1\u2264 i\u2264 K, \u03b1_i+g(\u03b1_i)\u2264 1.\n\n In <cit.>, it is shown that the benefits of partial hosting are limited to the setting where \u03b1_i+g(\u03b1_i)\u2264 1. Motivated by this, we consider the case where  \u03b1_i+g(\u03b1_i)\u2264 1 for all candidate values of \u03b1_i.\n\n \n\tFor any fraction of service \u03b1_i, 1\u2264 i\u2264 K,\n\tc\u03b1_i+g(\u03b1_i)r_t\u2264\u03ba\n\n Assumption <ref> follows from  Assumptions <ref> and <ref>\n \n\n\tFor stochastic arrivals, \u03bc>0 and for adversarial arrivals, R_T\u2265 1.\n\nThis assumption eliminates degenerate cases where there are no request arrivals in the time-horizon of interest. \n\n\n\nThe total cost incurred in time-slot t by policy \ud835\udcab, denoted by \ud835\udc9e^\ud835\udcab_t(r_t), is the sum of the rent, service, and fetch costs. It follows that,\n\n    \ud835\udc9e^\ud835\udcab_t(r_t)\n       =c\u03c1_t^\ud835\udcab+ g(\u03c1_t^\ud835\udcab) r_t+ M (\u03c1_t^\ud835\udcab-\u03c1_t-1^\ud835\udcab)^+.\n\nLet r={r_t}_t\u22651 denote the request arrival sequence and \ud835\udc9e^\ud835\udcab(T,r) denote the cumulative cost incurred by policy \ud835\udcab in time-slots 1 to T. It follows that, \n\n    \ud835\udc9e^\ud835\udcab(T,r) = \u2211_t=1^T \ud835\udc9e^\ud835\udcab_t(r_t).\n\n\nPerformance metrics: We consider two performance metrics, namely regret and competitive ratio.\n\n\nFor i.i.d. stochastic arrivals, the regret of a policy \ud835\udcab, denoted by \u211b^\ud835\udcab_S(T), \nis defined as the difference in the total expected cost incurred by the policy and the oracle static hosting policy. The oracle static hosting policy makes a hosting decision at t=1 using the knowledge of the statistics of the request arrival process but not the entire sample-path. For ease of notation, we define \u03bc=[r_t], \u03bc_i=c\u03b1_i+g(\u03b1_i)\u03bc. It follows that the expected cost incurred by the optimal static hosting policy in time-slots 1 to T is min_i{c\u03b1_iT+g(\u03b1_i)\u03bc T+M\u03b1_i}, and therefore, \n\n    \u211b^\ud835\udcab_S(T)   =  _\ud835\udcab,r[\ud835\udc9e^\ud835\udcab(T,r)] -min_i{c\u03b1_iT+g(\u03b1_i)\u03bc T+M\u03b1_i}\n       =_\ud835\udcab,r[\ud835\udc9e^\ud835\udcab(T,r)] -min_i{\u03bc_i T+M\u03b1_i},\n       \u2264_\ud835\udcab,r[\ud835\udc9e^\ud835\udcab(T,r)] -min_i{\u03bc_i T},\n \n\nwhere _\ud835\udcab,r represents the expectation over the randomization in policy \ud835\udcab and the request arrival sequences r. \n\nFor i.i.d. stochastic arrivals, the competitive ratio of a policy \ud835\udcab, denoted by \u03c3^\ud835\udcab_S(T), \nis defined as the ratio of the expected total cost incurred by the policy and expected total cost incurred by the optimal static hosting policy as discussed above. It follows that,\n\n    \u03c3_S^\ud835\udcab(T)= _\ud835\udcab,r[\ud835\udc9e^\ud835\udcab(T,r)]/min_i{c\u03b1_iT+g(\u03b1_i)\u03bc T+M\u03b1_i}.\n \n\n\nFor adversarial arrivals, the regret of a policy \ud835\udcab, denoted by \u211b^\ud835\udcab_A(T), is defined as the worst case difference in the total expected cost incurred by the policy and the optimal static hosting policy. The expectation is taken over the randomization in policy \ud835\udcab. It follows that for any request sequence r, the total cost incurred by the optimal static hosting policy in time-slots 1 to T is min_i{c\u03b1_iT+g(\u03b1_i)R_T+M\u03b1_i}, and therefore, \n\n    \u211b^\ud835\udcab_A(T,r)   =_\ud835\udcab[\ud835\udc9e^\ud835\udcab(T,r)] - min_i{c\u03b1_iT+g(\u03b1_i)R_T+M\u03b1_i},\n    \u211b^\ud835\udcab_A(T)   =sup_r(\u211b^\ud835\udcab_A(T,r) ).\n\n\nWe have the following relation between the regret induced by a policy under i.i.d stochastic arrivals and adversarial arrivals.\n\n\tFor any online policy \ud835\udcab and stochastic arrivals we have,\n\t\u211b_S^\ud835\udcab(T)\u2264\u211b_A^\ud835\udcab(T).\n\nThe proof can be found in Section <ref>.\n\n\nFor adversarial arrivals, the competitive ratio of a policy \ud835\udcab, denoted by \u03c3^\ud835\udcab_A(T), is defined as the worst case ratio of the expected total cost incurred by the policy and the cost incurred by the offline optimal policy. The optimal offline policy can change the hosting status over time using the knowledge of the entire request process a priori. Let the cost incurred by the optimal offline hosting policy in time-slots 1 to T be denoted by \ud835\udc9e^OFF-OPT(T,r). It follows that, \n\n    \u03c3^\ud835\udcab_A(T)=sup_r_\ud835\udcab[\ud835\udc9e^\ud835\udcab(T,r)]/\ud835\udc9e^OFF-OPT(T,r).\n\n\nGoal: The goal is to design online hosting policies with provable performance guarantees with respect to regret and competitive ratio.\n\nNotations: We define some notations which will be used in the rest of this paper. Let s=[0 , \u03b1_2, \u03b1_3, \u22ef, 1]', f=[1,g(\u03b1_2), g(\u03b1_3), \u22ef, 0]', and \u03c1_t^\ud835\udcab\u2208\ud835\udcb3, where \ud835\udcb3 is the collection of all possible one hot vectors in {0,1}^K  and thus |\ud835\udcb3|=K. The position of 1 in the one hot vector \u03c1_t^\ud835\udcab represents the level of service hosted at the edge in slot t, that is \u03c1_t^\ud835\udcab=\u27e8\u03c1_t^\ud835\udcab,\ud835\udc2c\u27e9. \n\nThe total cost in slot t as given in (<ref>) can be rewritten  using the above notations as follows,\n\n    \ud835\udc9e_t^\ud835\udcab(r_t)    = c\u27e8\u03c1_t^\ud835\udcab,s\u27e9 + r_t \u27e8\u03c1_t^\ud835\udcab,f\u27e9 + M (\u03c1_t^\ud835\udcab-\u03c1_t-1^\ud835\udcab)^+,\n       =\u27e8\u03c1_t^\ud835\udcab,\u03b8_t\u27e9 + M (\u03c1_t^\ud835\udcab-\u03c1_t-1^\ud835\udcab)^+,\n\nwhere \u03b8_t= cs+r_tf. \n\n\n\nFor ease of notation, for stochastic arrivals we define \u03bc = [r_t], \u03bc_i=c\u03b1_i+g(\u03b1_i)\u03bc, \u0394_ij=\u03bc_i-\u03bc_j, i^\u22c6=_i \u03bc_i , \u0394_i=\u03bc_i-\u03bc_i^\u22c6, \u0394_min=min_i \u0394_i, \u0394_max=max_i \u0394_i.\n\nWe summarize important notations used in this paper in \u00a0<ref>.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 POLICIES\n\n\n\n\nOur Policy: Our policy called Wait then Follow the Perturbed Leader (W-FTPL), is a variant of the popular FTPL policy. A formal definition of FTPL is given in Algorithm <ref>. FTPL is a randomized policy and is known to perform well for the traditional caching problem, in fact achieving order-wise optimal regret for adversarial arrivals <cit.>.  Under FTPL, in any time slot t, for each i, FTPL considers the cumulative cost that would have been incurred had the system used \u03b1_i hosting fraction in the entire duration [1, t -1], and then perturbs this by an  appropriately scaled version of a sample of a standard Gaussian random variable. FTPL then hosts the fraction of service for which the perturbed cost is minimum in that slot.\n\n\n\n\n\n \n\n\nWe propose a policy called Wait then Follow The Perturbed Leader (W-FTPL). The key idea behind the W-FTPL policy is to not host the service for an initial wait period. This is to reduce the number of fetches made initially when the estimate of the arrivals is noisy.  The duration of this wait period is not fixed apriori and is a  function of the arrival pattern seen till that time. Following the wait period, W-FTPL mimics the FTPL policy. Refer to Algorithm <ref> for a formal definition of W-FTPL. Let T_s be the time slot, after which W-FTPL starts acting as FTPL. Formally we define T_s=min{t:t<(max_i j(\u0398_t+1,i-\u0398_t+1,j))^2/\u03ba^2\u03b2 (log M)^1+\u03b4}, where \u03b2>1, \u03b4>0 are constants.\n\n\n\n\n\n\nRetro-Renting (RR) <cit.>: The RR policy is a deterministic hosting policy, and it either hosts the complete service or hosts nothing in a slot. The key idea behind this policy is to use recent arrival patterns to make hosting decisions. We refer the reader to Algorithm 1 in <cit.> for a formal definition of the RR policy. The performance of RR with respect to the competitive ratio was analyzed in <cit.>. \n\n\u03b1-RR <cit.>  is a variant of RR where one partial level of hosting  the service is allowed. The formal definition of \u03b1-RR, borrowed from <cit.> is given in Algorithm <ref>. Similar to RR, the key idea behind \u03b1-RR policy is to check whether the current hosting status is optimal in the hindsight using recent arrival patterns to make hosting decisions. \u03b1-RR checks the optimal offline policy cost for the recent request arrivals and chooses the fraction of service with the minimum cost. For \u03c1_t^\ud835\udcab\u2208{0,1}, \u03b1-RR behaves as RR <cit.>. Therefore we refer \u03b1-RR as RR in this paper.\n\n\n\n\n\n\n\n\nIn this section we consider different polices we want to analyze with the metrics defined  in Section <ref>.\n\n\n \u00a7.\u00a7 Retro Renting (RR)\n\nThis policy was proposed in <cit.>. It is a deterministic policy and tries to mimic the optimal off-line policy and it is considered as optimal off-line policy with some delay. The Algorithm <ref> represents the RR policy. The competitive ratio analysis for RR is also there in <cit.>. We analyze the regret of RR in this paper.\n\n\n \u00a7.\u00a7 Follow The Perturbed Leader (FTPL)\n\nThis policy already exists in the content caching, on-line learning literature <cit.>, <cit.> where as we adapted it to the service caching setting and analyzed its regret. The Algorithm <ref> with \u03b2=0 represents the FTPL policy. Note that it is a randomized algorithm and does not consider M while making decisions and leads to large fetch cost if M is large. \n\n\n \u00a7.\u00a7 Our policy (W-FTPL)\n\nIn our policy there will be an initial wait period in which service is not fetched or hosted at edge and all the requests are forwarded to edge. After the wait period we follow the FTPL policy. So we named our policy as Wait then FTPL (W-FTPL) which is given in Algorithm <ref>. Note that the initial wait period depends on M, which helps in reducing the fetch cost when M is large compared to FTPL.\n\n\n\n\n\n\n"}