{"entry_id": "http://arxiv.org/abs/2303.06967v2", "published": "20230313100840", "title": "Isotopic piecewise affine approximation of algebraic or $C^1$ varieties", "authors": ["Christophe Raffalli"], "primary_category": "math.AG", "categories": ["math.AG"], "text": "\n\nFirst results from the JWST Early Release Science Program Q3D: Ionization cone, clumpy star formation and shocks in a z=3 extremely red quasar host\n    Lillian Whitesell\n    March 30, 2023\n===================================================================================================================================================\n\n\n\n\nWe propose a novel sufficient condition establishing that a piecewise affine\nvariety has the same topology as a variety of the sphere \ud835\udd4a^n defined by\npositively homogeneous C^1 functions. This covers the case of C^1 varieties\nin the projective space \u2119^n. We prove that this condition is\nsufficient in the case of codimension one and arbitrary dimension. We describe\nan implementation working for homogeneous polynomials in arbitrary dimension\nand codimension and give experimental evidences that our condition might still\nbe sufficient in codimension greater than one.\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\n\n\n\n \u00a7.\u00a7 Contribution\n\n\nLet a variety V be defined by a system of implicit equations: V = {x \u2208\ud835\udd42, f_1(x) = 0, \u2026, f_m(x) = 0} on some compact polyhedron\n\ud835\udd42\u2282\u211d^n, with 1 \u2264 m \u2264 n.  We assume that the\nfunctions f_1, \u2026, f_m : \u211d^n \u2192\u211d are C^1.  Let S =\n(S_i)_i\u2208 I be a decomposition of \ud835\udd42 into a family of simplices.\nA piecewise affine variety may always be defined from V and S by defining\nfor each 1 \u2264 i \u2264 k an approximation f\u0303_i of the function f_i\nby\n\n \n  * f\u0303_i(x) = f_i(x) for any x vertex of S_i for i \u2208 I and\n \n  * f\u0303_i is affine when restricted to any S_i for i \u2208 I.\n\nFrom this, we define \u1e7c = {x \u2208\ud835\udd42, f\u0303_1(x) = 0, \u2026,\nf\u0303_k(x) = 0}.  The question is to find a sufficient condition ensuring\nthat V and \u1e7c are isotopic.\n\nMoreover, we search for a criteria that can be computably approximated with\narbitrary precision in the case of multivariate polynomials, to allow for an\nimplementation.\n\nWe propose two theorems in codimension one (m = 1) and two\nconjectures, one weaker than the other, supported by some experimental evidence,\nin the general case. More precisely:\n\n  \n  * In section <ref>, we give a theorem that answers the question\n  when \ud835\udd42 is a compact polyhedron in \u211d^n, in codimension one\n  (m = 1) and when f_1 is of C^1 class.\n  \n  * In section <ref>, we show that the same condition is\n    correct if \ud835\udd42 = \ud835\udd4a^n the unit sphere of\n    \u211d^n+1, in codimension one and when f_1 is of C^1\n    class and positively homogeneous of degree d (i.e. f(\u03bb x) = \u03bb^d\n    f(x) for all \u03bb\u2208\u211d_+ and x \u2208\u211d^n+1).\n    This case could be considered as codimension 2, but the homogeneity allows\n    to ignore completely the equation of the sphere.\n  \n  * In section <ref>, we generalise the previous statement to\n    arbitrary codimension and conjecture that it still holds.  This conjecture\n    is supported by an implementation which was tested on many examples and\n    never gave wrong topology. We actually give two conjectures, because we\n    lack some results on convex set of full rank matrices. We give more details\n    in subsection <ref> and section <ref>.\n\n\nLet give now the statement of our first theorem in section <ref>:\n<ref> page thcompact\n  Let \ud835\udd42\u2282\u211d^n be a compact polyhedron.\n  Let (S_i)_i\u2208 I be a simplicial decomposition of \ud835\udd42.\n  Let f : \u211d^n \u2192\ud835\udd42 be a C^1 function in n variables.\n  Let V = { x \u2208\ud835\udd42, f(x) = 0} be the zero locus of f\n  restricted to \ud835\udd42.\n  Assume that V \u2229\u2202\ud835\udd42 = \u2205.\n\n  We define p\u0303 : \ud835\udd42\u2192\u211d the piecewise affine\n  function such that for all i \u2208 I, f\u0303S_i is affine\n  and for any v vertex of S_i, we have\n  f(v) = f\u0303S_i(v).\n  We define the following:\n  \n  \n  * \u1e7c = { x \u2208\ud835\udd42, f\u0303(x) = 0} the zero locus of\n  f\u0303.\n  \n  * \ud835\udd42(f) = { x \u2208\ud835\udd42, f(x)f\u0303(x) \u2264 0}.\n  \n  * \u2207\u0303f(x) = {\u2207f\u0303S_i(x), x \u2208 S_i\n    }\u2282\u211d^n\n  \n  * G(f,x) = {\u2207 f(x) }\u222a\u2207\u0303f(x) \u2282\u211d^n\n  \n  If the condition (<ref>) below holds, then V and \u1e7c are isotopic:\n  \n    \u2200 x \u2208\ud835\udd42(f), 0 \u2209G(f,x) the convex\n          hull of G(f,x)\n\n\n\nLet us give some ideas about this theorem: the isotopy is naturally defined by\nf_t(x) = t f(x) + (1 - t) f\u0303(x) for x \u2208\ud835\udd42 and t \u2208\n[0,1]. The function x \u21a6 f_t(x) is not differentiable, but it is\ndifferentiable in any direction, and its gradient at x in direction D is\nalways given by a scalar product V.D where V is in the convex hull of\nexactly the gradients we are considering in the set G(f,x). Thus our\ncondition ensures that V \u2260 0, which we find is very natural\nsmoothness condition. This condition only needs to hold in region where\nf_t may be null, i.e. when f(x) and f\u0303(x) have opposite sign, this\njustifies the definition of \ud835\udd42(f).\n\nThe theorem of section <ref> is almost the same, we ask\nfor the function to be positively homegenous and we decompose\n\u211d^n+1 in simplicial cones, which is defined in section\n<ref>. Appart from this, the statement is unchanged.\n\nIn section <ref> we propose two conditions (conjecture <ref>\nand <ref>) that could apply in arbitrary codimension (i.e. with more than\none polynomials). Unfortunately we are not able to prove those conjectures.\n\nThe first one (conjecture <ref>), the most natural, generalises the\ncondition (<ref>)\n\n    \u2200 x \u2208\ud835\udd42(p), 0 \u2209G(p,x)\n\ninto\n\n    \u2200 x \u2208\ud835\udd42(p), \u2200 A \u2208G(p,x), A  is of\n        maximal rank\n\n\nThis is natural as with codimension greater than one, the gradients become\nmatrices and maximal rank expresses transversality, hence smoothness.\n\nRemarks: we do not need extra hypotheses, like smoothness (or non complete\nintersection with codimension greater than one). However, if the\nvariety is not sm\nooth, our criteria will never be satisfied. We should also\nsay that our condition is frame independant. Indeed, a change of\ncoordinates will multiply all the gradients by the same invertible matrix and\nthe convex hull is transformed accordingly.\n\n\n\n \u00a7.\u00a7 A global criteria\n\n\nA standard way to compute piecewise affine approximation of varieties defined by\nimplicit equations are decomposition method that proceed by incrementally\nsubdivising the ambient space in simplices or hypercubes, until some criteria is met.\n\nOur criteria is such a stopping condition, but it is global. To our knowledge,\nall existing criteria (like in <cit.>) will ensure the isotopy of the\norginal variety and its approximation when restricted to each simplex of\nhypercube. This is not the case of our criteria.\n\nLet us explain more precisely what we mean by global. From the\ndefinitions in our theorem or conjecture, if follows that if X is the set of\nvertices of the simplicial decomposition, we have X \u00d7 V isotopic to X\n\u00d7\u1e7c. This means that the isotopy can not traverse the vertices of\nthe decomposition. However it may traverse faces of simplices of dimension one\nor more, allowing to use less simplices.\n\n\n\nThis is illustrated by figure <ref>. This figure represents a\npiece of a C^1 variety in blue and\nits approximation in black. In the triangle which is fully displayed, the\napproximation has only one component while the original variety, has two\ncomponents. Still our criteria accepts this decomposition.\nThis can save quite a lot of triangles.\n\n\n\n \u00a7.\u00a7 Testing the criteria\n\n\nImplementing a test for the criteria is not possible in general. But, in the\ncase of polynomials, we can use Bernstein basis: for all x in a simplex S,\n\u2207 p(x) always lies in the convex hull of the coefficients of the\npolynomial \u2207 p, in this basis, after a change of variable to send the\nunit simplex in S. This gives easily a sufficient condition to satisfy the\ntest in each face of the simplicial decomposition. This is detailed in section <ref>.\n\nMoreover, we can approximate the real criteria with arbitrary precision by\nsubdividing each face to test. We only do this subdivision for the\ntest. Refining the decomposition requires to\nsubdivise the neighbour simplices and we do not want to do that if we can\navoid it.\n\n\nWe implemented a heuristic that searches for a simplicial decomposition\nsatisfying our criteria. This is relatively quick because it uses\nfloating point arithmetic. But when an apparently correct decomposition is\nfound, we retest the criteria with exact rational arithmetic, ensuring the\ncorrectness.\n\nMoreover, the search for the decomposition produces certificates that the\nrelevant convex hulls do not contain 0. In codimension one, such a\ncertificate is a vector which has a positive scalar product with all the\ngenerators of each convex hull. This way the only computation we have to do in\nexact arithmetic are change of coordinates, scalar products and comparison. We\ndo not perform nested computation in loops and this limits the growth of the\nsize of numerators and denominators. In our experiments, the computing time of\nthe final exact test is faster than the search for a simplicial decomposition.\n\n\n\n \u00a7.\u00a7 Examples\n\n\n\n\n  \n*Remark:\nBecause polynomials have no well defined value in the projective space, we\nwill work within \u211d^n+1 and its unit sphere \ud835\udd4a^n. This is\nequivalent and much easier. Still all the examples will be depicted in the\nprojective space as it avoids to draw every point  of the variety twice.\n\nThe green line segments in figures <ref> and <ref> are the edges of a simplicial\ndecomposition of  and  respectively (in the latter case, it is\nunfortunately not\neasy to guess the simplices from their edges).\nThe figure <ref> gives the piecewise affine\napproximation of a plane curve of degree 4. It uses a decomposition of the\nprojective plane with 13 vertices and 24 triangles and requires 58ms to compute. The figure <ref>\nshows an algebraic surface of the same degree together with its\napproximation. The decomposition uses 32 vertices and 152 tetrahedron and\nrequires 3.3s to compute.\n\n\n\nAs those varieties are enclosed in a compact polyhedron, their approximations\ncan be proved isotopic to the original varieties by the previous theorem\n<ref>. They can also be proved correct by the theorem\n<ref> of section\n<ref>.\n\n\n\n \u00a7.\u00a7 Another conjecture\n\n\nA key ingredient for both the proof and the implementation is the geometric\nform of Hahn-Banach theorem: in codimension 1, if S is a finite set of\nvectors, from 0 \u2209S, we get a vector N such that N.V > 0 for\nall V \u2208 S. Unfortunately, we could not find nor prove a similar result for\nconvex sets of full rank matrices. This suggests the following very\ninteresting conjecture:\n\n<ref>\n  Let 1 < m \u2264 n be two natural numbers, let S \u2282Mat_m,n(\u211d) be a\n  convex set of matrices of rank m. There exists a matrix M \u2208Mat_m,n(\u211d) such that M  A + A  M is symmetric definite and\n  positive for all A \u2208 S.\n\n\nThis Hahn-Banch conjecture also allows for a notion of certificate\nallowing to search for a decomposition using efficient floating point\ncomputations, and rechecking the final result using exact rational arithmetic.\nWe can check quickly that M  A + A  M is symmetric definite and\npositive using Choleski decompostion for each matrices A in S (if S is\nfinite). This does not require to compute the spectrum of the matrix.\n\nUnfortunately, we do npt know how to implement a test to decide if all\nmatrices in a convex set of matrices are fullrank (used in <ref>), that produces\na certificate. A constructive proof of conjecture <ref> would likely\nprovide such a test.\n\nTo be able to propose an implementation working in codimension greater than\none, we use a simpler sufficient condition, using only scalar products, that\nimplies (<ref>). This means we have stronger evidence for another\nconjecture <ref> using this stronger condition than for conjecture\n<ref> using (<ref>).\n\n\n\n \u00a7.\u00a7 Search for a simplicial decomposition\n\n\nOur implementation is described in section <ref> and is\navailable on github:\n\n  .\n\nIt implements a semi-algorithm building a simplicial decomposition satisfying\nour criteria. This means we can solve non-degenerate systems of homogeneous\nreal polynomial equations. Non-degenerate means that the jacobian matrix of the\nsystem is full rank at point that are in the solution.  By solving we\nmean finding a piecewise affine approximation of the solution that is isotopic\nto the real solution. It allows to compute topological invariants of the\nsolution and in particular the number of connected components and the Betti\nnumbers of each component (see for instance the appendix B.3 of\n<cit.> for definitions). It is a semi-algorithm, which means\nthat it may loop when the system of polynomials is degenerated. Our\nsemi-algorithm terminates, in principle, if we know that the system of polynomials is\nnon-degenerated.\n\nIn codimension one, our implementation is exact and provides a proved result\nabout the hypersurface that reposes only on the correction of the final test\nusing the certificate. This test is a rather short piece of code and would\nbe easy to rewrite. For codimension greater than one, the validity of the\nanswer of our algorithm depends upon conjecture <ref>.\n\nThe search for an adequate simplicial decomposition is in an early\nstage. Still some examples are already quite interesting. For instance, we are\nable to compute Betti numbers of random cubic given by a random homogeneous\npolynomials up to dimension 6 in less than one hour. Moreover, to our\nknowledge, there is no available exact implementation working in arbitrary\ndimension and codimension.\n\n\n\n \u00a7.\u00a7 Related work\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Viro's method\n\n\nOur main result may be seen as some inverse of Viro's method\n<cit.>, more precisely the combinatorial patchworking version for\ncomplete intersection <cit.>. Indeed, Viro's method allows for the\nconstruction of polynomials with a zero locus having the same topology than a\ngiven piecewise linear variety. We do the opposite.\n\nAn important difference is that we use arbitrary simplicial decomposition\nrather than the Newton polytope of polynomials of a chosen degree, reflected\nin each orthant.  Due the fact that we do not use only polynomial and\ntherefore Newton Polytope, we did not manage to use <cit.> to\nshorten the proof.\n\n\n\n  \u00a7.\u00a7.\u00a7 Decomposition methods using Descartes' rule of sign\n\n\nFor univariate polynomials, there is a similar available criteria: Descartes'\nrule of sign. It allows to ensure that a polynomial as at most one root in a\ngiven interval. There are many attempts to generalise this rule to the\nmultivariate case. Most of these work\n<cit.> only consider the zero dimensional\ncase. They give an upper bound of the number of solutions. If this upper bound\nis one, it would allow to isolate each solution. A counter-example to Roy and\nItenberg conjecture <cit.> given by Li and Wang\n<cit.>, means that even for the zero dimensional case, there is no\nknown generalisation of Descartes' rule of sign that works in all cases.  In a\nrecent work <cit.> Descates rules of sign is generalised\nto arbitrary hypersurfaces, but only give a bound to the number of components\nwhich is not enough to compute the topology of hypersufaces.\n\n\n\n  \u00a7.\u00a7.\u00a7 Other decomposition methods\n\n\nOur approach is similar to many other algorithms that work by subdivising the\nambient space in hypercubes or simplices. See <cit.> for a book covering\nmost algorithms in the domain. In dimension 3, Marching cube algorithms usually\nensure correct topology between the piecewise trilinear function given by the\nvalue at the vertex of each hypercube and the produced piecewise affine\nvariety <cit.>. There are not many algorithms for\nhypersurfaces in arbitrary dimension, we may cite <cit.>.\n\nFor works that provide exact algorithms using decomposition, in the case of polynomials\nfor 2D or 3D curves or 3D surfaces, we may cite <cit.>. Some of\nthese works, like <cit.> also use Bernstein basis in the\nimplementation. This latter also uses Descartes' rule of sign of the partial\nderivative of the polynomials.\n\nAs we mentioned it previously, we think a key property of our criteria to stop\na decomposition is its global nature. Moreover, we are not aware of any\ncriteria that would work in arbitrary dimension and codimension.\n\n\n\n  \u00a7.\u00a7.\u00a7 Algebraic methods\n\n\nOther algorithms, which are exact to compute topological invariants of algebraic\nvariety, are roughly based on the decidability of the theory of real closed\nfields. Thus, they are more algebraic, using cylindrical\ndecompositions, Groebner basis, resultants, \u2026. They have the main\nadvantage of being able to deal with arbitrary singularities, but are of a\nvery different nature. Moreover, very few of these algorithms have free\nimplementations and we could not compare them with our algorithm, for instance\non the computation of Betti numbers of random cubic in dimension up to 6.\n\nSome available implementations, that could fit in this algebraic category, are limited to curves\nand surfaces like  <cit.> or to the zero\ndimensional case like  <cit.>. Those two are probably the\nbest ones available. It is worth noticing that, unlike most available\nimplementation for curve and surfaces,  does not limit the\nnumber of variables and allow to compute a surface embedded in a space of high\ndimension. However, unlike ,  is only using\narbitrary precision floating point arithmetic and is not an exact algorithm.\n\n\n\nCurrently the above cited algorithms support some management of\nsingularities and seem faster than our algorithm. This is to be expected as it\nis natural that more general algorithms are slower than specialised\nones. Moreover, our search for a simplicial decomposition that satisfies our\ncriteria is in an early stage.  We outline below some directions of research\nthat could allow our criteria to be used in an algorithm that could compete with\nthe state of the art algorithms.\n\nRemark: a lot of the algorithms found in the literature are not freely available\nor hard to install. We only succeeded to install  and !\n\n\n\n \u00a7.\u00a7 Further theoretical research\n\n\nApart from proving or disproving the afford mentioned conjectures,\nit would be nice to provide a complexity analysis for our algorithm. This will\nrequire (as for some algorithms searching for roots of univariate polynomials), a\nmeasure of regularity of the system of polynomials. This bound will probably\nbe very bad because it will assume the worst everywhere, but it would still\nbe interesting.\n\nWe would like to extend our work to product of projective spaces,\nweighted projective spaces or compact of \u211d^n with a border\ncondition allowing the variety to meet the border.\n\nFor singular varieties, it is likely that our criteria is still correct for\nsingularities which are affine subvariaties, provided that all singularities\nof dimension m are entirely covered by some faces of the simplicial\ndecomposition of dimension m. For instance, isolated points must be among\nthe vertices of the decomposition. Then, the only modification of our criteria\nis to ignore the singular faces and it seems to work. We tested this on\nisolated singularities, and this seems to work.  Singularities which are not\naffine subvarieties seem must more challenging.\n\n\n\n \u00a7.\u00a7 Further implementation research\n\n\nThe main problem with the current implementation is that we do not know yet\nwhat are the best triangulations for our criteria, especially in the case of\ncodimension greater than one. For instance, if we impose the vertices of the\ndecomposition, what is the best triangulation to try to meet the criteria?\nCurrently we use the convex hull of the vertices projected on the unit\nsphere. This is similar to Delauney's triangulation. This is frame independant,\nbut there is no reason that such triangulations are the best to meet our\ncriteria for a given polynomial system.  The same is true for the choice of\nvertices. Currently, we favour critical points as it seems to give good\nresults, but this is not frame independant and does not always give enough\npoints and we don't really known what other points to choose.\n\nWe should also note that our implementation is written in OCaml using functors\nto parameterise the implementation by the representation of numbers, because\nit allows for rapid prototyping. A C implementation optimised for speed could\ngain a factor 2 or 3 and parallelisation could allows to gain a factor 10 and\nshould be possible using OCaml 5.\n\nWe think it is possible to reach computing time matching those of existing\ndecomposition algorithms for curves and surfaces.\n\nAnother way to improve the efficiency is to combine our criteria with variables\nelimination techniques. An idea would be to perform easy eliminations,\nbefore using our algorithm. For instance, one could eliminate a variable if it\noccurs only in one monomial of some polynomials. The current implementation is\nnot even doing elimination of linear equations! But this is planed.\n\n\n\n \u00a7.\u00a7 Thanks\n\n\nWe thank St\u00e9phane Simon for showing us his marching cube implementation,\n25 years ago, starting our interest in this research topic. We thanks Ilia\nItenberg for several discussions, in particular about Viro's method. Finally,\nwe heartily thanks Fr\u00e9d\u00e9ric Mangolte for the lengthy discussions on this\nresearch, his comments and great help.\n\n\n\n\n\n\n\u00a7 NOTATION AND CONVENTION\n\n\nHere are a few notation we use:\n\n\n\n  * S denotes the convex hull of a subset S of \u211d^n.\n\n  * When f: \u211d^n \u2192\u211d is\n  differentiable in all direction, we denote \u2207(f)(x)(v) the\n  differential of f at x in the direction v. In general, we only have\n  \u2207(f)(x)(\u03bb v) = \u03bb\u2207(f)(x)(v)  for \u03bb > 0 as\n  v \u21a6\u2207(f)(x)(v) may be non linear.\n\n  * When f: \u211d^n \u2192\u211d^m is differentiable\n  \u2207(f)(x) will denote the m \u00d7 n Jacobian matrix.\n\n\n\n\n  \n*Simplicial decomposition\n\nIn section <ref>, we consider  simplicial decomposition of a compact polyhedron \ud835\udd42\u2282\u211d^n. By\nsimplicial decomposition, we mean,  as in <cit.>, a family of simplices\n(S_i)_i \u2208 I such that:\n\n\n  * \ud835\udd42 = \u222a_i \u2208 I S_i\n\n  * \u2200 i,j \u2208 I, i\u2260 j, S_i \u2229 S_j is a simplex of dimension at most n-1 which is the\n  common face of S_i and S_j.\n\n  * \u2200 i,j \u2208 I, i\u2260 j, S_i \u2229S_j = \u2205.\n\n\n\n\n  \n*Decomposition in simplicial cones\n\n\n  A simplicial cone, is a set S, that is defined from a simplex S'\n  that do not contain 0 by\n  \n    S = {\u03bb x, x \u2208 S', \u03bb > 0 }\n\n\n\nIn section <ref> and after, we consider decomposition in simplicial\ncones of \u211d^n+1. We mean a family of simplicial cone\n(S_i)_i \u2208 I such that:\n\n\n  * \ud835\udd42 = \u222a_i \u2208 I S_i\n\n  * \u2200 i,j \u2208 I, i\u2260 j, S_i \u2229 S_j is a simplicial cone of dimension at most n which is the\n  common face of S_i and S_j.\n\n  * \u2200 i,j \u2208 I, i\u2260 j, S_i \u2229S_j = \u2205.\n\n\n\n\n  \n*Bernstein basis\n\nIn section <ref> we refer to Bernstein basis. In the case of\nhomogeneous polynomials of degree d, it is\n \n    (d!/\u03b1! x^\u03b1)_\u03b1\u2208\u2115^d,  \u03a3_i  \u03b1_i = d where  x^\u03b1 = \u03a0_i\n      x_i^\u03b1_i and \u03b1! = \u03a0_i \u03b1_i!\n\n\nThe key property of Bernstein basis it that its value in the unit simplex\nlies in the convex hull of the coefficients. It is an immediate consequence of\nDe Casteljau algorithm to compute the value of the polynomial as a\nbarycenter. We also use this property with the gradient of a polynomial, seen\nas a polynomial whose coefficients are vectors.\n\n\n\n\n\n\n\n\u00a7 HYPERSURFACES ON A COMPACT POLYHEDRON\n\n\nHere is a first theorem for an hypersurface which is enclosed in the interior\nof a compact polyhedron of \u211d^n. This hypothesis seems essential and\nunnatural, but will disappear when we consider the entire projective space of\ndimension n.\n\n\n  Let \ud835\udd42\u2282\u211d^n be a compact polyhedron.\n  Let (S_i)_i\u2208 I be a simplicial decomposition of \ud835\udd42.\n  Let f : \u211d^n \u2192\u211d of class C^1.\n  Let V = { x \u2208\ud835\udd42, f(x) = 0} be the zero locus of f\n  restricted to \ud835\udd42.\n  Assume that V \u2229\u2202\ud835\udd42 = \u2205 cond0.\n\n  We define f\u0303 : \ud835\udd42\u2192\u211d the piecewise affine\n  function such that for all i \u2208 I, f\u0303S_i is affine\n  and for any v vertex of S_i, we have\n  f(v) = f\u0303S_i(v).\n  We define the following:\n  \n  \n  * \u1e7c = { x \u2208\ud835\udd42, f\u0303(x) = 0} the zero locus of\n  f\u0303.\n  \n  * \ud835\udd42(f) = { x \u2208\ud835\udd42, f(x)f\u0303(x) \u2264 0}.\n  \n  * \u2207\u0303f(x) = {\u2207f\u0303S_i(x), x \u2208 S_i\n    }\u2282\u211d^n\n  \n  * G(f,x) = {\u2207 f(x) }\u222a\u2207\u0303f(x) \u2282\u211d^n\n  \n  If the condition below holds, then V and \u1e7c are isotopic:\n  \n    \u2200 x \u2208\ud835\udd42(f), 0 \u2209G(f,x)\n\n\n\n\n  Assume the definitions and hypotheses of the theorem.\n  For any x \u2208\u211d^n and \u03f5 >\n  0, we define\n  \n    G(f,x,\u03f5) = \u22c3_y \u2208\ud835\udd42(f), y - x < \u03f5 G(f,y)\n\n\n  Remark: we need to define G(f,x,\u03f5) for x \u2208\u211d^n because\n  the convolution product below will cover the border of\n  \ud835\udd42(f). Clearly, for points too far from \ud835\udd42(f), we have\n  G(f,x,\u03f5) = 0.\n\n  We now prove that there exists \u03f5 > 0 such that\n  \n    \u2200 x \u2208\ud835\udd42(f), 0 \u2209G(f,x,\u03f5)\n\n  We proceed by contradiction and choose a sequence (x_n)_n \u2208\u2115 in\n  \ud835\udd42(f) such that 0 \u2208G(f,x_n,1/n). As\n  \ud835\udd42(f) is compact, we can assume that x_n converges to x_\u221e\u2208\ud835\udd42(f). Let us define\n  \n    \u03b4 = min_i\u2208 I, x_\u221e\u2209S_i(x_\u221e,S_i)\n\n  We have\n  for any y \u2208\ud835\udd42,\n  y - x_\u221e < \u03b4 and y \u2208 S_i implies x_\u221e\u2208 S_i and therefore\n  \u2207\u0303f(y) \u2282\u2207\u0303f(x_\u221e).\n  Thus, for \u03b4 n > 1, we have\n  \n    0 \u2208{\u2207 f(y), y \u2208\ud835\udd42, x_n - y < 1/n}\u222a\u2207\u0303f(x_\u221e)\n\n\n  The set {\u2207 f(y), y \u2208\ud835\udd42, x_n - y < 1/n}\n  converges to the singleton {\u2207 f(x_\u221e)} for the Haussdorf metric\n  and \u210b is continuous for that metric. Hence,\n  \n    {\u2207\n        f(y), y \u2208\ud835\udd42, x_n - y < 1/n}\u222a\u2207\u0303f(x_\u221e)\u27f6G(f,x_\u221e) when  n \u27f6 +\u221e\n\n  This implies 0 \u2208 G(f,x_\u221e), because it is a closed set,\n  which contradicts (<ref>).\n\n  By the geometric form of Hahn-Banach, we\n  can find N: \u211d^n \u2192\u211d^n such that\n  \n    \u2200 x \u2208\u211d^n, \u2200 v \u2208 G(f,x,\u03f5), N(x).v > 0\n\n\n  Let us choose a function \u03bc : \u211d^n \u2192\u211d_+ of C^\u221e\n  class, with support in the sphere of radius\n  \u03f5 and such that \u222b_\u211d^n\u03bc(u) du = 1. We\n  define:\n\n  \n    N'(x) = N \u22c6\u03bc = \u222b_\u211d^n N(u - x) \u03bc(u) du\n\n\n  N' is of C^\u221e class on \u211d^n. Let us consider v \u2208\n  G(f,x) for x \u2208\ud835\udd42, if u < \u03f5 and therefore x - (u - x) < \u03f5,\n  we have v \u2208 G(f,u-x,\u03f5) which implies N(u - x).v > 0. This\n  establishes:\n\n  \n    \u2200 x \u2208\ud835\udd42(f), \u2200 v \u2208 G(f,x), N'(x) . v > 0\n\n\n  The next step is to consider the maximal integral curves of N'. By\n  The Cauchy-Lindel\u00f6f-Lipshitz-Picard theorem those curves exist, are\n  unique in \ud835\udd42(f) and continuous in the initial conditions.\n\n  For t \u2208 [0,1] we define f_t : \ud835\udd42\u2192\u211d, such that\n  f_t(x)  = t f(x) + (1 - t) f\u0303(x). We remark that\n  f\u0303 is differentiable in every direction and that\n  the differential of f\u0303 at x in the direction D is given\n  by D.V for some V \u2208\u2207\u0303f(x). Remark the differential in the\n  direction D and -D may be different.\n\n  Therefore, the differential of f_t at x \u2208\ud835\udd42(f) in the\n  direction N'(x) is given by the expression N'(x).(t \u2207 f(x) + (1 - t)\n  V) for some V \u2208\u2207\u0303f(x) and is therefore positive by\n  (<ref>).\n\n  This means that the functions f_t(x) are increasing along an integral\n  curve of N' and therefore each integral curve meet the variety\n  V_t = { x \u2208\u211d, f_t(x) = 0} for t \u2208 [0,1] in at most one\n  point. Remark that V_t \u2282\ud835\udd42(f).\n\n  To finish the proof we must show that the maximal integral curves of N' have their\n  extremity in the border of \ud835\udd42(f), which are points x with either\n  f(x) = 0 or f\u0303(x) = 0, by the condition (<ref>). This is\n  true because we can find K > 0 such that \u2200 x \u2208\ud835\udd42(f), K\n  < N'(x) by compacity and regularity of N'. This means that a maximal integral\n  curve of N' will join the border of \ud835\udd42(f) on an interval\n  [t_1,t_2] for t_2 - t_1 < M/K where M is an upper bound of\n  both f\n  and f\u0303 on \ud835\udd42.\n\n  Therefore, (x,t) \u21a6 f_t(x) is the wanted isotopy.\n\n\n\n\n\n\n\u00a7 HYPERSURFACES ON THE PROJECTIVE SPACE\n\n\nWe now give a condition to establish that an hypersurface in \ud835\udd4a^n\nthe unit sphere of \u211d^n+1\ndefined by a positively homogeneous C^1 function in n+1 variables is istopic to a\nvariety defined by a piecewise linear function on\n\u211d^n+1. We state the theorem on the unit sphere \ud835\udd4a^n\nbecause it is simpler to write the condition than working on the projective space.\n\n\n  Let (S_i)_i\u2208 I be a decomposition of \u211d^n+1 in simplicial\n  cones with vertices on \ud835\udd4a^n, the\n  unit sphere of \u211d^n+1.\n  Let p : \u211d^n+1\u2192\u211d be a positively homogeneous C^1\n  function of degree d.\n  (i.e. p(\u03bb x) =\n  \u03bb^d p (x) for any \u03bb\u2208\u211d_+ and x \u2208\u211d^\ud835\udd5f+1).\n  Let V = { x \u2208\ud835\udd4a^n, p(x) = 0} be the zero locus of p\n  restricted to \ud835\udd4a^n.\n\n  We define p\u0303 : \u211d^n+1\u2192\u211d the piecewise linear\n  function such that for all i \u2208 I, p\u0303S_i is linear\n  and for any v vertex of S_i, we have\n  p(v) = p\u0303S_i(v).\n  We define the following:\n  \n  \n  * \u1e7c = { x \u2208\ud835\udd4a^n, p\u0303(x) = 0} the zero locus of\n  p\u0303.\n  \n  * \ud835\udd42(p) = { x \u2208\ud835\udd4a^n, p(x)p\u0303(x) \u2264 0}.\n  \n  * \u2207\u0303p(x) = {\u2207p\u0303S_i(x), x \u2208 S_i\n    }\u2282\u211d^n+1\n  \n  * G(p,x) = {\u2207 p(x) }\u222a\u2207\u0303p(x) \u2282\u211d^n+1\n  \n  If the following condition (<ref>) holds, then V and \u1e7c are isotopic:\n  \n    \u2200 x \u2208\ud835\udd42(p), 0 \u2209G(p,x)\n\n  This implies that the projective varieties associated to V and \u1e7c\n  are isotopic if the simplicial decomposition is stable by the symmetry x\n  \u21a6 -x.\n\n\n\n  By taking \ud835\udd42 = \ud835\udd4a^n, we can use exactly the same\n  definitions and reasoning as the proof of theorem <ref> until\n  the definition of N' of C^\u221e class satisfying\n\n  \n    \u2200 x \u2208\ud835\udd42(p), \u2200 v \u2208 G(p,x), N'(x) . v > 0\n\n\n  We must change the definition of p_t(x), using  d the degree of p:\n  \n    p(x)    =   p\u0303(x x^d-1) \n        p_t(x)    =    t p(x) + (1 - t)p(x)\n\n\n  We have p_t(\u03bb x) = \u03bb^d p_t(x) for all \u03bb\u2208\u211d_+.\n  As in the previous proof, p\u0303(x) has a differential in any direction\n  v. Hence, the functions p and p_t are differentiable in\n  any direction, hence they satisfy Euler relation:\n  \n    \u2207p(x)(x) = d  p(x)  \u2207 p_t(x)(x) = d  p(x)\n\n\n  We need more precision for the derivative of p\u0303: if x,v \u2208\u211d^n+1 we can define i(x,v) \u2208 I such that x \u2208 S_i(x,v)\n  and x + hv \u2208 S_i(x,v) for all h > 0 small enough. We also define\n  S(x,v) = S_i(x,v). Using this notation, the gradient of p\u0303(x) in the direction v is given by\n  \n    \u2207p\u0303(x)(x)    =   \u2207p\u0303S(x,v)(x).v\n\n  But as p\u0303S(x,v) is linear, its gradient\n  is constant and we can simply write \u2207p\u0303S(x,v).v. Remark: i(x,v) is not uniquely defined, but the\n  choice of index in I does not change the value of the differential in a\n  given direction.\n\n  Using these notations, we compute:\n  \n    \u2207p(x)(v)    =    d \u2207p\u0303S(x,v).v x^d-1\u2207 p_t(x)(v)    =    (t \u2207 p(x) +\n          (1-t) d \u2207p\u0303S(x,v)x^d-1).v\n\n\n  We now prove that for x \u2208\ud835\udd42(p), N'(x) is not normal to\n  the unit sphere at x. Let us choose x \u2208\ud835\udd42(p), we can\n  find t \u2208 [0,1] such that p_t(x) = t p(x) + (1 - t)p(x) = 0\n  (take t = 0 if p(x) = p\u0303(x) = 0 and t = p(x)/p(x) - p(x) otherwise). This is well defined because in\n  \ud835\udd42(p) we can only have p(x) = p(x) if p(x) = p\u0303(x) = 0. Let us define\n  \n    V = t \u2207 p(x) +  (1-t) d \u2207p\u0303S(x,v)\n\n  The gradient p_t(x) in the direction of x,\n  is given by V.x = p_t(x) = 0 by Euler relation.\n  V \u2208 (t + (1-t)d) G(p,x) and t + (1-t)d = d - t(d-1) > 0 for t \u2208\n    [0,1].\n    This means that N'(x) can not be normal to\n  \ud835\udd4a^n at x as this would imply V.N'(x) = 0 which is impossible\n  by (<ref>). This ends the proof that  N'(x) is not normal to\n  the unit sphere at x.\n\n  We can now define for all x \u2208\ud835\udd42(p), N^T(x) = N'(x) -\n  (N'(x).x)x, the projection of N'(x) on the hyperplane tangent to\n  \ud835\udd4a^n at x. For x \u2208\ud835\udd42(p),\n  as the polyhedra S_i are simplicial cones we can assume S(x,N'(x)) =\n  S(x,N^T(x)) that we will simply write S(x). Indeed, for h > 0 small\n  enough, x + hN'(x) and x + hN^T(x) belong to the same simplicial cone S_i\n  because they only differ by a vector in the direction of x and S_i is a cone.\n\n  Using this notation, for a point x \u2208\ud835\udd42(p) such that p_t(x) =\n  0, the gradient of p_t(x) in direction N'(x)\n  and N^T(x) verify:\n  \n    \u2207 p_t(x)(N'(x))    =    (t \u2207 p(x) + (1-t) d \u2207p\u0303S(x) ).N'(x)    >    0  by (<ref>) \u2207 p_t(x)(N^T(x))    =    (t \u2207 p(x) + (1-t) d \u2207p\u0303S(x) ).N^T(x)    =    (t \u2207 p(x) + (1-t) d \u2207p\u0303S(x) ).(N'(x) - (x.N'(x))x)    =    (t \u2207 p(x) + (1-t) d \u2207p\u0303S(x) ).N'(x)  by Euler relation   >    0\n\n\n\n  Let \u03b3 : J \u2192\ud835\udd42(p) be a maximal integral curve of\n  N^T. This means \u03b3'(u) = N^T(\u03b3(u)).\n  There are particular cases where\n  \u03b3 is reduced to one point x when p(x) = p\u0303(x) = 0.\n\n  In all other cases, as p\u0303 is derivable in all directions, u \u21a6p\u0303(\u03b3(u)) is derivable (but not necessarily of C^1\n  class). Similarly u \u21a6p(\u03b3(u)) and u \u21a6\n  p_t(\u03b3(u)) for t \u2208 [0,1] and t(u) = p(u)/p(u)\n    - p(u) are derivable. Moreover, a point x \u2208\ud835\udd42(p) with p(x) = 0 or p\u0303(x) = 0 can only be\n  at the extremity of \u03b3, otherwise, by (<ref>), \u03b3 would leave\n  \ud835\udd42(p). This means that p and p\u0303 have constant\n  sign on \u03b3 and may be null only on the extremity. This implies that\n  p(\u03b3(u)) - p(\u03b3(u)) is of contant signe along such a\n  curve \u03b3.\n\n  We have:\n  \n    p_t(u)(\u03b3(u))    =    0\n        (p(\u03b3(u)) - p(\u03b3(u))) t'(u) + \u2207\n        p_t(u)(\u03b3(u))(\u03b3'(u))    =    0\n        (p(\u03b3(u)) - p(\u03b3(u))) t'(u)    =   \u2207\n        p_t(u)(\u03b3(u))(N^T(\u03b3(u))) \n        (p(\u03b3(u)) - p(\u03b3(u)))t'(u)    >    0\n\n\n  This means that t(u) is monotonous along any curve \u03b3 that is not\n  reduced to one point. As in the previous proof, N^T(\u03b3(u)) is never\n  null and is minored by some constant K > 0, thus the extremity of maximal integral\n  curve \u03b3 will necessarily be a point where p is null and another\n  point where p\u0303 is null.\n\n  This means that p_t defines the isotopy we are looking for.\n\n\n\n\n\n\n\n\u00a7 INCREASING CODIMENSION\n\n\nWe propose the following conjecture for several positively homogeneous C^1 funciton:\n\n\n  Let (S_i)_i\u2208 I be a decomposition of \u211d^n+1 in simplicial\n  cones with vertices on \ud835\udd4a^n, the\n  unit sphere of \u211d^n+1.\n  Let p = (p_1,\u2026,p_m) be a family of m \u2264 n positively homogeneous\n  C^1 functionx from \u211d^n+1 to \u211d^\ud835\udd5f of respective\n  degree (d_1,\u2026,d_m) not necessarily equal (i.e. p_i(\u03bb x) =\n  \u03bb^d_i p_i (x) for any \u03bb\u2208\u211d_+ and x \u2208\u211d^\ud835\udd5f+1).\n  Let V = { x \u2208\ud835\udd4a^n, p(x) = 0} be the zero locus of p\n  restricted to \ud835\udd4a^n.\n\n  We define p\u0303 : \u211d^n+1\u2192\u211d^m the piecewise linear\n  function such that for all i \u2208 I, p\u0303S_i is linear\n  and for any v vertex of S_i, we have\n  p(v) = p\u0303S_i(v).\n  We define the following:\n  \n  \n  * \u1e7c = { x \u2208\ud835\udd4a^n, p\u0303(x) = 0} the zero locus of\n  p\u0303.\n  \n  * \ud835\udd42(p) = { x \u2208\ud835\udd4a^n, \u2200 i \u2208{1,\u2026,m}, p_i(x)p\u0303_i(x) \u2264 0}.\n  \n  * \u2207\u0303p(x) = {\u2207p\u0303S_i(x), x \u2208 S_i\n    }\u2282Mat_m,n+1(\u211d)\n  \n  * G(p,x) = {\u2207 p(x) }\u222a\u2207\u0303p(x)  \u2282Mat_m,n+1(\u211d)\n  \n  If the condition below holds, then V and \u1e7c are isotopic:\n  \n    \u2200 x \u2208\ud835\udd42(p), \u2200 A \u2208G(p,x), A  is of\n          maximal rank\n\n\n\nThis conjecture is the natural generalisation of theorem <ref>\nand our implementation described in the next section suggest that it might be true.\n\nUnfortunately, to adapt the proof of the previous section, we need a result\nanalogous to Hahn-Banach for convex set of full rank matrices. This would give\nthe countepart of the vector N(x) in the previous proof and also the\ncertificate we need for the implementation.\n\nHere is the expected result that seems unknown and that we could not prove\nneither disprove:\n\n\n  Let 1 < m \u2264 n two natural numbers, let S \u2282Mat_m,n(\u211d) a\n  convex set of matrices of rank m. There exists a matrix M \u2208Mat_m,n(\u211d) such that M  A + A  M is symmetric definite and\n  positive for all A \u2208 S.\n\n\nWe could not prove that conjecture <ref> implies conjecture <ref>\nbut we feel that it is a key element of the proof. A way to prove this\nimplication would be to ensure that N^T : \ud835\udd42(p) \u2192Mat_m,n+1(\u211d) satisfies the Schwartz condition.\nThis means we should have that the\nderivative of N_i^T in the direction N_j^T should be equal to the\nderivative of N_j^T in the direction N_i^T.\nThen, we could construct unique integral hypersurfaces of N^T and\nprobably finish the proof. To to this, an idea if to build the kernel used in the\nconvolution product defining N' by solving a partial differential equation...\n\nAs we can not prove constructively conjecture <ref>, we have no\nalgorithm to test condition <ref> that would give a certificate.\nTherefore, for our implementation, we use a stronger condition using this definition:\n\n\n  Let 1 < m \u2264 n two natural numbers, let S \u2282Mat_m,n(\u211d) a\n  set of matrices. S is said to be\n  strongly full rank if\n  \n    \u2200\u03c3\u2208{-1,1}^m, 0 \u2209{\u03c3 A, A \u2208 S}\n\n\n\n\nIf S \u2282Mat_m,n(\u211d) is strongly full rank, then\nS contains only full rank matrices.\n\n\n\n  If A \u2208S is not full rank, then there exists\n  v \u2208\u211d^m such that v A = 0.\n  Take \u03c3 = (\u03c3_1, \u2026, \u03c3_n) such that \u03c3_i = 1 if v_i\n  \u2265 0 and \u03c3_i = -1 otherwise and we find\n  0 \u2208{\u03c3 A, A \u2208 S}.\n\n\nThis stronger condition gives a weaker conjecture that correspond to our implementation:\n\n  Let (S_i)_i\u2208 I be a decomposition of \u211d^n+1 in simplicial\n  cones with vertices on \ud835\udd4a^n, the\n  unit sphere of \u211d^n+1.\n  Let p = (p_1,\u2026,p_m) be a family of m \u2264 n positively homogeneous\n  C^1 functionx from \u211d^n+1 to \u211d^\ud835\udd5f of respective\n  degree (d_1,\u2026,d_m) not necessarily equal (i.e. p_i(\u03bb x) =\n  \u03bb^d_i p_i (x) for any \u03bb\u2208\u211d_+ and x \u2208\u211d^\ud835\udd5f+1).\n  Let V = { x \u2208\ud835\udd4a^n, p(x) = 0} be the zero locus of p\n  restricted to \ud835\udd4a^n.\n\n  We define p\u0303 : \u211d^n+1\u2192\u211d^m the piecewise linear\n  function such that for all i \u2208 I, p\u0303S_i is linear\n  and for any v vertex of S_i, we have\n  p(v) = p\u0303S_i(v).\n  We define the following:\n  \n  \n  * \u1e7c = { x \u2208\ud835\udd4a^n, p\u0303(x) = 0} the zero locus of\n  p\u0303.\n  \n  * \ud835\udd42(p) = { x \u2208\ud835\udd4a^n, \u2200 i \u2208{1,\u2026,m}, p_i(x)p\u0303_i(x) \u2264 0}.\n  \n  * \u2207\u0303p(x) = {\u2207p\u0303S_i(x), x \u2208 S_i\n    }\u2282Mat_m,n+1(\u211d)\n  \n  * G(p,x) = {\u2207 p(x) }\u222a\u2207\u0303p(x)  \u2282Mat_m,n+1(\u211d)\n  \n  If \u2200 x \u2208\ud835\udd42(p), G(p,x) is strongly full rank, then V and \u1e7c are isotopic.\n\n\n\n\n\n\n\n\n\u00a7 IMPLEMENTATION\n\n\nObtaining an implementation from theorem <ref> or conjecture\n<ref> is not very difficult.\n\nLet (S_i)_i\u2208 I be a decomposition of \u211d^n+1 in simplicial\ncones with vertices on \ud835\udd4a^n, the unit sphere of \u211d^n+1.\nLet p = (p_1,\u2026,p_m) be a family of m \u2264 n homogeneous polynomials\nwith n+1 variables.\n\nLet us consider now a simplicial cone F which is a subset of a face of\ndimension d_F of one\nof the simplex S_i for i \u2208 I. F could be reduced to a vertex when d_F\n= 0 or could\nbe of dimension d_F=n+1. By doing a change of coordinates sending\nthe unit simplex of dimension d_F to F and writing the resulting polynomials in the Berstein\nbases, we can use the fact that the value of polynomials or their\ndifferentials are in the convex hull of the coefficients to check that the\ncondition of our theorem <ref> or conjecture\n<ref> holds in F.\n\nThis leads to the following procedure:\n\n[TEST_FACE]  \n\n  Inputs:\n  \n  \n  * (S_i)_i\u2208 I a decomposition of \u211d^n+1 in simplicial\n    cones with vertices on \ud835\udd4a^n.\n  \n  * p = (p_1,\u2026,p_m) a family of m \u2264 n\n    homogeneous polynomials with n+1 variables.\n  \n  * p\u0303 = (p\u0303_1,\u2026,p\u0303_m) the piecewise linear\n    functions associated to p and (S_i)_i\u2208 I.\n  \n  * a simplex F of dimension d_F which is included in a face of\n    one of the S_i.\n  \n  * a minimal size for simplices.\n  \n  * a heuristic to split a simplex in 2 (that may use all other inputs).\n  \n  Algorithm:\n  \n  \n  * Build the matrix P sending the unit simplex of dimension d_F to F\n  \n  * Write p(M(x)) and p\u0303(M(x)) in the Berstein basis, this gives\n    two families of homogeneous polynomials q(x) and q\u0303(x) with d_F + 1\n    variables. Remark: if F is\n    a vertex, it is equivalent to evaluating the polynomials!\n  \n  * If there is 1 \u2264 i \u2264 m such that all coefficients of q_i and\n    q\u0303_i have the same sign, return  because F does not meet \ud835\udd42(p).\n  \n  * Otherwise, compute the list L such that {S_l, l \u2208 L} is the set all\n    simplicies that contains F.\n  \n  * Write \u2207 p(M(x)) and, for all l \u2208 L, \u2207p\u0303S_l(M(x)) in the Berstein bases. Define the set A of m \u00d7 (n + 1)\n    matrices which are the coefficients of those polynomials. If for all\n    \u03c3\u2208{-1,1}^m we have 0 \u2209{\u03c3 M, M \u2208 A}\n    return  because A is strongly full rank.\n  \n  * Otherwise, if F is not too small, subdivide F in F_1 and F_2 and\n    recursively call the procedure  on F_1 and F_2 and\n    return  if both calls return .\n  \n  * Otherwise, if F was too small, return .\n  \n\n\nUsing this procedure, we can implement our main loop:\n\n[MAIN_LOOP]  \n\n  Inputs:\n  \n  \n  * (S_i)_i\u2208 I a decomposition of \u211d^n+1 in simplicial\n    cones with vertices on \ud835\udd4a^n.\n  \n  * p = (p_1,\u2026,p_m) a family of m \u2264 n\n    homogeneous polynomials with n+1 variables.\n  \n  * p\u0303 = (p\u0303_1,\u2026,p\u0303_m) the piecewise linear\n    functions associated to p and (S_i)_i\u2208 I.\n  \n  * a heuristic to refine the decomposition (that may use all other inputs).\n  \n  * a minimal size for simplices.\n  \n  * a heuristic to split a simplex in 2\n  \n  Algorithm:\n  \n    \n  * For each face F of one of the simplex call the procedure\n      . If all calls return , return p\u0303.\n    \n  * If the procedure  returned  on F,\n      try to refine the decomposition, preferably in a way that splits F.\n    \n  * Update p\u0303 to the new decomposition.\n    \n  * Call back  with the refined subdivition and new\n      p\u0303.\n  \n\n\nHere is the entry point of our implementation:\n\n[MAIN]   \n\n  Inputs:\n  \n  \n  * p = (p_1,\u2026,p_m) a family of m \u2264 n\n    homogeneous polynomials with n+1 variables.\n  \n  * a heuristic to refine a decomposition of \u211d^n+1 in simplicial cones.\n  \n  * a minimal size for simplices.\n  \n  * a heuristic to split a simplex in 2.\n  \n  Algorithm:\n  \n  \n  * Build (S_i)_i\u2208 I a decomposition of \u211d^n+1 in simplicial\n    cones with vertices on \ud835\udd4a^n.\n  \n  * Build p\u0303 = (p\u0303_1,\u2026,p\u0303_m) the piecewise linear\n    functions associated to p and (S_i)_i\u2208 I.\n  \n  * Call the procedure .\n  \n  * If it return p\u0303, build the piecewise affine projective variety of\n    equation p\u0303(x) = 0 and return it.\n  \n\n\n\n  Given p = (p_1,\u2026,p_m) a family of m \u2264 n\n    homogeneous polynomials with n+1 variables,\n  if there is only one polynomial or if conjecture <ref> is true, the\n  above algorithm loops or returns a piecewise affine projective variety that\n  is isoptopic to the variety defined by p(x) = 0.\n\n\n\n  This is a consequence of the definitions and the properties of Bernstein\n  basis. It is important to note that the property \u201c0 is the convex hull\u201d\n  used in the algorithm is invariant by a linear change of variable.\n\n\n\n   Let p = (p_1,\u2026,p_m) a family of m \u2264 n homogeneous polynomials\n   with n+1 variables.  Assume that the matrix \u2207 p(x) is full rank for\n   all x \u2208\ud835\udd4a^n such that p(x) = 0. Then, our algorithm\n   terminates, if the heuristic to refine decompositions, when repeated, gives\n   decompositions such that all simplicial cones have diameter that converges to 0,\n   when intersected with the unit sphere.\n\n\n\n  If the diameter of all simplicial cones restricted to \ud835\udd4a^n are\n  small enough, then p will be almost linear on each of them and the points\n  where p(x) = 0 will be separated from the points where the matrix \u2207\n  p(x) is not full rank. This means that one of the two tests will always\n  succeed in the procedure .\n\n\n\n\n  \n*Test for 0 in the convex hull\n\nClearly we do not want to compute the convex hull to check for one point.\nThis problem is traditionally implemented as a reduction to linear\nprogramming. We chose to implement it directly:\n\nFor a finite set of vector A, we try to minimise N^2 for N = \u2211_V\n  \u2208 A\u03b1_V V with \u03b1_V > 0 for all V \u2208 A and \u2211_V \u2208 A\u03b1_V = 1. We perform this minimisation by alterning two kinds of steps:\n\n  \n  * Linear steps: we solve a linear system to find a direction which\n    is not always a direction of descent but that often offers rapid progress.\n    This kind of steps may set some of the \u03b1_V to zero.\n  \n  * Descent in the direction V \u2208 A if N.V \u2264 0. It is easy to show that\n    N + \u03b1 V/1 + \u03b1^2 < N^2 in this case. This kind\n    of steps increase \u03b1_V, even if \u03b1_V = 0. We stop if there is\n    no such vector V and we know that 0 \u2209A.\n  \n  * We stop if v^2 is too small (meaning we can probably reach 0).\n  \n  * It is important to avoid setting \u03b1_V\n    = 0 in a linear step, followed by a descent in the direction V. This\n    yields to very slow progress. Thus, we do not select\n    V for descent if \u03b1_V was set to 0 by the previous linear step.\n\n\nThis relatively simple algorithm works very well for this specific case and\nmight be the object of a separate publication in the near future. It is worth\nnoticing that our algorithm is not an interior point method nor a method that\nstay on the border of the convex hull.\n\nWe mentioned the algorithm to make it clear that when we fail to find a\ndescent direction, we have N.V > 0 for all V \u2208 A and therefore N is\nthe vector given by the geometric form of Hahn Banach theorem and considered\nby the proof.\n\n\n\n  \n*Certificate and exact algorithm\n\nThe above algorithm is implemented using 64 bits floating point numbers.\nHowever, the procedure  keeps a trace of the subdivision it\ndid as a binary tree and it also keeps in the leaf of the tree a boolean\ngiving the reason of\nsuccess: either  if the sign of the polynomials was constant or\n if the test for the convex\nhull succeeded. In the latter case it also keeps the vectors N given by the\nalgorithm for each value of \u03c3\u2208{-1,1}^m.\n\nSuch a tree is associated to each face of the simplicial decomposition and\nform a certificate.\n\nThis allows to recheck the criteria using exact rational arithmetic and the\nonly operations are:\n\n\n  * change of coordinates in the polynomials,\n\n  * scalar products and\n\n  * comparisons.\n\n\nAs a result the final check of this certificate is fast (in practice faster\nthat the initial computation) and ensures an exact result (if conjecture\n<ref> is true when codimension is greater than 1).\n\n\n\n\n\n\n\u00a7 EXPERIMENTS\n\n\nNote: all figures in this article use a projection of the projective space into\na sphere, so we see the entire variety.\n\n\n\n  \n*Study near singularity\n\nOur first example is with the family of quartic polynomials:\n\n\n    p_\u03f5(x,y,t) =   (x^2+y^2-t^2)^2 + \u03f5 x y (x-y) (x+y)\n\n\nWhen \u03f5 > 0, the curve p_\u03f5(x,y,t) = 0 has four components and it converges\nto a circle of double points when \u03f5\u2192 0. However, a simplicial decomposition with\nonly 24 triangles seems sufficient for any \u03f5>0. Only the number of\nsubdivision of each triangle increases when  \u03f5\u2192 0. Figure <ref> is\nthe simplicial decomposition (in green) and the curve p_\u03f5(x,y,t) = 0 we\nget for some \u03f5>0 (in black):\n\n\n\nWe now give a table that gives for some value of \u03f5, the total computing time,\nthe time for the exact test using rational arithmetic and the\nmaximum number of time we split a simplex in 2 parts (i.e. maximum depth of\nrecursive call in ).\n\n\n\n\n  \u03f5     time     \u211a-time    \u211a-time/time    max splits 5.10^-1     0.079s     0.016s     20%      0 5.10^-2     0.150s     0.022s     15%     6 5.10^-3     0.264s     0.095s     36%     10 5.10^-4     0.607s     0.210s     35%     14 5.10^-5     1.638s     0.656s     40%     175.10^-6     5.380s     2.548s     47%     205.10^-7     17.087s     6.732s     39%     24\n\n\n\nThe maximum number of splits seems linear in the exponent of \u03f5, therefore the\nnumber of subdivision may be at most linear in \u03f5 (some simplices needs less\nsubdivision than others).\n\nWe also observe that the final exact test using rational arithmetic never\nexceeds half of the total running time. Remark: very small \u03f5 would require\nmulti-precision which we implemented using GMP. But it is far too slow in practice.\n\n\n\n  \n*Some curves and surfaces in 2D and 3D\n\nIt is well know that sextic curves have at most 11 components and that this can\nbe realized in three ways: one oval containing p empty ovals and 10 - p\nempty ovals outside for p = 1, 5 or 9 <cit.>. Construction being\nrespectively due to Harnak (figure <ref>), Hilbert (figure\n<ref>) and Gudkov (figure <ref>). Our\nimplementation succesfully computes the topology of these three curves.\n\nWe also experimented succesfullt with two quartic surfaces and two complete\nintersection of degree 3\u00d7 2 and 4 \u00d7 2:\none maximal quartic (referred as \u201cM quartic\u201d, figure <ref>) with two components, a sphere and a sphere with 10 handles\nand another quartic with 10 spheres (referred as \u201cM-2 quartic\u201d, figure\n<ref> in the introduction). We also show the intersection of four planes\n(product of four linear forms) and a sphere which are used to build the M-2\nquartic (referred as \u201cM-2 quartic \u2229 S\u201d). Finally, we tested with a 3D curves which is the\nintersection of a cone and a cubic surface that gives 5 components (referred as\n\u201ccubic \u2229 cone\u201d). This last example is used in\n<cit.> to construct Del Pezzo surfaces of degree 1.\n\nResults are summarised in the table below where we give for each example the\ncodimension (number of polynomials) and projective dimension (number of\nvariables - 1), the total computing time, the time to check the certificate,\nthe total number of simplices in the decomposition and the maximum number of\nsplits  (i.e. maximum depth of\nrecursive call in ).\n\nThe number of simplices is smaller than the number of simplices in\nthe corresponding Newton polytope (counting all quadrants/octants): 4 \u00d7  36 =\n144 for sextic curves and 8 \u00d7 30 = 240 for quartic surfaces.\n\n\n\n\n      codim/dim     time     \u211a-time     simplices     max splits Harnack's sextic     1/2     1.430s     0.142s     60      8 Gudkov's sextic      1/2     15.748s     1.488s     76     27 Hilbert's sextic     1/2     26.036s     7.724s     84     23 M quartic     1/3     5.243s     0.845s     204     7 M-2 quartic     1/3     4.380s     0.639s     141     7 cubic \u2229 S     2/3     4.050s     0.280s     54     16 M-2 quartic \u2229 S     2/3     12.809s     1.304s     87     17 \n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n*Random varieties\n\nWe also performed experiments with random Polynomials for Bombieri's norm.\nThis norm is known to give more interesting topology, hence more difficult to\ncompute than with Euclidien norm. It shows the limit of the current\nimplementation: we can compute quartic hyper-surfaces up to dimension 5 in\naround 20 minutes.\n\nFor the zero dimensional case (for which much better approach exists like\nmsolve), we managed to handle in dimension 4 systems with 3 polynomials of\ndegree 2 and one of degree 3 (total degree 24) in around 8 minutes (this\ntakes less than a second with msolve).\n\nYou may find in appendix our raw measurements for random polynomials.\n\nIt is worth noticing that for all these random tests, the exact test did always\nsucceed. This is not so surprising as random\nvarieties are expected to be smooth enough.\n\n\n\n  \n*Problematic cases\n\nAs mentioned in the previous section, concentric circles (or near to parallel\ncurves) are currently problematic. We experimented with\n\n    p(x,y,t) = (x^2+y^2-(1-\u03b1)^2)(x^2+y^2-(1+\u03b1)^2)\n\n\nWe give in the table below the computing time,  number of simplices and max\nsplits as above. For a difference of radius of 2\u03b1=10^-4\nwe need far more simplices than Newton the polytope for a quartic curve 4 \u00d7 16 =\n64. This is rapidely unfeasible.\n\n\n\n2\u03b1     time     simplices     max splits1     0.083s     12     1 10^-1     0.370s     48     6 10^-2     1.793s     128     13 10^-3     20.476s     690     2010^-4     417.259s     3504     28\n\n\n\n\n\n\n\n\nplain\n\n\n\n\u00a7 TIMINGS ON RANDOM POLYNOMIALS\n\n\nHere is how to read a line in these raw results:\n[basicstyle=]\n  4, (2, 2, 2, 3) => 348.0254s [16.8249s] < 364.8503s (2 samples)\n\nYou can read from left to right:\n\n\n  * the projective dimension,\n\n  * the degree of each polynomials,\n\n  * the average time to compute a piecewise linear approximation,\n\n  * the standard deviation,\n\n  * the worst time observed and\n\n  * the number of samples.\n\n\n[basicstyle=]random.txt\n\n\n\n"}