{"entry_id": "http://arxiv.org/abs/2303.07181v1", "published": "20230313152251", "title": "Probabilistic Uncertainty-Aware Risk Spot Detector for Naturalistic Driving", "authors": ["Tim Puphal", "Malte Probst", "Julian Eggert"], "primary_category": "cs.AI", "categories": ["cs.AI"], "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilistic Uncertainty-Aware Risk Spot \n Detector for Naturalistic Driving\n    Tim Puphal, Malte Probst and Julian Eggert\n\n\n The authors are with the Honda Research Institute (HRI) Europe, Carl-Legien-Str. 30, 63073 Offenbach, Germany \n\t(e-mail: tim.puphal@honda-ri.de; malte.probst@honda-ri.de; julian.eggert@honda-ri.de) \n\n    March 30, 2023\n=========================================================================================================================================================================================================================================================\n\n\n\n\n\n\nRisk assessment is a central element for the development and validation of Autonomous Vehicles (AV). It comprises a combination of occurrence probability and severity of future critical events. \n\nTime Headway (TH) as well as Time-To-Contact (TTC) are commonly used risk metrics and have qualitative relations to occurrence probability. However, they lack theoretical derivations and additionally they are designed to only cover special types of traffic scenarios (e.g.\u00a0longitudinal following between single car pairs).\n\nIn this paper, we present a probabilistic situation risk model based on survival analysis considerations and extend it to naturally incorporate sensory, temporal and behavioral uncertainties as they arise in real-world scenarios. The resulting Risk Spot Detector (RSD) is applied and tested on naturalistic driving data of a multi-lane boulevard with several intersections, enabling the visualization of road criticality maps. Compared to TH and TTC, our approach is more selective and specific in predicting risk. RSD concentrates on driving sections of high vehicle density where large accelerations and decelerations or approaches with high velocity occur.   \n\n\n\n\n\n\nValidation of automated driving, gaussian method, survival analysis, uncertainties in normal driving, collision probability, time headway, time-to-collision, criticality maps.\n\n\n\n\n\n\n\n\n\n\u00a7 INTRODUCTION\n\n\n\nCritical events are extremely sparse in field operational tests for Autonomous Vehicles (AV). As an example, about 0.1-5 accidents happen per 1 million km on german roads <cit.>. \nIn order for an AV to have the same collision/km rate with an evidence probability of 50%, it needs to be 2 times better than the human driver on a 10 million km distance. Consequently, an unfeasible vast amount of real-world data is necessary to validate its safety <cit.>. \nSince there is no travelling without risk, AV's should additionally be able to transparently show the reasoning behind their actions. Compared to previous mobility technologies, the launch of AV's faces disproportionately high requirements. This validation trap could be circumvented with anf objective traffic situation risk measure, which allows to continuously quantify the overall driving performance.\n\n\nIn technical terms, risk is defined as the occurence probability of a loss multiplied with its consequence or severity. The consideration of the future poses thereby two challenges for risk assessment. On one hand, the involved processes which cause criticalities are inherently uncertain. AV's encounter non-linearities (behavior interaction and feedback loops), sensor inaccuracies (false positive or false negative detections), unknown environment parameters (occlusions or missing map data) as well as unobservable facts (drivers' state of mind) <cit.>.  \nOn the other hand, the variability of traffic situations leads to multiple dimensions in the probability of dangerous events:\n\n \n  * Different types of risks might arise during the scene progress. Typical risks are vehicle-to-vehicle collision, loss of control in a curve or rule violation. \n \n  * Possible subset of entities that are involved in critical events. For collision risks, this implies the pairwise consideration of traffic participants. \n \n  * For a particular risk type and subset of concerned entities, multiple evolutions of the scene (e.g. turn left, go straight, turn right or lane change) create distinct events. \n \n  * For a particular scene, a countless number of critical events can happen at various predicted states (position, velocity, acceleration, etc.). \n\n\nTraditional approaches are based e.g.\u00a0on deterministic Time Headway (TH) <cit.> and Time-To-Collision (TTC) <cit.> as the most prevalent risk indicators for AV, but do not address the listed issues.  \nFor this reason, we propose a probabilistic risk estimation method called Risk Spot Detector (RSD) that is able to evaluate general collision risks for all surrounding cars under measurement, prediction, historical and behavior uncertainties. In RSD, we combine a Gaussian method for an instantaneous collision probability with the survival analysis <cit.> to retrieve an accumulated critical event probability. The framework of RSD was presented previously in <cit.>. In this paper, we extend its functionality to account for low but existing risk in normal driving on multi-lane segments and intersections with dense traffic. The resulting performance from RSD is tested on the naturalistic dataset NGSIM (Next Generation Simulation) <cit.> to visualize experienced criticality levels on road maps. In contrast to TH and TTC, our RSD classifies different hazards in all velocity intervals more selectively and with greater precision. \n\n\n\n\nThe next Section <ref> introduces state of the art time-based, probabilistic and ex-post risk metrics. After explaining the basics of RSD in Section <ref>, we detail in Section <ref> our modeling of real-world uncertainties. Section <ref> outlines the difference in behavior extrapolation between RSD, TH as well as TTC and Section <ref> shows a comparative analysis on NGSIM to find out risky areas. In Section <ref>, we conclude with a summary and prospect for future research topics.\n\n\n\n \u00a7.\u00a7 Related Work\n\n\n\nThe major fields engaging in risk assessment and visualization are the automotive industry [4-12,14,16-18,21-22], robotics [15,19], aviation [20,23,26] plus aerospace technology [13], civil engineering [24], data science [25] and economics [27]. \n\nHereby, risk metrics frequently serve in a cost function for motion planning and find hazards on which an entity has to react. \n\nWhile TH and TTC assume and describe the remaining time to a collision event with kinematics (distance and velocity) for longitudinal traffic scenarios, Post-Encroachment Time (PET) <cit.> and 2D-TTC <cit.> generalize this notion to intersections. To even consider kinematical constraints of the acting vehicles, Time-To-Brake (TTB) and Time-To-Steer (TTS) analyze the time until an emergency brake or steering maneuver still succesfully avoids the longitudinal crash <cit.>. Because of the simple calculation and intuitive interpretation of TH and TTC, the series product assistance function Adaptive Cruise Control (ACC) controls TH and Collision Mitigation Systems (CMS) often take TTC into account. ACC has thereby been formally verified on highways to be stable and safe for several cars with distributed control <cit.>.   \n\nAlongside time-based indicators, \nprobabilistic risks are able to incorporate uncertainties in the prediction. \nGaussian methods, such as <cit.>, model predicted trajectories of moving entities with spatial normal distributions and calculate their overlap as a collision probability. \nIn the process, the Gaussian parameters can also be taken from the covariance matrix of a Kalman Filter. With this in mind, <cit.> extrapolates Constant Yaw Rate and Acceleration (CYRA) and <cit.> employs a Particle Filter with Dirac delta function as a distribution instead. \nFor vehicles, planes and satellites, it is easy to constrain their movement along fixed paths. In contrast, mobile robots and pedestrians have very variable actions in space <cit.>. To determine the common measurement uncertainties of cars, <cit.> inspected the errors in position, velocity, heading and acceleration from real sensors and found parameter values for the describing multi-modal Gaussians.\n\n\nOpposed to calculating an analytical solution for event probabilities, Monte Carlo strategies <cit.> are wide-spread in research. They approximate risks by sampling position sequences from distribution functions and comparing the number of collisions with misses. This is especially useful when the direct solution is complex, but requires high computational costs for reliable estimates. For example, <cit.> apply Monte Carlo for simulating collisions of wheeled robots with specific shapes. Similarly, <cit.> improve the convergence time by importance sampling in three-dimensional ranges of motion. \n\nIf the future behavior is known or easier to estimate, collisions can be checked discretely as well. In one work, traffic participants are projected onto map data paths and predicted longitudinally using prior knowledge (e.g.\u00a0stopping at a stop line or driving at constant velocity) <cit.>. Afterwards, a possible crash is determined with intersection checks of geometrical shapes around the assumed positions. Closely related, <cit.> detect deviations from assumed paths with a Gaussian process as well as intentions (e.g.\u00a0brake or accelerate) via Hidden Markov Models (HMM) and \n<cit.> create in the context of Dynamic Probabilistic Risk Assessment (DPRA) discrete cells in spatiotemporal state-space to backtrace faulty maneuvers or system behaviors.\n\nFinally, warning systems compare measured risk values with predefined safety thresholds in real-time to support the driver and critical situations are analyzable after they happened with ex-post scores for the purpose of e.g.\u00a0traffic flow management. \n\nApproaches in this direction include kriging techniques <cit.>, which allow to create incident heat maps by extrapolating accident ratios from road locations with data to segments where no data is available. \nSimilarly, <cit.> derive caution spots on map data from recorded driven acceleration and jerk profiles of cars, and airplane risk zones are constructed with the probability of one point colliding into another volume using the rice formula in <cit.>. Furthermore, the authors of <cit.> optimized the structure and parameters of a Bayesian network from accident data causes (weather, inattention, lane change, etc.). \n\nThe proposed Risk Spot Detector (RSD) falls into the category of probabilistic risk measures. However, RSD is grounded on a mathematical theory of sparse events. Spatial Gaussian probability distributions feed an inhomogenous Poisson process for a survival analysis. Related work employs Gaussian methods or the survival analysis separately. Aside from that, the Gaussian method is refined by modeling 2D Gaussians which have velocity-dependent growth and bent along the future path. RSD thus focuses not only on uncertainties in position, but also in velocity and predicted time of multiple interacting traffic participants. When parametrizing RSD with real data from NGSIM, we can infer plausible output thresholds for distinct criticality levels. As a result, RSD can more reliably distinguish safe from dangerous situation evolutions of multiple types and is seen as suitable for the validation of AV's.\n\n\n\n\u00a7 RISK SPOT DETECTOR\n\n\n\n\n\n \u00a7.\u00a7 Gaussian Method with Survival Analysis\n\n\n\nWe start by considering a dynamic driving situation with two traffic participants 1 and  2 at an arbitrary moment in time t. From t on, the target of RSD is to estimate the risk of a critical event that could happen at a future time t+s, that is, at a temporal distance s into the future. We assume the events to be disruptive and to have no duration. Since most of the commonly used risk measures do not address severity explicitly, we will, for simplicity, concentrate on risk as an event occurrence probability with equal severity events. Nonetheless, the approach can be extended to include different severities in a straightforward way. An indicator for risk is then the probability function P_coll(s;t,\u0394 t) that a collision will happen during an interval of size \u0394 t around t  +  s. A compact risk measure R(t) comprises, for each t, the entire accumulated expected future risk contained in P_coll(s;t,\u0394 t), during s\u2208[0,\u221e).  \n\nThe RSD framework consists of three components as pictured in Figure <ref>. In a first step, a prediction of how the situation will evolve in the future is calculated. In our notation, designating z as the state vector of a  scene, the predicted sequence of future scene states is given by z_t:t+s. \nThe prediction is thereby modeled with the help of road geometry information to constrain the paths on which vehicles can drive\nand by a longitudinal velocity model in kinematic equations, with constant velocity as the easiest model. \nIn a second step, z_t:t+s is evaluated in terms of criticality.  \n\n\n\nFor this purpose, the normalized probability densities for the respective spatial positions of two TP's indexed i=1,2 are \ndescribed by Gaussian functions \n\n\n\n    f_i(x)=1/\u221a(2\u03c0\u03c3^2_i) exp{-(x-\u03bc_i)^2/2\u03c3_i^2}\n \n\nwith the mean positions \u03bc_i and variances \u03c3^2_i.[The univariate bell curve is described, but generalizations to the bivariate case are analog.]\nA collision at a position x then occurs if both TP's coincide at the same position. Consequently, a way to quantify the likelihood \nof a collision at a common position x is f_coll(x)=f_1(x) f_2(x).\nThe probability that the first TP, driving along its trajectory, is hit by the second TP is eventually given by spatially \nintegrating f_coll(x) over all positions where the first TP can be \n\n\n    P_coll(s;t,\u0394 t)    \u223c\u222b_\u221e f_coll(x)   dx  \n     \n    = 1/\u221a(2\u03c0(\u03c3^2_1+\u03c3^2_2))    exp{-(\u03bc_2-\u03bc_1)^2/2(\u03c3^2_1+\u03c3^2_2)}.\n\n\nThe moving TP's follow a trajectory which undergoes certain variations in speed and \nheading. This accounts for mean positions through time \u03bc_i(t+s) and growing spatial variances \u03c3^2_i(t+s). For\n\u03c3^2_i(t+s), a simple Brownian motion diffusion model with constants \u03c3^2_0,i and D_i is used\n\n    \u03c3^2_i(t+s):=\u03c3^2_0,i + D_i s.\n\n\n\n\n\nIn the last step, accident occurrences are modeled as a thresholding process based on a Poisson-like event probability. \nOur inhomogeneous Poisson process is defined by a state-dependent total event rate \u03c4^-1(z_t:t+s), which characterizes the mean time between events and consists of a critical event rate \u03c4^-1_crit and an escape rate \u03c4^-1_0 (any type of influences or behavioral options that contribute to mitigate resp.\u00a0\"escape\" from critical events) \n\n    \u03c4^-1(z_t:t+s)=\u03c4^-1_0     + \u03c4^-1_crit.\n\n\nHere, we consider collision risk to be represented by the event rate \u03c4_coll^-1 for one TP pair. However, situations in which the ego car interacts with several other TP's j  and other types of risks, such as the risk of losing control in curves \u03c4^-1_curv, may be included likewise\n\n \n\n    \u03c4^-1_crit = \u2211_j  \u03c4^-1_coll,j+\u03c4^-1_curv,\n\n\n\n\n    \u03c4_coll^-1(z_t:t+s) = P_coll(s;t,\u0394 t) / \u0394 t.\n\n\nA so-called \"survival function\" indicates the probability that the vehicle will not be engaged in an event like an accident \nfrom t until t+s and is given by\n\n    S(s;t,z_t:t+s)=exp{-\u222b_o^s \u03c4^-1(z_t:t+s')   ds'}.\n\n\nCombining Eq. (<ref>) with Eq. (<ref>) as in <cit.>, one can derive a probability density for general events \n\n    p_E(s;t,z_t:t+s) = \u03c4^-1_0S(s;t,z_t:t+s)+ \u03c4^-1_critS(s;t,z_t:t+s)\n\nand obtain the overall future risk as the integral over all predicted times of the critical events only \n\n    R(t) = \u222b_0^\u221e\u03c4_crit^-1(z_t:t+s)S(s;t,z_t:t+s) ds.\n \nDue to numerical reasons, the actual temporal integration is capped with a fixed prediction horizon s_max.\n\n\n\n \u00a7.\u00a7 Uncertainties in Naturalistic Driving\n \n\n\nIn RSD, the Gaussian probability densities allow to formulate collision uncertainty as a function of spatial uncertainties \u03c3^2_i(t+s) from the involved TP's. The value of \u03c3^2_0,i quantifies measurement uncertainty and can be different for each TP. It reflects the uncertainty at the current time with s=0. For future times s>0, the parameter D_i specifies prediction uncertainty. Subsequently, the survival analysis normalizes the event probabilities related to all TP's and risk types and for the time s_E until a critical event \n\n    lim_s_E \u2192 0 R(t)\u2192 1  andlim_s_E \u2192\u221e R(t)\u2192 0\n\nholds true. A constant escape rate \u03c4^-1_0 reduces thereby S(s;t,z_t:t+s) over the predicted time and introduces an accumulating event avoidance effect (events in the more distant future are considered to a lesser extent). Similarly, if high \u03c4^-1_crit occurs early, for all times afterwards S(s;t,z_t:t+s) is diminished. RSD thus takes historical uncertainty correctly into account (future risks that arise after another critical event are further reduced).  \n\nAs shown in <cit.>, longitudinal following and intersection crash cases are detected by RSD earlier than by the Gaussian method alone or TTC (at least [1.1]sec before the critical event actually happens).[As comparison, the Gaussian method had a minimal detection time of [0.8]sec and TTC could identify only longitudinal crashes >[0.7]sec ahead.] At the same time it has a considerably lower number of false positive detections for near- and non-crash cases.[In the experiments, we used an event threshold of R(t)>0.7 for up-coming accidents. Decreasing the threshold would lead to higher sensitivity of RSD for accidents.] Nevertheless, to better quantify the predicted risks in normal TP driving, RSD needs to precisely account for further uncertainties. For this purpose, in the following Subsections <ref>, <ref> and <ref>, \nwe introduce extensions of the uncertainty models that improve RSD in three special situations: close passing of other TP's in 1. longitudinal segments, 2. when stopping in front of as well as 3. turning at intersections.\n\n \n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 2D Gaussians\n \n\n\n\n\nBecause the TP's are predicted to drive along predefined paths, we assume that \u03c3^2_i(t+s) has to be extended to 2 dimensions for handling longitudinal and lateral influences. \nIn this way, we obtain ellipses  \nspecified by an uncertainty matrix \u03a3^'_i around the mean \nposition vector \u03bc_i. \n\n    \u03bc_i = \n      [ \u03bc_x,i; \u03bc_y,i;       ],   \u03a3^'_i = \n      [ \u03c3^2_lon,i         0;         0 \u03c3^2_lat,i;           ]\n\n\n\nThe top of Figure <ref> shows the 2D Gaussians for one point in time t+s. The relative orientations to the absolute x,y-coordinate system are indicated with \u03b1_i.\n\nTo retrieve the product of the corresponding Gaussian functions \ud835\udc1f_i, the longitudinal and lateral uncertainties \u03a3^'_i have to be transformed with\n\n    \u03a3_i = \ud835\udc11\u03a3^'_i\ud835\udc11^T  and\ud835\udc11 = \n      [  cos\u03b1_i -sin\u03b1_i;  sin\u03b1_i  cos\u03b1_i;         ].\n\nEquation (<ref>) can then be rewritten in 2D to \n\n    P_coll(s;t,\u0394 t) = |2\u03c0   (\u03a3_1+\u03a3_2)|^-1/2 * \n    exp{-1/2\n    (\u03bc_2-\u03bc_1)^T(\u03a3_1   +\u03a3_2)^-1\n    (\u03bc_2-\u03bc_1)}.\n\n\nWithout incorporating the orientation of the TP's, a longitudinal scenario of two TP's passing closely with a lateral constant offset from time t_start to t_end (see bottom of Figure <ref>) has the same high risk as an intersection scenario of two TP's passing closely with 90^\u2218. By contrast, elongated 2D Gaussians rate longitudinal passing as safe. \n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Position Uncertainty by Velocity Variance\n \n\n\nOver the predicted time, \u03c3_i(t+s) grows proportionally to \u221a(s) according to Equation (<ref>). \nWe extrapolate the kinematics of the current state to retrieve trajectories, but the velocities of the TP's\nare not influencing the uncertainty prediction. After a prediction step of size \u0394 s, their longitudinal position on the path l_i\nis shifted by \u0394 l_i according to \n\n    l_i(s+\u0394 s) = l_i(s) + \u0394 l_i = l_i(s) + v_i(s) \u0394 s\n\nwith velocities v_i.[Remark: we set the current time t=[0]sec and look only at the increment in the predicted time s.]\n\nWhen we additionally assume a longitudinal velocity uncertainty according to e.g. a normal distribution with variance \u03c3_v,i=\u27e8 v_i \u27e9 c_i, the increase of spatial uncertainty is determined by the velocity uncertainty factor c_i. For a discrete step in prediction time we then get   \n\n\n\n\n\n    \u03c3_l,i(s+\u0394 s) := \u03c3_l,i(s)    + c_i v_i(s) \u0394 s, \n     \n    \n    \u03c3_l,i(s=0)    = \u03c3_0,i.\n\nHere, \n\u03c3_l,i(s) becomes essentially proportional to s.  \n\n\n\nEspecially in scenarios with extreme velocities (i.e., v_i<[5]m/sec and v_i>[15]m/sec), the previous Brownian diffusion model lead to over- or underestimation of uncertainties and thus the contained risk.\nFigure <ref> outlines the change in the width of the Gaussians 2\u03c3_l,i(s) and a waiting TP at a T-intersection while another TP is crossing during the time interval [t_start, t_end]. Although the situation can be categorized as safe, Brownian position uncertainty would lead to large risk areas around the standing green car position. To the contrary, the velocity propagation approach yields constant small \u03c3_l,i(s) for the stopped car and classifies this situation as non-critical.\n\n \n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Path-following Mixture Model\n\n\n\nLarge \u03c3_i(t+s) at prediction times s\u226b0 might unintentionally cover opposite lanes \nwhen a TP is turning. Therefore, we include geometry-sensitive Path-following Mixture Models (PMM) allowing curved Gaussian shapes for position uncertainties <cit.>. \n\nFirst, we split the Gaussian with 2\u03c3_i into N smaller Gaussians of 2\u03c3_i,k as drawn in the upper half of Figure <ref>. The smaller Gaussian components at \u03bc_i,k are spread to the right and left from \u03bc_i, while intersecting close to their Full Width at Half Maximum 812 FWHM value.[At the same time, we require one element with \u03bc_i,k=\u03bc_i and thus an uneven number N.] The composition heuristics are summarized by\n\n    \u03c3_i,k = m_f 812 FWHM/N\u03c3_i,\n\n\n\n\n    \u03bc_i,k = \u03bc_i + 2k/m_f812 FWHM\u03c3_i,k\n     with k=0   ,...,\u00b1N-1/2 and 812  FWHM=2\u221a(2ln2).\n\nThe constant m_f ensures that the constructed PMM does not contain additional local minima and that it has a smooth shape.[For m_f>1, the mixture components get closer to each other and have higher \u03c3_i,k.] \n\nAt last, each function of the component f_i,k is summed up and weighted with the factor w_i,k to reduce the deviation from the former Gaussian f_i, which leads to\n\n\n    w_i,k = f_i(\u03bc_i,k) f_i(\u03bc_i)/\u2211_k f_i(\u03bc_i,k) f_i,k(\u03bc_i),\n\n\n    f_pmm,i(x) = \u2211_k w_i,kf_i,k(x).\n\n\nIn w_i,k, the collective peaks of the components \u2211_k f_i,k(\u03bc_i,k) are scaled to match the desired original heights f_i(\u03bc_i,k). \nOur PMM composition heuristics achieves similar reconstruction errors as parameter optimization approaches for f_pmm,i(x) and N>13, however providing a fast and direct calculation. \n\nIn the lower half of Figure <ref>, one TP takes a sharp curve and another TP crosses the intersection. During the situation occuring from t_start until t_end, the resulting phantom risks from the elongated Gaussians are avoided with the PMM. \n\n\n\n\u00a7 BEHAVIOR EXTRAPOLATION\n\n\nFor longitudinal collisions, Time Headway (TH) or Time-To-Collision (TTC) are able to quantify risks in terms of (inverse) time until a critical event happens. In this Section, we describe their underlying formulas and describe how the properties of RSD can be used to cover risks in more general terms and in particular to integrate the prediction assumptions from both TH and TTC.\n\n\n\n\n \u00a7.\u00a7 TH and TTC\n\nWhile an ego vehicle is driving with longitudinal velocity v_1 along a path and following another vehicle, TH <cit.> describes the time until the ego car travels from the current longitudinal position l_1 to the current longitudinal position of the other car l_2 according to[Here, index i=1 always denotes the ego car and i=2 the next car in front.]\n\n    TH = -\u0394 l/v_1 with \u0394 l = l_1 - l_2.\n\n\nThe average human reaction time lies around t_r \u2248[1]sec <cit.>. By keeping TH > t_r, once the other entity brakes at l_2, the ego entity has some time left to apply an appropriate deceleration to mitigate or even avoid a collision. \n\n\n\nTH can be seen as a risk measure. Its inverse 1/TH is assumed to correlate with the collision probability given that the follower drives with constant v_1 in combination with the front vehicle suddenly stopping at l_2. By contrast, TTC <cit.> assumes that both cars continue driving with constant longitudinal velocities v_1 and v_2 and calculates the time until a collision occurs when l_1=l_2,\n\n\n    TTC = -\u0394 l/\u0394 v, whereby \u0394 v = v_1 - v_2.\n\n\nThe left and middle part of Figure <ref> visualize the longitudinal car following scenario and the designated collision points in TH and TTC.\nFor forward driving, a valid TTC only exists for -\u0394 l>0 and \u0394 v >0. In this case, v_1 >\u0394 v holds so that TH always overestimates potential risks as compared to TTC (i.e., 1/TH>1/TTC). \n\n\n\n\n\n\n \u00a7.\u00a7 Behavior Uncertainty\n\n\n\nTH and TTC approximate the critical event probabilities based on the point of maximal criticality by deriving one collision time with simple kinematic equations. If the hypothetical accident does not occur as for non-longitudinal scenarios, there is no risk at all. Some attempts have been made to make TTC more flexible with e.g. extrapolating constant deceleration for the obstacle <cit.>. Analogously, the required longitudinal acceleration of the follower can be compared with its maximal possible value to calculate Brake Threat Numbers (BTN) <cit.>. \n\n\nNevertheless, RSD has the beneficial property of estimating a continuous, differential, probabilistic risk along the entire future predicted time, see Eq.\u00a0(<ref>). Furthermore, it is valid independently of the predicted behavior and thus can be used with the same prediction assumptions from TH or TTC, but also for completely arbitrary paths and velocity profiles.\nWith RSD, the velocity-dependent position uncertainty \u03c3_l,i(s) allows to systematically incorporate behavior uncertainty. For constant velocity assumptions, this results in the front part of the probability densities being fed by acceleration and the back part by deceleration behaviors. The middle of the probability densities around \u03bc_i constitutes constant average velocity. \n\n \n\n\n\nWe set s_max= [12]sec and \u03c4^-1_0= [3]sec to be capable of incorporating other TP's at least TH<[5]sec far away. Then, the motion planner Risk Optimization Method (ROPT) <cit.> was employed to parametrize \u03c3_0,i and c_i. ROPT utilizes RSD in a cost function to find safe behaviors through traffic. For longitudinal and intersection scenarios, we ran sanity checks whether ROPT holds reasonable distance thresholds to other TP's in various v_i settings. Increasing c_i lets ROPT keep longer distances. In addition, we looked at typical accelerations at s=0 plus velocity changes after s=[3]sec in NGSIM and fitted their standard deviations to c_i. In both procedures, we obtained 6\u03c3_0,i=[4]m as the average TP length[Equations (<ref>) and (<ref>) are both extended to consider the car sizes by changing \u0394 l to \u0394 l^* = \u0394 l + [4]m.]\nand c_i=0.1.\n\nThe length increase of the Gaussians over the predicted time differ according to v_i(s). In the example of Figure <ref> (see right part), the velocity of the follower v_1 is larger than v_2 of the front TP. In other words, the ellipses grow for TP1 while staying nearly constant for TP2. \nWe found that the fitted parameter setting covers the average behavior uncertainty of normal NGSIM driving statistics well, resulting in a mixture of the sudden stop assumption from TH and the constant velocity prediction from TTC. \n\nIn the RSD formalism, positional uncertainties between TP's are not explicitly correlated. Aside from this, the constant velocity prediction suggests unawareness of the TP's from each other. However, the risk calculation incorporates a mutual influence in TP's by the spread of the Gaussian velocity distributions and thus assuming that vehicles can take on velocities that deviate from constant velocity (e.g. a follower that accelerates onto an obstacle in front that brakes and vice versa). Furthermore, since RSD is agnostic to the type of predicted trajectories, additional interactions can be incorporated by modeling particular motion patterns. \n\n\n\n\n\n\n\n\u00a7 SIMULATIONS\n\n\n\n\n \u00a7.\u00a7 Lankershim Boulevard\n\n\n\nThe NGSIM dataset <cit.> consists of 5 traffic study areas in the US, in which cameras are mounted on high buildings. With computer vision techniques, the positions of all vehicles were detected with an accuracy of (\u0394 x=[0.6]m, \u0394 y =[1.2]m). \nIn particular, Lankershim Boulevard is suitable for testing the robustness of RSD. It has multiple intersections (4 with traffic lights, 2 with priority), wide and narrow road structures (2, 3 and 4 lanes), inner-city and highway stretches (velocities in the range v = [0-20]m/sec), a long curve (making up 20 % of the total section) and dense traffic (1000 vehicles in 15 minutes). As 96 % of the TP's are cars, it is reasonable to neglect the particular masses and sizes (3.5 % trucks plus buses and 0.2 % motor bikes). \n\nFor the risk analysis, we first loaded and normalized the trajectories <cit.>. By employing an exponential moving average filter forwards and backwards\n\n, we afterwards separately smoothed the positions p, velocities v and accelerations a. Both v and a are gained by differentiation from p, which results in additional noise. Consequently, we set different smoothing widths T_p=[10]sec, T_v=[20]sec and T_a=[80]sec to compensate the effect <cit.>. As a next step, we successively assumed each car to take the role of an ego car and extracted all other cars in the same time interval. \nIn the simulation, we eventually took the real driven position sequence as paths for the trajectory prediction of RSD, TH plus TTC. \nIn this way, we already know in advance the intentions of the cars (e.g. lateral lane changes or turn at intersection). Because of fixed velocity extrapolations (i.e., constant velocity or sudden stop), their longitudinal behavior is however assumed to be unknown. Risks can only come from wrongly applied velocities of the cars along their paths.\n\n\n\nFigure <ref> shows the resulting probability mass function pmf and cumulative distribution function cdf with a histogram representation for the occurring v and a as well as distances -\u0394 l and relative velocities \u0394 v to the front vehicle.[Looking exemplarily at the histogram for v, pmf represents the share of data points within an interval of [1]m/sec and cdf is the successive, accumulative sum of pmf values from left to right.] \nMore than 25% of the time, the vehicles stand in traffic or in front of an intersection. The velocity distribution is bimodal, with a high peak at v\u2248[0]m/sec and a broader peak around v=[12]m/sec. Overall, vehicles do not excessively brake or accelerate. The acceleration distribution has its mean at \u03bc_a=[0]m/sec^2 with a deviation of \u03c3_a=[0.4]m/sec^2. When there is a front vehicle, most -\u0394 l lie around \u03bc_\u0394 l=[5]m of a possible log-normal distribution. Only 5% have lower values than \u03bc_\u0394 l and these happen at small v. In contrast, \u0394 v correspond to a logarithmic distribution with \u03bc_\u0394 v=[1]m/sec, whereby big \u0394 v take place in any interval of v. \n\n \n\n \n\n\n\n \u00a7.\u00a7 Results\n\nIn the following, we analyze the qualititave and quantitative differences between the risk measures based on RSD, TH and TTC. The experimental goal is to reason about which driving behaviors may create potential fatal outcomes and to find the corresponding street areas on which they likely appear. For this purpose, we define four criticality bins (dangerous, offensive, uncomfortable, noticeable) and set them for TH accordingly to b_1=[[0]sec, [0.5]sec], b_2=[[0.5]sec, [1]sec], b_3=[[1]sec, [2]sec] and b_4=[[2]sec, [4]sec].[As references, in ACC the minimal TH is [1]sec and the maximal [3]sec. Furthermore, TH=[2]sec is recommended on US highways.] \nThe bins are colored red, yellow, cyan and blue and every calculated TH value of the NGSIM trajectories with discretization of \u0394 t =[0.1]s is sorted into them.[Approximately 40% of the data points are in the bins, the rest 60% reflect safe behaviors with no noticeable risk at all.] For RSD and TTC, we then fill the bins consecutively with the most to least hazardous events until they contain the same amount of events as for TH. The boundaries of the bins arise automatically from the corresponding first and last data points sorted into each bin. \nEventually, we create criticality maps plotting the most riskful color of RSD, TH and TTC at each road point and analyze the velocity distributions in their bins. \n\n \n\nThe outcome for TH is depicted in Figure <ref>. TH classifies dangerous and offensive risks at velocity intervals around a Gaussian with \u03bc_TH=[12]m/sec and \u03c3_TH=[2.5]m/sec. When the ego car is following another car with high v and relatively low |\u0394 l|, the sudden stop prediction causes strong worst cases. These situations are located mostly on the top right curvy segment. Moreover, uncomfortable and noticeable TH appear also for interplays of an ego car braking from moderate v approaching another car waiting close to an intersection. Due to the discontinuity of Equation (<ref>), TH cannot evaluate risks for v\u21920. \n\n \n\nNote the difference in the boundaries of the last two bins to TTC in Figure <ref>. RSD is capable of having low but existent risk values, while TTC cannot distinguish all tailgaiting incidents from safe behaviors.\n\nNow we concentrate on TTC, which depends on \u0394 v. \nMainly for approaching the lowest large intersection (East=[70]m,North=[120]m) with big \u0394 v, TTC detects risks in the red and yellow bins (see Figure <ref>). Their boundaries lie at b_1,TTC=[[0]sec, [2.15]sec] and b_2,TTC=[[2.15]sec, [5.76]sec] in the common warning intervals of [1-5]sec for CMS. Alongside the logistic distribution of \u03bc_TTC=[3]m/sec and \u03c3_TTC=[3]m/sec, the cyan bin includes the critical car following scenario of TH. But since b_3,TTC=[[5.76]sec, \u221e], the data points are\ntoo few. TTC cannot extract car following incidents with small distances, since \u0394 v \u2248 0 in these cases. On that account, the last blue bin includes arbitrary v in NGSIM. This can be seen by comparing the distribution shape of the last blue bin with the overall  of v from Figure <ref>.\n\n\n\nWhereas TH and TTC only capture frontal longitudinal collision risks, RSD is able to capture all possible collision risks. However for a fair comparison, RSD is initally applied solely on the front TP. The same parametrization of \u03c3_0,i and c_i from Section <ref> is set for both the ego vehicle and other TP. As R is normalized to [0,1] and represents a probability, the first bin in Figure <ref> starts with R=1 and the last ends with R\u22480. The thresholds are as follows:\nb_1,RSD=[1, 0.39], b_2,RSD=[0.39, 0.17], b_3,RSD=[0.17, 0.01] and b_4,RSD=[0.01, 0.002\u00b710^-4]. \nTo be compatible with TTC, we base the RSD on a constant velocity prediction. Also similarly to TTC, RSD sorts risk zones around intersections from existent \u0394 v in combination with decreasing |\u0394 l| at \u03bc_RSD,1=[4]m/sec into b_1,RSD and b_2,RSD. In addition, RSD incorporates acceleration and deceleration behavior from the velocity uncertainty. A distribution shape similar to TH appears with \u03bc_RSD,2=[12]m/sec in b_3,RSD and b_4,RSD. With large c_i, the abrupt stop prediction from TH can also be incorporated into RSD. This would shift the critical following incidents to b_1,RSD and b_2,RSD as well as the intersection approaching to b_3,RSD and b_4,RSD. In general, constant velocity is however statistically more realistic (refer to \u03bc_a=[0]m/sec^2 in Section <ref>). \n\n \n\n\n\n\n\n\n  \u00a7.\u00a7.\u00a7 Traffic Situation Risk\n\nWe discovered that TH is able to filter larger amounts of critical points than TTC into the bins, but arranges risks in a different order of criticality levels. Besides that, TTC is not precise for the uncomfortable and noticeable bins. RSD can label the existing two types of risk causes into reasonable criticalities. To evaluate \ncomplete traffic situation risk, we considered in RSD all other TP's within a sensor range of r=[50]m. Figure <ref> shows that RSD filters out correctly the critical TP's on the same path in the front and back. No errors emerge from passing TP's during straight driving \nand turning at intersections. The criticality map has analogous hazard zones at the curve segment (East=[180]m,North=[400]m). This is achieved with elliptic 2D Gaussians that bend along the curve when using the PMM. \n\nRemarkably, the red and yellow risk spots in the proximity of intersections are more localized. Overall, we observe that RSD is more selective and has less false positives than the other risk indicators. Since the criticality maps always display the highest detected risk at each spot, and since by construction the same total number of incidents per bin appear in all criticality maps, a smaller area covered by red spots implies that many cases fall onto a single spot. In that sense, the RSD criticality map taking all surrounding cars into consideration is the most specific one in terms of risk localization. A normal distribution around \u03bc_RSD,3=[0]m/sec with \u03c3_RSD,3=[0.5]m/sec is observable. RSD rates risks as most critical in b^*_1,RSD=[1, 0.51] when standing in traffic jam with TP's to the sides and in front, while another TP comes from the back with large -\u0394 v. In the other three bins b^*_2,RSD=[0.51,0.29], b^*_3,RSD=[0.29,0.11] and b^*_4,RSD=[0.11,0.03] this relation is carried on and increases the respective boundary values compared to b_2,RSD, b_3,RSD and b_4,RSD. It describes the generic notion of higher collision probabilities for denser traffic. In b^*_2,RSD the akin TTC and in b^*_3,RSD plus b^*_4,RSD TH distribution are superposed as in mixture distributions.\n\n\n\n\n\n\u00a7 CONCLUSION AND OUTLOOK\n\n\n\nIn this work, we introduced RSD as a new and generalizing risk metric for the criticality assessment of dense and complex traffic situations in real-world operating conditions. For each considered vehicle, RSD first extrapolates kinematic trajectories and finds the overlap between spatial Gaussian distributions to arrive at continuous collision probabilities over future time points. These are then integrated and normalized within an inhomogenous Poisson process of the survival analysis. We improved the robustness of RSD for naturalistic driving with several extensions comprising 2D Gaussians of positional uncertainties (relevant during longitudinal passing), velocity uncertainty (notable e.g.\u00a0while waiting at intersections) and the PMM method (for normal distributions that follow sharp curves).\n\nTH and TTC assume a vehicle-to-vehicle crash and characterize the time to the event with different predictions. For TTC the other vehicle has constant speed, whereas TH acts as if it would come to an abrupt halt. In both TH and TTC, the ego vehicle is assumed to continue driving with constant velocity.  \nWith this in mind, we optimized the velocity uncertainty parameters in RSD so that both the TH and the TTC cases can be incorporated. The parametrization is additionally chosen to comply with sanity rules in car following plus intersection crossing and matched to the statistics in kinematics of the analyzed data. \n\nAn application on NGSIM revealed that RSD is able to differentiate different hazard categories: 1. dynamic stop and go in heavy traffic, 2. approaching with moderate velocity standing front car, and 3. keeping low distance with high speed to the other car. To the contrary, TH as well as TTC are not able to extract the points on the criticality map to the same extent, but rather cover special cases. There are no intense accelerations and accidents in NGSIM. The detected risks of RSD are potential/hypothetical and the scenario always evolved in a way that the cars avoided the criticality. In other words, RSD filters fundamental situations which represent causes for frequent crashes. \n\nThe framework of RSD allows to include not only collision probabilities, but any other type of risk when explicitly modeled (such as disobeying traffic rules, driving off curves or neglecting occlusions). With the help of the survival analysis, RSD steadily outputs a scalar value containing the overall future accident risk of the driving scene at the current time. For this reason, RSD shows to be promising as a standard traffic risk indicator for the validation of AV's. Recording RSD over longer periods in AV's, the driving strategies and errors become ratable and analyzable more easily. To further verify RSD, the criticality map should moreover be compared with heat maps from real accidents for a specific traffic study. Once proven alike, road and traffic sign layouts can be designed to avoid risk spots and to minimize the actual emergence of conflicts.\n\nBehavior planning systems, such as ROPT, balance risk against utility of the travel (i.e., the needed time to arrive at the goal). Since risks with high traffic density are existent, paths which avoid coming close to other cars are automatically preferred. In future work, the averaged risk values at each point of the criticality map could be beneficial as zone risk priors. Consequently, ROPT would even steer slowly through intersections with high risk priors and accelerate in safe segments with low priors. This would correspond to an experienced human driver during his daily commutes. \nAt last, a navigation system based on RSD might find routes that are short in distance and low in overall critical event rates. An included ex-post analysis based on RSD and the actually driven trajectories can be calculated in a straightforward way and would make the users' propensity to risk analyzable for each run.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a7 ACKNOWLEDGMENT\n\nThis work has been supported by the European Unions Horizon 2020 project VI-DAS, under the grant agreement number 690772.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIEEEtran\n\n\n\n\n\n\n\n\n"}